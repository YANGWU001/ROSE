[
  {
    "prompt": "\n\nHuman: Is there a term, or process, for being able to broach discussion about a social subject in a way that is inclusive and acknowledging of the complexity and even contradictory components that fall within the subject? Please forgive the amateur attempt to articulate this.   Say Person A is supportive of a movement, lets say Revolutionary Feudalism, and makes a statement to that effect, almost immediately there will be Person B with \"Yes, But\" and a list of examples of where the cause creates negative outcomes.   Both are true. One will be 'more right' than the other if we could weigh every sub-argument objectively, but that's a lot of rabbit holes, and it doesn't invalidate the contrary truths that do exist within the shadow of the main subject at hand.   And we find i think in order to protect the important point from being diminished that we are tempted to sail close to a kind of 'no true scotsman' approach via omission - arguing only for the strengths of the position and ignoring or downplaying the importance of counter-arguments.   either the discussions are approached with: 1) All broad generalized statements are immediately followed with caveats acknowledging likely  contrarian positions or 2) both parties are agreed ahead of time for the sake of simplicity not to pursue contrarian points on statements that are broadly true.  not sure where to post - perhaps i should be over in a /r/debate ?\n\nAssistant:",
    "golden_answer": " Dialectic might be a good place to look.  It's a different manner of conversation/dialogue that could be said to stand in contrast with debate and polemic, where those focus on contrasting strengths of opposing perspectives and attacking those who hold the opposing perspectives, respectively.  Dialectic focuses on establishing mutual truths and commonality between the interlocutors, which definitely seems to fall in line with what you're talking about."
  },
  {
    "prompt": "\n\nHuman: Should we be worried about the student debt bubble?  There is a lot of info out there that implies that higher education costs and debts are getting to the point where they are (or ought to be) a public policy concern. For one, the Washington Post today said that student debt in the US is now over $1 trillion, default percentages are rising, but a college degree is ostensibly less valuable now than ever. What seems like the biggest concern is that you can't go bankrupt from student loans, which is great for banks, horrible for debtors. [More can be said here, but I'll avoid the block o' text and let the discussion happen below.]   But despite all I've read that says its bad, I haven't come across anything that explicitly suggests that it will cause the sort of catastrophic damage to the economy that the housing bubble did or even the dot com bubble. What's going on here? And how worried should we be?\n\nAssistant:",
    "golden_answer": " There's very little evidence that there is a student loan bubble - and in fact, it doesn't even make sense in theory.   1. A bubble is a term with a specific meaning - \"Bubbles refer to asset prices that exceed an asset's fundamental value because current owners believe they can resell the asset at an even higher price. \". There is no mechanism for which this can work in the education market. 2. The last 30 years have been characterized by a huge increase in the college wage premium. In 1979, a college educated worker made 35% more than an HS graduate on average, by 1999, they would be making 80% more. The Race Between Education and Technology is a great overview of this. A college education is still a really good investment. This isn't because of selection effects - see The Caual Effect of Education on Earnings. 3. Virtually no one pays market price for a college education. The financial aid process allows universities to practice almost-perfect price discrimination. They can effectively charge a different price for every student, so that the market just follows the demand curve up until their maximum tuition level. 4. The is definitely is a sheepskin effect - http://en.wikipedia.org/wiki/Signalling_(economics)#A_basic_job-market_signalling_model - for college diplomas. But this is extremely well understood (Spence shared the economics Nobel with Akerlof for signalling theory). I think that separating bright, talented and hard working 18 year olds from bright, talented and lazy 18 year olds is a non-trivial process.  5. Tons of articles imply that you don't need higher education, because you can take classes online. If this was the case, why did the university lecture have survived the invention of the printing press? Books reduced the cost to the diffusion of knowledge far more than the internet did, without ending the university system. This implies that there is something else going on to me."
  },
  {
    "prompt": "\n\nHuman: Is this Tumblr post accurate in claiming that if Walmart paid its employees a living wage, the family that owns it would have to take an 2% cut to their yearly profits, meaning they’d make only 294 million a year instead of 300 million a year? https://www.reddit.com/r/tumblr/comments/ihgn6s/if_walmart_paid_its_employees_a_living_wage_the/  Is this Tumblr post accurate in claiming that if Walmart paid its employees a living wage, the family that owns it would have to take an 2% cut to their yearly profits, meaning they’d make only 294 million a year instead of 300 million a year?   https://www.youtube.com/watch?v=vAcaeLmybCY  This is the video linked in the post.   It defines living wage as enough no longer qualifying for food stamps.   It says that to do this, Walmart would have to raise prices by about 1.4%.   It says it's based on data analysis by researchers and statisticians at the UC Berkeley Center for Labor Research and Education, but the link is broken.\n\nAssistant:",
    "golden_answer": " > It says it's based on data analysis by researchers and statisticians at the UC Berkeley Center for Labor Research and Education, but the link is broken.  Without comment on the substance of the issue, from this reference the relevant study appears to date from 2007: \"Living Wage Policies and Wal-Mart: How a Higher Wage Standard Would Impact Wal-Mart Workers and Shoppers\" by Arindrajit Dube, Ken Jacobs, Dave Graham-Squire, and Stephanie Luce."
  },
  {
    "prompt": "\n\nHuman: Why are \"gay meccas\" usually larger cities, while \"lesbian meccas\" are usually smaller towns? (In the United States, at least.)\n\nAssistant:",
    "golden_answer": " Here's an Autostraddle article entitled \"Where Do the Lesbians Live?\".  Essentially;  * lesbians are more likely to start families, which is easier/cheaper in rural areas * the inevitable gentrification of gay meccas tends to force out lesbians before it ousts gay men because of systematic factors such as the wage gap * historical associations with butch identities has a tendency to tie lesbians to rural/farming areas and rural women/lesbian communes and farming cooperatives are very popular in the community    > “Lesbian couples are more likely than gay ones to live in rural areas, in part because they seek different things from their hometowns,” Francie Diep writes in The Geography of Queer Folks, summarizing Lisa Wade’s conclusions. “For example, lesbian couples are much more likely than gay couples to be raising children, the costs of which might be lower outside of cities.” This is perhaps consistent with a recent survey that showed most same-sex couples raising children are doing so in the South. Or, as Lisa Wade summed up one theory on why lesbians might be more comfortable in the rural south than gay men: “If being “butch” is normative for people living in rural environments, lesbians who perform masculinity might fit in better than gay men who don’t.” There’s also a strong tradition of rural lesbian communes and rural queer women’s lands, which continues today."
  },
  {
    "prompt": "\n\nHuman: How do the Swiss maintain cohesion when they have so many referendums? I ask because I saw how divisive the Scottish secession campaign ended up and I'm starting to see the same with the EU referendum campaign here in the UK at the moment.  Do the Swiss go through the same kind of social trauma or do they take a different approach? Does having so many referendums moderate how people debate and behave in public environments?\n\nAssistant:",
    "golden_answer": " I am a student of political science and swiss.  First I tried to find some relevant sources, concerning cohesion and  referendums, which failed. People usually don't really link the two.  Are the two things comparable?  Switzerland votes very often, alone last sunday there were two referendums and three initiatives (changes of the constitution initiated by collecting signatures ). And the some of the votes are really not very important topics, for example about the change of the value added tax for restaurants. Also important to note: Switzerland has this referendums since over 100 years, the people are used to it.  *^(\"The referendum: direct democracy in Switzerland -              KW Kobach - 1993\")*  On the other hand in Scotland there are usually no Referendum. The topic they voted about is probably one of the most important vote you can make as a region. So you would expect it to be very polarizing.   If we look at a very important vote in Switzerland, which might be the closest to the importance of the Scottish referendum, are the ones concerning relations to the EU. These votes too are very polarizing and cause huge discussions long after they happened.   A good example is the vote about joining the EEA (European Economic Area) in 1992. The vote was really close and showed huge divides in the population and also between the different language regions. There is still discussion today about this vote, due to change in EU relations.  ^(^20 ^Jahre ^EWR-Volksabstimmung: ^Was ^haben ^wir ^damals ^entschieden? ^- ^Claude ^Longchamp ^, ^gfs )  Also the trauma you are talking about. One I am not sure if you might overrate it. And I don't think that just applies to referendums. Just look at the US elections now.  To answer your question: It isn't really the referendum which polarizes society, but the gravity of the question asked. Additionally it might be that Switzerland is just used to having referendums and adapted its behavior."
  },
  {
    "prompt": "\n\nHuman: What keeps so many people from internalizing sociology and psychology? No matter if you go politically left or right, people always seem to not be able to really grasp the consequences of psychological/sociological imagination.  They always think they know the basics and agree with those disciplines on a shallow level, but then go into tangents that show how they do not really see social or personal phenomena through the lens of those sciences. It often means they will switch to antiscientific, hyper-individualist perspective (regardless if they are talking about nationalism or gender identity) and shut you off.  Is there any literature on the topic? Some comparisons between societies or countries? Or maybe even essays by famous sociologists or psychologists on the popular \"understanding\" of their disciplines?\n\nAssistant:",
    "golden_answer": " This is a great question that I have thought about a million times. I have actually spent a lot of time trying to find a book on it, but I have not come across one that is *specifically* about Sociology or Psychology.   I first started to think about this when I was getting my masters degree (in Sociology). Often times I was super excited to share the things I would learn with my family and friends, and how the things I was (and still am) learning are often in contradiction to the things I was told/learned growing up. For context, I'm a white girl who grew up in an upper-middle class politically conservative suburb in a large city with successful parents, and I was always given everything I wanted/needed. I considered myself a Christian and I told people that I was a republican (although I knew nothing about politics and was just identifying with my parents).   Then I started studying Soci and my entire perspective on the world changed. It opened my eyes and forced me to look beyond my tunnel vision of society. It was really hard at times to come to terms with things that I thought I already understood, especially social issues that I had never thought about before or issues that had always been presented to me in a one-sided, biased manner.  A good example of this is the trope of the Welfare Queen. I was told that poor people, esp. poor black people, were moochers and only wanted handouts because they were lazy and didn't want to get a job. Of course, I learned that the Welfare Queen (and welfare \"fraud\") is a myth that was promulgated by Ronald Regan in order to stigmatize people in poverty so that he could convince Americans that rolling back the social safety net was justified because it was only being used by poor black (read: undeserving) citizens. The truth is that most people on welfare *do* have jobs (i.e. the 'working poor'). Also, the welfare reforms of 1996 created a 5-year maximum lifetime cap on benefits so that welfare \"cheaters\" (which did not exist anywhere near the level that we're often told) were literally unable to collect benefits for life (also, contrary to popular opinion, women do not have more babies to get more benefits. In fact, if a woman has a child *while* receiving benefits, she and her family will be removed from the rolls). Welfare is probably one of the least understood/mischaracterized social issue in American society.   Science in general is often met with the sting of anti-intellectualism, which is part of the answer to your question. However, I think *social* science in particular gets it worse than the 'natural' sciences like Biology and Chemistry. I used to say that it was because people were generally more suspect of social sciences, but I think it's more than that. People like to dismiss facts about social issues that they don't agree with or have a different view on because it's much easier to disagree that we live in a post-racial society (we don't) than it is to disagree on the functions of bodily organs. People also tend to conflate their individual life experiences with overall reality (i.e. \"well, i've never experienced blank] so it must not be true or its exaggerated\" or \"well, I know someone who is [blank] but [blank] doesn't happen to them\"). You get what I am saying here? Most people don't question or critically think about social norms or commonsense 'truths' because these 'truths' are so embedded in our milieu that its hard to imagine otherwise. So instead of thinking critically, people dismiss sociological knowledge as either \"elitist\" or \"not real science\" so that they can remain undisturbed in their own little worlds.   Once I saw a question on r/askreddit that asked what the slogan of your college major or job would be. I would say, \"Sociology: reminding people of uncomfortable truths since 1838\" or \"Sociology: everything you were taught about society was a big lie\" lol.   I'm sorry I can't find any literature for you, but I can recommend these instead:   [Anti-Intellectualism in American Life   The Death of Expertise: The Campaign Against Established Knowledge and Why it Matters."
  },
  {
    "prompt": "\n\nHuman: What do trained economists think about trickle-down economics? Why? I did some google searching and could find very little that wasn't deeply politically charged.  What does the economics field think of trickle-down economics?\n\nAssistant:",
    "golden_answer": " Trickle-down economics isn't really a thing in economics. It is a political quip used to discredit people. The idea is basically a corruption of supply-side economics, which again isn't exactly what I'd call a \"field\" of economics, but whatever. If you are going to do any searching, I'd use that phrase instead though.   One of the \"controversial\" ideas is that cutting taxes will spur economic growth to the point that the government will collect more revenue even with the lower tax rate. I don't know of any empirical evidence supporting it, though it seems theoretically plausible. The Laffer Curve deals with this, though most people use it in the context that *raising* taxes may *lower* tax revenue.   I think most economists would agree that in general, assuming just a regular market in equilibrium, cutting taxes would increase growth and that growth is generally good. But one must differentiate between the idea of a permanent tax cut and a temporary tax cut. According to Milton Friedman's Permanent Income Hypothesis, consumers will not respond very much to what they perceive as a temporary change in income, i.e., a temporary tax cut will do little to stimulate an economy because consumers expect the taxes to rise again and they'd eventually have to pay more taxes to make up for the deficit. This is, of course, just a hypothesis.   I'd say this is a thorough write-up on the topic that I found on Google.  EDIT:: Changed the wording of whether or not the Laffer Curve has empirical evidence so it doesn't sound like there is none, just that I don't know if there is any."
  },
  {
    "prompt": "\n\nHuman: Can someone explain contemporary race laws and race-based policies in North America (USA and Canada), such as affirmative action and tax exemption for native Americans? Why are these laws not considered racist/discriminatory? (Not intended to be inflammatory, respectful discussion please) I'm not sure if this is the right subreddit, so please shoot me down if I'm ruining your wonderful sub (although if you could point me in the right direction first, I'd greatly appreciate it).  My question is not intended to be racist or inflammatory, and at the risk of sounding condescending I'd like to plead for discussion to be civil and for upvotes etc. to be alloted by reason rather than emotion. I'd also like to clarify that I am not North American, but recently visited a relative of mine in Canada and learnt, in broad strokes, about the race laws there. I'd like to share the experience as it adds context to my question; feel free to skip to the end to see my question on its own.  I visited my cousin when he got married in Toronto. He's white and Irish (1st gen immigrant), and his girlfriend is also white, originally from the Ukraine. They had lived there for about 10 years. She worked as a teacher on a Native American (or American Indian, I'm afraid I don't know what term is appropriate, apologies if I cause offense) reservation (I think she used a better name for it, apologies again). I was quite surprised by many things I learnt. According to her, many people in the native community are exempt from various taxes, and receive free education up to and including University (unlike other Canadians in that prefecture), and also benefit from various other favoritist policies based on race. However, to qualify for the full benefits (which could include ownership of land), you had to be at least n% American Indian - if your bloodline was too watered down, you no longer qualified.  I was quite surprised by this, because it didn't seem fair at all. First of all, there's something a bit grim about your birth (and your % indigenous blood) determining your relationship to the state etc.; I like to think that in a developed country, the law, rights, and duties should apply to all equally regardless of race. I was also distressed by my relative's reaction to my surprise. They reasoned that since they were white, it was fair - they'd oppressed the Indians in their own day, and it was time to pay reparations. However, this argument didn't make sense to me. First of all, many taxpayers (who are footing the bill for indigenous privilege) are non-white. They might be Japanese Canadians, who were hideously mistreated very recently, or just recent immigrants from China or Bangladesh who've never done anything wrong to the indigenous people. I also pointed out that a Ukrainian and an Irishman have also probably done nothing wrong (historically speaking) - heck, almost no-one suffered so much at the hands of the British as the Irish, and Ukraine hasn't exactly had a fun 150 years either. Finally, I pointed out that really, guilt shouldn't be inherited, and race laws don't really have a place in a first world country.  My relatives reaction is what surprised me the most, and what lead me to ask this question. They became very defensive and actually angry at me. I honestly felt as if they'd been brainwashed. I must admit, I don't understand the Canadian educational system at all, but it seems like it's trying to make people feel guilt - or worse, actually BE guilty - of crimes they have not committed. What is also strange is that they objected to my use of the term 'race law' in reference to laws which specifically stipulate different treatment by the law based on race.  I am given to understand that the USA has similar policies, for instance permitting Native Americans to circumvent various state and federal laws, again based on bloodline (Casinos spring to mind).  I was surprised to discover that Canada and the USA have different legal treatment for different races, and I have the impression that mainstream society doesn't question this much. Am I correct in that impression? What is the discussion in the field of social science of the validity of having 'preferred' races, 'tax exempt' races, etc.? Doesn't serious social science frown upon 'race' as a construct anyway, and if so, why hasn't that attitude permeated society as a whole? Finally, is opposing such policies considered racist?  TL;DR: Explain race laws in Canada and the USA, affirmative action, and social attitudes towards the same; please remain civil! (although obviously if you think I'm a monstrous racist, please tell me! I'm moving to the USA soon and want to be careful not to offend anyone in that country.)  PS: apologies for grammar problems, English is not my first language.\n\nAssistant:",
    "golden_answer": " On very basic terms the difference between Canadian and American Natives is that in Canada, from day one, they were negotiated with - NOT conquered. They have Treaties that were signed between their tribes and the Government of Canada which laid out both sides of the deal - what they got in exchange for moving to a designated area and completely changing their way of life. These are still legal documents just like a  Constitution - they are valid as long as 'rivers flow and grass grows'. At no point do the First Nations rights suddenly expire.   In America, this might have happened occasionally but American Indians fought back and were conquered. Agreements were made after the fact.   After those Treaties were signed, the problems have largely stemmed from interpretations. The Indians couldn't necessarily read, they have a different culture and different understanding. The translations were murky at best. The Indian Act is another factor which is where all the laws associated with Indian treatment are laid out. They are pretty harsh. While they may not have to pay income tax (while working on the reservation) they also cannot build their own house on that land, they are essentially rented. Any buildings or businesses need Indian Agent approval. Also look up Residential Schools.   Everyone who has immigrated to Canada since day 1 has come after it was already established by the Indians and Inuit. We are all living on their land (Turtle Island), according to signed legal documents, and everyone should respect that. Time doesn't erase everything.   (On my phone so I can't get as detailed as I would like!)"
  },
  {
    "prompt": "\n\nHuman: What research is there on the psychological tools Fox News uses to convince its audience to believe in conspiracies? Thought about this after reading about these anecdotes identifying Fox News viewership as the common factor in discounting public health information: https://www.thedailybeast.com/fox-loving-parents-are-driving-coronavirus-paranoid-kids-insane\n\nAssistant:",
    "golden_answer": " First, a note on terms: I think you're conflating misinformation and conspiracy thinking. The two are related but not identical. The way I explain it to students is a person can believe there are 26 Justices on the Supreme Court and they would be wrong, but they don't have to believe there is some grand conspiracy hiding the true number of Justices to be wrong. They're misinformed. And a person in, say, September 1972 could think that this whole Watergate break-in is kind of fishy and maybe some government higher-ups were involved. They believe a conspiracy is a afoot and they also happen to be right (i.e. not misinformed). The two often do go hand-in-hand (NBA player Kyrie Irving has on several occasions suggested the world is flat. He is misinformed and also necessarily believes a cabal of governments and scientists have been secretly trying to trick everyone into thinking the world is round for...reasons...so he also believes a conspiracy theory). There's also the differences between misinformation and disinformation (there's a known maliciousness to the latter). I think we can mostly set aside disinformation for this specific example, however.  Let's start with your initial point about conspiracy theories and Fox News. There are examples of conspiracy beliefs about COVID-19, for example that it was manufactured in a lab by Chinese scientists.  Why does anyone, and especially Republicans (the Pew data doesn't include Fox News viewership so we don't have that specifically), believe such a thing? Because they are predisposed to believe conspiracy theories and because this particular one has aligned with their political beliefs. Some people appear more susceptible to conspiracy theories and there's nothing right or left about it. But such people will be much more likely to believe a conspiracy if it also aligns with their political identity. Liberals/Democrats don't make up the Pizzagate rank and file. So Fox News viewers are more likely to subscribe to such conspiracy theories because they're a group with highly salient political identities and because Fox News serves as a conduit for the political elites who represent those identities to stress why believing such a conspiracy theory would align with their politics. I also recommend this book for more on the subject of conspiracy theories in general.  That said, I think what we're really discussing here is misinformation. The engine that makes misinformation run is motivated reasoning. All reasoning is motivated, but sometimes it is motivated to achieve partisanship goals (i.e. to make yourself feel good/smug about your political identity) and sometimes it is motivated to achieve accuracy goals (to get the right answer). When motivated by partisanship, people: a) search out information that conforms to their preexisting beliefs (confirmation bias), b) rank congruent arguments as more credible (prior attitude effect), and c) expend more cognitive resources counter-arguing incongruent arguments (disconfirmation bias). The last two are really key for misinformation. When a person encounters a bit of misinformation (let's say that social distancing doesn't work), if that would make them feel better about their politics (then we should start the economy back up which will help Trump get reelected) they will rank it as credible. When they encounter corrective information that tells them they're wrong (actually it does work), they will then work harder to find a reason not to accept this new information.  Under both conspiracy theories and misinformation, Fox News doesn't need any special psychological tricks to mislead their audience. All they need is a clear alignment between the partisanship of what they're saying and the partisanship of their audience. Once that's present, the information spread is easy regardless of the accuracy of the information.  That's the answer I'd give, but I also would like to caveat this by saying I'm no super sold on the whole point. I'm trying to find the actual survey and having little luck, but they discussed the self-reporting of preventative behavior (i.e. wearing a mask when going out) on a recent 538 Politics podcast and the gaps by partisanship weren't all that big. Honestly, I think most Republicans are taking this only slightly less seriously as Democrats and the article you linked to is anecdotal and overstating the real differences. Also, Leticia Bode makes the point that we should really think of the quality of information as a hierarchy rather than purely right or wrong. Because this disease is so new, there aren't real scientific consensus around anything. We don't know what the truth is regarding, well, just about anything having to do with COVID-19. We have well-informed guesses. Keeping some modicum of skepticism strikes me as what a reasonable person should do in this situation. Trust the experts, but don't assume they're infallible."
  },
  {
    "prompt": "\n\nHuman: Why have stereotypes from young urban black males in poorer communities seem to have been co-opted to define the entire African American community I understand how stereotypes are inherently incorrect. But, I was wondering about how stereotypes from young black males in poorer urban communities have been used to define the entire african American community. LIke why specifically from young black males?\n\nAssistant:",
    "golden_answer": " First, it is important to know that stereotypes are not “inherently incorrect”. A large body of research has now shown that, in general, many stereotypes actually have high levels of accuracy.   Humans are naturally inclined towards categorization. From a young age, individuals begin to form associations that help them to identify and categorize different aspects of the world around them (Packer & Cole, 2015). Through this process, we soon learn to regard objects that look, feel, or act similarly as being in a similar category. Most of the time, we are probably right. This process is evolutionarily advantageous because it makes it so that we do not have to use a lot of mental resources any time we encounter something new. We can rapidly make a guess about an object based on our past experience and we are usually correct.  These processes also work for social categorization. We have differing ideas about what various groups are like (often called stereotypes). If we define stereotypes as people’s beliefs about groups and their individual members (Ashmore & Del Boca, 1981), research has found that inaccurate stereotypes are the exception and that most stereotypes have moderate to high levels of accuracy (Campbell, 1967; Jussim et al., 2016, 2018, 2019; Mackie, 1973; Ryan, 2003). This means that (like with any other form of category) if stereotypes are accurate, they should represent a generalized belief that is accurate for most members of a group most of the time.  This means that stereotypes themselves are not the issue. Instead the issue comes when we are unwilling to look past stereotypes. The stereotypes of “young urban black males in poorer communities” probably accurately represent many aspects of members of that group. Additionally, this stereotype probably overlaps a lot with stereotypes for black males in general.   So in answer to your question  >why specifically from young black males  First, this topic is popular in the world right now (as another poster has stated) and so there is going to be a lot of selective reporting in what you see. Not all people likely use the young black male stereotype to apply to the “entire African American community”.   Second, even before this year, black males make up the largest percentage of reported crime (this is an FBI database, there is a lot of information here so let me know if you have trouble navigating it) and so they are also more likely to be featured in news stories and through anecdotal evidence. This makes them a likely candidate for the availability heuristic and so people may be more likely to make “young black male” consistent judgments when judging other black males.   This on only one explanation though. In order to better answer your questions, I would need to know some specific examples of what you are talking about.  Please reply to this message and let me know what you think.   \\------------------------------------------------------------  Ashmore, R. D., & Del Boca, F. K. (1981). Conceptual approaches to stereotypes and stereotyping. Cognitive Processes in Stereotyping and Intergroup Behavior, 1, 35.  Campbell, D. T. (1967). Stereotypes and the perception of group differences. American Psychologist, 22(10), 817–829. https://doi.org/10.1037/h0025079  Jussim, L., Crawford, J. T., Anglin, S. M., Chambers, J. R., Stevens, S. T., Cohen, F., & Nelson, T. D. (2016). Stereotype accuracy: One of the largest and most replicable effects in all of social psychology. In Handbook of prejudice, stereotyping, and discrimination (2nd ed., Vol. 2, pp. 31–63).  Jussim, L., Stevens, S. T., & Honeycutt, N. (2018). Unasked questions about stereotype accuracy. Archives of Scientific Psychology, 6(1), 214–229. https://doi.org/10.1037/arc0000055  Jussim, L., Stevens, S. T., & Honeycutt, N. (2019). The Accuracy of Stereotypes About Personality. In T. D. Letzring & J. S. Spain (Eds.), The Oxford Handbook of Accurate Personality Judgment. Oxford University Press.  Mackie, M. (1973). Arriving at “truth” by definition: The case of stereotype inaccuracy. Social Problems, 20(4), 431–447.  Packer, M., & Cole, M. (2015). Culture in Development. In M. Bronstein & M. E. Lamb (Eds.), Developmental science: An advanced textbook (7th ed., pp. 43–111). Psychology Press.  Ryan, C. (2003). Stereotype accuracy. European Review of Social Psychology, 13(1), 75–109. https://doi.org/10.1080/10463280240000037"
  },
  {
    "prompt": "\n\nHuman: [Sociology]Why is it that most older American women seem to prefer short hair styles, while most younger women favor longer hair styles. Why is it is that most older American women (in their 60's and up) seem to prefer shorter hairstyles, while most younger women (teens and 20's) seem to prefer longer hairstyles?  What would be the sociological reasons for this?\n\nAssistant:",
    "golden_answer": " There are some interesting theories in here, but they all miss the mark in this (borderline middle-aged) woman's opinion.   Older women cut their hair shorter because long hair makes an old woman look even older.   That's it. Simple.   There are exceptions, and some older women can pull off long hair. But to be perfectly blunt about this, when gravity has begun to have its way with your body and everything is sagging downward more than you want it to, having long hair hanging by your face only exaggerates the effect. Short haircuts give your appearance a bit more of a structured, upward-oriented lift. Take an older woman with long hair, cut it off above the shoulder and style it, and she instantly looks ten years younger, or at least more put-together for her age.   The other point here is that grey hair is different. It's coarser and tends to curl in strange ways, which makes it ill-suited to the long, silky, flowing thing that we expect from beautiful long hair. Long grey hair tends to make a woman look a bit like an unkempt old crone. Short haircuts keep grey hair craziness as contained as tidy as possible.   Nothing to do with what was in style when they were younger, nothing to do with upkeep. They're just trying to groom themselves as flatteringly as possible."
  },
  {
    "prompt": "\n\nHuman: Why is the US so dominating in entertainment and culture? I'm from Norway, not the largest country in the world, and I was thinking about where my entertainment comes from. Speaking a small language, I'm accustomed to speaking or listening to another language when I interact online or watch/listen to other entertainment mediums, and I'd guess that most non-english speaking people would do the same.   But it seems like most of my entertainment comes from the US, something that I find weird when I think about the size of the country. Europe has more than double the population, and by that logic why isn't 2/3 of my entertainment from the continent? In global terms, the US is roughly 5% of the world population, yet it's dramatically overrepresented in most media.   If I turn on my television, most - if not all - foreign shows are made by the US, with the exception of Top Gear and a few select other British shows. Almost every move I see is made in the US, even though the UK also has a sizable movie industry. I sometime see French movies, but I can't remember the last time I saw a German or Italian movie, for example. Even the Internet seems to be dominated by the US (I'd guess that at least half of Reddit is from the US), as I only seem to visit American sites unless it's in Norwegian.  Does anybody have an idea why this is the case?\n\nAssistant:",
    "golden_answer": " First: The Division of Labor is limited by the extent of the market. English language extends to a much larger number of wealthy people than any other language, which means there can be more differentiation within the English language market than other language markets. If there are 500 million English speaking people who will pay for content (or who advertisers will pay to reach), and 80 million German speakers, a movie that appeals to 10% of the German population only need appeal to 2.5% of the English-speaking population. The types of art that will appeal to 2.5% of the population are much more numerous than the types of art that require 10% of the population to be sustained.  Second: Agglomeration effects and economies of scale*. Certain types of art thrive by being done at a place where other types of that art are being done. Obviously, if I want to make a movie the cheapest place to produce it will be Hollywood (filming it is a different question), because there are people and equipment there who specialize in making movies. Need an editor for your screenplay? In Hollywood you could probably find one in the phonebook; but probably not anywhere else. Similar effects lead to Hollywood having great advantages over other locations--even shows set in NYC or DC will be shot in LA.   To compare, almost 90% of carpet in the world is produced in or around Dalton, Georgia. Why? Agglomeration effects make it so that it is cheaper to make carpet in GA and ship it to Moscow than it is to make carpet in Moscow. Why is most of your carpet made in Dalton? No really good reason, it just happened someone started making carpet there and it snowballed. Hollywood, to some extent, can be explained by that. It could have been Vancouver, or London, and then Americans would consume a lot more Canadian and British culture.  Note: the arguments apply to other art forms than movies, just to a lesser extent. Why, if I consume postmodern literature, is most of it from Paris? The community of writers that developed there was a resource in production unique to Paris.   *Agglomeration effects mean that if someone is producing X at a certain location, it becomes cheaper to produce X at that location. It's cheaper to write good software in Silicon Valley than the middle of nowhere, because Silicon Valley has programmers and an infrastructure that a software company requires. Land may be cheaper in BFE, but internet and programmers aren't. In addition, you're more likely to run into someone at the bar who has good ideas about software that you can then benefit from in Silicon Valley than in rural nowhere.   Economies of Scale indicate the range of production where average cost is decreasing. It's cheaper per-meal for me to make 4 servings for dinner than it is for me to make 2 servings, because there are a lot of fixed costs when I go to make dinner that are paid regardless of the number of servings. These are related to agglomeration effects (and, in fact, are an agglomeration effect)."
  },
  {
    "prompt": "\n\nHuman: What do I need to know to understand Marxist international relations? I'm interested in Marxist international relations but am not familiar with Marx's writings on sociology, economics, etc. Just want to understand how to explain international relations with his ideas without having to go through lots of books. Can anyone recommend some reading?\n\nAssistant:",
    "golden_answer": " What most of these comments seem to be missing, and likely indicative of the fact that most are probably not IR scholars, is that Marx isn't a scholar of international relations. There's a difference between Marxist IR and Marx's theory of capitalism. Yes, Marxist IR is certainly built off the foundations of Marx's theory of capitalism, but Marxism as a distinct theoretical approach in the field of International Relations emerges around the late 50s and early 60s as part of a broader theoretical movement known as 'structuralism'.   If you want a solid introduction to Marxist IR, what you really want to read is Marxism and International Relations by Kublakova and Cruickshank (1985). It is a bit dated, but it's definitely still worth reading.   If after exposure to various writings of Marxist IR you want to go to the source, go back and read Marx's Capitalism. Frankly, I would not recommend anyone with a serious interest in Marxist IR start with Marx himself."
  },
  {
    "prompt": "\n\nHuman: Is the Barter economy really a myth? I was reading this article by the Atlantic:  https://www.theatlantic.com/business/archive/2016/02/barter-society-myth/471051/   Where it is supported that according to anthropological research the barter economy has never existed and is only believed by economists. I only have knowledge of economics and a rather limited one I may admit. Other social scientists, is this really true, is the barter economy really fake or just some specific anthropologists say so?\n\nAssistant:",
    "golden_answer": " Historically, economists assumed that barter pre-dated money. Money was abstracted barter, so the story went.   Going back to Malinowski's kula ring, Marcel Mauss's \"the Gift\"), the North American potlatch, up through Marshall Sahlins's very influence essay \"The Original Affluent Society\" (later expanded into the book *Stone Age Economics*) make a pretty strong argument that internal to most small scale communities, we don't see barter. We don't see trade. We see what people (following Mauss) called \"gift economies\".   David Graeber, in his very influential *Fragments of An Anarchist Anthropology*:  >Before Marcel] Mauss, the universal assumption had been that economies without money or markets had operated by means of “barter”; they were trying to engage in market behavior (acquire useful goods and services at the least cost to themselves, get rich if possible...), they just hadn’t yet developed very sophisticated ways of going about it. Mauss demonstrated that in fact, such economies were really “gift economies.” They were not based on calculation, but on a refusal to calculate; they were rooted in an ethical system which consciously rejected most of what we would consider the basic principles of economics. It was not that they had not yet learned to seek profit through the most efficient means. They would have found the very premise that the point of an economic transaction—at least, one with someone who was not your enemy—was to seek the greatest profit deeply offensive. (pg. 21)  Earlier in the book, he gives a little more history of Mauss's idea:  >[Mauss's] most famous work was written in response to the crisis of socialism he saw in Lenin’s reintroduction of the market in the Soviet Union in the ‘20s: If it was impossible to simply legislate the money economy away, even in Russia, the least monetarized society in Europe, then perhaps revolutionaries needed to start looking at the ethnographic record to see what sort of creature the market really was, and what viable alter- natives to capitalism might look like. Hence his “Essay on the Gift,” written in 1925, which argued (among other things) that the origin of all contracts lies in communism, an unconditional commitment to another’s needs, and that despite endless economic textbooks to the contrary, there has never been an economy based on barter: that actually-existing societies which do not employ money have instead been gift economies in which the distinctions we now make between interest and altruism, person and property, freedom and obligation, simply did not exist. (pg. 17)  Later, in his book *Debt*, Graeber argues pretty convincingly (at least to me, a non-specialist in Mesopotamia economics) that the origin of money is not abstracted barter but debt, to over simplify somewhat, based on rationalized gifts.   Nothing here, I think, would be particularly controversial within anthropology or sociology or even, to some degree, within economics. Many economists, including Stiglitz, Cowen, and others, recommended reading *Debt* (while having very obvious disagreements about some of its core conclusions, but not necessarily its interpretation of the early historical data). I go through many of the reactions in this older [/r/AskAnthropology post.   Which is to say, I think it's entirely convincing that for internal exchange, the modal (perhaps even \"overwhelming\") form exchange was some form of gift exchange. Please note that gift exchange does *not* mean complete equality as there was still accumulation and inequality in gift economies. In fact, this has been recognized (going all the way back to Mauss) as a consistent feature of gift economies.   However, what I'm much less convinced based on the readings of the above, is that gift economies was as overwhelming for *external* exchange. Think of it this way: the family you grew up in was a gift economy. Your father or mother (hopefully) never charged you for breakfast in high school. This does not mean, necessarily, that outside of your family there were no other forms exchange, i.e. money or barter. In fact, one consistent features of actually existing gift economies today is that they are often enmeshed with other forms of trade and in some context we'll see gifts and in some contexts we'll see market exchange and in some contexts it'll be a little unclear what we're seeing because one will have the veneer of the other. Even in our very market-based societies, we have lots of gift economies for things. College parties is one that I always explained to my students (the one who gives away the most by throwing a college party with free flowing cheap beer gains the most prestige). The trade of blood and organs is another (two academics have written books about these, Kieran Healy's *Last Best Gifts: Altruism and the Market for Human Blood and Organs* and the older *The Gift Relationship: from Human Blood to Social Policy* by Richard Titmuss).  Certainly, there are external gift exchanges—gift exchanges with outsiders. I love the guest-host relationships theorized to exist in early Indo-European society. I think the kula ring is a particularly famous example. But the kula exchange existed along side market/barter exchange, called *gimwali* (as both Malinowski and Mauss actually emphasize). This isn't my area, but I haven't seen a fully articulated discussions of this in relationship to the origin of barter.   So yes, this line is true if read in a  certain way:  >But various anthropologists have pointed out that this barter economy has never been witnessed as researchers have traveled to undeveloped parts of the globe. “No example of a barter economy, pure and simple, has ever been described, let alone the emergence from it of money,” wrote the Cambridge anthropology professor Caroline Humphrey in a 1985 paper. “All available ethnography suggests that there never has been such a thing.”  There has never been a *pure and simple* barter economy. But there have existed barter systems that exist along side, and complimentary to (arguably part of), of gift economies. It's been a while since I've read Mauss or Malinowski, but I don't think they argue that *gimwali* barter emerged from money. Within the society, there was very little *explicit* quid-pro-quo, but there was a ton of implicit quid-pro-quo. Though it's an external example, in the kula ring, as Wikipedia helpfully summarizes:  >Participants travel at times hundreds of miles by canoe in order to exchange Kula valuables which consist of red shell-disc necklaces (veigun or soulava) that are traded to the north (circling the ring in clockwise direction) and white shell armbands (mwali) that are traded in the southern direction (circling counterclockwise). *If the opening gift was an armband, then the closing gift must be a necklace and vice versa.*  Similar unspoken rules and assumptions are often present in gift exchanges (just as today if I loan a neighbor my lawn mower, I expect he'll give it back—and let me borrow his chainsaw when I need it). But Mauss and Graeber emphasize, what I think that article misses, is that these exchanges are always unequal. The relationships can never be \"zeroed\", the debts and values never fully calculated, which ensures the continuity of the relationship. However, in relationships that were not as continuous—that is, certain external relationships—it does seem like various forms of barter exist. Anthropologist Anne Chapman even has an article called \"Barter as a Universal Mode of Exchange\", where she argues that it is a universal mode of exchange alongside gift exchanges. And while she doesn't make the internal/external distinction I'm making, that's where all her examples come from (\"Bushmen\" and Bantus or Europeans; Munchi and Jukum in Central Sudan; various long distance trade in Australia, etc). She emphasizes instead that while gifts engender good feelings, friendliness (continuity, in my terms), barter engenders competition, hostility, and force (the potential for this to be a one off relationship, in my terms). Barter exchanges, as Chapman puts it and all the others agree, fundamentally differs from gift exchanges in that \"it is a purely economic transaction involving no mutual obligation between the partners.\" In some of the barter exchanges—like those in the kula ring—gift exchanges are layered with barter exchanges which facilitates continued relationships while also circulating desired goods between groups.   It seems like your article somewhat conflates this, and takes the internal situation as the universal situation. Now, what this does not mean is that barter is the precursor to money. But it also doesn't mean that barter isn't part of external exchange in non-state societies. However, I do think that Graeber is right in arguing that where we see \"pure and simple\" barter economies for in-group exchange (that is, without a heavy dose of gift economies) is after the breakdown of once robust market economies (during war, etc.), rather than non-state economies."
  },
  {
    "prompt": "\n\nHuman: We've heard of Italian mafia, Russian gangs, the Turks, etc. Why are organized crimes and gangs organized based on ethnicity? Both in popular depiction and media we've heard of this Italian mafia, Russian gang, the Turks, the Chinese triads, the Japanese yakuza, etc.  Why is ethnicity important for them? I mean, if gangs and organized crimes are just illegal corporations, why does ethnicity matter? Companies wouldn't limit their employers based on their ethnicity if it could be profitable for them, ain't it?  Which leads me to another question. Is it true that those organized crimes are composed of single ethnicity? Like, are there no blacks in a Yakuza gang, or no Italians in a Russian gang? Or is it just a fictional depiction?\n\nAssistant:",
    "golden_answer": " Trust. Whether rationally or not, people are more likely to trust someone from their own ethnic group. In any criminal conspiracy, trust between the conspirators plays a huge role.   > if gangs and organized crimes are just illegal corporations, why does ethnicity matter?   Because where there is no recourse to the legal system to settle disputes, trust is essential. And though the situation is different today in the developed world, for much of history legitimate businesses were indeed segregated according to ethnicity. This also had to do with trust."
  },
  {
    "prompt": "\n\nHuman: Has the anti-vaccination stance moved from the far left to the far right or is that just my perception? I feel like the anti-vaccination movement has been around forever, though admittedly they were far less visible before social media.  When I was young, however, it was the super left-wing hippy types who wanted everything to be \"all natural\" and feared \"Chemicals\" but now it seems like most of the anti-vaccine voices are right wing anti-government types.  Is there documentation of this shift, and is it real or is my experience not reflective of the overall trend?\n\nAssistant:",
    "golden_answer": " \" Our findings demonstrate that ideology has a direct effect on vaccine attitudes. In particular, conservative respondents are less likely to express pro-vaccination beliefs than other individuals. Furthermore, ideology also has an indirect effect on immunization propensity. The ideology variable predicts an indicator capturing trust in government medical experts, which in turn helps to explain individual-level variation with regards to attitudes about vaccine choice. \"  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5784985/"
  },
  {
    "prompt": "\n\nHuman: Should AskSocialScience enact rules and moderate in a way closer to AskHistorians and AskScience? I've noticed that the signal/noise ratio in this subreddit has been getting worse for some time. Purely speculative answers dominate, while cited papers or analysis languish at the bottom. In this recent thread for example, the top comment is purely speculative (though IMHO largely correct), there is a highly rated comment that asserts that labor demand is *upward* sloping, and languishing at the bottom is a comment that points to relevant academic articles.   I think it's time this subreddit started started implementing a policy similar to AskHistorians official rules or the AskScience FAQ  IMHO, 1st level comments should cite a source (preferably an academic paper, but also magazine articles, or even Wikipedia), or be from a credentialed social scientist in the relevant field.    What say you all?\n\nAssistant:",
    "golden_answer": " YES. As a panelist on /r/AskHistorians, I say bring the hammer down. Rule with the iron fist encased in velvet. Strong moderation is the only way to ensure quality."
  },
  {
    "prompt": "\n\nHuman: Will the children born today write by hand and own (physical) books when they grow up? So, we had a bit of an interesting debate around the lunch table at work today, about the impact that technology in general and iPads and the like in particular is having and will have on those growing up today. During this discussion, a colleague of mine made the following claims:  - Children born today won't really learn to write by hand, since they'll never have reason to do so, and will exclusively type as adults. - Amongst children born today having one bookcase full with books in your home when you are in your 20s-30s will be a rarity.  - Public libraries will disappear rather rapidly because no-one will read printed books anymore but simply use electronic readers.  Now, we didn't have time to go into it in detail, but his stance seemed to be based mostly on the idea that electronic tools like this are more practical and now widely available and that there simply won't be a reason to keep writing by hand and reading printed books.   Although I do think that electronic readers and the like will have a big impact on people's reading habits, I felt his claims were rather rash on the following grounds:  - Technology changes things, but not always as quickly as people predict. When I was a kid and computers had just become/were just becoming a common household object everyone was on about \"the paper-free office\" which was bound to soon become a reality. As an administrator, I can verify that very large amounts of papers are still being shuffled around offices.  - Electronics of this sort are only affordable (or at least, affordable on a scale where each child in a family has their own  in addition to those owned by the parents) to certain demographics in certain societies (that is, financially stable people in industrial societies). This still leaves many, many people depending wholly or partially on \"old school\" pen and paper, and it seems to be that a complete switch would only be plausible if it effected an entire society. I feel that affordability will remain an issue for quite some time, even if prices are bound to decrease gradually.  - Electricity is fickle. My own country has very stable electricity and generally good internet coverage, but blackouts still do happen occasionally. Additionally, leaving your charger at the house by accident happens so unless battery life goes up a LOT or public charging stations or somesuch become widely available, it's still likely that people would occasionally end up in situations were scribbling something on a piece of paper will be the best/only way of leaving someone a message or retaining information or a reminder to yourself.  - It seems to me that most kids are introduced to pens/pencils not by writing but by drawing! Although drawing on electronic mediums can be fun for users of all ages, but drawing with pen and paper strikes me as stimulating in a different way (physically selecting colors, being able to cut and paste and get the whole 3D thing that you can't get on a screen). Additionally, even while drawing on a tablet, most people (in my experience anyway) still use a stylus which, let's face it, is basically a pen so even a child growing up in a crayon-free house would be somewhat accustomed to the mechanics of working a pen/pencil.  - Practicality/durability. Tablets and the like can probably be great tools for learning and entertainment for kids, if used right, but they simply cannot take the same abuse (at the same cost) as a plain piece of paper or a kids' books (I'm thinking particularly of those cardboard books for young toddlers who don't yet read). In order for something to replace pen and paper for kids, I think it would need to be possible to be used without parental supervision or perhaps rather, with intermittent parental supervision. Although electronics seems to gradually be getting more durable, I have a feeling that it'll be a long time before a tablet can be drooled on, dropped, bitten, flung across the room, ripped at and juggled with at as low a cost (and as low a risk of personal injury) as a sheet of paper can.   - And, lastly, that human behavior to such a large part is transmitted down through the generations. Even if a 20-something 30 years from now wouldn't have any *practical* reason to write by hand and read paper books, they would still have parents, relatives, teachers, bosses etc who were doing it and chances are that would mean that they would've learned to do it too. For this reason, if non-electronic text ever falls completely out of fashion, I think it will take a lot longer than the time it'll take for children being born today to grow up.    Okay, sorry for that little wall of text, I got a tad carried away! What I wanted to ask you kind and knowledgeable people is: what do you think about these arguments (on both sides)? Will people stop writing by hand? Will books become an entirely electronic thing? And, if so, what sort of time-span are we talking about here? Really I'm just curious about the topic in general, whether any studies have been made on it so far and what the predictions of those in relevant fields are on the topic?  Thanks for reading!\n\nAssistant:",
    "golden_answer": " It's unlikely that handwriting or books will disappear anytime soon. Many books for young children also include tactile components (fur, scales, sandpaper, etc.) that, as far as I know, is good for a child's development and not really reproducible with a tablet. There's also the fact that many children's books are made to be beaten up, so to speak. I don't see very many parents letting their young ones chew on, poke, and step on a tablet---they would have to be rugged which isn't a problem in principle, I guess, but still not practical.   Many people take great pleasure in collecting books and displaying them on bookshelves---they look nice. I don't see this going away anytime soon either.  Plus, there are many practical reasons to keep books around---they are way more durable than electronic versions. There are books around that are hundreds of years old (and stone tablets which are thousands of years old). It will be some time before we can make electronic devices which are still usable when they are 500 or more years old. Plus, even if we make machines which can retain data after 500 or more years, there's still the problem of getting the then-modern machines to be able to read it. Many computers today can't read files produced with old software, for example. Have you ever tried to read a 20 year old Word Perfect file? Good luck!  These problems are not insurmountable, but it's hard to imagine how it will ever be more practical than just printing a book.  As far as handwriting goes, I don't see how I could have the skill to read and type and not have the skill to write. That is, if I recognize the letters, what's to stop me from being able to write them down myself on a piece of paper? Nothing, I'd imagine. So, as long as people can read and type, they will be able to write. Perhaps they won't need to write very often, but they'll be able to if they want."
  },
  {
    "prompt": "\n\nHuman: Book on sociological dynamics in Appalachia? In the vein of books like “white trash” or JD Vance’s “Hillbilly Elegy”, I am interested in the sociology of rural southern areas, specifically Appalachia.  Anyone have any recommendations for reading?\n\nAssistant:",
    "golden_answer": " Not Appalachian, but Strangers in their Own Land by Hochschild (2016) is a great book and may scratch some of that itch you have. Plus, it has the added bonus of not being written by a twat like Vance."
  },
  {
    "prompt": "\n\nHuman: How would you structure a Semester-long High School Sociology class? I myself just inherited one and I start in six days. So, yeah. change in faculty means I've picked up my first ever High School Sociology class which Starts next week.  I'm not at square one, I know the field a bit, took classes in it back in college, thought I had a pretty good handle on it back in the day, but yikes... I'm an AP European History teacher who doesn't want to phone in this recent singleton. I really, honestly want to construct a valid and valuable course for these kids, but I am a bit behind the eight ball here.    Any suggestions would be greatly appreciated.  Any Syllabus will be perused and doted over.  And honestly, any ideas would be super helpful at this point.  Wish me luck.\n\nAssistant:",
    "golden_answer": " I'm going to encourage our moderators (myself included) to allow non-cited and sourced answers to this rather unique question."
  },
  {
    "prompt": "\n\nHuman: Can someone explain to me what happened to Venezuela's economy?\n\nAssistant:",
    "golden_answer": " Price controls are near universally frowned upon by economists. It's where the government says, by decree, that something must be traded for \"exactly X\" (or more than X, or less than X).  It somewhat defeats the market process - instead of something getting more expensive as it gets scarcer or increases in demand, it simply runs out of stock. Or vice versa, you end up with more for sale than can be sold, with the producers unable to sell their wares.  Everyone price controls to some degree though - a minimum wage is an example, rent control in some markets are another example. There are academic defences of the minimum wage, but we'd all be lying if we were to say there's no disadvantages/problems caused by it.  The point of all this, is that Venezuela for a long time has been attempting to price control *everything*. From the price of toilet paper, through to wages, through to electricity, through to even the currency itself.  The latter is a huge one. In Venezuela, the currency must be exchanged for USD at a price decreed by the government. This isn't a fixed exchange rate in the traditional sense (where the central bank builds up \"reserves\" and then sells them at a fixed price) - Venezuela has attempted to do the same purely through decree. The problem with this, is that they overvalue the currency so much that you can't actually trade at the official rate. Nobody (or few) will sell you USD for the price the government says they must.  Markets are all incredibly interconnected, we all depend on foreign trade for prosperity - but even operating a business in Venezuela you're shut out from all of this. Only well connected individuals can buy USD from the government at the official rate, otherwise you're stuck applying for \"allowances\" through application processes that take who-knows-how-long. This means the only way to actually import en-masse in Venezuela is by breaking the law. Using black market currency traders. Can you imagine running a business like that?  Oh. Not that you'd want to operate a business - as per the toilet paper article, if the government feels you're not running with the country's interests at heart, it'll just seize it. This makes everyone incredibly suspicious about investing in the country, and avoiding it completely.  So you have inability to export, inability to import, inability to set your own prices, a government that will seize your company on a whim... all acting to reduce \"aggregate supply\". There's chokes on absolutely everything - you cannot buy foreign stuff, you cannot employ workers except at wages decreed by government, and then you can't even sell your goods except at prices also decreed by the government.  Anyway. With trashed supply, come shortages and/or raising prices (price controls be damned). The government attempts to address all these by bringing in tougher price controls, but they're doomed to fail too. Their economy is choked from top to bottom by controls on everything, people can't produce stuff, can't sell stuff, etc. And with a weak economy comes a low (and falling) exchange rate. Well, it would, except that's price controlled too (so read: falling black market exchange rate).  Then hit oil price crashes. Venezuela has more oil than anyone else (which goes to show how spectacularly shockingly they're being run), which accounts for nearly all their exports - again no doubt largely due to the illegality of currency exchange. So oil price crashes, and their entirely non-diversified economy sinks with it.  Adding on to all of these (even with terrible management economies tend to persevere until there's a combination of things - they're nowhere near as fragile as we think), they've been hit by the worst drought in 47 years. With the drought 3 years running, their dams are now on the brink of empty. For a country that depends on hydro for 73% of their power generation, that's a *huge problem*. One that undoubtedly could have been avoided with better management and contingency planning, but Venezuela has anything but good management.  So what do they do? Well, reduce the number of workdays. Send people home from public sector jobs. Roll blackouts. All things further constricting aggregate supply, further making it harder/impossible to run a business.  With reduced aggregate supply, you can basically either take measures to reduce aggregate demand (like raising taxes), or let inflation erode people's living standards for you. The latter can be extra problematic, as inflation means lower real interest rates, encouraging people to spend further: it can *increase* aggregate demand and trigger all kinds of terrible feedback loops (like getting wage increases due to inflation due to wage increase, etc). Venezuela has all that, but then also a bunch of price controlled stuff experiencing shortages, and just generally the economy is undergoing a slow collapse. It's fascinating to watch.  Oh. And I forgot another big one: they happen to owe a lot of foreign currencies. Somehow, the country needs to bring in USD to repay those public debts. Combine that with the collapse in the export sector, collapse in the electricity sector, massive inflation and shortages out of the wazoo... and yeh, good luck to them with that.  If you ask me (and I'm definitely no authority on the matter), one of the biggest mistakes they made was price controlling their currency. Currencies should be free floating, fixed or managed if you absolutely must, but making it illegal to trade except at a government-determined rate is just the worst possible system excusable never. Argentina until last year had the same system and there is just really not a single thing to recommend it for. Well, that and/or deciding to seize businesses willy-nilly. Actually, that latter one's probably even worse. Sigh."
  },
  {
    "prompt": "\n\nHuman: Why aren't the so called \"terrorists\" of the world using nuclear weapons? I don't want them to, but what is the real reason?\n\nAssistant:",
    "golden_answer": " There are three ways for a terrorist group to obtain a nuclear weapon:  * By developing them. * By stealing them. * By being gifted them.  According to this study (edit: try this if the other link doesnt work), well-organized terrorists should both be capable of developing nuclear weapons and launching them. The reasons why they haven't developed nuclear weapons is because it is difficult (both Al-Qaeda and Aum Shinrikyo (a Japanese terrorist group trying to achieve a nuclear Armageddon) have tried). Reasons why (p. 146):  * Al Qaeda recruits \"have **little technical sophistication and expertise**\" (\"al Qaeda reportedly concluded that its attempt to make nerve gas weapons by relying on the group’s own expertise had “resulted in a waste of effort and money”) * \"Others assert that a group with al Qaeda’s structure of **small cells would not be well suited for an arguably large, long-term project like making a nuclear bomb**, particularly given the substantial operational disruptions sustained since 9/11\" * \"In the absence of a **stable sanctuary with large fixed facilities**, it would be nearly impossible for a terrorist group to make a nuclear bomb.\"   As for being gifted nuclear weapons, an article in the summer edition of International Security (here is a summary of the article) brilliantly explained why governments with nuclear weapons are not in the business of giving them to terrorist groups:  Using terrorists to launch your nukes for you only makes sense if you want to use nukes without getting the blame for it:  P. 85:   > The calculated, “back-door” approach of transferring weapons to terrorists makes sense only if a state fears retaliation. **The core of the nuclearattack- by-proxy argument is that a state otherwise deterred by the threat of retaliation might conduct an attack if it could do so surreptitiously by passing nuclear weapons to terrorists**. Giving nuclear capability to a terrorist group with which the state enjoys close relations and substantial trust could allow the state to conduct the attack while avoiding devastating punishment.  That does not make sense though since it would be fairly easy to trace the nukes back to the terrorist sponsoring state:  P. 83-84:   > We conclude that **neither a terror group nor a state sponsor would remain anonymous after a nuclear terror attack**. We draw this conclusion on the basis of four main ªndings. First, data on a decade of terrorist incidents reveal a strong positive relationship between the number of fatalities caused in a terror attack and the likelihood of attribution. Roughly three-quarters of the attacks that kill 100 people or more are **traced back to the perpetrators**. Second, attribution rates are far higher for attacks on the U.S. homeland or the territory of a major U.S. ally—97 percent (thirty-six of thirty-seven) for incidents that killed ten or more people. Third, **tracing culpability from a guilty terrorist group back to its state sponsor is not likely to be difficult**: few countries sponsor terrorism; few terrorist groups have state sponsors; each sponsored terror group has few sponsors (typically one); and only one country that sponsors terrorism, Pakistan, has nuclear weapons or enough fissile material to manufacture a weapon. In sum, attribution of nuclear terror incidents would be easier than is typically suggested, and passing weapons to terrorists would not offer countries an escape from the constraints of deterrence.  Other reasons why a state would not give nukes to a terrorist organization:  > Some analysts are skeptical about such sponsored nuclear terrorism, arguing that a state may not be willing to deplete its small nuclear arsenal or stock of precious nuclear materials. More important, a state sponsor would fear that a terrorist organization might use the weapons or materials in ways the state never intended, provoking retaliation that would destroy the regime.14 Nuclear weapons are the most powerful weapons a state can acquire, and handing that power to an actor over which the state has less than complete control would be an enormous, epochal decision—one unlikely to be taken by regimes that are typically obsessed with power and their own survival.   So to conclude, the reason why terrorists haven't obtained nuclear weapons is because it is hard to obtain them (at least through development or gifting) and trying to do so would be a waste of resources.  edit: Note that I didn't adress the buying/stealing of nuclear weapons (which is relevant to the \"loose nukes\" question) as I forgot. I can not provide an answer that satisfies the criteria to that specific question, so I encourage someone in the know to adress that one."
  },
  {
    "prompt": "\n\nHuman: Theory Wednesday | January 22, 2014 Theory Wednesday topics include:  * Social science in academia  * Famous debates  * Questions about methods and data sources  * Philosophy of social science  * and so on.  Do you wonder about choosing a dissertation topic? Finding think tank work? Want to learn about natural language processing? Have a question about the academic applications of Marxian theories or social network analysis? The history of a theory? This is the place!  Like our other feature threads (Monday Reading and Research and Friday Free-For-All), this thread will be lightly moderated as long as it stays broadly on topics tangentially related to academic or professional social science.\n\nAssistant:",
    "golden_answer": " Recently, this article topped my front page feed through a post on /r/technology. Now I've been thinking about social networks and virtual communities for a long time. Recently I had a debate with a friend about the development of Facebook, and how it may eventually fade away. Our conclusion was that moves away from FB by users could be modeled by accounting for the following variables (applicable to those who are currently on FB):  1. The relative \"entrenchment\" of users - time on the website overall, average time weekly spent, amount of information posted (storage in bytes, mb, or gb).  2. The number of people they have \"friended\" who are heavy content creators (invocation of the supposed 1% rule.)  3. The number of strong relationships maintained through FB.  Now this is nothing academic - we didn't base our **very** rough \"model\" on previous studies, or collected data. We were just shooting the shit! The next day, I see this above article and I found it very interesting - these folks are taking a virus-spread epidemiological model (much more firmly established than conversation over beers). According to their lit review, application of the SIR model can be applied using Google Trends data to monitor and predict the relative life of a disease. In this instance, Facebook is the disease, and they want to use Google Trend data to predict its life.  They then go on to validate this approach by applying it to MySpace which has, as they argue, a \"..full life cycle.\" I love elegant, simple models - they tend to have broader reliability than adding in all the variables I suggested above. However this approach to me is reminiscent of the invasion-succession model in social ecology (adopted, of course, from biological life sciences). The model has some broad applications, but seems to lack nuance - showing weakness especially with regards to matters like gentrification and some rental patterns.  So, to the thoughts/questions I have for discussion: Is applying the SIR (their method specifically called irSIR) going to be a useful method for roughly estimating the life cycles of virtual social networks? What instances are there where this method may fall flat? Can this model be adjusted to incorporate \"stability\" effectively, or does its reliance on Search Trend Data limit its effectiveness? By stability, I am thinking of MySpace - it's still around, not nearly as big, but has a user population (no idea how static that number is, or how we would capably capture that). Does the irSIR model misleadingly suggest that the disease is more or less gone which in fact it is still around?  Finally, on theory nuance - predicting social diseases like FB (I'm sorry for the narrative language on this one, I admit to thinking of social developments as spreading viruses both funny but accurate on some level) - can a social disease like FB achieve a lot of saturation but maintain relatively high stability? For example, if the majority of 30+ users currently on FB **largely** maintain their presence for the next 20 years or so (controlling for attrition through natural processes), would the irSIR model still be useful in predicting its decline? It seems to rely on search trend data, so my thinking is not necessarily. In this instance, it seems like a more nuanced, researched model may yield broader insights into the spread of the disease itself.  Any thoughts on the irSIR model applied to FB would be appreciated. Ideas on how we could more capably model life cycle patterns in virtual communities in general would also be great."
  }
]