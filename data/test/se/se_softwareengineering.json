[
    {
        "prompt": "\n\nHuman: <p>...to prevent messing up with data updates, such as prices, titles, of the products that are placed in an order.</p>\n\n<p>Namely, a customer buys 3 items: for $5, $10 and $33 and pays for them. All is well. When I as an owner of a shop step in and, before I've delivered those products to a customer, decide to descrease the price of the product, say, #2. Its new price will be $8 instead of $10. And I'll also rename the product #3 a little bit. A customer then would go to a status tracking page and they'll see updated data. Yes, they've paid and the order is being delivered, but the data has already changed in the database.   They'll be consufed. </p>\n\n<p>And so will be I in a year after I'll have changed the prices again, renamed something, etc... and decide to view history of the orders for a year.</p>\n\n<p><strong>Question 1</strong>: is there a practise of making a snaphot of the current prices, names, total order price and other characteristics of the products that constitute an order, as well as other details (chosen shipping rate and shipping method, taxes, discounts, etc) at the moment when it's being placed? Rather than calculating those dynamically when an \"order page\" is opened?</p>\n\n<p>If yes, does it have a name? And are there recommendations of how to do it properly? </p>\n\n<p><strong>Question 2</strong>: where and how should I store a snaphot?</p>\n\n<p>option #1: </p>\n\n<p>I'd have to create multiple tables then:</p>\n\n<ul>\n<li>frozen_products</li>\n<li>frozen_discounts</li>\n<li><p>frozen_shipping_method_and_rates</p>\n\n<p>etc...</p></li>\n</ul>\n\n<p>that will have the <strong>same structure</strong> as their dynamics corresponding ones.</p>\n\n<p>Laborious. Is there a better way?</p>\n\n<p>option #2: </p>\n\n<p>along with an order, in the \"orders\" table. But how again, given the fact that an order is a single row? For instance, the products in an order is <strong>a list</strong>. How would I store a list with its characteristics (price, weight, colour, material, what have you) in a row in such a way that'll be more or less easy to retrieve in the future? Not as a string. </p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes, you are correct in needing a \"snapshot\" of the Product details at the time the sale is made. This technique as it related to SQL databases is often referred to as \"denormalization\".</p>\n\n<p>Basically, for whatever database element you have that represents a product of X quantity on order number Z, you'll copy the price/name fields into the row from the Product Catalog row at the time the sale is generated. That way, you will know for an older sale, what the product name/price were at the time of the sale, no matter what they are right now.</p>\n\n<p>An alternative some use instead of this is that the Product Catalog doesn't hold one price per item, but rather holds unchangeable rows representing the price/name at a specific datetime. So when they \"change\" the core product price, a new row with a 'starting' datetime of now gets inserted. Now, your Orders table doesn't need to be denormalized, it'll just have to know how to inspect the Product Catalog table to locate the name/price for that product on the same datetime as the order. Both approaches are valid although the denormalizing one is probably a bit simpler to implement. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm building at a Build and Deployment pipeline and looking for clarification on a couple points. In addition, I'm trying to implement Trunk Based Development with short-lived branches.</p>\n<p>The process I have thus far:</p>\n<ol>\n<li><p>Local development is done on the <code>main</code> branch.</p>\n</li>\n<li><p>Developer, before pushing to remote, rebases on remote <code>main</code> branch.</p>\n</li>\n<li><p>Developer pushes to remote short-lived branch: <code>git push origin main:short_lived_branch</code>.</p>\n</li>\n<li><p>Developer opens PR to merge <code>short_lived_branch</code> into <code>main</code>.</p>\n</li>\n<li><p>When PR is submitted it triggers the <code>PR</code> pipeline that has the following stages:</p>\n<ol>\n<li>Builds the microservice.</li>\n<li>Unit tests the microservice.</li>\n<li>If passing, builds the Docker image with a <code>test-latest</code> tag and push to container registry.</li>\n<li>Integration testing with other microservices (still need to figure this out).</li>\n<li>Cross-browser testing (still need to figure this out).</li>\n</ol>\n</li>\n<li><p>If the <code>PR</code> pipeline is successful, the PR is approved, commits are squashed, <code>short_lived_branch</code> is merged to <code>main</code> and <code>short_lived_branch</code> is deleted.</p>\n</li>\n<li><p>The merge to <code>main</code> triggers the <code>Deployment</code> pipeline, which has the following stages:</p>\n<ol>\n<li>Builds the microservice.</li>\n<li>Unit tests the microservice.</li>\n<li>If passing, builds the Docker image with a <code>release-&lt;version&gt;</code> tag and push to container registry.</li>\n<li>Integration testing with other microservices (still need to figure this out).</li>\n<li>Cross-browser testing (still need to figure this out).</li>\n<li>If passing, deploy the images to Kubernetes cluster.</li>\n</ol>\n</li>\n</ol>\n<p>I still have a ton of research to do on the integration and cross-browser testing, as it isn't quite clear to me how to implement it.</p>\n<p>That being said, my questions thus far really have to do with the process overall, unit testing and building the Docker image:</p>\n<ol>\n<li><p>Does this flow make sense or should it be changed in anyway?</p>\n</li>\n<li><p>Regarding unit testing and building the Docker image, I've read some articles that suggest doing the unit testing during the building of the Docker image in the <code>Dockerfile</code>. Basically eliminating the first two stages in my <code>PR</code> and <code>Deployment</code> pipelines. Some reasons given:</p>\n<ul>\n<li>You are testing the code and not the containerized code which is actually what will be run.</li>\n<li>Even if unit testing passes, the image could be broke and it will be even longer before you find out.</li>\n<li>Building on that, it increases the overall build and deployment time. From my experience, the first two stages in my pipelines for a specific service take about a minute and half. Then building and pushing the image takes another two and half minutes. Overall about four minutes. If the unit tests were incorporated into the Docker build, then it could possibly shave a minute or more off the first three stages in my pipeline.</li>\n</ul>\n<p>Would this be a bad practice to eliminate the code build and unit testing stages, and just moving unit testing into the Docker build stage?</p>\n</li>\n</ol>\n<p>Thanks for weighing in on this while I'm sorting it out.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Both</p>\n<h3>Unit Tests</h3>\n<p>Unit test are test for a small piece of code within a larger binary. These tests shouldn't care about the docker image or any other issue.</p>\n<p>Though as its intended to run within docker, within a given base image, it does stand to reason that you should run these tests within that platform to eliminate platform variability. But if there is platform variability its not your unit tests that you need to be looking at, but the platform itself.</p>\n<h3>Integration Tests</h3>\n<p>Integration tests are aimed at larger systems of code for example a deployable service. These tests require the environment to reflect the real one as much as possible, and as such they would apply to testing you code within its assembled docker image.</p>\n<hr />\n<p>As such you would:</p>\n<ul>\n<li>Checkout, and gather any other dependencies</li>\n<li>Build the binary executables and libraries from source</li>\n<li>Run unit tests to verify that the source is well-formed</li>\n<li>Build the docker image from the binaries just built</li>\n<li>Deploy the docker image</li>\n<li>Run the integration Tests against the running docker image, using as life-like an environment as possible</li>\n<li>Push the docker image into a repository for formal deployments.</li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Do you believe there is a gap between computer science research and software engineering problems?  For example, do software engineers ever have to worry about \"factoring and graph isomorphism\" or some complex computer science problems if they have to....say build a shopping cart website?  Probably not.</p>\n\n<p>And if there is a disconnect between computer science and the engineers that build applications?  Is that the way that engineering and science should exist?  Will engineers dive through years and years of research papers to solve a particular problem that they have? </p>\n\n<p>Edit-1: After thinking about it, general science probably has the same problem.  I am sure there are top chemists working at companies like McDonald's and Taco Bell that are tasked with making a better, easier to manufacture burger.</p>\n\n\nAssistant:",
        "golden_answer": " <p>In most software engineering positions, fundamental computer science problems rarely pop up, for one of two reasons:</p>\n\n<ul>\n<li>They have been solved by the tools you use. Examples are parsing algorithms for the programming language you use by your compiler, scheduling algorithms for the applications you run by the operating system, query resolution in the database you use, etc.</li>\n<li>They simply are not crucial to whatever you are trying to achieve. Not because they wouldn't help, but rather because the mundane automation task is much more important than the maximum optimized version.</li>\n</ul>\n\n<p>The reason so many software engineers are building information systems that are trivial from a theoretical point of view, is simply because they are needed. The way our world is currently automated is probably at less than 0.01% of what could be achieved. So for the coming decades we're probably just going to be building mostly information systems and interfaces. Once we have those, some fundamental problems will start popping up.</p>\n\n<p>These problems currently exist, for instance with regard to scalability, threading, etc. but they are simply an extremely small part of everything that needs to be done. So the reason companies are building relatively trivial information systems over and over is because (1) people need them and (2) it's much easier (and more lucrative) than solving fundamental problems.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Say I have the following data-structure describing a given widget sold by my company, which contains fields of purely atomic information (i.e. data that cannot be otherwise derived from other available fields).</p>\n<pre><code>my-widget = { &quot;widget-id&quot;: 1, &quot;amount-sold&quot;: 100, &quot;profit-per-sale&quot;: 0.2 }\n</code></pre>\n<p>Suppose that across my app(s), in addition to the information above, I might want frequent access to the total profit accrued from sales of the widget, calculated using</p>\n<pre><code>calc-total-profit(widget-info) = widget-info.amount-sold * widget-info.profit-per-sale\n</code></pre>\n<p>There are two approaches I see available:</p>\n<ol>\n<li>Merely call <code>calc-total-profit</code> whenever I need it, even though that may be with significant frequency.</li>\n<li>Append the result of <code>calc-total-profit</code> when I initially create the data-structure, and access it directly whenever its required.</li>\n</ol>\n<p>I feel like option 1 is more &quot;correct&quot; in that the data-structure ends up containing only the information it absolutely needs, and nothing else. Though it will result in perhaps slightly more crowded and repetitive code.</p>\n<p>On the other hand option 2 may result in code that is otherwise more parse-able. However, this is a simple example, and I could see one being able to justify multiple other calculated fields (for example: total-profits in different currencies), conceivably leading to data-structures that begin to &quot;bloat&quot;.</p>\n<p>I feel like this must be a well-tread dilemma, but I've perhaps been unable to pick out the correct search-terms; I would be interested in reading more about this topic if material/wisdom is available.</p>\n\n\nAssistant:",
        "golden_answer": " <p>The answer depends largely on the mutability of the structure.  If the values used to  create the calculation can change, then storing the computed result can be a source of bugs.  That is, you must ensure that it is recalculated when the inputs to the calculation are updated.  This is achievable but adds risk.  I would avoid it unless the cost of the calculation is high enough to justify the additional code and testing.  This is especially true if you are working in a multithreaded application.  Encapsulation is your friend if you need this optimization: you don't want to be searching around the code for all the places the data might be changed or worry about someone adding some new code that changes values and doesn't know about they need to recalculate the composed fields.</p>\n<p>However, if you are using an immutable data structure, there's really no risk with doing this.  I wouldn't bother if the cost of doing the calculation is very small but the effort associated with composed values on immutable structures is much lower.  You could either calculate this when the structure is created or lazily when it is access and store the result.  This is yet another reason why immutability is a very good thing.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In the project, I found a file, <code>math.c</code>, with a big GPL header and ...</p>\n\n<pre><code>//------------------------------------------------------------------------------\n/// Returns the minimum value between two integers.\n/// \\param a  First integer to compare.\n/// \\param b  Second integer to compare.\n//------------------------------------------------------------------------------\nunsigned int min(unsigned int a, unsigned int b)\n{\n    if (a &lt; b) {\n        return a;\n    }\n    else {\n        return b;\n    }\n}\n</code></pre>\n\n<p>OK, cool so I need to get min value and ... <strong><em>this file</em></strong>!? So I need to open the whole project because of it? Or do I need to reinvent mathematics?</p>\n\n<p>I don't believe it's just insane, so the question is: when we can just remove the GPL header?</p>\n\n<p>Must I <em>be a weirdo and do it</em>?:</p>\n\n<pre><code>unsigned int min(             unsigned int\nJEIOfuihFHIYEFHyigHUEFGEGEJEIOFJOIGHE,\nunsigned int hyrthrtRERG            ) {  if\n(JEIOfuihFHIYEFHyigHUEFGEGEJEIOFJOIGHE\n&lt; hyrthrtRERG            ) {  return JEIOfuihFHIYEFHyigHUEFGEGEJEIOFJOIGHE;  }\nelse {return hyrthrtRERG            ;    } }\n</code></pre>\n\n<p>Seriously, do they want me to write code like the above?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Unlike many of the user here, I would simply suggest: Copy it!</p>\n\n<p>Make sure the formatting of the code fits your coding standard and also you should probably remove or rewrite the comment. No one will ever know you copied it - when a piece of code is this simple, you might as well have written it from scratch. If your coding standard somehow requires the function to look exactly as it does in the snippet, so be it - as long as it looks as it would look if you had written it from scratch. </p>\n\n<p>Think about it, this is hardly(!) the first time this exact piece has been written - when something is this trivial, there is little reason not to copy it, if you do not feel like writing it yourself.</p>\n\n<p>Even having this discussion seems a little superfluous to me - we need to be pragmatic if we are to get any real work done!</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm looking to get a snapshot of Rails 3 at this point in time. We're about to start a new long term project, and I'm wondering if R3 is ready for real use. Or, if there are still a lot of bumps to be worked out. E.g. I saw questions about its compatibility with Passenger. (?)</p>\n\n<p>Thanks!</p>\n\n\nAssistant:",
        "golden_answer": " <p>Rails 3 is very much ready for production use. It's in use on big sites like <a href=\"http://www.shopify.com/\">Shopify</a> (you can read about their long path to Rails 3 here: <a href=\"http://blog.shopify.com/2010/11/16/our-upgrade-to-rails-3\">http://blog.shopify.com/2010/11/16/our-upgrade-to-rails-3</a>).</p>\n\n<p>I've recently upgraded my own Rails 2.3.x app to Rails 3, and it runs fine on Passenger. I didn't encounter any compatibility problems with Passenger 3 and the <a href=\"http://www.wego.com/\">site</a> has been running on Rails 3 + Passenger for about a month now with no problems.</p>\n\n<p>Since you're starting a new project, I'd <strong>strongly recommend</strong> you start on Rails 3 because frankly the upgrade to Rails 3 can be quite painful like Shopify's story.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm having difficulty grasping how to structure/architect a canvas application using an MVC like approach in Javascript. UI will be fairly fluid and animated, the games fairly simplistic but with heavy emphasis on tweening and animation. I get how MVC works in principle but not in practice. I've googled the buggery out of this, read an awful lot, and am now as confused as I was when I started.</p>\n\n<p>Some details about the application area:</p>\n\n<ul>\n<li>multi screen game framework - multiple games will sit within this framework\ncommon UI \"screens\" include: settings, info, choose difficulty, main menu etc.</li>\n<li>multiple input methods</li>\n<li>common UI elements such as top menu bar on some screens</li>\n<li>possibility of using different rendering methods (canvas/DOM/webGL)</li>\n</ul>\n\n<p>At the moment I have an AppModel, AppController and AppView. From here I was planning to add each of the \"screens\" and attach it to the AppView. But what about things like the top menu bar, should they be another MVC triad? Where and how would I attach it without tightly coupling components?</p>\n\n<p>Is it an accepted practice to have one MVC triad within another? i.e. can I add each \"screen\" to the AppView? Is \"triad\" even an accepted MVC term?!</p>\n\n<p>My mind is melting under the options... I feel like I'm missing something fundamental here. I've got a solution already up and running without using an MVC approach, but have ended up with tightly coupled soup - logic and views and currently combined. The idea was to open it up and allow easier change of views (for e.g. swapping out a canvas view with a DOM based view).</p>\n\n<p>Current libraries used: require.js, createJS, underscore, GSAP, hand rolled MVC implementation</p>\n\n<p>Any pointers, examples etc., particularly with regards to the actual design of the thing and splitting the \"screens\" into proper M, V or C would be appreciated.</p>\n\n<p>...or a more appropriate method other than MVC</p>\n\n<p><em>[NB, if you've seen this question before it's because I asked it in 2 other incorrect stackexchange communities... my brain has stopped functioning]</em></p>\n\n\nAssistant:",
        "golden_answer": " <p>MVC has been covered in so many places so there shouldn't be much to re-iterate here. Essentially you want your object graph, helpers, and logic to be contained in the model tier. The views will be the screens that get pushed out to fill the dynamic part of the page (and may contain a light amount of logic and helpers). And the controller, which be a lightweight implementation to serve the screens based on what was available from the object graphs, helpers, and logic.</p>\n\n<p><strong>Model</strong></p>\n\n<p>This should be where the meat of the application sits. It can be tiered out into a service layer, a logic layer, and an entity layer. What does this mean for your example?</p>\n\n<p><em>Entity layer</em></p>\n\n<p>This should house the definitions of your game's models and internal behaviors. For example, if you had a game for minesweeper, this would be where the board and square definitions were along with how they change their internal state.</p>\n\n<pre><code>function Location(x,y){\n this.x = x;\n this.y = y;\n}\nfunction MineTile(x,y){\n this.flagged = false;\n this.hasMine = false;\n this.pristine = true;\n this.location = new Location(x,y);\n}\nMineTile.prototype.expose = function(){\n if( this.hasMine ) return false;\n this.pristine = false;\n return this.location;\n};\n</code></pre>\n\n<p>So the MineTile will know its internal state, such as if it is showing or was examined (<code>this.pristine</code>), if it was one of the tiles that has a mine (<code>this.hasMine</code>) <em>but</em> will not determine if it was supposed to have a mine. That will be up to the logic layer. (To go even further into OOP, MineTile could inherit from a generic Tile).</p>\n\n<p><em>Logic layer</em></p>\n\n<p>This should house the complex ways that the application will interact with changing modes, keeping state, etc. So this would be where a mediator pattern would be implemented in order to maintain the state of the current game. This would be where the game logic resided for determining what happens during a game over for example, or for setting up which MineTiles will have a mine. It would make calls into the Entity layer to get instantiated levels based on logically determined parameters.</p>\n\n<pre><code>var MineSweeperLogic = {\n construct: function(x,y,difficulty){\n  var mineSet = [];\n  var bombs = 7;\n  if( difficulty === \"expert\" ) bombs = 15;\n  for( var i = 0; i &lt; x; i++ ){\n   for( var j = 0; i j &lt; y; j++ ){\n    var mineTile = new MineTile(i,j);\n    mineTile.hasMine = bombs-- &gt; 0;\n    mineSet.push(mineTile);\n   }\n  }\n  return mineSet;\n },\n mineAt: function(x,y,mineSet){\n  for( var i = 0; i &lt; mineSet.length; i++ )\n   if( mineSet[i].x === x &amp;&amp; mineSet[i].y === y ) return mineSet[i];\n }\n};\n</code></pre>\n\n<p><em>Service layer</em></p>\n\n<p>This will be where the controller has access to. It will have access to the logic layer for building the games. A high level call may be made into the service layer in order to retrieve a fully instantiated game or a modified game state.</p>\n\n<pre><code>function MineSweeper(x,y,difficulty){\n this.x = x;\n thix.y = y;\n this.difficulty = difficulty;\n this.mineSet = MineSweeperLogic.construct(x,y,difficulty);\n}\nMineSweeper.prototype.expose = function(x,y){\n return MineSweeperLogic.mineAt(x,y,this.mineSet).expose();\n}\n</code></pre>\n\n<p><strong>Controller</strong></p>\n\n<p>Controllers should be light weight, essentially this is what is exposed as the client to the model. There will be many controllers, so structuring them will become important. Controller function calls will be what the javascript calls hit based on UI events. These should expose the behaviors available in the service layer and then populate or in this case modify views for the client.</p>\n\n<pre><code>function MineSweeperController(ctx){\n var this.context = ctx;\n}\nMineSweeperController.prototype.Start = function(x,y,difficulty){\n this.game = new MineSweeper(x,y,difficulty);\n this.view = new MineSweeperGameView(this.context,this.game.x,this.game.y,this.game.mineSet);\n this.view.Update();\n};\nMineSweeperController.prototype.Select = function(x,y){\n var result = this.game.expose(x,y);\n if( result === false ) this.GameOver();\n this.view.Select(result);\n};\nMineSweeperController.prototype.GameOver = function(){\n this.view.Summary(this.game.FinalScore());\n};\n</code></pre>\n\n<p><strong>View</strong></p>\n\n<p>The views should be organized relative to the controller's behaviors. They will probably be the most intensive part of your application since it deals with canvasing.</p>\n\n<pre><code>function MineSweeperGameView(ctx,x,y,mineSet){\n this.x = x;\n this.y = y;\n this.mineSet = mineSet;\n this.context = ctx;\n}\nMineSweeperGameView.prototype.Update = function(){\n //todo: heavy canvas modification\n for(var mine in this.mineSet){}\n this.context.fill();\n}\n</code></pre>\n\n<hr>\n\n<p>So now you have your entire MVC setup for this one game. Or at least, a bare bones example, writing the whole game out would have been excessive.</p>\n\n<p>Once this is all done, there will need to be a global scope for the application somewhere. This will hold the lifetime of your current controller, which is the gateway to all of the MVC stack in this scenario. </p>\n\n<pre><code>var currentGame;\nvar context = document.getElementById(\"masterCanvas\").getContext('2d');\nstartMineSweeper.click = function(){\n currentGame = new MineSweeperController(context);\n currentGame.Start(25,25,\"expert\");\n};\n</code></pre>\n\n<hr>\n\n<p>Using MVC patterns are very powerful, but do not worry too much about adhering to every nuance of them. In the end, it is the game experience that will determine if the application is a success :)</p>\n\n<p>For consideration: <a href=\"http://www.joelonsoftware.com/articles/fog0000000018.html\" rel=\"nofollow\">Don't Let Architecture Astronauts Scare You by Joel Spolsky</a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Coming from the world of C and C++, most build system have an <code>install</code> target, notably Makefiles (where it is <a href=\"https://www.gnu.org/prep/standards/html_node/Standard-Targets.html\" rel=\"noreferrer\">recommended by GNU</a> for example) or <a href=\"https://cmake.org/cmake/help/latest/command/install.html\" rel=\"noreferrer\">CMake</a>. This target copies the runtime files (executables, libraries, ...) in the operating system (for example, in <code>C:\\Program Files\\</code> on Windows).</p>\n\n<p>This feels really hacky, since for me <strong>it is not the responsibility of the build system to install programs</strong> (which is actually the responsibility of the operating system / package manager). It also means the build system or build script must know the organization of installed programs, <em>with environment variables, registry variables, symlinks, permissions, etc.</em></p>\n\n<p>At best, build systems should have a <code>release</code> target that will output an installable program (for example <code>.deb</code> or <code>.msi</code>), and then kindly ask the operating system to install that program. It would also allow the user to uninstall without having to type <code>make uninstall</code>.</p>\n\n<p>So, my question: <strong>why do build system usually recommend having an <code>install</code> target?</strong></p>\n\n\nAssistant:",
        "golden_answer": " <p>Many build scripts or Makefiles have an installation target because they were created before package managers existed, and because even today lots of systems don't have package managers. Plus, there are systems where <code>make install</code> actually <em>is</em> the preferred way of managing packages.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Python's lack of pointers makes data-structure construction intuitively more challenging, and has so much built in functionality that, as an amateur, I can't see when, why, or how you would create something beyond what's already there.</p>\n\n<p>When have you built your own, and why did you do it? E.g. special types of trees, etc.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Well, that kind of depends on what you are willing to call a \"data structure.\" According to Wikipdia, a data structure is simply a \"particular way of storing and organizing data in a computer so that it can be used efficiently.\" So, therefore, classes would be a form of data structure, and classes are very widely used in Python. But, for the sake of this answer, I will assume you are more interested in what you might learn about in a data structures and algorithms class (e.g. trees, linked lists, queues, hashes, etc...).</p>\n\n<p>Now, because of Python's pseudo-code-like syntax it can be a very useful language for implementing data structures in. If for no other purpose than just to aid in understanding these basic concepts. For example, when I first learned about linked list I decided to implement them in Python:</p>\n\n<pre><code>class node:\n    def __init__(self, data = None, is_header = False):\n        self.data = data\n        self.next = None\n    def __str__(self):\n        return \"|{0}| --&gt; {1}\".format(str(self.data), str(self.next))\n\n\nclass linked_list:\n    def __init__(self):\n        self.header = node(\"!Header!\", True)\n\n    def add_node(self, add_me):\n        current_node = self.header\n        while 1:\n            if current_node.next == None:\n            current_node.next = add_me\n            break\n            else:\n            current_node = current_node.next    \n\n    def print(self):\n        print (str(self.header))\n</code></pre>\n\n<p>Now, this isn't a perfect example, nor is it even a totally proper implementation of a linked list, but it goes to illustrate something: </p>\n\n<p><em>Python's simple syntax can be helpful in understanding data structures</em></p>\n\n<p>Another example would be a priority queue that I built back in the day:</p>\n\n<pre><code>class priority_queue:\n    def __init__(self):\n        self.element = []\n        self.priority = []\n\n    def enqueue_with_priority(self, me, priority):\n        where = 0\n        for i in range(len(self.element)):\n            if not priority &lt; self.priority[i]:\n            where = i\n            break\n\n        self.element.insert(where, me)\n        self.priority.insert(where, priority)\n\n    def dequeue_highest(self):\n        return self.element.pop(0)\n\n    def print(self):\n        for i in self.element:\n            print i\n</code></pre>\n\n<p>Again, not a perfect implementation but it illustrates another benefit of coding a data structure in Python:</p>\n\n<p><em>Python is useful in prototyping data structures to optimize them for lower-level programming languages</em></p>\n\n<p>Looking back on this code I see flaws in my implementation. The Python code, however, tends to be short and sweet. So if I wanted to implement a data structures in a lower-level language (such as a c-style language) I could first generate a quick Python prototype and then optimize later. </p>\n\n<p>Finally, I think Python can help in the development of data structures, because:</p>\n\n<p><em>In Python, development is quick, mistakes are allowed and you can try things out.</em></p>\n\n<p>Imagine you are building a hash-table-like data structure, in a strongly-typed, compiled language you would usually try things out in an IDE, then have to compile and run it. In Python, you can just pull up IDLE, iPython or the Python interpreter and just try things out! No need to recompile for each little change to the hash function you want to try -- just plug it into the interpreter.</p>\n\n<p>So, in conclusion, I guess what I'm saying is that I agree with you: there's not a lot of <em>practicality</em> in building your own data structures (since most anything you may want has already been implemented and optimized). However, for me, there is a lot of educational benefit (because of Python's ease of syntax), as well as a lot of creative and developmental freedom (due to Python's low-constraint, <a href=\"http://docs.python.org/2/glossary.html\" rel=\"nofollow\">EAFP</a> design).</p>\n\n<p>It is important to note that although python (through its wide-reaching library) provides many standard data structures, a \"data structure\" (by definition) can be almost anything. So, in Python as well as any other language we may use to solve non-trivial problems, we are going to need to define new data structures. Therefore, it is quite arguable that serious Python developers create custom data structures just as much as serious developers in other languages do.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm trying to decide whether to extend a base interface with additional methods or create several independent interfaces. I have a <code>Task</code> interface that looks like this</p>\n\n<pre><code>interface Task\n{\n    public function name();\n    public function run(array $args);\n}\n</code></pre>\n\n<p>Now I want to add optional <code>description</code> and <code>dependencies</code> methods. Should I create a new <code>DetailedTask</code> interface like this?</p>\n\n<pre><code>interface DetailedTask extends Task\n{\n    public function description();\n    public function dependencies();\n}\n</code></pre>\n\n<p>This way I could choose to implement either the base <code>Task</code> interface for a basic task class, or the <code>DetailedTask</code> interface if I needed a description and dependencies. Alternately I could create separate interfaces for the extra methods like this.</p>\n\n<pre><code>interface Describable\n{\n    public function description();\n}\n\ninterface TaskDependent\n{\n    public function dependencies();\n}\n</code></pre>\n\n<p>According to the interface segregation principle, the second is better because it is more flexible. However, I don't ever anticipate using <code>Describable</code> and <code>TaskDependent</code> on anything besides a <code>Task</code> instance. The extra interfaces just seem to add extra complexity. Which technique should I use?</p>\n\n\nAssistant:",
        "golden_answer": " <p>First of all, with your question details:</p>\n\n<blockquote>\n  <p>Now I want to add optional description and dependencies methods.</p>\n</blockquote>\n\n<p>If you want an optional method, then you should not go for interface, because as per interface rules, you MUST need to define methods in implementation class. See <a href=\"http://php.net/manual/en/language.oop5.interfaces.php\" rel=\"nofollow\">PHP interface</a>.</p>\n\n<p>So according to that rule, your first solution will not work because if you define class that implements <strong>DetailedTask</strong>, then that class must define both method <strong>description</strong> and <strong>dependencies</strong>.</p>\n\n<p>The second way will give you freedom to choose whatever interface you want to implement.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>For example</p>\n\n<pre><code>class A \n{\n    public int data1 {get; set;}\n    public int data2 {get; set;}\n}\nclass B \n{\n    public A objectA;\n}\nclass C\n{\n    public B objectB;\n}\nclass D\n{\n    public C objectC\n}\nclass E\n{\n    public D objectD;\n}\n\nclass Caller\n{\n    public void foo(E input)\n    {\n        var bar = input.objectD.objectC.objectB.objectA;\n\n        // code that looks nice\n        if (bar.data1 == 1)\n        {\n            // do something\n        }\n\n        // code that looks nice again\n        if (bar.data2 == 2)\n        {\n            // do something again\n        }\n\n        // but why?\n        if (input.objectD.objectC.objectB.objectA.data1 == 0)\n        {\n        }\n    }\n}\n</code></pre>\n\n<p>Just for the sake of getting my point across, here is an example call for a property that is nested deep within an inner class. Surely a class that requires such a deep call to get into data requires refactoring. But as an example of what I'm trying to say consider class E who has a property of class D which references down to other class up to class A which holds the data we need.</p>\n\n<p>To avoid typing a long winded call to objectA coming from class E, I store objectA into a variable. If the object is only to be used within the scope of a few lines would it be a waste of memory? Aside from making it easier to type, readable, or maybe even maintainable; what other merits are there?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You can use local variables as much as you like.  They are super cheap (basically totally free) and offer an opportunity to document (by choosing a meaningful name) what you are doing.  </p>\n\n<p>Personally, I like local variables, as I find they increase readability and tend to facilitate debugging &#8212; you can quickly see their values during single stepping, and when exceptions happen, shorter expressions setting local variables help narrow them down.</p>\n\n<p>However, some find this highly annoying and prefer to repeat expressions rather than collect information in local variables.  They might say, why are you capturing this value in a local variable -- are you expecting it to change (and want to work only with the original value)?? </p>\n\n<p>There is sometimes merit to these arguments, but I tend to disagree with them.  When I see repeated uses of complex expressions, I ask the same question from another orientation: why did the programmer keep repeating the same expression -- are they expecting it to change (and want to work each time with the new value)??  </p>\n\n<p>Many algorithms won't work if certain values change within a few lines of code; though fortunately, it turns out that they typically don't so this isn't as big a problem as we might make out, and perhaps it is more a matter of style, I think, as to use of local variables vs. repeating yourself.</p>\n\n<p>(Please note that the above advocates use of local variables as temporaries, but not additional fields as temporaries.)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Here is a theoretical problem.  It could apply to many systems.  Let's assume RESTful Web services for example.  You want to find out something but as it happens you can't get it in a single query.  You can make multiple queries.  For example, you have a joint bank account (or a company bank account) and you want to find out how much money is in there.  Meanwhile someone else transfers money from checking to savings.</p>\n\n<pre><code>Checking:  $5,000   Savings:  $3,000\n</code></pre>\n\n<blockquote>\n  <p>Me:  Query Checking.    Response: $5,000</p>\n</blockquote>\n\n<p>&nbsp;</p>\n\n<blockquote>\n  <p>Joe:  Transfer $4,000 from Checking to Savings</p>\n</blockquote>\n\n<pre><code>Checking: $1,000   Savings:  $7,000\n</code></pre>\n\n<p>Me:  Query Savings.  Response:  $7,000</p>\n\n<p>Total $12,000.</p>\n\n<p>How do you avoid anomalies like this?  The example shows two accounts at one bank, but it can also happen with two accounts at two different banks. </p>\n\n\nAssistant:",
        "golden_answer": " <p>You need some form of concurrency control to deal with problems like this.</p>\n\n<p>Some possible solutions in your example:</p>\n\n<ol>\n<li>Ensure that the service can return both Savings and Checking figures in a single query, perhaps as a Total.</li>\n<li>Implement some kind of session so that the user requesting values can lock the data until she has finished reading all the values in which she is interested. This approach is often called \"pessimistic concurrency control\".</li>\n<li>Design the service so that you can pass your previous Checking figure back when you request a Savings figure. If the Checking figure no longer matches its previous value, the service should indicate an error rather than return a value for Savings. This approach is a variation of \"optomistic concurrency control\".</li>\n</ol>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am working on the frontend of a product, and it is now broken due to bad data from the backend.</p>\n\n<p>This can be caught internally before it gets anywhere close to production, but we end up fiddling with our fingers as the backend is being fixed. (Hence why I'm here...)</p>\n\n<p>I have some hackish fix that does a sanity check, in this particular instance, on the data being received; does this imply I have to do a check for <em>all</em> data?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Honestly, how much do you trust the data from the backend after the actual experience? I guess not 100%, so adding some additional checks might be worth it to catch some potential bugs.</p>\n\n<p>However, we do not know your product, we do not know what happens when your frontend gets broken, and what financial risk is at stake when your users see the kind of error message your product shows now with \"bad data\". We also do not know if your product becomes totally unusable, or if only a minor feature of your product does not work. We also do not know if sanitizing \"all data\" means only a few hours of additional work, or a three months delay in delivery. But <strong>these are the factors you have to consider</strong> when asking yourself \"shall I add only a few checks\" or \"shall I sanitize all input data like hell\". </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am trying to break down a large application so that multiple teams can work on it.  I have created a number of Bounded Contexts for the domain layer.  Each bounded context is contained in its own solution with an Infrastructure layer and a Service Layer.  There is one repository per aggregate root.</p>\n\n<p>How do you deal with the User Interface layer? Please see this article here: <a href=\"http://arunendapally.com/post/how-to-use-a-mvc-area-in-multiple-applications\" rel=\"nofollow noreferrer\">http://arunendapally.com/post/how-to-use-a-mvc-area-in-multiple-applications</a>.  Say I have three bounded contexts.  Is it normal to split the UI into three MVC areas.  Each area would represent a bounded context.  Therefore the team developing bounded context 1 would also develop Area 1.  Is it normal to do this:</p>\n\n<p>1) Team 1 develop Area 1, which references the main MVC5 app</p>\n\n<p>2) Team 2 develop Area 2, which references the main MVC5 app</p>\n\n<p>3) Team 3 develop Area 3, which references the main MVC5 app</p>\n\n<p>Is it normal to map Areas to Bounded Contexts like this? If the answer is no, then how do you break down the User Interface layer (MVC) so that multiple teams can work on it?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>Is it normal to map Areas to Bounded Contexts like this?</p>\n</blockquote>\n\n<p>Common sense typically would tell us that architectural decisions like the split-up of a system into \"Bounded Contexts\" should be driven by the requirements of a system. However, it is indeed quite normal that software designs follow much more the communication structure of the organization who creates that design. The name for this is <strong><a href=\"https://en.wikipedia.org/wiki/Conway%27s_law\" rel=\"nofollow noreferrer\">Conway's Law</a></strong>, and it is about 50 years old.</p>\n\n<p>This is not necessarily a bad thing as long as it works for you and your organization in context of your current project. However, keep in mind that some tasks can be solved better by adopting the team's structure to the task instead of doing it the other way round.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm currently writing a job requirement for a software engineer position for my company, in which we are looking for a developer to work on client-side web application work. How should I title the job title / position? I don't necessarily want to call it a \"Web Developer\", for fear that it might attract more designer-y types. On the other hand, \"Software Engineer\" doesn't really give the indication that the work, while application based, will be web-based. Is \"Web Application Software Engineer\" a valid position title?</p>\n\n<p>Also, I'm somewhat torn on what the required skills set should be. I don't necessarily think that the ideal candidate should have x years of experience in say, JavaScript or ActionScript, but rather am just looking for someone who has experience in developing client-side applications, and is willing to learn and develop web applications. My current attempt at this, is that I have a section in which I state:</p>\n\n<blockquote>\n  <p>Experience in the following frameworks\n  and technologies are a plus, but not\n  necessarily required for the position:</p>\n</blockquote>\n\n\nAssistant:",
        "golden_answer": " <p>I think stating what you are looking for in English is better than listing years of experience in specific technologies.  List the qualities of your ideal candidate and a description of what you would be expecting from them on a daily basis.  This would give potential candidates a much better idea of what the job will be like rather than guess based on the technologies involved.</p>\n\n<p>As far as a title that might depend a little on where you are located.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm implementing a simple command line game using TDD principles and Unit Testing. My goal is to implement the whole game using Test-First Programming, so every behaviour/class is created from a test.\nI've already implemented things like a Player (the game needs a player), the Enemy (the player fights the enemy) and other stuff but now that I have to implement the Game logic itself, which actually takes all these classes and combines them together to achieve the functionality, I'm stuck. \nThe problem is that the Game itself should just expose a Run() method and nothing more. This is because it's the game itself that runs its logic and not someone else from the outside that tells it what to do.</p>\n\n<p>Here is some pseudo-code,</p>\n\n<pre><code>class Game\n{\n    Game(Player p, EnemyFactory f)\n    {\n       this._player = p;\n       //and so on...\n    }\n\n    public void Run()\n    {\n       // All the game logic goes here\n       // In example:\n       int totalEnemies = 5;\n       while(_player.IsAlive &amp;&amp; totalEnemies &gt; 0)\n       {\n           Enemy enemy = _enemyFactory.CreateEnemy();\n           _player.Fight(enemy);\n           // other stuff\n           totalEnemies--;\n       }\n\n       GameOver();\n    }\n\n    private GameOver()\n    {\n       //other stuff\n    }\n}\n</code></pre>\n\n<p>As you can see, the main logic is inside the Run function, which makes sense to expose as public, so that the Main() function that creates a Game class also calls Run(), but since all the logic will be a bunch of private functions, how do I create it from the tests first?\nThe only thing that comes to my mind is or to use Mock, which I really don't want to do, or to expose some public functionality, but I don't want to create public behaviours that will be called only from the tests, because it's not a good practice.</p>\n\n<p>Any idea please?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n<p>I'm implementing a simple command line game</p>\n</blockquote>\n<p>I frequently use this as a starting point for TDD exercises.  It's a really good choice, as it forces you to discover important distinctions between logic and effects.</p>\n<blockquote>\n<p>As you can see, the main logic it's inside the Run function, which makes sense to expose as public, so that the Main() function that creates a Game class also calls Run(), but since all the logic will be a bunch of private functions, how do I create it from the tests first?</p>\n</blockquote>\n<p>Your program is going to have a natural break between two parts - I/O and logic.  Testing I/O is harder - it lives higher up the <a href=\"https://martinfowler.com/articles/practical-test-pyramid.html\" rel=\"nofollow noreferrer\">test pyramid</a> than the logic tests.  This is in part because the IO system tends to be shared; you can't as easily run two tests concurrently without them interfering with each other.</p>\n<p>So you are likely to end up with some tests that look like</p>\n<pre><code>cat input | my-game &gt; actualOutput\ndiff actualOutput expectedOutput\n</code></pre>\n<p>If you read <em>Growing Object Oriented Software, Guided By Tests</em>, you find that Freeman and Price will talk about dedicating their initial work to a test like this run as part of their build/deploy pipeline.  It won't be a fancy implementation of the game yet (think hello world), but it will be enough to demonstrate that the project delivery system works.</p>\n<p>Moving down the pyramid, we're going to find some tests that use <a href=\"https://martinfowler.com/bliki/TestDouble.html\" rel=\"nofollow noreferrer\">test doubles</a>; in this case, a &quot;stub&quot; or a &quot;fake&quot; for STDIN and a &quot;mock&quot; or &quot;spy&quot; for STDOUT.  So imagining an implementation of <code>Game.main</code>, it might look like:</p>\n<pre><code>void main (String [] args) {\n    Game.run(System.in, System.out);\n}\n</code></pre>\n<p>or</p>\n<pre><code>void main (String [] args) {\n    Game g = new Game(System.in, System.out);\n    g.run();\n}\n</code></pre>\n<p>You don't normally try to &quot;unit test&quot; this <code>main</code> method, because it is directly coupled to the shared instances of STDIN and STDOUT.  Instead, the unit tests will measure the behavior of <code>run</code> using test doubles.  We'll be asserting on information collected by the implementation of STDOUT that we provide during the test.</p>\n<p>This is an important idea in TDD - we've deliberately designed the interface of game such that it can be tested in a more cost effective way.</p>\n<p><a href=\"https://blog.thecodewhisperer.com/permalink/beyond-mock-objects\" rel=\"nofollow noreferrer\">J. B. Rainsberger wrote</a>:</p>\n<blockquote>\n<p>If we want to introduce indirection, then we ought to introduce the smallest indirection possible. And we absolutely must try to introduce better abstraction.</p>\n</blockquote>\n<p>What we've done here is introduce a <em>seam</em>, which is the indirection that gives us control of the subject in the test environment.  What we want to be discovering as we iterate on the internal design is better abstractions.</p>\n<p>Note that, to this point, we haven't really done anything to introduce <code>Player</code>, <code>Enemy</code>, or any of the other domain abstractions that we expect to use.  Those concepts are things that we expect to discover and extract during the refactoring step.  Once you have discovered them, and feel that their API is sufficiently stable, you can start writing tests that specifically measure those elements.</p>\n<p>Which is to say, the tests of the Game, working seam to seam, tend to be too big, in this sense: they span a lot of distinct behaviors.  Because there are so many behaviors within the scope of the test, those tests tend to be &quot;brittle&quot;; we decide one little bit of behavior should be slightly different, and the entire test falls over.</p>\n<blockquote>\n<p>The only thing that comes to my mind is or to use Mock, which I really don't want to</p>\n</blockquote>\n<p>Well, then lets go a level deeper; STDIN and STDOUT are sources of <em>messages</em> to and from the IO System.  From a very high level, we have some thing like</p>\n<pre><code>String [] lines = read(this.stdin)\nString [] output = this.gameLogic(lines)\nwriteTo(this.stdout, output)\n</code></pre>\n<p><code>gameLogic</code> here doesn't depend on the IO system at all; it only cares about the data structure passed to it.  So you can test everything that is interesting and unique about your game in memory, without needing to worry about the IO system at all.</p>\n<p>You probably wouldn't choose this API, because we like to think of games being interactive.  Instead, you'd probably end up with something like a state machine</p>\n<pre><code>while(game.running) {\n    String line = nextLine(this.stdin)\n\n    game.onLine(line)\n    String output = game.output()\n\n    writeTo(this.stdout, output)\n}\n</code></pre>\n<p>Again, that middle section is just passing in memory data structures into and out of the game logic that you actually care about.  You &quot;discover&quot; this sort of API while iterating on the design that uses the mocks, but once this API is stable you can start writing tests directly against the API.</p>\n<p>Gary Bernhardt's <a href=\"https://www.destroyallsoftware.com/talks/boundaries\" rel=\"nofollow noreferrer\">Boundaries</a> talk is a great introduction to this concept.</p>\n<p>From this point, it's turtles all the way down; you continue to add new tests for desired behavior, and iterate on your internal design, and as concepts like <code>Player</code> and <code>Enemy</code> begin to stabilize, you start writing even smaller tests directly against those elements.</p>\n<blockquote>\n<p>you are saying that I started from the &quot;smaller&quot; classes that are composing the Game, instead of starting from the Game itself. I agree, I did that because I was stuck with this Run() problem.</p>\n</blockquote>\n<p>Right.  And to be fair, a <em>lot</em> of TDD literature starts from the inside and works outwards -- the members of the &quot;Detroit school&quot; already had the habits to separate the domain model from the plumbing, so they had a tendency to start from the middle.</p>\n<blockquote>\n<p>The other thing you are suggesting is basically use an external logic passed through the game (that can be mocked) to see if the game behaves in a certain way based on what is set on that logic.</p>\n</blockquote>\n<p>No, I'm not suggesting that; although I will admit that it <em>works</em>.  What I'm actually suggesting is slightly different -- that if you have the right arrangement of tests, you can iterate on your internal design until you have a &quot;CLI Framework&quot; component and a core game logic component.  The framework will be something that you can re-use for your next CLI app; the game logic will be something you can re-use when you decide your game should be accessible via a web api.</p>\n<p>What I have found, in practice, is that as you become familiar with the basic isolation patterns, you tend to start &quot;closer&quot; to the interesting bits.  So, for instance, if I'm writing an interactive CLI game, or a pipes-and-filters component, then I will just jump right past all of the plumbing tests and write the API signature straight from my head.</p>\n<p>On the other hand, as soon as you introduce something like &quot;we also need to be able to save and load games from the file system&quot;, I need to zoom out a few layers and work my way back inwards more slowly, with more tests to reach my confidence threshold.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a method that looks like this:</p>\n\n<pre><code>Public Function NormalizeStreetAddress(country As Namespace.Country,\n                                       streetAddress As Namespace.StreetAddress) _\n                                   As Namespace.StreetAddress\n\n        Dim _streetAddress As New Namespace.StreetAddress = streetAddress\n\n        If My.Settings.Streeteable = True Then\n            Dim _AddressCustom As New Namespace.AddressCustom\n            _streetAddress = _AddressCustom.NormalizeStreetAddress(country, streetAddress)\n        End If\n        Return _streetAddress\nEnd Function\n</code></pre>\n\n<p>I receive a streetAddress object, but inside the method I need to use another streetAddress object which I called _streetAddress&nbsp; is that following the standard? A friend of mine told me that object names such as _yourNameObject are for global variables, but I can't find info about this and I want to make this method more readable.</p>\n\n\nAssistant:",
        "golden_answer": " <p>The names of the variables must be explicit, i.e., when possible, the reader must know what is the variable just by looking at its name.</p>\n\n<p>If you have both <code>streetAddress</code> and <code>_streetAddress</code> in the same code, there is a huge problem. Since the two variables are referring to something different, they should have different names.</p>\n\n<p>Keeping both names is not only confusing, but extremely error prone. Would you be able to immediately make the difference between those two variables in six months when modifying some code in the middle of the method? If you type the wrong name and the program fails, would you be able to immediately see in the debugger where the error comes from?</p>\n\n<p>What about:</p>\n\n<pre><code>Public Function NormalizeStreetAddress(country As Namespace.Country,\n                                       streetAddress As Namespace.StreetAddress) _\n                                       As Namespace.StreetAddress\n\n    If My.Settings.Streeteable = True Then\n        Dim _AddressCustom As New Namespace.AddressCustom\n        Return _AddressCustom.NormalizeStreetAddress(country, streetAddress)\n    Else\n        Return streetAddress\n    End If\nEnd Function\n</code></pre>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm currently using an open source project called <a href=\"http://codefirstmembership.codeplex.com/\">CodeFirstMembership</a> for one of my projects.  There's a critical issue that I need to get past, and the more I use it, the more I find things I need to modify.  It's extremely useful, except it doesn't look like the developer has much time to update it (totally cool, we've all been there).  I'm wondering about the etiquette and legality and general \"hey, you stole my code you jerk\" responses I'd get if I copied the source, moved it to github and made my own fork.</p>\n\n<p>On Github, we do this all the time, forking projects, but it FEELs less jerk-ish because there's a connection to the original.  Is there anything wrong with me doing this, whether legal or otherwise since there's no copyright notice or license associated with this library?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You can just fork it, send an email letting the original author know as a kindness. But you have to remember that the author has already told you you can copy it and modify it. No developer truly wants his code to bitrot. If you're lucky your modifications will be pulled back in.</p>\n\n<blockquote>\n  <blockquote>\n    <p>\"Grant of Rights</p>\n    \n    <p>(A) Copyright Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free copyright license to reproduce its contribution, <strong>prepare derivative</strong> works of its contribution, and distribute its contribution or any derivative works that you create.\"</p>\n  </blockquote>\n</blockquote>\n"
    },
    {
        "prompt": "\n\nHuman: <p>First of all, yes I'm aware of PEP8 and the <a href=\"https://stackoverflow.com/questions/20762662/whats-the-correct-way-to-sort-python-import-x-and-from-x-import-y-statement/20763446#20763446\">alphabetical method</a>.</p>\n\n<p>I do sort my imports first by the <a href=\"https://www.python.org/dev/peps/pep-0008/#imports\" rel=\"noreferrer\">PEP8 recommendation</a>:  </p>\n\n<blockquote>\n  <ol>\n  <li>standard library imports  </li>\n  <li>related third party imports  </li>\n  <li>local application/library specific imports</li>\n  </ol>\n</blockquote>\n\n<p>But then, within each category, I like to sort by the length of the module name. Yes, it makes it look pretty, but then I find it arguably makes it easier to find a module than the alphabetical way.</p>\n\n<p>Also, the shorter names tend to be the more basic, common modules (like <code>os</code> and <code>sys</code>), so there's an additional organization layer in that way. You know the length of the name you're looking for, and the visual shape of the import list tells you very quickly where to look for names that long.</p>\n\n<p>An example:</p>\n\n<pre><code>import os\nimport sys\nimport time\nimport logging\nimport argparse\nimport subprocess\n\nimport django\nimport requests\nimport webencodings\n\nimport mymodule\nimport localthing\nimport supercustomstuff\n</code></pre>\n\n<p>Right now I mostly write for myself, and I don't work with a team. But I intend to in the future. So what I'm wondering is, does anyone else do this, does anyone else see the sense in it, or will everyone else think I'm nuts?</p>\n\n<p><strong>Edit</strong>: Separate subgroups in example, as suggested by Mark Ransom, in order not to distract from the core issue about the ordering. </p>\n\n\nAssistant:",
        "golden_answer": " <p>First, I would say to do what works for you on your own projects. Its not going to hurt anything and it helps you, so its a win!</p>\n\n<p>For projects with others I would discuss it with the team. Often a team will have a style guide that they expect developers to follow. Other times they allow every developer to do their own thing. I would advise following what others on your team do. </p>\n\n<p>Personally, your system seems arbitrary to me and quite odd. Others probably have systems they use for equally arbitrary reasons. I dont feel like yours would help me in general. I have to wonder how much it helps when the module names are all close in length? At least with alphabetic (which is also not my favorite) I know to use the first 2 letters when two files start with the same letter.</p>\n\n<p>Also, Im not sure about Python but in some languages, if developers arent careful, import order can change the behavior of a program. (That shouldnt be the case and it shouldnt be relied on, but the reality is that it happens.) </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p><em>Just to be clear, by authentication I don't mean user-authentication, but I want to make sure that my app is running on the customer's server and in a defined time-span.</em></p>\n\n<p>Some of our customers use our web apps in their Intranet and on their own servers, on the other hand some of them use Hosting services and they don't own any server machine.</p>\n\n<p>With that said, I'm looking for ways to make sure about customer's Identity. I don't want them to be able to xcopy the app, also I'd like to have some kind of time-expiration limit.</p>\n\n<p>In traditional desktop apps we could use USB security tokens, but their not usable with hosting providers.</p>\n\n<p>It seems that we have to make a central authentication server. I'm a little confused about possible options, so any suggestion about where to start is welcome.</p>\n\n\nAssistant:",
        "golden_answer": " <p>This is a very complex thing. What you need is a licensing mechanism where you create for example a key based on unique system information like servername, mac address, company name, cpu id, etc. You can also have a compbination of those information. After that you need to create a \"key generator\" and in your software read this information, verify on each startup if they are identical and run the software. Additionally you can add a time information for the expiration date, or days which the user can use your app.</p>\n\n<p>But (and this is my personal opinion) you dont need to develop a super complex licensing mechanism. Nearly everthing is breakable. The question is: is your software worth to put so much effort in cracking your licensing mechanism? Is you app designed for small, mid size or large companies? How expensive is your app?</p>\n\n<p>Here is an <a href=\"https://stackoverflow.com/questions/16222674/software-license-key-and-activation\">SO article</a> on that. Search for 'licensing', 'software licensing [development language]' , 'key generator' ... </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Say I have have a class <code>Event</code> as follows:</p>\n\n<pre><code>class Event {\n    private var attendees: [Person] = []\n\n    // Case 1\n    //*******\n    // Should I use a func\n    func countOfAttendees() -&gt; Int {\n        return attendees.count\n    }\n\n    // or a var\n    var countOfAttendees: Int {\n        return attendees.count\n    }\n\n    // Case 2\n    //*******\n    // Should I use a func\n    func countOfPaidAttendees() -&gt; Int {\n        return attendees.filter({$0.hasPaid}).count\n    }\n\n    // or a var\n    var countOfPaidAttendees: Int {\n        return attendees.filter({$0.hasPaid}).count\n    }\n}\n</code></pre>\n\n<p>Is it best practice to use <strong>functions</strong> or <strong>computed properties</strong> in the 2 cases indicated above?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Follow the <a href=\"https://en.wikipedia.org/wiki/Uniform_access_principle\" rel=\"noreferrer\">Uniform Access Principle</a>, </p>\n\n<blockquote>\n  <p>All services offered by a module should be available through a\n  uniform notation, which does not betray whether they are implemented\n  through storage or through computation</p>\n</blockquote>\n\n<p>To me, this means that I don't write funcs that take no arguments and return a value. I always use computed properties. That way, if I later decide to change the computed property into a stored property, I can do so without having the urge to remove the parens everywhere in my app and without having a separate \"getter\" method that just returns the value of a stored property, which seems pretty wasteful IMHO.</p>\n\n<p>And if I change a stored property into a computed one, I don't have to add parens to the end of it, and everywhere that it is used in the app.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have two ideas on how to proceed with an availability class but I'm not sure which one is better.</p>\n\n<pre><code>public class TimeRange {\nprivate Timestamp startTime;\nprivate Timestamp endTime;\n\npublic TimeRange() {\n    //set defaults\n}\n// appropriate getters\n//setters\npublic void setStartTime(Timestamp startTime) {\n    this.startTime = startTime;\n}\n\npublic void setEndTime(Timestamp endTime) {\n    this.endTime = endTime;\n}\n// some code that validates the object is in a valid state.\n}\n</code></pre>\n\n<p>First Idea:</p>\n\n<pre><code>public class WeeklyAvailabilities {\nprivate TimeRange mondaySlot;\nprivate TimeRange tuesdaySlot;\nprivate TimeRange wednesdaySlot;\nprivate TimeRange thursdaySlot;\nprivate TimeRange fridaySlot;\nprivate TimeRange saturdaySlot;\nprivate TimeRange sundaySlot;\n\npublic WeeklyAvailabilities() {\n   // set defaults\n}\n// some getters and such\npublic void setMondayStartTime(Timestamp start) {\n   mondaySlot.setStartTime(start);\n}\n\npublic void setMondayEndTime(Timestamp end) {\n   mondaySlot.setEndTime(end);\n}\n// continue the pattern for all the slots\n}\n</code></pre>\n\n<p>Second Idea:</p>\n\n<pre><code>public class WeeklyAvailabilities {\nprivate TimeRange mondaySlot;\nprivate TimeRange tuesdaySlot;\nprivate TimeRange wednesdaySlot;\nprivate TimeRange thursdaySlot;\nprivate TimeRange fridaySlot;\nprivate TimeRange saturdaySlot;\nprivate TimeRange sundaySlot;\n\npublic WeeklyAvailabilities() {\n   // set defaults\n}\n// some getters and such\npublic void setMondaySlot(TimeRange mondaySlot) {\n   this.mondaySlot = mondaySlot;\n}\n\n// continue the pattern for all the slots\n}\n</code></pre>\n\n<p>I'm conflicted due to the fact that the first idea doesn't require a new object to be created every time while the second idea would require something of the sort. Really just wondering if I could have some input on which one is better, or if there might be a third option that I'm completely overlooking.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Both ideas have their pros and cons in many different aspects, with the amount of instance creation being one of the less important ones.</p>\n\n<p>Most important is: what are the state changes of <code>WeeklyAvailabilities</code> that you want to support, making sure whatever setter someone calls in whatever situation, you always result in a consistent state (or throw an exception). And do you really foresee any changes to a <code>WeeklyAvailabilities</code> instance after its initialization?</p>\n\n<p>Then the questions are:</p>\n\n<p>How does a <code>WeeklyAvailabilities</code> instance reach its initial state? There seems to be a default setting in the no-args constructor. Will any <code>WeeklyAvailabilities</code> instance ever keep these values or will they typically set individual timeslots, making the no-args constructor rather worthless, and instead call for a full-args one (or application of some builder pattern).</p>\n\n<p>Do you think someone will want change the start or end times individually, not pair-wise? Only then should you offer individual setters.</p>\n\n<p>To sum it up, my wild guess is that you might be better off with a seven-<code>TimeRange</code> constructor and no setter at all.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm current the sole developer/architect of a fairly large web application (ASP.NET MVC stack, roughly 150K+ lines of code) and the end of development is on the horizon. As such, I'm starting to think about what needs to be done for the hand off of the project and I want to make sure I do the right thing for anyone that has to maintain the project in the future. </p>\n\n<p>What are some things to be aware of when getting ready to hand a project off to another developer or team of developers of maintenance?</p>\n\n\nAssistant:",
        "golden_answer": " <p>IMHO, if you could only do one thing before handing off your project (either directly or indirectly), I would recommend that you double and tripple check that it compiles as-is from source control.</p>\n\n<p>No laughing, but I cannot tell you how many times I've gotten \"latest\" from a source control and it failed to compile, only to find out later that I wasn't \"on Fred's old box\" because apparently the code \"only compiles on Fred's old box\". I even had a former employer promptly remove my desktop from my cube, and replace it with \"Fred's old box\" so I could work on the project I was suppose to.</p>\n\n<p>As an extension of the above recommendation, because sometimes getting latest isn't all that is necessary to compile an application, I recommend that you create a README.txt and place it in the root directory of your application and put that in source control. This README document should contain a list of external dependencies that could not be checked into source control (if any exist), how to setup the database, and any other oddities about the compilation, execution or deployment cycles of the application.</p>\n\n<p>Anything above and beyond the above two suggestions would just be gravy, but IMHO the above two are almost required on any project larger than \"Hello World\".</p>\n\n<p><strong>EDIT:</strong></p>\n\n<p>On the topic of documentation...</p>\n\n<p>Over the years I've both written and read my fair share of software documentation for the purpose of easing a developer's transition. I'd say that such documents are rarely worth the paper they are printed on. Developers (myself included) rarely think of the important parts of the application while writing such documents, we only tend to think about the most recent fires we've battled. Above and beyond the fact that these documents tend to not cover all the important aspects of the software, they also get outdated VERY quickly. Once the document is out of date a future developer is more than likely going to completely disregard it instead of bringing it back up to match reality (think changing requirements).</p>\n\n<p>Instead of documentation per se, I recommend unit tests. I know it probably sounds old at this point, but let the code do the documenting for you. Broken unit tests are hard to ignore (and easier to spot) than a Word document. Additionally, the English language is horribly imprecise for articulating the finner points of software design. There are simply too many ways to interpret the meaning of even the simplest of English sentences, and this just leads to confusion and/or bugs.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm migrating a website that use Javacsript/HTML/PHP using reusable javascript code, in certain moment I saw the opportunity to simplify code in functions that use almost the same code. </p>\n\n<p><strong>Let's say</strong>: <em>I want to display values from the database into various <code>&lt;span&gt;</code> or <code>&lt;div&gt;</code> elements using AJAX. all the referred elements use the same layout to display the data, the difference only resides in the element id or a minimal procedure to validate data.</em> <strong>That's all.</strong></p>\n\n<p>However, I quickly came to the conclusion that I don't have a way to refer a specific element in HTML without use the <code>id</code> property, and the only alternative that I think was the use of <code>name</code> property. I know that this property it's only for <code>&lt;input&gt;</code> in a <code>&lt;form&gt;</code>,and because this elements are not <code>&lt;input&gt;</code> this rule doesn't <em>apply</em> (<em>I know that in HTML the rules are not enforced</em>). </p>\n\n<p>The basic idea is to stop using <code>id</code>s to make my code more reusable. </p>\n\n<p>To pass from this:</p>\n\n<pre><code>&lt;div id='sGroupName1'&gt;\n  +---&lt;div id='elementA1'&gt;\n  |     +---&lt;span id='txtA1'&gt;\n  +---&lt;div id='elementB1'&gt;\n        +---&lt;span id='txtB1'&gt;\n\n&lt;div id='sGroupName2'&gt;\n  +---&lt;div id='elementA2'&gt;\n  |     +---&lt;span id='txtA2'&gt;\n  +---&lt;div id='elementB2'&gt;\n        +---&lt;span id='txtB2'&gt;\n</code></pre>\n\n<p>to this:</p>\n\n<pre><code>&lt;div id='sGroupName1'&gt;\n  +---&lt;div name='elementA'&gt;\n  |     +---&lt;span name='txtA'&gt;\n  +---&lt;div name='elementB'&gt;\n        +---&lt;span name='txtB'&gt;\n\n&lt;div id='sGroupName2'&gt;\n  +---&lt;div name='elementA'&gt;\n  |     +---&lt;span name='txtA'&gt;\n  +---&lt;div name='elementB'&gt;\n        +---&lt;span name='txtB'&gt;\n</code></pre>\n\n<p>Doing my code in this way, i think will break the HTML5 conformity rules. I know this isn't a problem <em>per se</em>, because I have solved in not orthodox way, but I want to hear what is the best way to deal with this situations.</p>\n\n<p>I know that exist a question related <a href=\"https://softwareengineering.stackexchange.com/questions/250106/html-alternative-for-id-when-id-is-only-unique-within-a-certain-scope\">HTML - Alternative for ID when ID is only unique within a certain scope?</a> but in this case I don't want to deal with classes and CSS rules because the current page is using a lot of CSS and there are a lot Javascript function in the page that manipulates the CSS class, using Class as kind of identifier, I think would lead to some bugs (but not so sure).</p>\n\n\nAssistant:",
        "golden_answer": " <p>One of the advantages of REST is the ability to cache the requests via traditional http caches (assuming that these are cacheable requests).</p>\n\n<p>When you have single, larger, less frequently used, and possibly different requests (I'm going to fetch items <code>a,b,c,d</code> this time and items <code>a,b,d,e</code> next time) you make the request more likely to be a cache miss and get expired from a cache that may be sitting somewhere between you and the source.</p>\n\n<p>Given the two sets of requests mentioned above, the second request may have a 75% cache <em>hit</em> rate and be substantially faster fetching just <code>e</code>, rather than all four things.</p>\n\n<p>Note that this may not be immediately apparent to people using it as the person who does the first set of cache miss requests will still have the cache misses.</p>\n\n<p>This isn't to say that it would be ideal on a mobile network connection where one is less likely to get non-local cache hits.  But for hot spots or other wifi situations, the cache hits could be much more useful.</p>\n\n<p>Much of this, again, is subject to how your application works.  Is it asking for all this data at startup? or are we talking about a page load where response time expectations are different?</p>\n\n<p>The ideal thing to do would be to test this to see how your application preforms in a variety of situations.  Consider setting up a situation where you've bound your mobile device to a local wifi network that <a href=\"http://docs.telerik.com/fiddler/configure-fiddler/tasks/configureforios\" rel=\"nofollow noreferrer\">you can monitor</a> (that is just the first hit on google) and <a href=\"https://stackoverflow.com/questions/11832505/simulating-a-bad-internet-connection\">simulating a bad internet connection</a> to see how things actually work (or don't) and which one has the best performance.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In the absence of a written policy, what is the preferred email domain (corporate or personal)   when contributing to an open source project that your employer sponsors?</p>\n\n<p>I'm interested in the programmer's preference assuming the company doesn't care either way.</p>\n\n\nAssistant:",
        "golden_answer": " <p>It seems unlikely that the company <em>really</em> doesn't care either way.</p>\n\n<p>But if that's the case, my answer would depend on my level of interest in the open source project.</p>\n\n<p>If it was something that I could see myself continuing to contribute to in the future even if I was working a different job, I'd prefer to use my personal email address, so there would be continuity in that case.</p>\n\n<p>If it was something that I didn't have any personal interest in and was only contributing to as part of my job, then I'd prefer to use my work email address, so that when I moved on to a different job in the future, I'd break off communications with the project.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What visualization method would you recommend for event driven programs? Are there industry standard diagrams, such as flowcharts?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The flow of an event driven program cannot easily be represented by a flow chart as it is very much dependent on outside things happening and flow charts just are not geared to that.</p>\n\n<p>One way to visualize the flow of an event driven program is to use the good ol' conversation design diagrams (which I learned when programming mainframes). In these diagrams, you have a symbols representing screens. In the center is the screen under analysis or design. At the top will be the screens from which application logic can lead to the central screen. At the bottom will be screens that you can go to from the central screen.</p>\n\n<p>Of course back in my mainframe days, we didn't have to deal with on-screen interactions like dropping down a menu (though for the top menu we had different diagrams) or opening up/filling out a details section on the same screen depending on the current selection in a list.</p>\n\n<p>To address interactions like those, you could define a \"screen\" per screen state, but that would mean that the number of screen would grow to unmanageable proportions pretty quickly. <strong>Mock ups</strong> are probably a better solution here. They are perfectly suited to communicate the design of a screen without getting lost in all kinds of itty-bitty details. They also allow for annotations and other ways to indicate on-screen interactions. And using arrows and labels with the name of a following or preceding screen, transitions to other screens can be indicated thus giving a feel for the major navigation within the app.</p>\n\n<p>Balsamiq ( <a href=\"http://www.balsamiq.com\" rel=\"nofollow\">http://www.balsamiq.com</a> ) is a mock up tool that you can try out online and also use on your desktop. Check it out to see whether it would help in what you are trying to do.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have recently developed a small module that performs queries against a database. At the end of each test that contains code performing modifying queries against the database,  I added an assert that checks that a record irrelevant to the query did not get affected. My reasoning is that I want to prevent a future developer from, for example, omitting the <code>where</code> clause in an update query and causing catastrophic side effects which won't be caught in tests. I created an &quot;irrelevant record&quot; in my database setup and a function that asserts the record hasn't changed. I call this function at the end of each test.</p>\n<p>I have several things I am not comfortable with in this solution:</p>\n<ol>\n<li>Each test case doesn't only test its described test case, but also the unwanted side effect case. The alternative is duplicating each test twice which I think will pollute the test suite and make it hard to maintain and add new tests. I feel this is wrong as a methodology, as for example if in the future I'll want to do <code>n</code> wide assertions on each test case, this will entail making <code>n</code> copies of each test, which sounds horrible.</li>\n<li>I have the feeling that testing this is overkill, but on the other hand without such an assertion there is not guarantee of unwanted side effects not happening.</li>\n</ol>\n<p>My question is how to approach this kind of problem, specifically checking for unwanted side effects in a module that has database access involved, but more generally when wanting to test a common assertion for all test cases.</p>\n<p>Thanks.</p>\n\n\nAssistant:",
        "golden_answer": " <p>A module that operates using a language as powerful as database query languages certainly warrants extreme paranoia while testing. And it is far worse to under-cover than to over-cover functionality.</p>\n<p>The trade-off you must consider is whether redundant tests like this affect the readability and the execution speed of your test suite. If you can find a a way to automatically test general sanity constraints after each test, whether through inheritance, decorators, or other means, and they don't make the test suite unusably slow, then such repeated checks are a very good idea.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Arrays are stored in a linear fashion, with memory cells of fixed size for each element. To have fixed sized memory cells Arrays should be homogenious. So in Arrays we get an Nth element by skipping certain amount of bits (defined by element type) N times.</p>\n<p>But what about lists? Or heterogenious arrays like we have in JavaScript? How are they stored in memory. And how does accessing a certain element work with lists?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n<p>How are they stored in memory.</p>\n</blockquote>\n<p>In general, this is not something which is defined by a language specification. A specific <em>implementation</em> of a language is free to store something in memory however it likes so long as that implementation is consistent with the behaviour defined by the language specification.</p>\n<p>That said, the answer for JavaScript is mostly &quot;everything is a reference&quot; - the object itself is not stored in the array or list, but a pointer to the actual object, and that pointer is of constant size independent of the type of object it is pointing to.</p>\n<p>For the other end of the scale, look at something like C: there, arrays do contain the object directly, and can therefore only contain objects of one specific type.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Consider a web service API that returns a complex Json object. Using the stock Python tools for the job, this will read in from the web service as a dict which contains, in turn, a mixture of arrays, dicts, strings, and numbers.</p>\n\n<p>I confess: this data is born in Java. In Java, there's a data model for this data. My question is, would dyed-in-the-wool Python programmers desire a Python class data model that adds some notational niceness, or would they expect to just be handed the situation described in the first paragraph.</p>\n\n<p>In code terms, what's the value of:</p>\n\n<pre><code> text.tokens[3].part_of_speech\n</code></pre>\n\n<p>as opposed to:</p>\n\n<pre><code> text['tokens'][3]['part_of_speech']\n</code></pre>\n\n<p>?</p>\n\n<p>Based on some comments, I want to expand this a little. What I wrote above is all about consuming a complex data structure that arrives in Python as Json, and I can see that 'sugaring' it with a pile of classes with @property markers is not very helpful.</p>\n\n<p>Another side of the coin is assembling one of these. As, admittedly, a person who has spent a lot more time in Java, C++, C (and Lisp?) than in Python, I would tend to see value in some API that helps me remember the names of all the bits and pieces. So maybe that suggests simply providing constants that provide the defined keys?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I don't know that there is one answer that everyone would agree with, but personally I would just use the built in Python classes. Reading JSON to python dictionaries and lists is a very standard thing to do, it maps very well.</p>\n\n<p>I'm all and for OO programming, but I don't see the point in writing a tiny class to be a thin wrapper over existing powerful data types. When someone reads your code, it's just one more type to grok. Whereas standard data structures are, well, standard. They know it's a dict, if a programmer wants to understand the contents at some point, they can just place a breakpoint, print it out, and let the program keep running.</p>\n\n<p>In addition, python has a lot of really nice syntax like dict and list comprehensions. You're probably losing as much niceness as you gain by not having to type a few extra []'s.</p>\n\n<p>Representing JSON in C++ or Java is a different situation, because if the JSON structure is not known at compile time, so the types are not known in advance. So writing a custom data structure is pretty well necessary anyway. Very different in python.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>So, I'm preparing to consider the outcome of training a lot of people (>25) to use <strong>Mercurial</strong> coming from a centralized mindset. I've done it with <strong>individuals</strong> and had success with it, although the time invested in each one has been different and most of them have been both proactive and open to trying something new.</p>\n\n<p>I was wondering if there was someone here with experience giving such training to a large group of people <strong>as I would like to find out what are the do's and don'ts... of course, this would be more oriented towards dealing with those resistant to change</strong>, and a don't I can come to think of is telling them to avoid cheat-sheets mapping commands, as Joel Spolsky <a href=\"http://hginit.com/00.html\">suggests</a>. </p>\n\n\nAssistant:",
        "golden_answer": " <p>I work as a <a href=\"http://aragost.com/mercurial/\">Mercurial consultant</a> and I've found that it's not too hard to explain DVCS to new users, provided that you don't confuse them. So what I do is:</p>\n\n<ul>\n<li><p><strong>Emphasize the core principles.</strong> The history model in Mercurial is actually very clean and simple. In particular, I find that branches are modeled better in Mercurial than in, say, Subversion. Talk with the users about how working together should work in an ideal world: I do a bit of work on my machine, you do a bit of work on your machine and we later reconcile (merge) our work. Then show them how Mercurial implements exactly this model.</p></li>\n<li><p><strong>Emphasize the centralized workflow.</strong> A lot of guides and tutorials put a lot of emphasis on the <em>distributed</em> aspect of DVCS  my experience is that this is not very important! Especially not in an organization where you already use a big centralized VCS. The important part is the new and improved workflows.</p></li>\n<li><p><strong>Emphasize simple use cases.</strong> Let the users get hands-on experience from playing with the tool. First they will commit and push/pull with a central server. Later you can guide them through a more structured scenario where they create a feature branch, make some commits, and merge it back.</p></li>\n</ul>\n\n<p>We've made some training material that we call a <a href=\"http://mercurial.aragost.com/kick-start/\">Mercurial Kick-Start</a>. I've used it several times and it normally has enough content for two or three days, depending on how much I talk.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have what is probably an over-engineering question. I have some PHP code that logs messages to a file. We've been having a problem with the file having the wrong perms from time to time. While we're troubleshooting that, I am writing a work-around for that in the logging function, changing the unix perms and owners on the log file. </p>\n\n<p>So my code looks like this:</p>\n\n<pre><code>function log($message) {\n  if ( FALSE === file_put_contents(log_path(), $message) ) {\n    chown(log_path(), 'apache');\n    chgrp(log_path(), 'www-data');\n    chown(log_path(), 0770);\n\n    // now I'm repeating this line\n    if ( FALSE === file_put_contents(log_path(), $message) ) {\n      // log error to database\n      db_log($message);\n    }\n  }\n}\n</code></pre>\n\n<p>In the interest of DRY, can I somehow change the code to avoid repeating the line <code>if ( FALSE === file_put_contents(log_path(), $message) ) {</code>? Of course, I can't use recursion, because that would go on forever. </p>\n\n\nAssistant:",
        "golden_answer": " <p>If you absolutely wanted to, you could do this:</p>\n\n<pre class=\"lang-php prettyprint-override\"><code>function log($message)\n{\n  for($i = 0; $i &lt; 2; ++$i)\n  {\n    if ( FALSE !== file_put_contents(log_path(), $message) )\n    {\n      return;\n    }\n    if($i == 0)\n    {\n      chown(log_path(), 'apache');\n      chgrp(log_path(), 'www-data');\n      chown(log_path(), 0770);\n    }\n    else\n    {\n      // log error to database\n      db_log($message);\n    }\n  }\n}\n</code></pre>\n\n<p>I don't like it, however... Just a simple function call? Well, it is OK. If it was a more complex code you had to execute before being able to make a decision, I'd write a separate function for <strong>this</strong>, returning true or false, and have it called twice, right as you did with the file_put_contents function.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I recently picked up learning PHP and MySQL and I am trying to build a small usersystem as a coding exercise. While learning to use classes and functions, I also stumbled upon the MVC model and would like to implement the model in my code.</p>\n\n<p>Is the following approach correct MVC?</p>\n\n<ul>\n<li><p>index.php, message.php, user.php are all a bunch of controllers. They start a model, collect $_GET, $_POST and $_SESSION user data and passes that on to the model. They may collect info from the model and pass it on to the views.</p></li>\n<li><p>the user class, message class, etc. ... are all parts of the model. They validate the data that the controller gives them, do the actual database stuff and return data to the controller and the view.</p></li>\n<li><p>the views are puzzled together by the controller. They mainly echo data from the model &amp; the controller and include html files.</p></li>\n</ul>\n\n<p>My main concern is how the view displays data from the model. Is it better to go through the controller or should I directly get it from the method whenever I can?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Your understanding is correct. Keep in mind that different frameworks use different approaches, so something which would for instance apply to Laravel won't necessarily apply to, say, Symfony.</p>\n\n<p>This is especially true when it comes to deciding where the logic goes: some frameworks use models as basic objects containing data, but practically no logic by themselves. Other frameworks encourage you to move some logic from the controllers to the models.</p>\n\n<p>A few comments:</p>\n\n<ul>\n<li><p>Why is your controller called <code>index.php</code>? Usually, the application has several controllers with the names which indicate their purpose. For instance, an e-commerce website can have a <code>products.php</code> file which contains the controller logic handling <a href=\"http://example.com/products/\" rel=\"nofollow\">http://example.com/products/</a>... requests, <code>customers.php</code> file for customer-related stuff, <code>cart.php</code> for you guess what, etc.</p>\n\n<p>Unless you have separate directories for each of them, such as <code>/products/index.php</code>, <code>customers/index.php</code> and <code>cart/index.php</code>, you are putting all the logic in the same file. As a consequence, even if the file is currently small, it will grow through time, and become very difficult to maintain.</p></li>\n<li><p>While doing input validation inside a controller is a perfectly valid approach, some frameworks move the validation logic from the controller to (1) the model and (2) the framework itself. I don't know PHP frameworks, so I'll give an example of ASP.NET MVC: usually, properties within the models have specific attributes which indicate how should they be validated. Then, basic validation logic is applied by the framework itself during the mapping.</p></li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Why don't some open source libraries provide binaries? I have noticed that some projects defer to third-parties who maintain current builds of the software, especially for Windows builds.</p>\n\n<p>I ask because it seems like a barrier for adoption of a library. It's more work for the developer since he must set up his environment to build it. A developer also has to worry that he introduced bugs by building the library incorrectly.</p>\n\n<hr>\n\n<p><strong>EDIT</strong>: Some updates to address comments and answers. I've removed the examples since they're not central to the discussion. Also rephrased my question as \"some open source libraries provide\" rather than \"open source libraries tend to provide\"... didn't realize people would take offense to that.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Because making windows binaries is a completely different job requiring a completely different knowledge base and tool set.  People seem to have a difficult time grasping this about Linux developers, so let me turn it around.</p>\n\n<ul>\n<li>You've used Windows for what seems like forever.</li>\n<li>You only have Windows installed at home.</li>\n<li>You've used Linux here and there at work, but only as a user, not administrating or developing for Linux.</li>\n<li>You know gcc is the most commonly used compiler for Linux, but have never installed it on your own computer.</li>\n<li>You mainly work on the software for yourself on Windows, but don't mind making bug fixes for Linux if someone else does the work to make it compatible and distribute binaries.</li>\n<li>You don't want to pay for another OS and toolchain when someone else who already has is perfectly willing to make the builds.</li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>For some time I used PUT or PATCH in order to update a REST API resource. After using a lot of PUT/PATCH calls I noticed that \"update\" could be also done with POST. </p>\n\n<p>Here is an example which is oversimplified that will hopefully explain the situation. There is an endpoint /api/cars/dealers/1 with a resource</p>\n\n<pre><code>{\n  \"id\": 1,\n  \"dealer_name\": \"Audi Atlanta\",\n  \"year_opened\": 2010,\n  \"contact_persons\": [\n    {\n      \"contact_person_type\": \"main_contact\",\n      \"contact_person_name\": \"Mike Smith\"\n    },\n    {\n      \"contact_person_type\": \"billing_contact\",\n      \"contact_person_name\": \"Luke Johnson\"\n    }\n  ]\n}\n</code></pre>\n\n<p>Would it be against REST API guidelines if I update this resource with POST such as</p>\n\n<pre><code>{\n  \"contact_to_change\": \"main_contact\",\n  \"contact_name\": \"John Smith\"\n}\n</code></pre>\n\n<p>instead of PATCH with</p>\n\n<pre><code>{\n  \"id\": 1,\n  \"contact_persons\": [\n    {\n      \"contact_person_type\": \"main_contact\",\n      \"contact_person_name\": \"Mike Smith\"\n    }\n  ]\n}\n</code></pre>\n\n<p>or instead of full resource update with PUT</p>\n\n<p>Please notice how the structure of payload is completely different then the structure of the resource itself. There are cases when this is much more easier then to go with a raw resource update following the same body structure.</p>\n\n<p>Could this way bring some issue that I don't see at the moment?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You can use POST to update a resource but not using the same URL as the resource you're updating. So, if the URL to use with PUT/PATCH is <code>/api/cars/dealers/1</code>, you'd have <code>/api/cars/dealerupdates</code> to send your POST requests with body as in your PATCH request.</p>\n\n<p>This way it's clear that you're not creating new entity under <code>/api/cars/dealers/</code> or <code>/api/cars/dealers/1</code>. What created is new update entity which will be applied at some point to the entity inside the request. Another way to see it is: sending GET request to <code>/api/cars/dealerupdates</code> can give a list of updates that have been processed.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>At work, we've been doing lunchtime book clubs for a while. So far we've done:</p>\n\n<ul>\n<li>Clean Code</li>\n<li>Working Effectively with Legacy Code</li>\n<li>The Pragmatic Programmer</li>\n</ul>\n\n<p>We read a chapter per week, and one person is assigned to present over the content and help facilitate discussion.  Of the three, we've probably had the most success with The Pragmatic Programmer. It seems like the more technically complicated the content was, the more people tended to drop out as the book went along.</p>\n\n<p>I'd like to do a technically-heavy book like SICP or Java Concurrency in Practice, but I don't know of good ways to make this work with the format we're currently doing. What advice do you have?</p>\n\n\nAssistant:",
        "golden_answer": " <p>What I like to do in a book club is find practical application - or examples of practical application of the concepts in the book. Instead of asking someone to present, ask multiple people (or anyone who wants to volunteer) to come up with relevant examples of the concepts in the book.</p>\n\n<p>For example, when you read the chapter in the pragmatic programmer about broken windows (I know you read this one already, but since <em>everyone</em> has read this book, it's a good example), ask for examples of broken windows in your own source code - or examples of broken windows on code the team is familiar with. For me, the connection between ideas that look good on paper and real examples do a ton to drive the points home.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Data persistency has recently become a really grip for me, especially how long to maintain database connectivity and how many connections are feasible for a given request.\nI've been using .NET; however, this is a generic question related to any lanaguage.\nFrom a .NET perspective, I'm connecting to database using EF4 and for a given website page I might create 6 connection per-request to render a page. The page might consist of news, stock prices, etc, and needs to be constantly updated. </p>\n\n<p>I've recently been looking at unit-of-work (i.e. per request) approach. So basically when a request starts, if required a database connection is opened and destroyed upon end of the request. I'm not convinced it's the best approach yet. I'm looking for opinions and experience on it. </p>\n\n\nAssistant:",
        "golden_answer": " <p>I use a pool of connections. Every time I am done with one, I throw it on a stack. If I need one, I start popping off the stack until I encounter an active connection (connection that didn't timeout while it was in the queue). I use this approach because I have many requests/second and my connections get recycled very fast. They rarely have enough time to timeout inside the stack. Of course you will need to synchronize the Stack.\nI use Redis as a database, but I assume it works for any type of connection which has an underlying socket.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>This quote is from the book <strong>HeadFirst C</strong>:</p>\n\n<blockquote>\n  <p>A linked list is an example of an abstract data structure. Its called\n  an abstract data structure because a linked list is general: it can be\n  used to store a lot of different kinds of data.</p>\n</blockquote>\n\n<p>Is this accurate / correct information? </p>\n\n\nAssistant:",
        "golden_answer": " <p>The question of abstractness is closely related to the language it is implemented in.</p>\n\n<p>In Java, C# and the like, an abstract data structure is truly an abstract one. You can't instantiate it directly. This may be because it is an interface or an abstract class.  It is a <em>concept</em> with some underlying things to it.  <code>LinkedList</code> isn't abstract - it is a concrete implementation of a <code>List</code> (that's an abstract data structure in Java), which itself is a <code>Collection</code> (for more abstract set of operations on it).</p>\n\n<p>In C, however, you don't have the generics.  Unless you are doing everything with <code>void*</code> types in a given data structure, it doesn't really exist in the <em>abstract</em>. And so concepts such as hash tables (a concrete type in Java) and linked lists remain in the abstract realm until you make a \"here is a struct with this data structure that allows you to implement a linked list\".</p>\n\n<p>So, is it abstract or not? In some languages it is, in others it isn't.</p>\n\n<hr>\n\n<p>Lets confuse things a bit.</p>\n\n<p>A linked list is a Pattern - it is a tool you use or implement when a particular problem calls for it. Some have argued that <a href=\"http://c2.com/cgi/wiki?AreDesignPatternsMissingLanguageFeatures\" rel=\"nofollow\">design patterns are missing language features</a>.  That it is abstract in one language and concrete in another is because it is a \"missing\" language feature in C and not in Java (but there its part of the class library rather than being a fundamental part of the language like in Lisp).</p>\n\n<p>At the end of the day, don't worry about if it is abstract or not. It is something. And you implement or use it somehow. When a C programmer and a Java programmer talk about a Linked List, they are talking about the same thing (just the C programmer did more work). That's all that matters. Its a common way of talking about a common thing, and that's what Patterns are about.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am mobile developer and always have one particular fight with my web-service/backend developer which believe in designing restful api. </p>\n\n<p>Issue: As per Restful design,every api should be atomic in nature,but this create alot of problems to clients especially mobile based. Since to perform any operation like opening of a particular page, i might have to make N calls to load the data which gives a very bad user experience . </p>\n\n<p>One valid user-case to explain : In an e-commerce application,load a product detail page. In this page we have to show product detail , inventory information , offer description , related products , recommended product etc,and as per restFul  each one them could be a individual api and loading each of them individually will kill user experience and making a aggregate call is against Restful principal.</p>\n\n<p>Can anyone tell me how you have solved/to solve this problem ? </p>\n\n\nAssistant:",
        "golden_answer": " <p>Something to remind the backend developer of: REST doesn't say anything about the size/complexity of the objects in the payload, only about the atomicity and stateless nature of the transactions. It's entirely allowable to have a path of the form <code>/product/{id}/details</code> which returns a payload rooted in the same object as <code>/product/{id}</code> but with additional information possibly pulled from multiple tables. You can use the path for simple-to-express variations, or query-string variables if you've got complex requirements for optional additional information. On the PUT side, a PUT to <code>/products/{id}</code> could either look at what's present in the payload and update tables based on that or it could only update the base product and require additional path segments and/or query-string variables matching the corresponding GET to update additional tables. The choice depends on what makes things simplest and most straightforward/understandable for the application.</p>\n\n<p>An internal API like this exists to serve a purpose. If using it's making things harder rather than easier, that's a sure sign something's not right with the API.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I just came across the following in a lab manual at university:</p>\n\n<blockquote>\n  <p>You do need to study the interfaces of the classes by generating the javadoc for them so you know what operations are provided (feel free to look at the code, but\n  when using somebody elses code, as here, you should work from the javadoc rather than the code whenever possible). </p>\n</blockquote>\n\n<p>I don't understand why this is the case; since the javadoc could be out of date, or could describe the function of the code badly. Surely looking at the source code, and reading the javadoc comments is best?</p>\n\n<p>Is there a reason why, or a case when reading only the javadoc is the best thing to do?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The recommendation is probably about programming to an <em>interface</em> rather than the <em>implementation</em>.</p>\n\n<p>Sure, if you have access to the code then there's nothing stopping you from looking at the implementation to understand <strong>how</strong> it works.  But you should always make sure that the <strong>how</strong> doesn't influence your consumption of the API.</p>\n\n<p>When you're consuming an API you're working against an abstraction.  Try to concern yourself only with <strong>what</strong> the API offers (the contract) and not the <strong>how</strong> (the implementation).</p>\n\n<p>This is because there is no guarantee that an API's implementation won't change drastically from one version to the next, even if the contract has remained unchanged.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>So I've been working at this job for a couple of months.  I'm a little frustrated because I do my best work from 2 to 7.  In previous jobs, I've come in at 9:30-10:00 and leave at 7.  Some companies have been okay with this, others have not.</p>\n\n<p>But my current company insists on my being there at 8:30.  Any deviation from this is a big deal.  Is this typical?  I have colleagues who are more 9:30 to 6:30, 10:00-7:00 guys...but maybe that is just startup culture?</p>\n\n<p>I don't see why, given that I don't meet clients, etc. what the advantage to having things be so rigid could be.  I also don't see why if there is 15 to 20 minute variation sometimes in coming in, why people don't just assume that I will adjust when I leave...</p>\n\n<p>Are these unreasonable expectations as a developer or am I missing something?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p><em>But my current company insists on my being there at 8:30. Any deviation from this is a big deal. Is this typical?</em>  </p>\n</blockquote>\n\n<p>Yes it is typical. And companies like that tend to have very high turnover with developers. I was chatting with one of the project managers I used to work with (he's now a VP with some other company) and he was describing the policy at the company he was working at (at that time, one of the big satellite tv providers): starting time was 0830. The second time you are late (within a certain period), the door doesn't open when you swipe your access card, it instead calls your boss who has to come let you in. The third time (in that certain period), it contacts HR who fires you. He was commenting on the 200% turnover they had, and chuckling at the clueless other managers who created this policy. He also mentioned that he gave out his cellphone number to everyone under him, so that if they were late, he could get around the system to get them to work.  </p>\n\n<p>Some managers are process oriented, and others are results oriented. You will quickly learn how to tell them apart. If you're smart, you'll figure out a way to ask in the interview some questions to determine one from the other without killing your interview. </p>\n\n<p>In a results-oriented company, <em>what</em> you get done is more important than how you look or what your hours are. These companies/bosses have the least impedance mismatch for developers. In those companies, when someone tries to say \"waaah, q303 comes in late\", a results-oriented boss will say \"q303 gets his products shipped on time and under budget, what have <em>you</em> done lately?\" Stars and heroes are very common in results-oriented companies. </p>\n\n<p>In a process-oriented company, <em>how</em> you get things done is more important. For a process-oriented boss, what time you arrive, what time you leave, and what <a href=\"http://www.youtube.com/watch?v=JBV9WkfZdvw\">cover sheet is stapled to your TPS report</a> is extremely important. There is a huge impedance mismatch between the typical developer and this sort of manager. There are no favorites, nor stars, in a process-oriented company, and this is the sort who will deliberately fire anyone found to be indispensable. The perfect example of a process-oriented company is a fast food franchise - the goal is for every burger to be the same at every store in the country. If you make a better burger, you'll lose your franchise with them.</p>\n\n<p>Modern business schools teach managers that they do not need to understand a business (nor what their employees actually do) in order to be a manager. These folks will want you warming that seat at the appropriate time because that is something that they <em>can</em> measure - they don't know what you do, nor do they care to, scientific management says they don't. </p>\n\n<p>As you gather more experience in the working world, you'll find out that what is important to your boss is what you give them. You could cure cancer, balance the federal budget while juggling running chainsaws, but that doesn't matter because you come in late. They don't see you when you leave at 2am, because they leave \"on time\" (whatever that means). </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>My aim here is to find out the best possible and feasible solution for my dilemma. I want to import some csv file (may contain around 50~60K records) into database after some manipulation into the files, manipulation includes comparison such as one record already exists into database or not. I already have a .net c# application which </p>\n\n<ul>\n<li>gets the file</li>\n<li>fetches its data into datatable</li>\n<li>loop through each record, do comparison for each of the record from database</li>\n<li>and finally updates/creates/deletes record.</li>\n</ul>\n\n<p>this whole process is apparently too time consuming. My client needs this process working as fast as possible. I suggested him to do this import process with SQL only(though I'm not sure whether it would work more efficiently using SQL features such as staging table, temp table and cursors). </p>\n\n<p>Now by SQL this is what I thought could be done in order to get it working better:</p>\n\n<ul>\n<li>create a staging table</li>\n<li>using BULK IMPORT or SQLBULKCOPY function import all csv file's data into this staging table.</li>\n<li>create a SP which would loop through(using CURSOR ofcourse) all records from staging table and will compare each records from already existing db table and will create/update/delete record accordingly.</li>\n<li>empty staging table.</li>\n</ul>\n\n<p>I'm not sure the SQL version would work more efficiently in my case or not. In total I'm not able to see a clear vision that whether I should go with the SQL version of solution or stick with the current .net C# code and optimize this current code only. It would be great if someone can advise me on the same.</p>\n\n<hr>\n\n<p>let me explain this with the help of an example:</p>\n\n<ol>\n<li>these are the headers of csv file:\nStudentId, StudentFname, StudentLname, ClassName, teacherId, teacherFname, teacherLname</li>\n<li>suppose I've copied all its data as it is into staging table.</li>\n<li>now I've to update those students which are already in STUDENT table and create those which do not exist, check if the classname already exists in CLASS table (if not then create class), check if the teacher id already exists in TEACHER table (if not then create teacher, otherwise update it).</li>\n</ol>\n\n\nAssistant:",
        "golden_answer": " <p>SQL servers will offer specific products such as DTS or SSIS for importing data. These can be pretty optimised and run very quickly.</p>\n\n<p>However!! If you have programming skills I highly recomend you write your own importing software.</p>\n\n<p>The reason for this is that although the Sql server may be able to run an import process faster in a best case senario, it is inherently unscalable.</p>\n\n<p>If you write your own importer then you can move all that logic and file reading off to a seperate server and only load your sql box with simple writes. This enables you to scale horizontaly.</p>\n\n<p>SQL databases are one of the major pain points when scaling and the way to minimise this is to keep all business logic off the box. I have seen systems with complicated scheduling logic literaly running out of hours in the day for importing files, running a top spec sql box at 100% 24/7</p>\n\n<p>Additonaly although tools lile DTS/SSIS are fine for DBAs who want to run the odd 'programming style' task. They fall well behind the features of a modern devops stack, such as versioning, debugging, no down time deployments etc etc</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>For example, the Objective-C convention is to prefix the symbols with two or three capital letters which are abbreviations of the project: NSString, CABasicAnimation, MGTwitterEngine In C, many projects also do this (OpenGL and nginx for example).</p>\n\n<p>Is this also considered namespacing or am I missing something?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I think it's not technically namespacing in the modern sense, it's more like the ancestor of namespacing. It's done for the same reason (disambiguation) and has many of the same benefits.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Say I have an existing callback interface that has multiple methods. To illustrate my point I use a callback the likes that you would see in code that performs some HTTP client operations:</p>\n\n<pre><code>public interface GetCallback&lt;T&gt; {\n    public void onSuccess(T data);\n    public void onAuthFailure();\n    public void onError(RequestError error);\n\n    //Potentially more methods like onPreGet etc...\n}\n</code></pre>\n\n<p>And a method that makes a request would take an instance of this callback as an argument:</p>\n\n<pre><code>public void issueRequest(String url, GetCallback&lt;T&gt; callback) {\n    // Implementation ...\n}\n</code></pre>\n\n<p>As is obvious, this suffers with verbosity at the call site:</p>\n\n<pre><code>public void getData(){\n    issueRequest(\"http://programmers.stackexchange.com\", new GetCallback&lt;String&gt;(){\n        public void onSuccess(String data) {/*Do Something*/}\n        public void onAuthFailure(){/*Ask for credentials*/}\n        public void onError(RequestError error){/*Show error message*/}\n\n    });\n}\n</code></pre>\n\n<p>I have something similar in my code and it has been working well. I use a <code>DefaultGetCallback</code> class that provides default implementation of the <code>onAuthFailure</code> and <code>onError</code> methods since the action I want to take in those cases is pretty much the same regardless of what resource I'm requesting.</p>\n\n<p><strong>The question is, does it make sense to refactor this into a class composed of a set of single-method interfaces in order to take advantage of the lambda syntax?</strong></p>\n\n<pre><code>public class GetCallback&lt;T&gt;{\n    public interface OnSuccessListener&lt;T&gt; {\n        public void onSuccess(T data);\n    }\n\n    public interface OnAuthFailureListener {\n        public void onAuthFailure();\n    }\n\n    public interface OnErrorListener {\n        public void onError(RequestError error);\n    }\n\n    private OnSuccessListener mSuccess;\n    private OnAuthFailureListener mAuthFailure;\n    private OnErrorListener mError;\n\n    public GetCallback&lt;T&gt;(OnSuccessListener&lt;T&gt; success) {\n        this.mSuccess = success;\n    }\n\n    public GetCallback&lt;T&gt; withAuthFailure(OnAuthFailureListener authFailure){\n        this.mAuthFailure = authFailure;\n        return this;\n    }\n\n    public GetCallback&lt;T&gt; withError(OnErrorListener error){\n        this.mError = error;\n        return this;\n    }\n\n}\n</code></pre>\n\n<p>I might use a Builder pattern to construct the <code>GetCallback</code> here but that's besides the point. The call site now becomes:</p>\n\n<pre><code>public void getData(){\n    issueRequest(\n        \"http://programmers.stackexchange.com\", \n        new GetCallback&lt;String&gt;(s -&gt; doSomething(s))\n            .withAuthFailure(() -&gt; askForCredentials())\n            .withError(error -&gt; showErrorMessage(error))\n    );\n}\n</code></pre>\n\n<p>One advantage is I can customize the behavior of individual \"events\" (success, error etc) in isolation, at the call site, rather than having to sub-class or to create an anonymous inner class.</p>\n\n<p>But then, how much is too much? Especially given the fact that my current design already served me well?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Instead of building a <a href=\"http://en.wikipedia.org/wiki/Facade_pattern\" rel=\"nofollow\">facade</a> wouldn't it make sense to do something more like this?</p>\n\n<pre><code>public interface SuccessListener&lt;T&gt; {\n\n    default void onSuccess(T data) {\n        // Completely ignore it.\n    }\n\n}\n\npublic interface AuthFailureListener {\n\n    default void onAuthFailure() {\n        // Completely ignore it.\n    }\n\n}\n\npublic interface ErrorListener {\n\n    default void onError() {\n        // Completely ignore it.\n    }\n\n}\n\n// Retain the old API\npublic interface GetCallback&lt;T&gt; extends SuccessListener&lt;T&gt;, AuthFailureListener, ErrorListener {\n    // Now empty - we are a conglmerate.\n}\n\npublic static &lt;T&gt; void issueRequest(String url, SuccessListener&lt;T&gt; successListener, AuthFailureListener failureListener, ErrorListener errorListener) {\n    // Implementation ...\n}\n\npublic static &lt;T&gt; void issueRequest(String url, GetCallback&lt;T&gt; callback) {\n    // Ensures backwards compatability.\n    issueRequest(url, callback, callback, callback);\n}\n\npublic void getData() {\n    issueRequest(\"http://programmers.stackexchange.com\", new GetCallback&lt;String&gt;() {\n\n        @Override\n        public void onSuccess(String data) {\n        }\n\n        @Override\n        public void onAuthFailure() {\n        }\n\n        //@Override\n        //public void onError() {\n        // Can now leave out the ones you don't want.\n        //}\n    });\n}\n</code></pre>\n\n<p>It is still compatible with your earlier API and internally who cares that the same object is a listener for all three events. It also opens up the possibilities of adding default implementations and allowing the chance to issue a request with only a <code>SuccessListener</code>.</p>\n\n<p><strong>Note:</strong> I tweaked the code to use <code>default</code> for even more niceness.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have started learning c# and am confused by the following feature. </p>\n\n<p>The following code uses a function Algs.Combinations(n,m) to produce an IEnumerable which contains the combinations of n objects taken from m. Its implementation is exactly as can be found on the Rosetta code page for combinations. For example, applying .toList() to Algs.Combinations(2,3) would produce the list [[0,1],[0,2],[1,2]]. </p>\n\n<p>Now in the foreach loop I add each int[] to a new list. I also print out the values of each array(ie the combination) after turning it to a list and then using the built in ForEach. Everything works as expected. </p>\n\n<p>In the next block I use the built in ForEach on my new list and it seems every int[] has become [2,2]. What is going on here? Presumably in my foreach I am not actually adding the integer array but some kind of pointer?</p>\n\n<pre><code>using System;\nusing System.Collections.Generic;\nusing System.Linq;\n\n\nnamespace Examples\n{\n    class main\n    {\n        public static IEnumerable&lt;int[]&gt; Combinations(int m, int n)\n        {\n            int[] result = new int[m];\n            Stack&lt;int&gt; stack = new Stack&lt;int&gt;();\n            stack.Push(0);\n\n            while (stack.Count &gt; 0)\n            {\n                int index = stack.Count - 1;\n                int value = stack.Pop();\n\n                while (value &lt; n)\n                {\n                    result[index++] = value++;\n                    stack.Push(value);\n                    if (index == m)\n                    {\n                        yield return result;\n                        break;\n                    }\n                }\n            }\n        }\n\n        static void Main(String[] args)\n        {\n            var l = Combinations(2, 3);\n            var newL = new List&lt;int[]&gt;();\n            foreach (int[] combs in l)\n            {\n                newL.Add(combs);\n                combs.ToList().ForEach(p =&gt; Console.Write(p + \" \")); // prints 0 1, 0 2, 1 2 \n                Console.WriteLine();\n            }\n            newL.ForEach(p =&gt;\n            {\n                p.ToList().ForEach(q =&gt; Console.Write(q + \" \")); // prints 2 2, 2 2, 2 2\n                Console.WriteLine();\n            });\n         } \n\n    }\n }\n</code></pre>\n\n<p>Googling hasn't helped so far. Any links to literature I should look at will be appreciated.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Your problem is that you are only returning a single array from your <code>Combinations</code> function, but returning it multiple times with the values changed inside the array between each iteration.</p>\n\n<p>Methods which use <code>yield return</code> are coroutines - in each <code>foreach</code> iteration they execute up to the next <code>yield</code> statement they find and then they exit, picking up where they left off in the next iteration. In your first <code>foreach</code> loop you are taking the enumerated <code>int[]</code> value and putting it into your <code>newL</code> variable - but it's always the same <code>int[]</code> value because <code>Combinations</code> only ever creates one array. The print out in the first <code>foreach</code> works fine because the coroutine is paused waiting for the next iteration to start.</p>\n\n<p>You have a couple of options. The best option is to make your <code>Combinations</code> have a sane implementation, in that it returns a new object for each <code>yield return</code> statement. That might look something like this:</p>\n\n<pre><code>    public static IEnumerable&lt;int[]&gt; Combinations(int m, int n)\n    {\n        while (weStillHaveMoreResultsToBuild)\n        {\n            int[] result = new int[m];\n\n            while (value &lt; n)\n            {\n                // fill result and break out of loop when done\n            }\n\n            yield return result;\n        }\n    }\n</code></pre>\n\n<p>Another option would be to not use <code>yield return</code> at all, and instead build a list inside <code>Combinations</code> and return that. This approach could take a lot more memory if your <code>n</code> and <code>m</code> values are large.</p>\n\n<p>A third option is to make a copy of the objects returned by <code>Combinations</code> and store those instead:</p>\n\n<pre><code>newL.Add(combs.ToArray()); // Calling ToArray() will make a copy\n</code></pre>\n\n<p>This is my least favorite option, because it requires any caller of <code>Combinations</code> to know that the same object will be returned multiple times but changed in each iteration.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Assuming the language provides it, what are some things to do or libraries to use that every programmer should know?</p>\n\n<p>My list would be</p>\n\n<ul>\n<li>Regular Expressions</li>\n<li>Named Pipes</li>\n<li>standard IO (std in/out/error)</li>\n<li>Executing outside executables (like imagemagik and your own scripts)</li>\n<li>How to grab an HTTP page as a string (mostly for updates and grabbing configs from servers)</li>\n</ul>\n\n<p>I have a similar questions about <a href=\"https://softwareengineering.stackexchange.com/questions/6157/what-tools-should-every-programmer-know\">tools</a>. Also I am looking for specific answers. I don't want answers that can be done in different ways (such as learn how to synchronize threads).</p>\n\n<p>I know how to do the above in 3+ languages. There always seems to be things programmers don't know how to do which can make their lives easier. For a long time I didn't know what regular expression was (although I did hear of it) and I was surprised how many people who tried to make a toolchain or complex app and did not know how to (or that you could) get the stdout from an exe they launched (they checked for errors in a very weird way or just didn't and hope it produce the expected results).</p>\n\n<p>What do you think is useful, not well known and should be something every senior (or starting out) programmer should know?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Handling date calculations, date formating and localization issues dealing with dates.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>We are developing a tool from scratch based on a Spring backend and VueJs frontend. I am primarily working on the backend and came to know about the HATEOAS principle of developing REST APIs and adopted it. I will confess that one of the reasons for adopting it was the out-of-the-box implementation that Spring provides.</p>\n\n<p>But, our frontend developer is skeptic of using HATEOAS REST APIs for developing the frontend. The APIs are directly linked to the database so if he uses this API only he has to make multiple calls to get relational data. For eg. if he wants to get the book details along with the library id it is in, he needs to make 2 calls, one to get the book details and another call to a link associated with the book response which would give him the library detail. He instead wants a single API call which would have the library id as an additional property withing the book details.</p>\n\n<p>Now of course the front end is not using a single API, there are lots of APIs and I have spent more time developing custom APIs than any backend logic.</p>\n\n<p>I am in 2 minds now as to which way is correct:</p>\n\n<ol>\n<li>Front end should make multiple calls if required, which would surely create delays, in order to conform to HATEOAS standards</li>\n<li>The front end should call custom APIs only and the APIs should be made so that data can be fetched in as less calls as possible.</li>\n</ol>\n\n<p>Which one should be followed?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The benefits of HATEOAS (Hypermedia) are real for both internal and external APIs. However, the tooling is often lacking to take advantage of those benefits.</p>\n\n<p>Let's start with the \"problem\" of having the make multiple requests to the server. There are several solutions. First of all, if the front-end consistently has to make multiple requests to get what it needs, you may have a data modeling problem. Your API shouldn't simply map 1:1 to your database. Focus on modeling how data flows through the system, rather than modeling the data.</p>\n\n<p>But, even if you do have to make multiple calls, there are several solutions at your disposal. Your most important tool is HTTP Caching. In theory, you should be able to retrieve a resource once, and then keep that local copy of the resource in sync with the server. If you make a change to your local copy, inform the server of the change with a PUT request and keep using your local copy. Checkout <a href=\"https://www.infoq.com/articles/webber-rest-workflow\" rel=\"noreferrer\">this</a> blog for a good explanation of this approach, or get a copy of the book, <a href=\"https://rads.stackoverflow.com/amzn/click/0596805829\" rel=\"noreferrer\">\"REST in Practice\"</a> (still the best book on REST I've every read).</p>\n\n<p>If your resources change very frequently on the server, or are frequently changed by other API users, this approach might not be very helpful. Fortunately, there are other options. Some hypermedia formats like <a href=\"https://github.com/kevinswiber/siren\" rel=\"noreferrer\">Siren</a> and <a href=\"http://stateless.co/hal_specification.html\" rel=\"noreferrer\">HAL</a> allow responses to return not just the resource requested, but also other resources that it expects you might also want to make followup requests for. I encourage you to check out those media types.</p>\n\n<p>However, the HTTP/2.0 server push feature makes that feature obsolete. This basically solves the same problem, but at the protocol level. I don't know this feature well, so I won't try to explain it further. The problem with this of course is poor server-side support for this feature. Hopefully our web frameworks will catch up soon.</p>\n\n<p>Now let's talk about the biggest problem, the lack of front-end tooling. The main challenge on the client-side is that the front-end has to figure out how to consume the Hypermedia enabled responses from the server. That can be a lot of work and it's not something front-end engineers want to have to concern themselves with, and they shouldn't have to. This is especially true when we start talking about some of the more complicated and more powerful Hypermedia formats such as <a href=\"http://json-schema.org/\" rel=\"noreferrer\">JSON Hyper Schema</a>. With the right tooling, the front-end engineers shouldn't have even know what links are being followed to get the data they requested.</p>\n\n<p>I know there was no small amount of hand-waving in this answer, but it's a pretty broad and complicated topic. I encourage you to follow some of those links to learn more. I'm hopeful that one day the tooling will be good enough that you don't need to think about this stuff any more. After all, how much do you need to know about HTTP, HTML, an URI in order to use a website like this one. Basically zero, and it should be the same for anyone consuming your API.</p>\n\n<p>One last thing I'll leave you with is that REST is not necessarily the right choice for all use-cases and it's okay not to use hypermedia if it doesn't fit your needs. These days, most people make that decision with a healthy dose of ignorance, but it's a valid question to ask and you are right to be asking it. Make sure you know the trade-offs and best of luck identifying the good sources for information from the bad.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a AR called <code>User</code>, which has among other entities one called <code>City</code>.</p>\n\n<p>The way I assign a <code>City</code> to a <code>User</code> is:\n<code>$user-&gt;addCity($city);</code></p>\n\n<p>The problem comes when a <code>id</code> is given at some Controller endpoint instead of a <code>City</code> entity, I can't relate them if it's not through an instance and I can't retrieve the entity intance without a repository.</p>\n\n<p>I could retrieve the entity with a <code>CityRepository</code> and then add it to the <code>User</code> but I though I should only use a repository for ARs.</p>\n\n<p>For the moment, I'm getting the reference through Symfony's EntityManager:</p>\n\n<pre><code>    public function __construct(UserRepository $users)\n    {\n        $this-&gt;users = $users;\n    }\n\n\n    public function execute(Passenger $user, int $cityId, string $companyName = '')\n    {\n        $city = $this-&gt;users-&gt;getCityReferenceById($cityId);\n        $user-&gt;addCity($city);\n        ....\n    }\n</code></pre>\n\n<p>while on UserRepository:</p>\n\n<pre><code>public function getCityReferenceById(int $cityId): City\n{\n    return $this-&gt;em-&gt;getReference(City::class, $cityId);\n}\n</code></pre>\n\n\nAssistant:",
        "golden_answer": " <p>The reason this is giving you so much trouble is that it is a very bad idea already.  You really should look at refactoring this completely so that you don't have to make the decision.</p>\n\n<p>The issue is that the semantics of <code>doThing()</code> seem to be very ill defined.  One subclass makes it do one thing (an operation \"now\") and one subclass defines it to do another thing (queuing an even to be done \"later\").  The reason you're struggling with the best way to tie these two together in the <code>Foo</code> class is that they <em>shouldn't</em> be tied together.</p>\n\n<p>If you must do one of these designs, I recommend Design 1 unless you have a strong reason to pick Design 2.  Design 2 is typically seen as an anti-pattern.  If you see code like that, it says \"The writers of <code>Foo</code> knew every way <code>Foo</code> would be used and all conditions where it would be used.  They knew all subclasses and how they should operate.\"  In general, this is against the spirit of OO programming.</p>\n\n<p>Of course, there are exceptions to every rule.  One case study is trees.  Sometimes you have a structure like a scene graph or an abstract syntax tree where you know ahead of time <em>all</em> of the possible nodes that could ever appear.  In cases like this, it can be convenient to implement functions like <code>bool isNow()</code> or <code>Later asLater()</code> rather than doing the more formal OO approach using visitors.  But this should be treated as a special case.  If you aren't <em>positive</em> you're in this situation, you shouldn't go down that path.  Thus Design 1 functions better than Design 2.  But you really should be warry of having one abstract function <code>doThing()</code> doing two rather different operations.</p>\n\n<p>If your function is nothing more than <code>doThing()</code> or <code>execute()</code>, you might get away with this.  But if what you really wrote was something like <code>doConnect()</code>, where <code>Now</code> immediately makes a connection to a server while <code>Later</code> does an async call to make the connection later, then you'll likely get in trouble by getting confused as to what is really happening when you call that function.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am confused about Dependency Inversion in general. Lets's say we have 2 layers: Layer0 the low level layer, and Layer1 the high level layer.\nLayer1 should define the abstract interface, and Layer0 should implement it. However if Layer1 requires other types then the built in types, \nthen in order to use Dependency Inversion I must extract the complex types into a separate library and use those types in both layers.</p>\n\n<p>My question is, for reassurance, that there is no way to use dependency inversion without sharing complex classes or applying an adapter between the 2 layers?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Dependency inversion is when compile time dependency point to the opposite direction then run-time dependency.<br>\nEven without classes when you change abstraction(some interface) then both layers need to be recompiled.<br>\nSo unless your complex types do not contain any functionality they can be and they are part of the abstraction.  </p>\n\n<pre><code>----------------------\n|                    |\n|    Higher layer    |\n|                    |    \n----------------------  \n         |\n         | Higher layer depends on abstraction\n         |\n         V\n--------------------------------\n|                              |\n|    Abstraction and classes   |\n|                              |    \n--------------------------------  \n         ^\n         |\n         | Lower layer depends on abstraction\n         |\n----------------------\n|                    |\n|    Lower layer     |\n|                    |    \n----------------------  \n</code></pre>\n\n<p>So Lower layer's compile time dependency still pointing \"up\"(different then run-time dependency) which mean you are still using \"Dependency inversion\".</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In this <a href=\"https://softwareengineering.stackexchange.com/questions/191637/in-c-why-and-how-are-virtual-functions-slower#answer-191641\">answer</a> to \"<a href=\"https://softwareengineering.stackexchange.com/questions/191637/in-c-why-and-how-are-virtual-functions-slower\">In C++ why and how are virtual functions slower?</a>\",\nthe author mentions below point: </p>\n\n<p>\"Get the right function address from the vtable into a register (the index where the correct function address is stored is decided at compile-time).\"</p>\n\n<p>As a follow up of this comment, i have some questions:</p>\n\n<ol>\n<li><p>What is the order of function pointers stored inside the <code>vtable</code>? Is it compiler dependent or all compilers have to implement it the same way?</p></li>\n<li><p>If compilers are free to implement it in their own way, then how does binary standard's like <code>COM</code> works. <code>COM</code> relies on the assumption that <code>vtables</code> are implemented in a uniform way by compilers, in order to pass <code>IUnknown</code> pointers to a component compiled by a different compiler. Isn't it?</p></li>\n</ol>\n\n\nAssistant:",
        "golden_answer": " <p>While it is implementation dependent, it is also fairly predictable.&nbsp; Especially historically speaking, the compilers layout members in declaration order.&nbsp; For fields (instance data) that means each field get assigned the next offset in the object (after alignment is rounded up as required), and, each virtual method that is introduced, is assigned next vtable slot.&nbsp; (Overrides share the same vtable slot as the virtual method that they override in the base class.)</p>\n\n<p>Multiple inheritance complicates field &amp; vtable layouts, introducing a notion of sections that group the field and vtable entries, and, the generated code has to switch between sections as their usage demands.</p>\n\n<p>Because among other things, C is the default standard for foreign function calling, many tools and programs rely on C to layout structs in the predictable order they have always done.</p>\n\n<p>C++ compilers are allowed some latitude for certain constructs these days, but as you have described, to be used with COM (which is of course a Microsoft standard, not a C++ language standard), they have also need to be predictable.</p>\n\n<p>See also:</p>\n\n<p><a href=\"https://stackoverflow.com/questions/9115020/order-of-fields-in-c-c-structs\">https://stackoverflow.com/questions/9115020/order-of-fields-in-c-c-structs</a></p>\n\n<p><a href=\"https://stackoverflow.com/questions/4178175/what-are-aggregates-and-pods-and-how-why-are-they-special\">https://stackoverflow.com/questions/4178175/what-are-aggregates-and-pods-and-how-why-are-they-special</a> </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm a teen who has been programming for about 3 years, I can do some basic Software and so, but I feel I can't do all by myself.</p>\n\n<p>What can I do to find people interested in Programming ? None of my friends does, I only have a Cousin which is studying Software Engineering, but he is in another country.</p>\n\n<p>I live in Spain, so It's more difficult that in USA.  </p>\n\n\nAssistant:",
        "golden_answer": " <p>You can contribute to open source and you will find people from all over the world , you can look at their code and learn. Some open source groups are very elitist some friendly. Choose your pick.</p>\n\n<p>Good for you on starting early :)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm trying to make my C programming exciting by learning assembly programming. </p>\n\n<p>I've encountered an image of flag registers in 8085 assembly programming. In that image blocks are named from d0-d7(numerals in subscript). Why are they named 'd'? Is this arbitrarily chosen? There is another register with the name 'D', are both same or different?</p>\n\n\nAssistant:",
        "golden_answer": " <p>If the image you saw is like <a href=\"https://i.stack.imgur.com/T1x9F.jpg\" rel=\"nofollow noreferrer\">this one</a>, <code>D0</code>-<code>D7</code> imply bit positions in the status register, called <code>F</code> (for flags) when part of the <code>AF</code> register pair.  The Ds are misleading because they imply some (nonexistent) relationship to the <code>D</code> register or the data pins (which are multiplexed with the address lines and are actually called <code>AD0</code>-<code>AD7</code>).</p>\n\n<p>Describing bit positions for the status flags doesn't mean much of anything for most people because the only instructions that operate on <code>F</code> deal with a single bit at a time (conditional jumps, conditional subroutine calls and the instructions that set and clear the carry flag).  The only way to operate on the flags as a whole would be to transfer them to or from another register by way of the stack.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I work on the software side of a company that provides custom hardware with software running on top of it.  Often times the hardware is not engineered well.  In those cases, I am often asked first to troubleshoot the problem - of course the symptom is always \"your software crashed\" or something along those lines.</p>\n\n<p>Just recently we had another one of these incidents where power on a USB line is not reliable, and it causes a USB device to fail.  This causes a usability problem in one of our applications.  I have been asked by upper management to handle this better - continually monitor the USB device, and if it disappears, then reboot, or try to reset it.  Doing either of these is not guaranteed to fix anything.</p>\n\n<p>Ultimately, the real fix is to correct the reliability of the device from the hardware side.  I could improve performance, but not to 100%, and of course I would be using my already limited time to bloat code and add yet another device monitoring thread.</p>\n\n<p>So with all that said, how do I make a good decision about when to say that this needs to be a hardware fix, and only a hardware fix?  Can I approach this quantitatively, and come up with some sort of definitive yes/no test?  I'm sure its not that easy.</p>\n\n\nAssistant:",
        "golden_answer": " <p>I would look at it this way.  Which adds more value to the company from the view of management. They probably don't care if the code is bloated or if it's not 100% perfect they want to do the least amount of work to make money.  Fixing hardware is usually way more expensive then changing code.  If you can by making your change make it good enough to sell with out massive amounts of cost in support then they will want the change on your side. If you change is not going to make it good enough to make money, you should bring this up and say we need to fix the hardware.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'd heard about Design by Contract a long time ago and always was confused by this question. The approach uses real-world client-supplier analogy to describe caller-callee relationships. It stays, that if a client ensures preconditions before calling a supplier, the supplier will get the benefits by avoiding preconditions check; and, on the other hand, if supplier ensures postconditions, the client will get benefit by avoiding checking those; everyone is happy. That's what is written in <a href=\"https://en.wikipedia.org/wiki/Design_by_contract\" rel=\"nofollow noreferrer\">Wikipedia</a>, on <a href=\"https://www.eiffel.com/values/design-by-contract/introduction/\" rel=\"nofollow noreferrer\">EiffelSoftware website</a> and in billions of other places.</p>\n\n<p><a href=\"https://i.stack.imgur.com/VdxeI.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/VdxeI.png\" alt=\"Example\"></a></p>\n\n<p>But. The world is cruel. And in most cases in the real world everyone prefers to check what he <em>got</em> for work instead of being sure that the work is done correctly. Even in the example above, we are checked in the airport for the preconditions (ticket, baggage, etc), the supplier doesn't trust us. And in the end of the fly, we want to be sure that we're  really in Chicago and our baggage hasn't been lost.</p>\n\n<p>So, what the benefits of checks made by a client instead of a supplier? I see no difference. Is the analogy with the real world is bad or did I just missed something? <strong>Could we swap checkers of postconditions and preconditions and still call it design by contract?</strong></p>\n\n\nAssistant:",
        "golden_answer": " <p>The reason that preconditions should be checked by the client is that the client is in a better position to collect or solicit any missing information because (presumably) it is better able to communicate with the user. By the time the supplier gets involved, all it can do is throw an error and abort processing, since it doesn't know where any missing information should come from.</p>\n\n<p>Postconditions should be handled by the supplier to alleviate the effort required to write a client. If the client is guaranteed that (for example) a particular value will never be null, or will only contain values within a specified range, it enables the client to simply process the values instead of having to validate them first.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm learning DDD and yet I have more questions than answers.</p>\n\n<p>Let's consider a model of a directory containing enormous number of files.<br/>\nHere is how I see it: </p>\n\n<p>Directory is an Aggregate root.<br/>\nThis entity should have the validation logic of checking file name uniqueness when it is added or just renamed. And File entity contains the 'SetName' logic, notifying Directory via Domain Event about name changes.<br/>\nBut how should Directory then work?<br/>\nIt is not always possible to load all files into memory. Should in this case Files repository have adhoc logic for checking name uniqueness? I suppose it is a viable decision.<br/>\nHowever, what if some files have been already added or renamed withing current not yet commited transaction? (nothing prohibits that. Transaction boundaries are set externally in relation to business logic). Probably repository should take into account both in-memory and persisted states (merging these states can be nontrivial task.)</p>\n\n<p>So, when aggregate root with all its children fits in memory - everything is fine.\nAnd as soon as you can not materialize all entities there are troubles.</p>\n\n<p>I'd like to know what are the approaches for such situations.\nMay be there is no problem at all and it is just because of my misunderstanding of the subject.</p>\n\n\nAssistant:",
        "golden_answer": " <p>My answer is biased with Vaughn Vernon's Implementing Domain Driven Design great book (a must read)</p>\n\n<p><strong>1. Favor small aggregates.</strong></p>\n\n<p>If I'm to model your domain, I would model a <code>Directory</code> as an aggregate and <code>File</code> as another aggregate.</p>\n\n<p><strong>2. Reference aggregates by ids.</strong></p>\n\n<p>Therefore <code>Directory</code> will have a collection of <code>FileId</code> value objects.</p>\n\n<p><strong>3. Use factories to create aggregates.</strong></p>\n\n<p>For a simple case a factory method may be enough <code>Directory.addFile(FileName fileName)</code>. However, for more complex cases I would use a domain factory.<br>\nThe domain factory could validate that the <code>fileName</code> is unique using a <code>FileRepository</code> and a <code>UniquefileNameValidator</code> infrastructure service.</p>\n\n<p><strong>Why model <code>File</code> as a separate aggregate?</strong></p>\n\n<p>Because <code>Directories</code> aren't made of <code>Files</code>. a <code>File</code> is associated with a certain <code>Directory</code>. Also, think of a directory that has thousands of files. Loading all these objects into memory each time a directory is fetched is a performance killer. </p>\n\n<p>Model your aggregates according to your use cases. If you know that there will never be more than 2-3 files in a directory then you can model them all as a single aggregate, but in my experience business rules change all the time and it pays if your model was flexible enough to accommodate the changes.</p>\n\n<p>Obligatory read <a href=\"http://dddcommunity.org/library/vernon_2011/\">Effective Aggregate Design by Vaughn Vernon</a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am new to C# development and wish to create a more responsive UI. In my preliminary research, I have seen two methods for achieving this:</p>\n\n<ol>\n<li>Multi-threading in conjunction with the BackgroundWorker class.</li>\n<li>The newer Async/Await modifiers. </li>\n</ol>\n\n<p>Does newer mean better? What's the difference between the two methods? If I wish to create a new project, how do I choose which method to go with?</p>\n\n<p>EDIT: Maybe I should specify. I am creating a Windows Forms application, where all necessary data will be saved/loaded on the local disk. I will also be communicating with several USB devices.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You will be able to accomplish your task using <code>BackgroundWorker</code>. It is a well known class, and many people have used it.</p>\n\n<p>The new C# 5 <code>async</code> and <code>await</code> keywords basically just make it easier to write readable asynchronous code. There may be fewer tutorials and examples of how to accomplish various tasks with these keywords rather than <code>BackgroundWorker</code>.</p>\n\n<p>Unless you need to use an older version of C#, I suggest learning how to use <code>async</code> and <code>await</code>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've been in my current position for a long time (10 years) and in that time, I feel like I've performed well as a designer, system architect, and programmer.  However, all that work has been on internal projects that aren't accessible from the outside world.</p>\n\n<p>I see a lot of <a href=\"https://softwareengineering.stackexchange.com/questions/6790/how-can-i-let-prospective-employers-know-im-a-great-developer/6795#6795\">advice like this</a> that suggests 'If you can literally point to something and say \"I wrote this\" it's very impressive'.  What about if you can 'literally point to' nothing at all, because while you're a passionate programmer who (as the classic Joel-ism puts it) \"is smart and gets things done\", all those things are invisible?</p>\n\n<p>Do I need to start frantically committing to open-source projects?  Start a \"real world\" (not corporate-internal) blog?  Frankly, I spent most of my 10 years happy here, and only recently have considered leaving for greener pastures.  Am I going to be sunk before I start looking because of my focus on work my current employer, at the expense of my \"public presence\"?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Showing external projects is helpful but it's never been an blocker for me hiring or getting hired in the past. </p>\n\n<p>If you can talk about the projects you worked on and explain to whoever is interviewing you some detail about what you did, what went well, how it provided value to your organization. Getting excited about what you did and programming in general is a good way to score points in a lot of places. Showing interest in open source stuff, having a github account, even if all you do is follow some projects, maybe a small patch, does show some value. I've found most employers don't actually try and look at the details of my open source projects on github, they are just excited to see it ;)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>With in the introduction of anonymous types in C# we got the <code>var</code> keyword.</p>\n\n<p>Now people use <code>var</code> everywhere instead of the correct type. The reasons I've heard given for this are:</p>\n\n<ul>\n<li>It makes refactoring easier</li>\n<li>It's shorter</li>\n<li>it improves readability</li>\n</ul>\n\n<p>A common example might be</p>\n\n<pre><code>var result = client.GetResult(query);\n</code></pre>\n\n<p>is better than:</p>\n\n<pre><code>MyObject result = client.GetResult(query);\n</code></pre>\n\n<p>Because if you refactor GetResult to return a different object; for example:</p>\n\n<pre><code>MyOtherObject result = client.GetResult(query);\n</code></pre>\n\n<p>you don't have to also refactor the calling code.</p>\n\n<p>However I recently had to do the following refactoring</p>\n\n<pre><code>IEnumerable&lt;MyObject&gt; GetResult(query)\n</code></pre>\n\n<p>to</p>\n\n<pre><code>Task&lt;List&lt;MyObject&gt;&gt; GetResult(query)\n</code></pre>\n\n<p>The calling code was along the lines of</p>\n\n<pre><code>//return true if there are any results\nvar result = client.GetResult(query);\nif(result != null)\n{\n    return true;\n}\nreturn false;\n</code></pre>\n\n<p>Which after the refactoring would still compile and always return true. Whereas the explicitly typed form would have thrown a compilation error.</p>\n\n<p>So. The question is. Given that there are downsides to using var instead of the explicitly typed variable. Is it simply a case of coding style preference, or are there clear reasons to use, or not use var in this fashion? (ie. other than where required with anonymous types)</p>\n\n\nAssistant:",
        "golden_answer": " <p>FWIW I do find that <code>var</code> is overused. That doesn't mean it shouldn't be used though. These are the standards we use at my workplace. </p>\n\n<ol>\n<li><p>Use <code>var</code> when the type is obvious. </p>\n\n<pre><code>var foo = new Foo();\n</code></pre></li>\n<li><p>Don't use <code>var</code> when the return type isn't obvious. </p>\n\n<pre><code>Foo foo = service.GetItem();\n</code></pre></li>\n<li><p>Don't use <code>var</code> when the method returns a concrete type. </p>\n\n<pre><code>ICollection&lt;Foo&gt; items = new List&lt;Foo&gt;();\n</code></pre></li>\n</ol>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm using Swift, but I understand computed properties are a thing in a few other languages as well. I have the following case:  </p>\n\n<ul>\n<li>var <code>bar</code> in class <code>Foo</code> is changed throughout program flow.</li>\n<li>vars <code>a</code>, <code>b</code>, <code>c</code> and <code>d</code> are constrained to <code>bar</code>'s value so defining them as computed properties is a clean way to handle that.</li>\n<li>the constraints are simple calculations that take <code>bar</code> and output a value</li>\n</ul>\n\n<p>I can write the formula in the getter of each of the individual vars (the formulas vary slightly), or I could have the vars be normal properties and just assign them in <code>bar</code>'s set.<br>\nWhich is more preferable? Is there anything more to consider than style?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes, if you move the computation to the <em>getter</em> of these properties, then it will be performed <em>only</em> when you actually read those computed properties, and not every time whether it's needed or not. Whether that makes a difference or not depends entirely on how common the access is and how costly the computation.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm 8 months into my first job as a developer at a mid-small company.  The four development teams have about 7 developers each, the design team consists of about the same number, and the administration / sales / marketing / hr team is 4 people.</p>\n\n<p>We mostly develop web apps, a one-time deal, to run on the client's (usually existing) environment.  I'm finding myself setting up development environments to match, usually things I've never used before (from C#.NET 1.1 and MS-SQL to a regionally developed WAS called JEUS), which takes a significant amount of time.  </p>\n\n<p>Sometimes I get help from other developers but mostly I follow online tutorials until it seems to work, and then I spend more time fixing my code when it breaks because the settings aren't exactly the same as the actual environment.</p>\n\n<p>I'm starting to think that one guy who specializes in this stuff would make it much easier for the developers to actually do what they're paid to do.  When does it make sense for a company to get a dedicated systems engineer?  Or am I wrong and should just suck it up and learn to do it?  I do realize that being familiar with different environments would improve my employability...</p>\n\n\nAssistant:",
        "golden_answer": " <p>My experiences working at a company with less than 20 people are that as a software developer I have to be top of the food chain and wear many hats.</p>\n\n<p>When I say top of the food chain, I mean that I am expected to excel at any IT problem thrown at me and surpass the abilities of my IT peers who work in a non software development role.  By wear many hats I mean that I do need to play many different IT roles from time to time.</p>\n\n<p>My peers consist of tech support, pc support specialists and a webmaster/network administrator/QA.  Besides QA, if the network goes down and the guy responsible is not in the office that day I am not only expected to fix the problem but do it better than the guy who was hired to do it.  Same thing if the website goes down and same thing if all the tech support people are on the other line and a password needs reset for a user.</p>\n\n<p>They don't view it that my skill sets are just coding/developing, but that these other IT professionals are there to shelter me from the daily grind of running a successful business so that I have time to work on projects with minimal distractions.</p>\n\n<p>Whatever you are struggling with, take the time to learn it and be happy you are learning a new skill because if the company falls into bad times and they have to let half the team go, they are going to get rid of the software developers who only code/develop and who only code/develop exactly what is written on a spec without question.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm a programmer currently working in rounds of meetings along with BAs and PM to gather/describe modules and functionality of our case management system; after a few meetings I saw that using 'use cases' would be a very very good fit to document many of the things and functions discuessed and/or proposed for the new system. When I suggested we needed to create 'use cases' so that we don't forget what we said/concluded and also to have programers know what they should code, the leading BA mentioned don't like 'use cases'.</p>\n\n<p>What can be used to gather/document requirements when people supposed to write user requirements say they don't like 'use cases', or when you realize that they don't want to write 'use cases' to describe what the system should do?</p>\n\n<p>I'm trying to find out if there's a close or effective substitution to using 'use cases' to document system functionality/scenarios.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Depending on your/their definition of a 'use case' you could instead look at 'user stories'. I say this if you define a use case similar to Usability.gov's definition</p>\n\n<blockquote>\n  <p>A use case is a description of how users will perform tasks on your Web site.\n  A use case includes two main parts:\n  the steps a user will take to accomplish a particular task on your site\n  the way the Web site should respond to a user's actions. A use case begins with a user's goal and ends when that goal is fulfilled.</p>\n</blockquote>\n\n<p>You can instead use user stories, which come from the agile development methodologies. They are more about <em>what</em> you want to do, then <em>how</em> to do it. There are many different articles and definitions about user stories out there. This older article actually presents what they see as the difference between use cases and user stories (<a href=\"http://www.scrumalliance.org/articles/169-new-to-user-stories\" rel=\"nofollow\">New to User Stories?</a>) And in the end, they really do the same thing. They just frame them differently. You still need the same information, who, what and why (goal). Their meant to be more narrative, with personas linked to real user types of your system. They're more descriptive, but still contain all the information you need.</p>\n\n<p>It sounds like in your case, representing the same information you need differently might be exactly what you need.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've been assigned an in-house web application that is basically an Employee and Project Management System.</p>\n\n<p>I'm getting confused as to where I should really start with this assignment (I mean I'm my own development manager and I really don't have experience with making a project alone) and I'm hoping that you guys could share your experiences when you were given an assignment/project to build by yourself.</p>\n\n<p>Thanks</p>\n\n\nAssistant:",
        "golden_answer": " <p>You need to ask yourself some questions about the project first to better understand what and how will be realized.</p>\n\n<p>Here are some key points you should consider. These are only suggestions, or points you may want to take into consideration or not. Everyone has a different way of doing things, just think about it.</p>\n\n<p><strong>By NO WAY this is a complete list!</strong></p>\n\n<p><strong>1) Gather info</strong></p>\n\n<p>Ask as much details about the project as possible. Both to your contractors, and to the people who will actually use it. Try to understand what are the expectations about this application and what it will be used for.</p>\n\n<p><strong>2) Understand what the project should be able to do when finished</strong></p>\n\n<p>You may want a detailed analysis about your project before actually thinking how to build it.</p>\n\n<p>What are the functionalities it must have?</p>\n\n<p>What kind of commands and data the users expect to see and use?</p>\n\n<p>How should the application being structured?</p>\n\n<p>You can make sketchs using paper and pen, post-it, or using some software to help you keeping tracks of your ideas and thinking.</p>\n\n<p><strong>3) Choose the right tools for the kind of application you need to make.</strong></p>\n\n<p>There are many programming languages, databases, server typologies, frameworks, etc. out there. You have to choose the right tools for the job, based on what you actually need to develop, and what you feel most comfortable with.</p>\n\n<p>Sometimes you cannot choose any of this, but if you can, choose them well.</p>\n\n<p><strong>4) Start making some prototypes of the user interface.</strong></p>\n\n<p>Again, you can use paper or software or both or what you think it's the most useful tool. Just start to have an idea of how the application will look like, where to put the functionalities you need, the commands, where to display the data, etc.</p>\n\n<p>This will give you a better idea if what you thought before is ok or if you need to change something (back to point 2).</p>\n\n<p><strong>5) Start to prototype some code functions.</strong></p>\n\n<p>You may want to be sure you are actually able to do what you are going to do before you are already halfway on your coding and understand (too late) that you went the wrong way.</p>\n\n<p>Start coding the key-functionalities of your application and test them to see if they work as expected.</p>\n\n<p>Perhaps the programming language you choose is not so well-suited for the kind of task?</p>\n\n<p>Or your skill with that particular language/framework are not so good and you feel you could do it better or faster using other tools?</p>\n\n<p><strong>6) Show your contractors your prototype, both the UI and the basic functionalities.</strong></p>\n\n<p>You only prototyped a basic UI skeleton and application functionalities so far. But it's already enough for other people to see if this is what they expect or not.</p>\n\n<p>Gather as much feedback as possible, understand what's wrong and what's work ok. If something is not working as expected you will have to rethink about it and change your project accordingly.</p>\n\n<p><strong>7) Start coding the application in detail.</strong></p>\n\n<p>Now you can start implementing all the code and UI details.</p>\n\n<p>The order in which you develop the application is up to you, and varies depending on the application.</p>\n\n<p>Just focus on one small piece of the application at a time, divide the project into small pieces.</p>\n\n<p>I won't go more far than this since the question was only about starting the project, but I think you have some good points to think about.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Interested in knowing from the more experienced ones if someone can find a job as a programmer without even a highschool degree. Consider the said person to be an average programmer. Would someone even consider giving him/her a chance on an interview ? The languages of interest would be python/php/java/c#</p>\n\n<p>Please answer for your region/city/country only. No \"go back to school\" answers please.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Your biggest difficulty is going to be getting through the HR filter. If you can do that, experience will trump education (most of the time).  </p>\n\n<p>In the meantime, try to find some small shop that just needs someone who can code. You should also try to join an opensource project (or two) to get some experience and show that you have some skills. You are going to have to start small and build on that.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am unsure, if I understand the principles of REST completely.</p>\n\n<p>The idea behind it is (according to e.g. Wiki and other sources) that data is transferred via HTTP(S) and addressed via URIs. Depending on the HTTP method used different operations on the underlying database are performed (CRUD operations). The glory details about different representations etc I neglect here for good reason.</p>\n\n<p>This is clearly only a very minimalistic description of a REST API but as far as I see it here, it only represents a transparent \"proxy\" to access the (SQL) database using basic HTTP actions. So it provides the database access via API. Nothing more.</p>\n\n<p>Is all business logic located on the client? Then I do not see the benefit of using such an architectural structure compared to other paradigms.</p>\n\n<hr>\n\n<p>To understand things a bit more in detail, I want to describe a bit my idea and what I think might be a way to get it working:</p>\n\n<p>I have a set of users A through D. Each user represents its own client. USers A through C now create some data and put this data in the database. This can be simply represented using the above mentioned structure, I agree.</p>\n\n<p>Now after this is finished, user D comes into action. He has a set of rules (call them laws) and can make a series of decisions based on the data from A-C. All these desicions have to be documented in the database and influence the following options (according to the rulesets).</p>\n\n<p>Now, I can make the following:</p>\n\n<ul>\n<li>Send the complete data from users A-C to user D and let the client's app handle all the business logic and send the result to the server back.\nSo after each decision the client sends the intermediate result to the server.</li>\n<li>Keep the business logic on the server.\nThe user D gets only a condensed version of the data of A-C.\nHe makes a decision and transfers it to the server.\nThe server applies the rules and provides the options to the user D on request.</li>\n</ul>\n\n<p>I think the first approach is critical as the user might change the business logic and send invalid data to the database through the CRUD interface. The server will not be able to detect this and accept the raw data.</p>\n\n<p>On another quesion of SE (<a href=\"https://softwareengineering.stackexchange.com/a/323343/58867\">https://softwareengineering.stackexchange.com/a/323343/58867</a>) it is suggested that the business logic is written on the server and to reduce overhead partly on the client. This last part is the part that contradicts my understanding of REST (see above). </p>\n\n<ul>\n<li>How is it possible to add more layers to abstract a problem using REST?</li>\n<li>How can one model a series of operations (one  decision must be made before the next can be addressed) without transferring the whole database on each step (stateless operation)?</li>\n<li>The server is never stateless as he has access to the data. How is this compatible with the requirement of a stateless server?</li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p>To understand REST you have to understand that there is at least two completely opposing interpretations of it. The first is the \"original\", from the author who coined it. The arguments from this interpretation are used all the time to justify implementations that do not actually follow it. Then there is the colloquial interpretation of \"CRUD through JSON/HTTP\".</p>\n\n<p>Because authors rarely say which interpretation they are speaking about, things get really confusing.</p>\n\n<p>To understand the <a href=\"https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm\" rel=\"noreferrer\">orignal</a> REST, just think about the web and people as clients. On the web, we are presented with options and we choose things from options. I have my own logic (the client logic) I want to achieve, but each resource I talk to may have its own logic. For example I want to book a flight, I may start with google, then go to a flight aggregator site, enter some data (which I don't normally have to enter again!), choose a provider, go there, enter some more data about payment maybe, and so on. I know what I want, and I interact with things in their own domain to do my thing. I have to of course know all of those and understand what they say (Google result page, flight wizard, etc.).</p>\n\n<p>In the colloquial interpretation none of those things matter. You just have some CRUD endpoints and you often hear about URIs, sub-resources, POST vs PUT, and things like that. Rarely if ever are Mediatypes, Links or Forms mentioned, although (original) REST does not exists without Hypermedia.</p>\n\n<p>So now to you questions (and I assume you want the \"original\" REST, because the colloquial one doesn't really have any specific rules):</p>\n\n<ol>\n<li><p>Where is the business logic: Both the client and server has logic of their own. But, the logic of the server is not be shared with the client. Think of the client as a person. Do you want a person to type in URLs and data with every new request? Of course not, you use Forms, Links, Hidden fields, whatever it takes.</p></li>\n<li><p>How is it possible to add abstractions? Well, how does google search work? How do Wizard dialogs work on the Web? How come you can book a hotel on the web? All those are REST applications, with a human as client. This is not a hyperbole, REST applications with programmatic clients work exactly the same way.</p></li>\n<li><p>How to avoid transferring the whole DB? Again, look at all the millions of web applications. It is not difficult.</p></li>\n<li><p>How is the server stateless? Statelessness != datalessness. State refers to the current interaction, not data. For example if I use a Wizard-type dialog to book a hotel, the progress I make is not tracked (in REST) on the server, instead I resubmit my state each time (via hidden fields, that I don't actually have to know). If I can choose to save a draft version of my booking for example, that is no longer conversational state, the server can very well save that.</p></li>\n</ol>\n\n<p>Here's an article of mine with some more info: <a href=\"https://javadevguy.wordpress.com/2017/12/01/5-signs-that-your-rest-api-isnt-restful/\" rel=\"noreferrer\">5 Signs That Your REST API Isnt RESTful</a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>How do current web browsers (or mobile mail clients and any software in general) save user passwords? All answers about storing passwords say we should store only hashes, not the password themselves. But I'm having a hard time searching the web trying to find the best techniques to store passwords when we know we will need them in plain text later on  without storing them in plain text, without using a weak encryption (known key) and without asking the user for a master password. Any ideas?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The passwords are stored in plain text, unless a master password is used.</p>\n\n<p>When people tell that you must store only hashes of passwords, they are talking about <strong>server-side</strong> storage, not client-side.</p>\n\n<h2>Server-side</h2>\n\n<p>When you have your own website when the users can register/logon with their passwords, you don't need (and must never) store the passwords themselves:</p>\n\n<ul>\n<li><p>You <strong>don't need to store plain passwords</strong>, because you only have to verify that the password used during a logon matches the password given by the user while registering. You can do it with hashes, since different passwords would have different hashes.</p></li>\n<li><p>You <strong>must not store plain passwords</strong>. What if your website is hacked? Moreover, many people reuse same passwords again and again, so you practically give to any hacker the ability to access your users Facebook account, mail account, etc.</p></li>\n</ul>\n\n<h2>Client-side</h2>\n\n<p>Browsers are different. They store the passwords on client machine, and must have an original password, not a hash.</p>\n\n<p>This means that those passwords are stored in plain text in most cases.</p>\n\n<ul>\n<li><p>Security-wise, it doesn't matter too much. Those passwords are stored in a directory which belongs to the user account. This means that <strong>it's up to the operating system (and to the user) to properly configure the permissions</strong> to the users files, and to restrict the access to the file which contains the passwords to the user himself.</p></li>\n<li><p>User experience wise, this is the easiest thing to do. Another possibility is to encrypt those passwords by a master password, in which case <strong>the user would have to provide the master password every time he opens the browser</strong>. I'm pretty sure most users would never enjoy that.</p>\n\n<p>If the master password is stored somewhere, the same problem arises: if you store the master password in plain text, what's the point? If you encrypt it, you must have a master-master password.</p></li>\n</ul>\n\n<h2>Sync</h2>\n\n<p>Note that most browsers enable the users to sync their data across multiple machines. The sync uses a remote server to store the cookies, history, bookmarks and passwords. For example, Chrome uses Google servers to store this data.</p>\n\n<p>In this case, <strong>the passwords are never stored in plain text on sync servers</strong>, otherwise, it would be a security issue. In Chrome, you have to choose the master password for sync (or use the one from your Google account). This master password will be used to encrypt the passwords (always), and other data like the history or the bookmarks (optional).</p>\n\n<hr>\n\n<p><sup> For the sake of simplicity, you can imagine that the different passwords cannot have same hashes. In theory, this is wrong, since collisions may exist. In practice, if you use a strong hash algorithm, like SHA-256, you can neglect the risk of collision for a website even with millions of registered users. Things are different if you use an obsolete and depreciated hash algorithm, like MD5.</sup></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I was now talking with some people and they told me that if i was intrested in a job in the future for Java programming i should not spend too much time only learning Java SE i should spend time learning Java EE instead.. Now that brought me to some questions..</p>\n\n<p>Java Enterprise Edition why use this ? What can i make with this that i can't make in Java SE?, And what kind of applications is this good for?</p>\n\n<p>Is there any good books out there that i can read to learn the Java EE?</p>\n\n<p>If i know Java SE well is it easier to learn Java EE ?</p>\n\n<p>Thanks! I will keep browsing the web for some anwears for theese questions.. And if i find anything i wil update this question.</p>\n\n\nAssistant:",
        "golden_answer": " <p>I suspect they have been pulling your leg. Java EE is nothing but a Java SE running a container application (like JBoss) that supports the additional Java EE frameworks. Not knowing the SE would be a major problem for your future in Java coding.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have built a Windows-only desktop application which is composed of two main executables and various configuration files. \nThe two applications are developed in different languages (JS and C++, respectively) and should always be in sync with versions (ie. appA-v1.0.exe would probably be incompatible with appB-v2.0.exe). </p>\n\n<p>I'm looking for an auto update method that helps me ensure this constraint is always true: this would mean <strong>distributing a single package containing both applications</strong> instead of using language-specific auto-updaters (I used Sparkle for C++ and Squirrel for electron in the past).</p>\n\n<p>I have full access to the machines this software would be installed on (5/6, all managed by us), so the idea is to have a timed update check that in case of need downloads and unpacks the update. The update should <strong>not require user interaction</strong>.</p>\n\n<p>I could write this on my own, using an FTP server to host the package, checking last modification date, downloading and unpacking if needed, but I was wondering if there are better solutions.. any idea?</p>\n\n<p>Thanks!</p>\n\n\nAssistant:",
        "golden_answer": " <p>One way you could handle this is by using extensions to the WSUS (Windows services update server?) to deploy updates to your application.  </p>\n\n<p>This answer from Microsoft is a little old but I think it still\napplies:</p>\n\n<blockquote>\n  <p>Hi Ahmed Shariff, to Patch third party software like Adobe Reader,\n  Flash player, Java and other you have the choice between :\n       - Free Applications (open source) :\n            - Local Update Publisher (<a href=\"http://localupdatepubl.sourceforge.net/fr/index.html\" rel=\"nofollow noreferrer\">http://localupdatepubl.sourceforge.net/fr/index.html</a>)\n            - Wsus Package Publisher (<a href=\"http://wsuspackagepublisher.codeplex.com/\" rel=\"nofollow noreferrer\">http://wsuspackagepublisher.codeplex.com/</a>)\n       - Commercial Applications :\n            - Patch Manager from Solarwinds (<a href=\"http://www.solarwinds.com/solutions/microsoft-wsus-patch-management.aspx\" rel=\"nofollow noreferrer\">http://www.solarwinds.com/solutions/microsoft-wsus-patch-management.aspx</a>)\n            - Corporate Software Inspector from Secunia (<a href=\"http://secunia.com/vulnerability_scanning/corporate/help/sfw.csiwsusconfiguration/\" rel=\"nofollow noreferrer\">http://secunia.com/vulnerability_scanning/corporate/help/sfw.csiwsusconfiguration/</a>)</p>\n</blockquote>\n\n<p>Source:  <a href=\"https://social.technet.microsoft.com/Forums/windows/en-US/67833919-6477-41ee-9c8f-1cdd34b9641e/using-wsus-v30-to-install-3rd-party-software?forum=winserverwsus\" rel=\"nofollow noreferrer\">Microsoft Help Forum Post</a></p>\n\n<p>Alternatively if your application is portable (no installer necessary) you could use a git server to host your binary and add a scheduled task which pulls from your repository.  It isn't exactly what it was built for but you do you get versioning out of the box and easy rollback capabilities.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>How could a true Vector type be implemented in Haskell? In order for something to be a Vector, it has to be stored sequentially in memory, with <code>O(1)</code> random access. But Haskell hides its memory management, and its datatypes describe trees! So how could you express that kind of requirement?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Not all data types in Haskell are trees. There are also the builtin types like functions or Int. Among those you find the type <a href=\"http://hackage.haskell.org/package/array-0.5.0.0/docs/Data-Array.html\" rel=\"noreferrer\">Array</a> which gives you O(1) access to its elements.</p>\n\n<p>Some compilers, like GHC, also provide unboxed arrays. Those use less memory and per element access is faster, but that does not change the complexity of course.</p>\n\n<p>On top of those arrays one can build data types similar to <code>std::vector</code> in C++. An example is the <a href=\"https://hackage.haskell.org/package/vector\" rel=\"noreferrer\">vector</a> library.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've got a DataSource base class and a few different sub-classes.  I want to be able to switch which sub-class i'm using at runtime so I'm doing the following :</p>\n<pre><code>// pointer for our datasource object\nDataSource *data;\nif (ds.equals(&quot;mqtt&quot;)) {\n  data = new Data_mqtt(config,display);  // Data_mqtt is a sub-class of DataSource\n\n} else if (ds.equals(&quot;wf&quot;)) {\n  data = new Data_wf(config,display);  // sub-class of DataSource\n</code></pre>\n<p>Is this the correct use case  ?  Is there an implicit object cast going on here ?  Everything is working fine but I've got a weird feeling about it (code smell?).</p>\n<p>Doing it this way, the only methods and members that are available via the data pointer are the ones declared in the DataSource.h with all the DataSource specific stuff hidden from the user so it's kinda of like an interface in that respect.</p>\n\n\nAssistant:",
        "golden_answer": " <p>This kind of code is fairly normal. You have different classes, and at some point it is necessary to decide which class shall be used.</p>\n<p>However, the limitation is that you have hard-coded support for a fixed number of classes. Depending on the context of your application, it could make more sense to create a data structure where classes can be dynamically registered, e.g. via plugins. That would allow new classes to be added without recompiling your entire application. Something like this:</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>using Constructor = std::function&lt;std::unique_ptr&lt;DataSource&gt;(Config, Display)&gt;;\nstd::unordered_map&lt;std::string, Constructor&gt; registry&amp; registry() {\n  // keep the static variable inside a function to control initialization order\n  static std::unordered_map&lt;std::string, Constructor&gt; r;\n  return r;\n}\n\n\n// selecting the appropriate implementation\nstd::unique_ptr&lt;DataSource&gt; create_data(std:string_view ds, Config c, Display d) {\n  return registry().at(ds)(c, d);\n}\n\nint main() {\n  // initialization: register available implementations\n  registry().emplace(&quot;mqtt&quot;, [](Config config, Display display) {\n    return std::make_unique&lt;Data_mqtt&gt;(config, display);\n  });\n  registry().emplace(&quot;wf&quot;, [](Config config, Display display) {\n    return std::make_unique&lt;Data_wf&gt;(config, display);\n  });\n\n  // ... some application code\n\n  return 0;\n}\n</code></pre>\n<p>This is the manually implemented version of what's performed in other languages by a <em>dependency injection container</em>. In some languages, reflection capabilities could also be used. Additionally, more complex DI containers can also track dependencies between the objects they construct, e.g. they might be able to automatically resolve the Config or Display objects. In C++, that would only be possible with lots of casting.</p>\n<p>Whether such a registry makes sense for your software depends on whether you want to be able to potentially keep the software extensible without recompilation. This is extremely useful for libraries or for plugin architectures, but is mostly useless for more monolithic applications.</p>\n<p>Your point that the use of a <code>DataSource</code> interface limits the available functions is very good. This is an example of the <em>interface segregation principle</em> where you try to avoid offering a larger interface than what's actually needed, in order to prevent unexpected dependencies.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I understand that C++ is a very fast language, but ain't C just as fast, or faster in some cases? </p>\n\n<p>Then you might say that C++ has OOP, but the amount of OOP you need for most programming puzzles is not that big, and in my opinion C would be able handle that.</p>\n\n<p><strong>Here's why I am asking this</strong>: I am very interested in programming contests and competitions, and I am used to coding in C on those. However, I noticed that the vast majority of people use C++ (e.g., 17 out of 25 finalists on Google Code Jam 2011 used it, while no one used C), so I am wondering if I am at a disadvantage going with C.</p>\n\n<p>Apart from the Object Orientation, what makes C++ a more suitable language for programming competitions? What are the features of the language I should learn and use to perform better on the competitions?</p>\n\n<p>For background, I consider myself pretty proficient in C, but I am just starting to learn C++.</p>\n\n\nAssistant:",
        "golden_answer": " <p>To start with, there will always be some problems that are better solved in one language than another. There will always be languages that solve specific problems \"better\" than any other language, for some definition of \"better\". However, a very very large number of problems have very similar needs (some I/O, some computation) and face similar requirements (reasonable reliability, reasonable performance). </p>\n\n<p>As you know C already, for the vast majority of problems out there, I state that C++ provides no significant downsides and a number of significant improvements.  Bold? Some people seem to think so, but it's really the case. Let's start out by clearing up a few very common C++ misunderstandings: </p>\n\n<ul>\n<li><p><strong>C++ is slower than C.</strong>  Wrong! Many C programs are valid C++ programs as well - and such a C program should run at identical speed when compiled with either the C compiler or the C++ compiler. </p></li>\n<li><p><strong>C++ specific features require overhead.</strong> Wrong! The so-called overhead introduced by certain C++ specific features (such as virtual function calls or exceptions), is comparable to the overhead you yourself would introduce should you implement a similar feature in C. </p></li>\n<li><p><strong>C++ is object oriented.</strong> Wrong! The C++ language contains some language extensions that facilitate object oriented programming and generic programming. C++ does not force object oriented design anywhere - it merely allows it.  C allows for object oriented programming as well, C++ only makes it simpler and less error-prone. </p></li>\n</ul>\n\n<p>So, if you believe me, we have established that \"C++ is not significantly worse than C\". Let's have a look at what makes C++ a better C: </p>\n\n<ul>\n<li><p><strong>Stronger typing</strong> The type system in C++ is stronger than in C. This prevents many common programming errors - coupled with the next very important feature, the stronger type system even manages not to be an inconvenience.</p></li>\n<li><p><strong>Parameterized types</strong> The template keyword allows the programmer to write generic (type-agnostic) implementations of algorithms. Where in C, one could write a generic list implementation with an element like: </p>\n\n<pre><code>struct element_t {\n  struct element_t *next, *prev;\n  void *element;\n };\n</code></pre></li>\n</ul>\n\n<p>C++ allows one to write something like: </p>\n\n<pre><code>template &lt;typename T&gt;\nstruct element_t {\n   element_t&lt;T&gt; *next, *prev;\n   T element;\n};\n</code></pre>\n\n<p>Not only does the C++ implementation prevent common programmer errors (like putting an element of the wrong type on the list), it also allows better optimization by the compiler! For example, a generic sort implementation is available in both C and C++ - </p>\n\n<p>the C routine is defined as: </p>\n\n<pre><code>void qsort(void *base, size_t nmemb, size_t size,\n           int(*compar)(const void *, const void *));\n</code></pre>\n\n<p>whereas the C++ routine is defined as </p>\n\n<pre><code>template void sort(RandomAccessIterator first, RandomAccessIterator last);\n</code></pre>\n\n<p>The difference being, that for example sorting an array of integers, would, in the C case, require a function call for every single compare, whereas the C++ implementation would allow the compiler to inline the integer comparison calls, as the actual sort routine is automatically instantiated at compile time by the compiler, with the correct types inserted in the template arguments. </p>\n\n<ul>\n<li><strong>A bigger standard library</strong>  C++ allows the full use of the C standard library. This is very important of course, as the C standard library is an invaluable resource when writing real world programs. However, C++ includes the Standard Template Library. The STL contains a number of useful templates, like the sort routine above. It includes useful common data structures such as lists, maps, sets, etc. Like the sort routine, the other STL routines and data structures are \"tailored\" to the specific needs the programmer has - all the programmer has to do is fill in the types. </li>\n</ul>\n\n<p>Of course, the STL is no silver bullet - but it does provide a great help very often, when solving general problems. How often have you implemented a list in C? How often would an RB-tree have been a better solution, if only you had had the time to do it? With the STL you do not need to make such compromises - use the tree if it's a better fit, it's as easy as using the list. </p>\n\n<p>Ok, so I've only been discussing the good parts. Are there any downsides? Of course there are. However, their number is shrinking day by day.  Let me explain:</p>\n\n<ul>\n<li><p><strong>There are no good C++ compilers</strong> It's been like this for a long time. But you must remember, that the language was standardized in 1998 - it is a complex language, more complex than C. It has taken a long time for compilers to catch up to the standard. But as of this writing, there are good compilers available for the most widely used platforms out there; GCC in versions 3.X are generally very good, and it runs on GNU/Linux and most UNIX platforms. Intel has a good compiler for Win32 - it is also pretty good, but unfortunately it still relies on the MS STL which is sub-par. </p></li>\n<li><p><strong>People don't know good C++</strong> This is not an often heard complaint, but it's something that I see a lot. C++ is a big and complex language - but it also used to be a language that was hyped a lot, especially back in the \"OOP solves hunger, cures AIDS and cancer\" days. The result seems to be that a lot of really poor C++ code, basically bad C with a few class declarations here and there, is out there and is being used as learning material. This means a lot of people who believe they know C++ actually write really crappy code. That's too bad, and it's a problem, but I think it's unfair to blame this on C++. </p></li>\n</ul>\n\n<p>So, the only two major problems with C++ are results of C++ being a young language. In time they will vanish. And for most problems out there, if you can get good programmers (or learn good C++ yourself), the problems are not really an issue today. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>According to the Wikipedia article on <a href=\"http://en.wikipedia.org/wiki/Spurious_wakeup\">Spurious Wakeups</a> </p>\n\n<blockquote>\n  <p>\"a thread might be awoken from its waiting state even though no thread signaled the condition variable\".</p>\n</blockquote>\n\n<p>While I've know about this 'feature' I never knew what actually caused it until, in the same article </p>\n\n<blockquote>\n  <p>\"Spurious wakeups may sound strange, but on some multiprocessor systems, making condition wakeup completely predictable might substantially slow all condition variable operations.\"</p>\n</blockquote>\n\n<p>Sounds like a bug that just isn't worth fixing, is that right?</p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>TL;DR</strong> Assumption (\"contract\") of spurious wakeups is a sensible architectural decision made to allow for realistically robust implementations of thread sheduler.</p>\n\n<p>\"Performance considerations\" are irrelevant here, these are just misunderstanding that became widespread because of having stated in a published authoritative reference. <sup>(authoritative references might have errors, y'know - just ask <a href=\"http://en.wikipedia.org/wiki/Galileo_Galilei\" rel=\"noreferrer\">Galileo Galilei</a>)</sup> Wikipedia article keeps the reference to the note you quoted just because it perfectly matches their formal guidelines of citing the published reference.</p>\n\n<p>Much more compelling reason for introducing concept of spurious wakeups is provided in <a href=\"https://stackoverflow.com/a/1051816/839601\">this answer at SO</a> that is based on additional details provided in an (older version) of that very article:</p>\n\n<blockquote>\n  <p>The Wikipedia <a href=\"http://en.wikipedia.org/w/index.php?title=Spurious_wakeup&amp;oldid=289803065\" rel=\"noreferrer\" title=\"older revision of the article\">article on spurious wakeups</a> has this tidbit:</p>\n  \n  <blockquote>\n    <p>The <code>pthread_cond_wait()</code> function in Linux is implemented using the <code>futex</code> system call. Each blocking system call on Linux returns abruptly with <code>EINTR</code> when the process receives a signal. ... <code>pthread_cond_wait()</code> can't restart the waiting because it may miss a real wakeup in the little time it was outside the <code>futex</code> system call...</p>\n  </blockquote>\n</blockquote>\n\n<p>Just think of it... like any code, thread scheduler may experience temporary blackout due to something abnormal happening in underlying hardware / software. Of course, care should be taken for this to happen as rare as possible, but since there's no such thing as 100% robust software it is reasonable to assume this <em>can</em> happen and take care on the graceful recovery in case if scheduler detects this (eg by observing missing <em>heartbeats</em>).</p>\n\n<p>Now, how could scheduler recover, taking into account that during blackout it could miss some signals intended to notify waiting threads? If scheduler does nothing, mentioned \"unlucky\" threads will just hang, waiting forever - to avoid this, scheduler would simply send a signal to all the waiting threads.</p>\n\n<p>This makes it necessary to establish a \"contract\" that waiting thread can be notified without a reason. To be precise, there would be a reason - scheduler blackout - but since thread is designed (for a good reason) to be oblivious to scheduler internal implementation details, this reason is likely better to present as \"spurious\".</p>\n\n<hr>\n\n<p>From thread perspective, this somewhat resembles a <strong>Postel's law</strong> (aka <a href=\"http://en.wikipedia.org/wiki/Postel%27s_law\" rel=\"noreferrer\">robustness principle</a>), </p>\n\n<blockquote>\n  <p>be conservative in what you do, be liberal in what you accept from others</p>\n</blockquote>\n\n<p>Assumption of spurious wakeups forces thread to be <em>conservative in what it does</em>: set condition when notifying other threads, and <em>liberal in what it accepts</em>: check the condition upon any return from wait and repeat wait if it's not there yet.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p><img src=\"https://i.stack.imgur.com/uF7KQ.png\" alt=\"Picture 1\">\n<img src=\"https://i.stack.imgur.com/Pz3jP.png\" alt=\"Picture 2\"></p>\n\n<p>I have a <strong>Figure</strong> represented through a matrix of bytes (bitmap-like matrix).\nExample <strong>Figure</strong> is shown on the <code>Picture 1</code>.</p>\n\n<p>The goal is to find the best rotation angle of some given <strong>Figure</strong>.\nWhen Figure is rotated by best angle, the rectangle that is parallel to X and Y axes and inscribes the <strong>Figure</strong> has the smallest area.</p>\n\n<p>Rectangles that inscribes the figure are shown as light-gray on the pictures.\nIn the <code>Picture 2</code>, you can see that ideal rotation of the Figure is about 30 degrees clockwise.</p>\n\n<p>Now, I know algorithm how to find this angle, but it seems to me that is very inefficient.\nIt goes like this:</p>\n\n<ol>\n<li>Loop through angles from 0 to 45.</li>\n<li>For the current angle, for every figure point calculate new, rotated, location</li>\n<li>Find bounds of rectangle that contains figure (minimum and maximum x,y) and register it if is the best match so far</li>\n<li>Next angle</li>\n</ol>\n\n<p>This is a kind of brute-force method and works well and reasonably fast for the small figures.\nHowever, I need to work with figures that contain up to 10 million points,\nand my algorithm becomes slow.</p>\n\n<p>What would be good algorithm for this problem?</p>\n\n\nAssistant:",
        "golden_answer": " <p>It looks like you can find the <a href=\"http://en.wikipedia.org/wiki/Minimum_bounding_box\">arbitrarily aligned minimum bounding box</a> using the linear time <a href=\"http://en.wikipedia.org/wiki/Rotating_calipers\">Rotating calipers algorithm</a>.</p>\n\n<p>Once you have the bounding box, you just need to determine the angle of rotation by calculating the slope of one of the sides.  </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Yesterday, the deployment of a financial website on a client was replaced with an older version which created unexpected issues and a downtime of almost 12 hours.</p>\n\n<p>We came to know that two guys from their IT are creating problems for each other and it was done by one of them, don't want to go into the details.</p>\n\n<p>This could have lead to financial discrepancies and losses, but fortunately didn't.</p>\n\n<p>IT guys have full rights on the server so it can not be controlled at machine/OS level.</p>\n\n<p>So, is there any possibility/option available inside ASP.NET to secure or ensure integrity of the deployment? </p>\n\n<p>For example what if version/hashcode of assemblies could be cross checked against database?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You should add a health check page or api to your website and use green/blue deployment to prevent this type of problem.</p>\n\n<p>The health check page, should return the version of the website. Ideally the versioning is done automatically on the build or deployment server and cant be changed manually.</p>\n\n<p>Deploy first to the offline set of servers and run your integration/smoke tests against them, including checking the version returned by the health check webpage.</p>\n\n<p>Only if these tests pass should you then switch   these servers to live and take the old version off line.</p>\n\n<p>Ideally your goal is to reduce the human component of deployment to clicking a single button. Automating all the tests and rollback procedures.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What exactly is the different between \"extensible programming\" and \"extendible programming?\"</p>\n\n<p><a href=\"http://en.wikipedia.org/wiki/Extensible_programming\" rel=\"noreferrer\">Wikipedia</a> states the following:</p>\n\n<blockquote>\n  <p>The Lisp language community remained\n  separate from the extensible language\n  community, apparently because, as one\n  researcher observed, any programming\n  language in which programs and data\n  are essentially interchangeable can be\n  regarded as an extendible [sic]\n  language. ... this can be seen very\n  easily from the fact that Lisp has\n  been used as an extendible language\n  for years.</p>\n</blockquote>\n\n<p>If I'm understanding this correctly, it says \"Lisp is extendible implies Lisp is not extensible\". So what do these two terms mean, and how do they differ? </p>\n\n\nAssistant:",
        "golden_answer": " <p>I call semantic shenanigans. </p>\n\n<p>Extensible has <a href=\"http://dictionary.reference.com/browse/extensible\" rel=\"noreferrer\">one meaning</a>: able to be extended. Extendible means the same thing. They are both adjectival forms of extend.</p>\n\n<p>Extend covers <a href=\"http://dictionary.reference.com/browse/extend\" rel=\"noreferrer\">a variety of contexts</a>, from mass, to length, to ability.</p>\n\n<p>The difference seems to be (from reading the wiki article) that <em>extensible</em> programming languages use a meta language to alter themselves, whereas <em>extendible</em> languages are modifiable using themselves, and Lisps use the transposability of data and programmes to do that.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>IN scrum , everything is written in terms of user , They are called <strong>user stories</strong>. For starting <strong>new projects</strong> in scrum , should one write <strong>SRS</strong> document ? Or just go directly for user stories . I did not find any relevant source that points SRS in scrum environment ? Am I missing something ?</p>\n\n\nAssistant:",
        "golden_answer": " <p>In the <a href=\"http://agilemanifesto.org/\" rel=\"noreferrer\">Agile Manifesto</a>, you should prefer working software over comprehensive documentation. If you need an SRS document, there is nothing preventing or discouraging it, but you should give it serious consideration before going through the trouble. Just make sure the creating of the documentation is not at the expense of creating working software. It's not a matter of exclusion or maybe even priority (some industries find these documents to be absolutely required) just keep the end result in mind.</p>\n\n<p>You could also see this as possibly modifying the amount of detail in the documentation or maybe don't write the entire document first, but do it as you go along, so you're not having to make constant changes. It would be a shame to not include changes in your project because an overly robust document becomes too difficult to change or worse no one has noticed that it hasn't.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have seen examples where even though the object is immutable there are situations in which we need to update some fields and as I understand it, the object is passed to a constructor which makes a copy with updated values but the original is not changed. Fine, but what if two threads want to do this? Do we not run into synchronization problems if they both are changing the same field? And how if now there are new objects made (rather than a changed original) do multiple threads know that the values of fields have changed? </p>\n\n<p>I have seen many examples of how to make an immutable class but it is not clear to me how updating attributes works in a multithreaded environment, how synchronization is not required and as I mentioned above, how to determine what object now represents the current state.</p>\n\n<p>Here is an article in which changing an immutable object is discussed: <a href=\"https://jlordiales.me/2012/12/24/the-ins-and-outs-of-immutability/\" rel=\"nofollow noreferrer\">https://jlordiales.me/2012/12/24/the-ins-and-outs-of-immutability/</a></p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>Fine, but what if two threads want to do this?</p>\n</blockquote>\n\n<p>Then one thread makes one change (and gets one version of the object) and another thread makes another change (and gets a different, independent version of the object).</p>\n\n<blockquote>\n  <p>Do we not run into synchronization problems if they both are changing the same field? </p>\n</blockquote>\n\n<p>Nope, because each thread gets their own copy of the object. </p>\n\n<blockquote>\n  <p>And how if now there are new objects made (rather than a changed original) do multiple threads know that the values of fields have changed?</p>\n</blockquote>\n\n<p>They don't. That's the point.</p>\n\n<blockquote>\n  <p>how to determine what object now represents the current state.</p>\n</blockquote>\n\n<p>And that's the gotcha. Immutability works great when things are values, or when things really are independent. But if you have an object that represents a single record - say from a database - then changes need to be merged back into that single record. That can be last in wins. That can be some manner of versioning/timestamping. There's lots of options with various tradeoffs. </p>\n\n<p>But the key bit is that synchronization only needs to happen at that last step where the changes are merged and actually take effect on the single source of truth.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have to extend an existing module of a project. I don't like the way it has been done (lots of anti-pattern involved, like copy/pasted code). I don't want to perform a complete refactor for many reasons.  </p>\n\n<p>Should I:</p>\n\n<ul>\n<li>create new methods using existing\nconvention, even if I feel it wrong,\nto avoid confusion for the next\nmaintainer and being consistent with\nthe code base?</li>\n</ul>\n\n<p>or  </p>\n\n<ul>\n<li>try to use what I feel better even if\nit is introducing another pattern in\nthe code ?</li>\n</ul>\n\n<hr>\n\n<p>Precison edited after first answers:</p>\n\n<p>The existing code is not a mess. It is easy to follow and understand. BUT it is introducing lots of boilerplate code that can be avoided with good design (resulting code might become harder to follow then). In my current case it's a good old JDBC (spring template inboard) DAO module, but I have already encounter this dilemma and I'm seeking for other dev feedback. </p>\n\n<p>I don't want to refactor because I don't have time. And even with time it will be hard to justify that a whole perfectly working module needs refactoring. Refactoring cost will be heavier than its benefits. Remember: code is not messy or over-complex. I can not extract few methods there and introduce an abstract class here. It is more a flaw in the design (result of extreme 'Keep It Stupid Simple' I think)</p>\n\n<p>So the question can also be asked like that:<br>\nYou, as developer, do you prefer to maintain easy stupid boring code OR to have some helpers that will do the stupid boring code at your place ?</p>\n\n<p>Downside of the last possibility being that you'll have to learn some stuff and maybe you will have to maintain the easy stupid boring code too until a full refactoring is done) </p>\n\n\nAssistant:",
        "golden_answer": " <p>Refactoring is best done in small steps, and preferably only if you have unit tests to cover the code. (So if you don't have tests yet, strive to write them first, and until then, stick to the simplest, most foolproof, preferably automated refactorings. A great help in this is <a href=\"https://rads.stackoverflow.com/amzn/click/com/0131177052\" rel=\"noreferrer\" rel=\"nofollow noreferrer\"><em>Working Effectively with Legacy Code</em></a> by Michael Feathers.)</p>\n<p>In general, aim to improve the code a little whenever you touch it. Follow the <em>Boy Scout Rule</em> (<a href=\"http://www.pearsonhighered.com/educator/academic/product/1,3110,0132350882,00.html\" rel=\"noreferrer\">coined by Robert C. Martin</a>) by leaving the code cleaner than you found it. When you add new code, try to keep it separated from the existing bad code. E.g. don't bury it into the middle of a long method, instead add a call to a separate method and put your new code in there. This way, you grow gradually bigger islands of clean(er) code within the existing codebase.</p>\n<h3>Update</h3>\n<blockquote>\n<p><strong>Refactoring cost will be heavier than its benefits.</strong> [...] You, as developer, do you prefer to maintain easy stupid boring code OR to have some helpers that will do the stupid boring code at your place ?</p>\n</blockquote>\n<p>I emphasized which I believe is the key point here. It is always worth assessing the costs and benefits of refactoring <strong>before</strong> we jump into it. As in your case, most of us have limited resources for refactoring so we must use them wisely. Spend that precious little time on refactoring where it brings the most benefits with the least effort.</p>\n<p>As a creative mind, of course I would prefer producing perfect, beautiful and elegant code, and rewriting everything which does not resemble my ideals :-) In reality though, I am paid to produce software which solves real problems for its users, so I should think about producing the most value for their money over the long term.</p>\n<p><strong>The benefit of refactoring only appears if there is sufficient savings in time and efforts to understand, maintain, fix and extend the code in the long term</strong>. So if a piece of code - however ugly it is - is rarely or never touched, there are no known bugs in it and I don't know of any upcoming features in the foreseeable future which would require me to touch it, I prefer leaving it in peace.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Model View Controller (MVC) is focussed on UI based applications. In MVC the model notifies the UI (view) when its values change and the view then decides what and if to update. I can understand this for desktop, mobile and single page web applications where there is a persistent UI.</p>\n<p>But why do some popular backend web frameworks such as  ASP.Net Core, Ruby on Rails, Django etc use MVC when there is no UI to update, once the templated page view is rendered and returned? Once it has has finished rendering the page, the backend is not responsible for updates to the UI.</p>\n<p>For example, ASP.Net Core refers to models as simple data structures without methods on them, that map to entities in e.g. a database. For example:</p>\n<pre class=\"lang-csharp prettyprint-override\"><code>using System;\nusing System.ComponentModel.DataAnnotations;\n\nnamespace MvcMovie.Models\n{\n    public class Movie\n    {\n        public int Id { get; set; }\n        public string Title { get; set; }\n\n        [DataType(DataType.Date)]\n        public DateTime ReleaseDate { get; set; }\n        public string Genre { get; set; }\n        public decimal Price { get; set; }\n    }\n}\n</code></pre>\n<p>Is there something I am misunderstanding about MVC, or is the term used quite loosely in this case?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The MVC design pattern was initially developed before the Web was a thing. It mainly addressed architectural problems that applications with a richly interactive GUI had. The main benefit was <strong>Separation of Concerns</strong>. Something had to handle business logic and persistent data storage (the &quot;Model&quot;). Something had to handle the presentation of the use case to the end user (the &quot;View&quot;). And something else had to coordinate the use case and initialize the whole thing (the &quot;Controller').</p>\n<p>It was determined that events were the ideal medium of communication between these three components, because it <strong>decouples</strong> the Model, View, and Controller. You will find that &quot;decoupling&quot; and &quot;Separation of Concerns&quot; are complimentary concepts. In fact, you really cannot &quot;separate your concerns&quot; without decoupling components. This is crucial to understanding why web frameworks, which have no persistent user interface, continue to use this design pattern. Don't get too hung up on events and persistent user interfaces. Events were an artifact of building an application with a persistent UI rather than being the foundation of the MVC design pattern.</p>\n<p>Even though the Web has a stateless UI, it is still desirable to separate business logic (the &quot;Model&quot;), presentation logic (the &quot;View&quot;), and use case coordination logic (the &quot;Controller&quot;). Since the Web has a stateless user interface, events are replaced with HTTP requests  an artifact of building an application with a stateless user interface. The main benefit of the MVC design pattern is separation of concerns. This is still realized on the Web, regardless of how the UI is implemented.</p>\n<hr />\n<p>As a side note, Microsoft's first widely-used web framework (ASP.NET WebForms) attempted to literally turn HTTP requests into application events. A hidden form field on each page contained a serialized version of the &quot;view state&quot;. Upon POSTing back to the server, the view state was rehydrated from this serialized form field. Then based on the name of a button, the framework would trigger a simulated UI event just like you would expect from a persistent user interface. The framework attempted to hide the messiness of a stateless UI for people already familiar with MVC in desktop applications. It turned out to be a <a href=\"https://www.onenaught.com/posts/42/aspnet-is-a-leaky-abstraction\" rel=\"nofollow noreferrer\">leaky abstraction</a>, though.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am a Java Programmer and I am relatively new to Java(1 Year). I am working for a small startup company.</p>\n\n<p>My problem is a bit strange and I am facing it a bit difficult to deal with and explain also.</p>\n\n<p>My director in the company usually assigns some programming tasks on the product we are developing. He is not from Java background, but from databases background. Usually he cares about application configuration and pluggable architecture which is very much desirable.</p>\n\n<p>What according to him is pluggable is obtaining object instances through Java Reflection. Always he insists us to write a class that reads an xml file where it is written which class has to be instantiated and do actual work \nfrom that object instantiated using reflection. I tried to explain about DI frameworks such as Spring and Java EE CDI, but of no use.</p>\n\n<p>And he thinks that whenever an xml file structure is changed, its parsing code or writing code <strong>need not be</strong> changed. We, the programmers, prefer using JAXB for marshalling and unmarshalling the xmls as it is intuitive.</p>\n\n<p>Very frequently he complains that the code is slow, or the programmers are incapable of providing an architecture that allows absolutely no change in Java code but all changes in xml configuration/data are consumed by the application. </p>\n\n<p>And every single possible decision we make are with his consent regarding finalising the xmls structure. Accordingly we code and develop things. But after some period he finds something else is fascinating and asks us to change the whole structure of the xml. Change in requirements is not a problem, but he thinks Java code need never be changed and keeps blaming that the programmers are incapable of writing code in such a way.</p>\n\n<p>Is it really possible? How do we convince him or explain?</p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>1) Where your manager is right</strong></p>\n\n<p>Your manager wants a <em>flexible</em> architecture. To accomplish this, you have to design our code, that it is easily composed of <em>pluggable</em> components. </p>\n\n<blockquote>\n  <p>What according to him is pluggable is obtaining object instances through Java Reflection</p>\n</blockquote>\n\n<p>That is a way to organize <em>object creation</em> and is how <a href=\"http://de.wikipedia.org/wiki/Dependency_Injection\">DI</a>-frameworks do their job.\nTypically you mark <code>dependencies</code> of an object using <code>@Inject</code> annotation. I do not see any sense in doing this by hand, when you have frameworks to do the job reliably.</p>\n\n<blockquote>\n  <p>he insists us to write a class that reads an xml file where it is written which class has to be instantiated and do actual reading from that object instantiated using reflection.</p>\n</blockquote>\n\n<p>Sounds to me, that he wants to develop his own version of <a href=\"http://docs.spring.io/spring/docs/current/spring-framework-reference/html/overview.html\">Spring</a> with all the legacy pains of using XML for (container) configration</p>\n\n<p><strong>2) Where your manager is (terribly) wrong</strong></p>\n\n<blockquote>\n  <p>And he thinks that whenever an xml file structure is changed, its parsing code or writing code need not be changed. </p>\n</blockquote>\n\n<p>This sounds like a weird version of <a href=\"http://en.wikipedia.org/wiki/Open/closed_principle\">the open/closed principle</a>, where a class should be open for extension, but closed for modification. </p>\n\n<p>A better design would be to <em>refactor</em> the <em>parsing behaviour</em> out to an <em>interface</em>. Then you are able to keep your <em>overall logic</em> dealing with the result and handle different types of <em>Parsers</em> with different objects.</p>\n\n<p>If you want to deal with different <em>versions</em> of your XML at the same time, you could design different parsers for each version. But if you only want to deal with a current version of your XML, it would make sense, to only update the code of the one parser, you have. </p>\n\n<p>If you never refactor your code and only pile classes you end with a mess.</p>\n\n<blockquote>\n  <p>We, the programmers, prefer using JAXB for marshalling and unmarshalling the xmls as it is intuitive.</p>\n</blockquote>\n\n<p>Which is - in short - perfectly fine.</p>\n\n<blockquote>\n  <p>Very frequently he complains that the code is slow, or the programmers are incapable of providing an architecture</p>\n</blockquote>\n\n<p>As far as I see, the only one providing a <em>messy</em> architecture is your boss. Sorry, bro!\n@ddyer gave you a hint, on how to convince your boss: Benchmarks - hard numbers / facts. Rewrite a part of the code and show the differences.</p>\n\n<blockquote>\n  <p>But after some period he finds something else is fascinating and asks us to change the whole structure of the xml. </p>\n</blockquote>\n\n<p>That's how management (oftentimes) <em>is</em>.</p>\n\n<p><strong>tl;dr</strong></p>\n\n<p>What to do?</p>\n\n<p><em>In case you want to convice your boss:</em></p>\n\n<p>If your time allows it, rewrite the application (partially) or at least do a fast prototype which has the core elements of the application, benchmark it, show the numbers to your boss. Perhaps you could do a comparing code review of how the old codebase looks like and the new one. And speak with him about the differences.</p>\n\n<p>But <em>honestly:</em> If you have the possibility - <strong>leave the company</strong> You are doing yourself a big favour.</p>\n\n<p>This sounds like a very bad environment for productive work. You are the programmer(s) and <em>you</em> are in charge for the <em>codebase</em> not your manager; or if he feels so - and that's what came to my mind reading your story, he should do your job (alone). As a professional software developer you should stand up against your boss. But it depends on the possibilites to get a new job. Perhaps you are in a dilemma of quitting, but having no alternative.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>If it's wiser to know a framework such as jQuery, MooTools, DoJo, etc. to get over cross-browser issues, why are interviews asking for only javascript?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Because if you know \"real\" Javascript, then it doesn't matter if you know jQuery but not MooTools, DoJo but not <a href=\"http://code.google.com/closure/\">Closure</a>, etc. If you know \"real\" Javascript, you should be able to pick up any particular Javascript library with relative ease.</p>\n\n<p>It's (often) better to use a library that helps with the cross-browser issues, but you can't know the library without knowing the language. If you don't know \"Javascript\" and all you can do is cut'n'paste samples from a particular library, then you can't really put \"Javascript\" as a language on your resume anyway, IMO.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>We want to allow the same core service to be either fully implemented or, as other option, to be a proxy toward a client legacy system (via a WSDL for example).</p>\n\n<p>In that way, we have both implementation (proxy &amp; full) and we switch which one to use in the configuration of the app.</p>\n\n<p>So in a nutshell, Some desired features:</p>\n\n<ul>\n<li>Two different implementation (proxy, full) instead of one implementation with a switch inside</li>\n<li>Switch implementation using configuration: dependency injection? reflection?</li>\n<li>Nice-to-have: the packaged delivered to the client doesnt have to change depending on the choice between proxy or full</li>\n<li>Nice-to-have: Client can develop their custom implementation of the Core Interface and configure the applciation to use that one</li>\n</ul>\n\n<p>With this background, the question is: What alternatives we have to choose one implementation or other of an interface just changing configuration?</p>\n\n<p>Thanks</p>\n\n\nAssistant:",
        "golden_answer": " <p>An IoC container which loads its configuration from an xml-config-file can do this.</p>\n\n<p>If you are using java you can use <a href=\"http://static.springsource.org/spring/docs/3.0.x/spring-framework-reference/html/beans.html\">spring-ioc</a> for this.</p>\n\n<p>The java config file for the Full service might contain this</p>\n\n<pre><code>&lt;bean id=\"catalogService\" class=\"com.mycompany.myproduct.MyFullCatalogService\" scope=\"singleton\" /&gt;\n</code></pre>\n\n<p>If you want to use the proxy version</p>\n\n<pre><code>&lt;bean id=\"catalogService\" class=\"com.mycompany.myproduct.MyProxyCatalogService\" scope=\"singleton\" /&gt;\n</code></pre>\n\n<p>Your main application just asks the container for id=\"catalogService\" to get the current service.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I recently refactored a program for code feasibility and maintainability; however, I am totally unaware of what software principle I did implement. I just followed my feeling.</p>\n<p>The purpose for this post is that I want to know what software principle I did implement so that I'm capable of referencing books or websites.</p>\n<p>Before refactoring:</p>\n<pre><code>int main(void)\n{\n    char input_cmd[ENOUGH_SIZE] = {0};\n    get_input_cmd(&amp;input_cmd, ENOUGH_SIZE);\n    int input_data = get_input_data(input_cmd, strlen(input_cmd));\n    int access_right = get_access(); //1 = admin; 0 = user\n\n    if (!strcmp(input_cmd, &quot;A_cmd&quot;))\n    {\n        if (access_right == admin)\n        {\n            A_calculate_data_and_save_result_to_buffer(input_data);\n            move_all_buffer_to_rom();\n            A_show_result();\n            \n            return 0;\n        }\n        else\n        {\n            //error: access deny\n            return -1;\n        }\n    }\n    else if (!strcmp(input_cmd, &quot;B_cmd&quot;))\n    {\n        B_calculate_data_and_save_result_to_buffer(input_data);\n        move_all_buffer_to_rom();\n        B_show_result();\n        \n        return 0;\n    }\n    else if (!strcmp(input_cmd, &quot;C_cmd&quot;))\n    {\n        C_calculate_data_and_save_result_to_buffer(input_data);\n        C_show_result();\n        \n        return 0;\n    }\n    else if (!strcmp(input_cmd, &quot;D_cmd&quot;))\n    {\n        D_calculate_data_and_save_result_to_buffer(input_data);\n        \n        return 0;\n    }\n    else if (!strcmp(input_cmd, &quot;E_cmd&quot;))\n    {\n        E_calculate_data_and_save_result_to_buffer(input_data);\n        move_all_buffer_to_rom();\n        \n        return 0;\n    }\n    else if (!strcmp(input_cmd, &quot;F_cmd&quot;))\n    {\n        if (access_right == admin)\n        {\n            F_calculate_data_and_save_result_to_buffer(input_data);\n            move_all_buffer_to_rom();\n            \n            return 0;\n        else\n        {\n            //error: access deny\n            return -1;\n        }\n    }\n    else if (!strcmp(input_cmd, &quot;G_cmd&quot;))\n    {\n        if (access_right == admin)\n        {\n            G_calculate_data_and_save_result_to_buffer(input_data);\n            \n            return 0;\n        else\n        {\n            //error: access deny\n            return -1;\n        }\n    }\n    else if (!strcmp(input_cmd, &quot;H_cmd&quot;))\n    {\n        if (access_right == admin)\n        {\n            H_calculate_data_and_save_result_to_buffer(input_data);\n            H_show_result();\n            return 0;\n        else\n        {\n            //error: access deny\n            \n            return -1;\n        }\n    }\n    else\n    {\n        //error: cmd not found\n        return -2;\n    }\n    \n    return 0;\n}\n</code></pre>\n<p>After refactoring:</p>\n<pre><code>static bool find_cmd(char* input, uint16_t* index);\nstatic bool check_access(void);\nstatic void do_nothing(void);\n\ntypedef struct cmd_t cmd_t;\nstruct cmd_t\n{\n    const char* cmd_name;\n    bool need_check_access;\n    bool need_move_all_buffer_to_rom;\n    void (*calculate_data_and_save_result_to_buffer)(int);\n    void (*show_result)(void);\n};\n\n#define YES 1\n#define NO 0\n\nstatic cmd_t cmd_table[] =  \n{\n    {&quot;A_cmd&quot;, YES, YES, &amp;A_calculate_data_and_save_result_to_buffer, &amp;A_show_result},\n    {&quot;B_cmd&quot;, NO,  YES, &amp;B_calculate_data_and_save_result_to_buffer, &amp;B_show_result},\n    {&quot;C_cmd&quot;, NO,  NO,  &amp;C_calculate_data_and_save_result_to_buffer, &amp;C_show_result},\n    {&quot;D_cmd&quot;, NO,  NO,  &amp;D_calculate_data_and_save_result_to_buffer, &amp;do_nothing},\n    {&quot;E_cmd&quot;, NO,  YES, &amp;E_calculate_data_and_save_result_to_buffer, &amp;do_nothing},\n    {&quot;F_cmd&quot;, YES, YES, &amp;F_calculate_data_and_save_result_to_buffer, &amp;do_nothing},\n    {&quot;G_cmd&quot;, YES, NO,  &amp;G_calculate_data_and_save_result_to_buffer, &amp;do_nothing},\n    {&quot;H_cmd&quot;, YES, NO,  &amp;H_calculate_data_and_save_result_to_buffer, &amp;H_show_result},\n};\n\n\nint main(void)\n{\n    char input_cmd[ENOUGH_SIZE] = {0};\n    get_input_cmd(&amp;input_cmd, ENOUGH_SIZE);\n    \n    uint16_t idx = 0;\n    bool cmd_found = find_cmd(input_cmd, &amp;idx);\n    if (!cmd_found)\n    {\n        return -2;\n    }\n    \n    if (cmd_table[idx].need_check_access)\n    {\n        bool access_allowed = check_access();\n        if (!access_allowed)\n        {\n            return -1;\n        }\n    }\n    \n    int input_data = get_input_data(input_cmd, strlen(input_cmd));\n    cmd_table[idx].calculate_data_and_save_result_to_buffer(input_data);\n    \n    if (cmd_table[idx].need_move_all_buffer_to_rom)\n    {\n        move_all_buffer_to_rom();\n    }\n\n    cmd_table[idx].show_result();\n    \n    return 0;\n}\n\nstatic bool find_cmd(char* input, uint16_t* index)\n{\n    //loop table and compare string to find cmd\n}\n\nstatic bool check_access(void)\n{\n\n#define allowed 1\n#define denied 0\n\n    bool rv = denied;\n    \n    int access_right = get_access(); //1 = admin; 0 = user\n\n    if (access_right == admin)\n    {\n        rv = allowed;\n    }\n\n    return rv;\n}\n\nstatic void do_nothing(void)\n{\n    \n}\n</code></pre>\n<p>The original code is definitely not that easy to read. For example, <code>A_calculate_data_and_save_result_to_buffer</code> might be <code>set_pswd</code>; <code>A_cmd</code> might be <code>set_pswd</code>, too.</p>\n<p>It costs me a lot of time reading into each function, knowing what each function do,  brainstorming, concluding that although <strong>every function's name is different</strong>, but <strong>all functions</strong> in fact are <strong>doing the same thing on concept level</strong>, and finally forming the struct members and deciding to use a function pointer to represent all the functions.</p>\n<p>By now, I'm still not figuring out what principle I did apply.</p>\n<p>As title, what design/component principle did I apply? How can I further improve it?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Believe it or not this is a refactoring called Replace Conditional with Polymorphism. It might be hard to see that because you didn't use classes or objects to get your polymorphism. You used an array of structs. But that's still polymorphism.</p>\n<p>This refactoring can be driven by a desire to reduce duplication or by a desire for flexibility. You have reduced duplication but since each struct resides in the same source file you haven't achieved the flexibility you might if adding a new command only required adding one new file. If that's important, you could still do that.</p>\n<p>If you're fine editing and compiling this file every time a new command is needed then this dispatch table is fine as is. It has a much more readable form than the nested if-else structure.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've been trying to understand when to mock and when not to mock, however I'm not able to come up with a consistent guideline and I'm hoping to get some input on the subject. Let's look at the following toy example:</p>\n<pre><code>class ServiceMixer:\n  def __init__(...):\n    self._expensive_rpc_service = ExpensiveRPCService(...)\n    self._db_scan_service = DBScanService(...)\n    self._cpu_intensive_computation_service = ExpensiveCPUService(...)\n\n  def get_results(input):\n    result_1 = self._expensive_rpc_service(input)\n    result_2 = self._db_scan_service(input)\n    result_3 = self._cpu_intensive_computation_service(input)\n\n    return compute_output(result_1, result_2, result_3) \n</code></pre>\n<p>I want to now write unit-tests on the <code>get_results</code> method. I do understand that in this example, I will need to use a mock somewhere regardless - two of the services have side-effects (i.e. they talk to a DB or make an RPC to another service). The question is, should I mock the 3 services shown here, or should I mock the RPC calls and the DB calls that the services make in the ServiceMixer unit tests?</p>\n<p>One advantage of mocking just the RPC / DB Calls is that I can test the contracts between the difference services and the ServiceMixer. If a downstream service changes, then the service mixer test will break. This is somewhat like an integration test. On the other hand, it will mean that the unit tests for get_results need to innately understand the nuances of how each service works so it can correctly place expectations of the arguments + returned values.</p>\n<p>If I were to just mock the services here, then I can just focus on testing the behavior of the ServiceMixer, but I will then miss out the caller-callee contract testing. So, what is the best practice here? It seems like using mocks is the right approach, but I've seen a few articles that state &quot;too many mocks are a code-smell&quot;. When is it appropriate to use a mock? When is it not?</p>\n<p>Thanks!</p>\n\n\nAssistant:",
        "golden_answer": " <p>When you unit-test class X, you should mock all the collaborators of X unless they're trivial and don't add significant cost or complexity to the test execution.</p>\n<p>So when testing <code>ServiceMixer</code>, you should mock all three collaborator services. The actual computation/DB lookups that the entire algorithm is about should play no part in your test at all; it should only test that <code>ServiceMixer</code> orchestrates things correctly.</p>\n<p>When you unit-test, say, <code>RPCService</code>, you would normally mock the external part of the computation and test only that <em>your</em> service issues the correct RPC commands to the <em>external</em> system. You should <em>not</em> verify that the external system does its job correctly; that is important, of course, but it's the job of an integration test.</p>\n<p>Keeping unit-level testing separate from system testing allows you to distinguish problems with a specific component from problems with the interaction between parts. This makes software engineering faster and more accurate. &quot;Divide and conquer&quot; is a thing, and it is invaluable when your system grows beyond a certain size - usually a surprisingly small size.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am working on Android with the query() method of the ContentResolver class and it accepts 6 parameters, <code>(uri,projection,selection,selectionArgs,sortOrder,cancellationSignal)</code> for selection and projection parameters.</p>\n\n<p>I am little bit confused with the selection and projection part of query.</p>\n\n<p>In below example, what is selection and project part in the query?</p>\n\n<pre><code>select * from Person\nwhere name='zeus';\n</code></pre>\n\n\nAssistant:",
        "golden_answer": " <p>Selecting means choosing some records from a table and leaving others out.</p>\n\n<p>Projecting means choosing some columns from each record and leaving others out.</p>\n\n<p>Therefore, your query performs selection (records with name='zeus' are chosen, but others are rejected) but not projection (those records that are chosen are returned with <em>all</em> of their columns).</p>\n\n<p>Broadly, the <code>select</code> keyword performs projection and the <code>where</code> keyword performs selection. (The fact that <code>select</code> is a language feature for choosing columns rather than rows, i.e. it performs projection, not selection, is unfortunate, but the syntax is far too established now to be corrected.)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>After reseaching the differences between OAuth and JWT, I decided to use JWT on my next project for simplicity and performance reasons. </p>\n\n<p>From what I learned until now, and please correct me if I'm wrong, JWT is self contained data, hashed with a public key on the client. I then can check it against a secret key and verify its validity on my backend. Ok..</p>\n\n<p>But there is one thing that I still can't quite understand: <strong>JWT token revoking</strong>. I saw many posts and topics about \"How to revoke JWT\" or whether it's \"Possible or not to revoke JWT\", \"JWT Blacklisting\", and even some posts saying there's no point in any of it. </p>\n\n<p>I want to understand: Why would I want to revoke JWT? Would not revoking it be a security flaw? How?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The default implementation of a JWT is stateless. That means you don't hold any information regarding the individual token in any form of storage (files, databases, memory, etc.). You're relying on the signature of the JWT to validate that you have issued this token.</p>\n\n<p>This not more or less secure than a stateful token per se as far as protecting the token goes. It does however have security implications for a compromised token.</p>\n\n<p>Since you have no way of knowing which individual token is due to not storing any information about them you cannot reject tokens which pass the basic signature validation. This means that if I somehow managed to acquire your token I will be able to pose as you until the token expires.</p>\n\n<p>You can create a stateful JWT. Just store some data about it the token and in a database. Say a unique ID along with to whom it was issued. I've done a few different things over time with JWTs to keep them in good shape:</p>\n\n<ul>\n<li>Store the API version which issued it</li>\n<li>Store a password version of the user in it (meaning a password update revokes old tokens)</li>\n<li>Store a unique ID to identify individual tokens</li>\n</ul>\n\n<p>For the record, revoking a token typically means outright removing the token information from your storage or marking it as deleted; as such it is rejected when authorization is attempted.</p>\n\n<p>For the record I'm not saying that you need to add state to the token so long as you are aware of the implications. Personally I would add some state, not for myself but for the users. Security concerns is typically at the bottom of their list until something tragic happens.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am scanning a directory of files and want to add them to a database. I have two variants:</p>\n\n<pre><code>for file in walk(basedir):\n    files.append(file)\nfor file in files:\n    add_to_database(file)\n</code></pre>\n\n<p>versus</p>\n\n<pre><code>for file in walk(basedir):\n    add_to_database(file)\n</code></pre>\n\n<p>The former has the advantage that if both the database and the scanned dir reside on the same physical disk, jumping between two locations on disk (assuming spindels) is avoided and thus should be faster, at the cost of additional memory consumption.</p>\n\n<p>The latter is much shorter. I am tending towards the latter, adding a note that the database should not reside on the same disk as the scanned dir.</p>\n\n<p>Any thoughts on this?</p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>Premature optimization is the root of all evil.</strong> -- Donald Knuth</p>\n\n<p>Any decent operating system is going to solve the jumping-around problem for you, using memory caches of disk blocks.  Solving that problem by accumulating an unnecessary list of filenames creates a new problem of memory consumption - how well will the first version work with 50,000,000 files?  Forget the note, unless your performance tests actually demonstrate a significant impact.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Usually I just throw my unit tests together using copy and paste and all kind of other bad practices.  The unit tests usually end up looking quite ugly, they're full of \"code smell,\" but does this really matter?  I always tell myself as long as the \"real\" code is \"good\" that's all that matters.  Plus, unit testing usually requires various \"smelly hacks\" like stubbing functions.</p>\n\n<p>How concerned should I be over poorly designed (\"smelly\") unit tests?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Are unit test smells important? Yes, definitely. However, they are <em>different</em> from code smells because unit tests serve a different purpose and have a different set of tensions that inform their design. Many smells in code don't apply to tests. Given my TDD mentality, I would actually argue that unit test smells are <em>more</em> important than code smells because the code is just there to satisfy the tests.</p>\n\n<p>Here are some common unit testing smells:</p>\n\n<ul>\n<li><strong>Fragility</strong>: do your tests fail often and unexpectedly even for seemingly trivial or unrelated code changes?</li>\n<li><strong>State Leak</strong>: do your tests fail differently depending on, for instance, what order they are run?</li>\n<li><strong>Setup/Teardown Bloat</strong>: Are your setup/teardown blocks long and growing longer? Do they perform any sort of business logic?</li>\n<li><strong>Slow Runtime</strong>: Do your tests take a long time to run? Do any of your individual unit tests take longer than a tenth of a second to run? (Yes, I'm serious, a tenth of a second.)</li>\n<li><strong>Friction</strong>: Do existing tests make it difficult to write new tests? Do you find yourself struggling with test failures often while refactoring?</li>\n</ul>\n\n<p>The importance of smells is that that they are useful indicators of design or other more fundamental issues, i.e. \"where there's smoke, there's fire\". Don't just look for test smells, look for their underlying cause as well.</p>\n\n<p>Here, on the other hand, are some good practices for unit tests:</p>\n\n<ul>\n<li><strong>Fast, Focused Feedback</strong>: Your tests should isolate the failure quickly and give you useful information as to its cause.</li>\n<li><strong>Minimize Test-Code Distance</strong>: There should be a clear and short path between the test and the code that implements it. Long distances create unnecessarily long feedback loops.</li>\n<li><strong>Test One Thing At A Time</strong>: Unit tests should only test one thing. If you need to test another thing, write another test.</li>\n<li><strong>A Bug Is A Test You Forgot To Write</strong>: What can you learn from this failure to write better, more complete tests in the future?</li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I took a PHP test for NASA recently and thought I should have done better. I believe the issue is something I used to know about, but need a refresher in. I can't remember what it is called though. It is the concept that you have to check for null, empty, and edge-cases. <em>No</em>, it's not unit testing or anything like that. It is a programming technique involving conditionals, equality, and existence tests, and then handling error exceptions.</p>\n<p>Does anyone know what the web-searchable, hash-taggable, technical term for this technique is?</p>\n\n\nAssistant:",
        "golden_answer": " <p>It's part of <a href=\"https://en.wikipedia.org/wiki/Defensive_programming\" rel=\"noreferrer\">defensive programming</a>, but that may encompass many other things:</p>\n<blockquote>\n<p>Defensive programming is a form of defensive design intended to ensure the continuing function of a piece of software under unforeseen circumstances. Defensive programming practices are often used where high availability, safety, or security is needed.</p>\n<p>Defensive programming is an approach to improve software and source code, in terms of:</p>\n<ul>\n<li>General quality  reducing the number of software bugs and problems.</li>\n<li>Making the source code comprehensible  the source code should be readable and understandable so it is approved in a code audit.</li>\n<li>Making the software behave in a predictable manner despite unexpected inputs or user actions.</li>\n</ul>\n</blockquote>\n<p>(source: Wikipedia)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>We have a legacy database full of stored procedures.</p>\n\n<p>These stored procedures are somewhat CRUD-categorized but upon inspection of some procedures, they are not \"simple\" as they might update, delete, whatever other records in other tables.</p>\n\n<p>So to my mind (correct me if I'm wrong) it would seem that using an ORM would be pretty difficult since</p>\n\n<ol>\n<li>I can't access the tables directly: I must use a stored procedure</li>\n<li>The stored procedures would not map to CRUD</li>\n</ol>\n\n<p>I'm leaning toward defining repositories to isolate the domain layer from the database but I fear that I would need to define a lot of infrastructure (caching, unit of work and the like) that I get for \"free\" in a ORM.</p>\n\n<p>Any insights?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I'm in almost the same situation; our database relies entirely on stored procs and we cannot introduce an ORM as <strong>everything</strong> would have to be rewritten to make use of it.  What I did was write an abstraction layer, basically an implementation of the <code>Table Data Gateway</code> pattern (although I call it a Repository, it's not the true DDD definition) that abstracts away the call to SqlCommand and friends.  Then I have a Service Layer sitting over that which just taps into the repository and calls the methods on it, returning business objects (essentially DTOs), sometimes with an inner collection of another business object (the mapping handled by the sproc and mapped in code).</p>\n\n<p>It's not perfect but it nicely hides the messy details of using a stored procedure.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Important discussion follows:</p>\n\n<p>C# and other language have made partial classes more popular.\nBut isn't this really a tool that have reinvented the subject-orientated programming wheel?\nWhat do you guys think? Should subject-orientated programming be taught more and get more focus to help programmers utilize partial classes better?\nResources: <a href=\"http://ptsoft.net/tdd/papers/MDSoC_Thesis_MsC_Final.pdf\" rel=\"nofollow\">http://ptsoft.net/tdd/papers/MDSoC_Thesis_MsC_Final.pdf</a></p>\n\n<p>Low important optional side track for discussion follows: </p>\n\n<p>I my self use a form of subject-oriented when making a space imperium hobby project in unity3d.\nIn unity3d gameobjects (3d models) that exist in the 3d engine can have \"scripts\" (read classes or any code file) attached to them with some special global functions that can run on each frame. This is a perfect ground to use subject orientated programming. \nTake for example a fleet gameObject, since i can attach one value class (weight, name, attack, defence), one gameRule class that handles all business logic and if i need a new subject, for example \"Raid\" i only add a raid class to the gameObject and all these are separated.</p>\n\n<p>These all implements a a general interface for their subject so they can be checked for and accessed by \n\"\nIRaid = gameObject.GetComponent[of IRaid]\nif IRaid is not null: \n  code\n\"</p>\n\n\nAssistant:",
        "golden_answer": " <p>At least in C# the purpose of partial classes is largely to keep the auto-generated code separate from the code typed by programmers, I've never seen a need to have a class separated into two+ files, it seems like if there was a good reason to do that, they probably should just be separate classes.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Dr Bjarne Stroustrup in his book D&amp;E says</p>\n\n<blockquote>\n  <p>Several reviewers asked me to compare C++ to other languages. This I have decided against doing. Thereby, I have reaffirmed a long-standing and strongly held view: \"Language comparisons are rarely meaningful and even less often fair\" . A good comparison of major programming languages requires more effort than most people are willing to spend, experience in a wide range of application areas, a rigid maintenance of a detached and impartial point of view, and a sense of fairness. I do not have the time, and as the designer of C++, my impartiality would never be fully credible. </p>\n  \n  <p>-- The Design and Evolution of C++(Bjarne Stroustrup)</p>\n</blockquote>\n\n<p>Do you people agree with his this statement \"<code>Language comparisons are rarely meaningful and even less often fair</code>\"? </p>\n\n<p>Personally I think that comparing a language X with Y makes sense because it gives many more reasons to love/despise X/Y <code>:-P</code></p>\n\n<p>What do you people think?</p>\n\n\nAssistant:",
        "golden_answer": " <p>i love comparing programming languages!</p>\n\n<p>i compare java to a warm breeze with a hint of rain</p>\n\n<p>i compare C# to beautiful spring day with just enough fluffy white clouds to keep the sky happy</p>\n\n<p>i compare C to a sledgehammer in a room full of glass</p>\n\n<p>i compare C++ to a bag of sledgehammers in a world of crystal</p>\n\n<p>i compare VB to an old wind-up toy sinking in a bathtub</p>\n\n<p>i compare PL/1 to a rusty anvil, bolted to the floor</p>\n\n<p>what do you compare them to?</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Assuming no experience with version control systems, just local to live web development. I've been dropped in on a few legacy website projects, and want an easier and more robust way to be able to quickly push and revert changes en masse. I'm currently the only developer on these projects, but more may be added in the future and I think it would be beneficial to set up a system that others can use.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You have to start somewhere. Might as well just dive in.</p>\n\n<pre><code>$ git init\n</code></pre>\n\n<p>or</p>\n\n<pre><code>$ hg init\n</code></pre>\n\n<p><a href=\"http://git-scm.com/documentation\">Git documentation</a></p>\n\n<p><a href=\"http://hgbook.red-bean.com/\">Mercurial documentation</a></p>\n\n<p>Flip through the beginner pages and pick the one that looks the most sensible to you. Or flip a coin. It doesn't really matter, as either will be infinitely superior to what you're (not) using now.</p>\n\n<p>(Note to others: Please don't turn the comments into a git vs. hg flame war. My point is simply to choose a modern source control system and learn it. Later on, learn the other. They are just tools, yet great tools at that.)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have been working as a software developer for many years now. It has been my experience that projects get more complex and unmaintainable as more developers get involved in the development of the product. </p>\n\n<p>It seems that software at a certain stage of development has the tendency to get \"hackier\" and \"hackier\" especially when none of the team members that defined the architecture work at the company any more.</p>\n\n<p>I find it frustrating that a developer who has to change something has a hard time getting the big picture of the architecture. Therefore, there is a tendency to fix problems or make changes in a way that works against the original architecture. The result is code that gets more and more complex and even harder to understand.</p>\n\n<p>Is there any helpful advice on how to keep source code really maintainable over the years?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The only real solution to avoid code rot is to code well! </p>\n\n<p>How to code well is another question. It's hard enough even if you're an excellent programmer working alone. In a heterogeneous team, it becomes much harder still. In outsourced (sub)projects... just pray.</p>\n\n<p>The usual good practices may help:</p>\n\n<ol>\n<li>Keep it simple.</li>\n<li>Keep it simple. This applies especially to the architecture, the \"big picture\". If developers are having hard time to get the big picture, they <em>are</em> going to code against it. So make the architecture simple so that all the developers get it. If the architecture has to be less than simple, then the developers must be trained to understand that architecture. If they don't internalize it, then they shouldn't code in it.</li>\n<li>Aim for <a href=\"http://en.wikipedia.org/wiki/Coupling_%28computer_programming%29\">low coupling</a> and <a href=\"http://en.wikipedia.org/wiki/Cohesion_%28computer_science%29\">high cohesion</a>. Make sure everyone in the team understands this idea. In a project consisting of loosely coupled, cohesive parts, if some of the parts becomes unmaintainable mess, you can simply unplug and rewrite that part. It's harder or near impossible if the coupling is tight.</li>\n<li>Be consistent. <em>Which</em> standards to follow matters little, but please do follow <em>some</em> standards. In a team, everyone should follow the same standards of course. On the other hand, it's easy to become too attached with standards and forget the rest: please do understand that while standards are useful, they are only a small part of making good code. Don't make a big number of it.</li>\n<li><a href=\"http://en.wikipedia.org/wiki/Code_review\">Code reviews</a> may be useful to get a team to work consistently.</li>\n<li>Make sure that all tools - IDEs, compilers, version control, build systems, documentation generators, libraries, <em>computers</em>, <em>chairs</em>, <em>overall environment</em> etc. etc. - are well maintained so that developers don't have to waste their time with secondary issues such as fighting project file version conflicts, Windows updates, noise and whatever banal but irritating stuff. Having to repeatedly waste considerable time with such uninteresting stuff lowers the morale, which at least won't improve code quality. In a large team, there could be one or more guys whose main job is to maintain the developer tools.</li>\n<li>When making technological decisions, think what it would take to switch the technology; which decisions are irreversible and which are not. Evaluate the irreversible decisions extra carefully. For example, if you decide to write the project in <a href=\"http://en.wikipedia.org/wiki/Java_%28programming_language%29\">Java</a>, that's a pretty much irreversible decision. If you decide to use some self-boiled binary format for data files, that's also a fairly irreversible decision (once the code is out in the wild and you have to keep supporting that format). But colors of the GUI can easily be adjusted, features initially left out can be added later on, so stress less about such issues.</li>\n</ol>\n"
    },
    {
        "prompt": "\n\nHuman: <p><strong>The Problem</strong></p>\n\n<p>We had a Environment class which would choose whether or not to use a webservice (it was set by a web reference) for our authentication methods by reading the host environment and if it was production or the same as the webservice would invoke it, otherwise would run the code before the migration for the webservice.</p>\n\n<p>Bad design, poor testing - when working on authentication we <b>manually</b> forced the webservice to be in the same environment we were testing so the webservice would be called.</p>\n\n<p><strong>The Solution</strong></p>\n\n<ol>\n<li><p>The Enviroment class was killed</p></li>\n<li><p>We created another webservice equals to the production but hosted on the same environment that calls it</p></li>\n<li><p>An interface that is implemented by both webservices was designed</p></li>\n</ol>\n\n<p>Now we use a factory to return the right webservice for those who want to authenticate, it is possible due to the interface so if we needed to change the webservice we would only change the new interface accordly.</p>\n\n<p><strong>Different Flavours of Wrong</strong></p>\n\n<p>A person said she'd go with a key in the web.config [\"I wouldn't use interfaces but the web.config\"] to return the right webservice but I fail to see how it solve our problem and I don't feel comfortable to argue with/ask her due to politics and our technical skills (newbie me).</p>\n\n<p>Here are some thoughts on my mind:</p>\n\n<ul>\n<li><p>Would her key return the correct type for those who seek authentication? If so what would be the \"interface\" to authenticate?</p></li>\n<li><p>Would her key be a boolean? In this case I'd need to write an if-else for each authentication method to call the right webservice?</p></li>\n<li><p>Would her key be a string? I guess it could have the host address so only one webservice would be used and one of its proprieties would be changed on-the-fly before calling its methods (I don't know if it is possible, btw)</p></li>\n</ul>\n\n<p><strong>Relevant</strong></p>\n\n<p>The webservice were created on the IDE, we'd not change theirs auto-generated code, but as they also are partials we could implement our interfaces in different files.</p>\n\n<p>I didn't find if it's possible to change the entry point of a webreference we generated automatically. The IDE writes methods it has found on that address and it acts as a proxy for the service.</p>\n\n<p>The factory helped us to avoid repetitive and unnecessary code, I don't see it happening with other solutions but the string on a key.</p>\n\n\nAssistant:",
        "golden_answer": " <p>If I understood your colleague's suggestion correctly, the solution proposed was to have a web.config key that contains a type name for the implementation class. You can use this name to retrieve the type, instantiate it (or register in DI container), and use it. I.e.:</p>\n\n<pre><code>public interface IAuthenticationBlaBla\n{\n    ...\n}\n\npublic class WebServiceAuthenticationBlaBla : IAuthenticationBlaBla {...}\npublic class AnotherAuthenticationBlaBla : IAuthenticationBlaBla {...}\n</code></pre>\n\n<p><strong>web.config</strong>:</p>\n\n<pre><code>&lt;add key=\"AuthenticationType\" value=\"Namespace.WebServiceAuthenticationBlaBla\" /&gt;\n</code></pre>\n\n<p><strong>somewhere in the initialization code</strong> (using DI, Autofac in this case):</p>\n\n<pre><code>ContainerBuilder builder = new ContainerBuilder();\n...\nbuilder.RegisterType(Type.GetType(ConfigurationManager.AppSettings[\"AuthenticationType\"]))\n    .As&lt;IAuthenticationBlaBla&gt;();\n</code></pre>\n"
    },
    {
        "prompt": "\n\nHuman: <p>How can I tell if a system is built upon a <a href=\"http://en.wikipedia.org/wiki/Service_%28Systems_Architecture%29\" rel=\"nofollow\">service oriented architecture</a> when reading its source code?</p>\n\n\nAssistant:",
        "golden_answer": " <p>SOA is an architecture style, and so, the intend is more important than the code. Who says, the code you think is SOA-Style does not get refactored the next iteration? Generally, i would expect, it's easier just to ask the architect.</p>\n\n<p>That said, ideally (i.e., when intend and source match), the following apply:</p>\n\n<ul>\n<li><p>The Source Code of the whole Project is split into very independend units that can be deployed 'standalone', i.e, without the rest beeing deployed. These are the services.</p></li>\n<li><p>Such a service would have an Interface to the external world, as a means of communication with other services. For Examle, a Date Service could answer under the url <code>http://example.com/current_date</code> something like <code>{\"year\": 2011, \"month\": 8, \"day\": 29}</code>.</p></li>\n<li><p>Except for it's interface, a service is a 'black box' to the other services. All communication is done over these interfaces. In particular, there is no shared database.</p></li>\n<li><p>When designed as SOA from the start, one would expect the same technology to be used for most of the interfaces. 'SOAP' and 'RPC over HTTP/JSON' would be examples for such technologies.</p></li>\n</ul>\n\n<p>(EDIT: cleaned the answer a little)</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>There's <a href=\"http://jalingo.sourceforge.net/dictionaries/\" rel=\"nofollow noreferrer\">DSL</a> format for creating and distributing dictionaries. Every dictionary article in such formats looks like this:</p>\n\n<pre><code>algorithm\n    [m0][b]algorithm[/b] {{id=000001018}} [c rosybrown]\\[[/c][c darkslategray][b]algorithm[/b][/c] [c darkslategray][b]algorithms[/b][/c][c rosybrown]\\][/c] [p]BrE[/p] [c darkgray] [/c][c darkcyan]\\[lrm\\][/c] [s]z_algorithm__gb_1.wav[/s] [p]NAmE[/p] [c darkgray] [/c][c darkcyan]\\[lrm\\][/c] [s]z_algorithm__us_1.wav[/s] [c orange] noun[/c] [c darkgray] ([/c][c green]computing[/c][c darkgray])[/c]\n    [m1]{{d}}a set of rules that must be followed when solving a particular problem{{/d}} [m3]\n    {{Word Origin}}[m3][c darkslategray][u]WordOrigin:[/u][/c]\n    [m3][c darkgray] [/c]{{d}}late 17th cent.{{/d}} [c dimgray]{{etymology}} (denoting the Arabic or decimal notation of numbers): variant (influenced by {{/etymology}} [/c][c darkslategray]{{lang}}Greek{{/lang}} [/c][c darkgray] [/c][c darkcyan]{{ff}}arithmos{{/ff}} [/c][c darkgray] [/c][c darkslateblue][b]{{etym_tr}}number{{/etym_tr}}[/b][/c][c dimgray]{{etymology}}) of {{/etymology}} [/c][c darkslategray]{{lang}}Middle English{{/lang}} [/c][c darkgray] [/c][c darkslategray]{{etym_i}}algorism{{/etym_i}}[/c][c dimgray]{{etymology}}, via {{/etymology}} [/c][c darkslategray]{{lang}}Old French{{/lang}} [/c][c dimgray]{{etymology}} from {{/etymology}} [/c][c darkslategray]{{lang}}medieval Latin{{/lang}} [/c][c darkgray] [/c][c darkcyan]{{ff}}algorismus{{/ff}}[/c][c dimgray]{{etymology}}. The {{/etymology}} [/c][c darkslategray]{{lang}}Arabic{{/lang}} [/c][c dimgray]{{etymology}} source, {{/etymology}} [/c][c darkcyan]{{ff}}al-Kwrizm{{/ff}} [/c][c darkgray] [/c][c darkslateblue][b]{{etym_tr}}the man of Kwrizm{{/etym_tr}} [/b][/c][c dimgray]{{etymology}} (now Khiva), was a name given to the 9th-cent. mathematician Ab Jafar Muhammad ibn Msa, author of widely translated works on algebra and arithmetic.{{/etymology}} [/c]\n</code></pre>\n\n<p>I need to parse it to <strong>HTML</strong> in <strong>Java</strong> application.<br>\nMy question is how to do it? I have thought about two options, </p>\n\n<ul>\n<li>write multiple <code>regex</code> expressions which will cover all cases</li>\n<li>parse it to something like a semantic tree by dividing to nodes, and each node parse on its own</li>\n</ul>\n\n<p>Absolutely have no experience with such kind of task, so I asking for advice and possible pitfalls.\nAny help will be appreciated!</p>\n\n\nAssistant:",
        "golden_answer": " <p>You could build a bunch of regex expressions and then write a bunch of code that will figure out when which regex should be used.  This is actually not a terrible idea for something fairly simple.  For something like this, you probably want define a <a href=\"https://en.wikipedia.org/wiki/Parsing_expression_grammar\" rel=\"nofollow noreferrer\">grammar</a> and use a tool like <a href=\"https://www.antlr.org/\" rel=\"nofollow noreferrer\">ANTLR</a> to build a lexer/parser.</p>\n\n<p>It can be a little intimidating at first but there are lots of resources that can help.  I would try one of the tutorials and build a simple language parser first.  You should find a lot of overlap with regular expressions and the way you use them.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Today I had a discussion with our architect about writing using statements in WorkUnits.</p>\n\n<p>Lets assume we have a PersonWorkUnit with methods:</p>\n\n<pre><code>public class PersonWorkUnit \n{    \n    private IContextFactory contextFactory;\n    private IRepositoryFactory repositoryFactory;\n\n    public PersonWorkUnit(IContextFactory contextFactory, IRepositoryFactory repositoryFactory)\n    {\n        this.contextFactory = contextFactory;\n        this.repositoryFactory = repositoryFactory;\n    }\n\n    public Person Get(int id) \n    {\n         using(var context = this.contextFactory.Create&lt;IPersonContext&gt;())\n         {\n              var personRepo = this.repositoryFactory.Create&lt;IPersonRepository&gt;(context);\n              return personRepo.Get(id);\n         }\n    }\n}\n</code></pre>\n\n<p>What he doesn't like is, that we have to write the <code>using(var context = this.contextFactory.Create&lt;IPersonContext&gt;()) { var personRepo = this.repositoryFactory.Create&lt;IPersonRepository&gt;(context);</code> in every method of the WorkUnit.</p>\n\n<p>My opinion is, that it is good to write (and read) it in every method because you can see explicitly the lifetime of the context and what is done during, or before/after the context. And if you have a usecases where you need multiple repositories.</p>\n\n<p>His opinion is, that it's bad to \"duplicate\" this code in every method of the class and wants to \"hide\" it in a method-level-aspect (attribute).</p>\n\n<p>What is your opinion on this topic?</p>\n\n<p>I'm looking forward for insights and reasons/advantages/disadvantages for the solutions.</p>\n\n<p>Thanks in advance</p>\n\n<p><strong>Edit:</strong> To answer some questions</p>\n\n<ul>\n<li>What is a context?<br>\nWith context I mean an entity framework DbContext</li>\n<li>Why have a ContextFactory?<br>\nI want to have a factory so I don't have <code>new PersonContext()</code> and I can mock the DbContext in acceptance tests with an InMemoryDbContext</li>\n<li>What is a repository?<br>\nRepositories (and repositories only) are responsible for accessing the database (DbContexts)</li>\n<li>What is a workunit?\nIn WorkUnits we have methods that correspond to use cases. A use case could need multiple (different) repositories. In a WorkUnit method there could be done more than only a call to a repository... the example above is simplified</li>\n<li>Why not use the ContextFactory in repositories?\nBecause some use cases require multiple repositories and I want them to use the same context, so that if something fails, the whole transaction is rolled back</li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p>From the way you describe your code, it sounds like <code>PersonWorkUnit</code> has a set of methods that all follow the follow format:</p>\n\n<pre><code>public SomeType Foo(...) \n{\n    using(var context = this.contextFactory.Create&lt;IPersonContext&gt;())\n    {\n        var personRepo = this.repositoryFactory.Create&lt;IPersonRepository&gt;(context);\n        // do something with personRepo to create SomeType instance\n        // return SomeType\n    }\n}\n</code></pre>\n\n<p>If that is the case, then just use delegates to create a single method that does everything bar the commented lines, and supply the latter via a <code>Func&lt;&gt;</code>:</p>\n\n<pre><code>public Person Get(int id) =&gt; ProcessPersonRepo(p =&gt; p.Get(id));\n\nprivate T ProcessPersonRepo&lt;T&gt;(Func&lt;IPersonRepository, T&gt; specificBehaviour) \n{\n    using(var context = contextFactory.Create&lt;IPersonContext&gt;())\n    {\n        var personRepo = repositoryFactory.Create&lt;IPersonRepository&gt;(context);\n        return specificBehaviour(personRepo);\n    }\n}\n</code></pre>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am working on a project to detect cancer and I am using deep learning (Convolutional neural network). In the user interface, the user has only to input an image number then click test</p>\n\n<p>when the user input the image number \" the number of the image in the dataset \" it will tell if this is a scan image of a person who has cancer or not.. also the dataset is used to train the model</p>\n\n<p>I want to draw a use case diagram.. the primary actor will be the user but what about the secondary? is it going to be the dataset?</p>\n\n\nAssistant:",
        "golden_answer": " <p>A use-case <a href=\"https://www.uml-diagrams.org/use-case-actor.html\" rel=\"nofollow noreferrer\">actor</a> <strong>interacts</strong> with the use case. </p>\n\n<p>If the actor is not human, its an independent system that contributes to the use case with the aim of fulfilling some of its own goals.</p>\n\n<p>In consequence, a passive dataset cannot be an actor: it does not really interact with the use case (its just data that is read and that has no behavior of its own). </p>\n\n<p>What would be a secondary actor, is a another independent system that provides the dataset as input.</p>\n\n<p>If there is no interaction however, there is no need to have a fictive secondary actor. If the data is provided by the normal user for upload, the dataset would only be (offline) input provided by the primary actor (i.e. a part of the input is aquited not via GUI but via file I/O). </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I want to add error handling to:</p>\n\n<pre><code>var firstVariable = 1;\nvar secondVariable = firstVariable;\n</code></pre>\n\n<p>The below won't compile:</p>\n\n<pre><code>try\n{\n   var firstVariable = 1;\n}\ncatch {}\n\ntry\n{\n   var secondVariable = firstVariable;\n}\ncatch {}\n</code></pre>\n\n<p>Why is it necessary for a try catch block to affect the scope of variables as other code blocks do? Consistency-sake aside, wouldn't it make sense for us to be able to wrap our code with error handling without the need to refactor?</p>\n\n\nAssistant:",
        "golden_answer": " <p>What if your code was:</p>\n\n<pre><code>try\n{\n   MethodThatMightThrow();\n   var firstVariable = 1;\n}\ncatch {}\n\ntry\n{\n   var secondVariable = firstVariable;\n}\ncatch {}\n</code></pre>\n\n<p>Now you'd be trying to use an undeclared variable (<code>firstVariable</code>) if your method call throws.</p>\n\n<p><strong>Note</strong>: The above example specifically answers the original question, which states \"consistency-sake aside\". This demonstrates that there are reasons other than consistency. But as Peter's answer shows, there is <em>also</em> a powerful argument from consistency, which would for sure have been a very important factor in the decision.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Do you spend your working hours learning new stuff, reading tech blogs, books on programming etc.? What's your opinion on it? Can an employer have benefits allowing developers to spend about 1-1.5 hrs a day on learning. Will it be repaid in future (with better productivity etc.)?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I am of the mindset that it is <strong>essential</strong> for a good development environment to allow for an hour or two at most for exploration and learning, barring when it's \"crunch time\" on an application of course.  </p>\n\n<p>An environment which doesn't do this is a red flag in my book because it tells me they don't value improvement.</p>\n\n<p><strong>EDIT</strong></p>\n\n<p>Worst of all is the place that reprimands it's developers for reading blogs/technical sites instead of \"writing code\".  That, to me, indicates an environment that doesn't care about it's developers beyond what they can squeeze out of them.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I recently moved into web development using ASP.NET MVC. The language I use is C#. Having considerable experience in C makes me look for optimized coding standards (memory, efficient data structures and speed of the loops to name a few).</p>\n\n<p>But my peers who have years of experience in this domain do not seem to take into account all these. So my question is, does the code need to be optimized when working with such languages as the servers we will be deploying these applications on has huge memory and processing speeds? Or is ignoring them a bad practice?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The culture of programming has changed considerably since the times that C was the language of choice and the hardware was so wimpy that C was actually a necessity.</p>\n\n<p>Luckily, we do not have to worry about optimization so much nowadays.  The general rule is to <strong><em>never</em></strong> optimize unless you have a good reason to do so.  And in order to have a good reason, you have to:</p>\n\n<ol>\n<li><p>Have a pre-established <strong><em>performance requirement</em></strong> for your product, something like \"server response time must be less than 200 milliseconds\".  (Vague requirements like \"as fast as possible\" are generally frowned upon.)</p></li>\n<li><p><strong><em>Measure</em></strong> the actual response time of your server and <em>actually witness</em> that it is failing to meet the requirement.</p></li>\n<li><p>Exhaust all options of meeting the requirement by <strong><em>reconfiguring your system</em></strong> to make it work more optimally.  (You would be surprised.  Some people don't know the difference between running a web server in debug mode and in production mode.)</p></li>\n<li><p>Exhaust all options of meeting the requirement by buying <strong><em>better hardware</em></strong> and/or <strong><em>more hardware</em></strong>.  Hardware nowadays generally costs far less than developers' salaries.</p></li>\n<li><p><strong><em>Throw the profiler</em></strong> on your system and determine that the bottleneck is in fact in code that you are responsible for and have the power to change.</p></li>\n<li><p>Exhaust all options for <strong><em>algorithmic optimizations</em></strong>. (Introduction of a caching layer somewhere; restructuring code so that something happens <em>asynchronously</em> rather than <em>synchronously</em>; etc.)</p></li>\n</ol>\n\n<p>Then, and only then, is it advisable to try your luck by tweaking code to make it work more optimally.  And as you might imagine, we hardly ever reach this stage.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Overheard at the watercooler yesterday: \"Scrum has no place in defense contracting.\"  </p>\n\n<p>I tend to disagree in the sense that I believe Scrum can be tailored to work in many scenarios and I can see defense being one of them.  This sparked a huge debate amongst my colleagues (many of us work in defense contracting) with a fairly even split for/against.</p>\n\n<p>To make this a proper question:  Has anyone successfully used (or has experience working with) scrum in a defense contracting situation?  What worked well, what didn't work well and what (if any) modifications to vanilla scrum did you do?</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>\"Scrum has no place in defense contracting.\"</p>\n</blockquote>\n\n<p>In my experience, the main impediment is the customer. Most government agencies have the waterfall model in their DNA. Even contracts are done in waterfall phases -- first we'll fund the requirements, then the design, then implementation. In classic waterfall theory they may even think they can get different companies to do different phases.</p>\n\n<p>There's ways to get around that though IMO. Do an upfront reqs and design like waterfall, then in implementation break requirements up into iterative user stories. Use internal test/expert users evaluate each iteration. Depending on the customer, they may or may not be interested in participating. Not pure scrum, but it may be the best you can do.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>For example:</p>\n\n<pre><code>var duckBehaviors = new Duckbehavior();\nduckBehaviors.quackBehavior = new Quack();\nduckBehaviors.flyBehavior = new FlyWithWings();\nDuck mallardDuck = new Duck(DuckTypes.MallardDuck, duckBehaviors)\n</code></pre>\n\n<p>As the Duck class contains all the behaviors(abstract), creating a new class <code>MallardDuck</code> (which extends <code>Duck</code>) does not seem to be required.</p>\n\n<p>Reference: Head First Design Pattern, Chapter 1.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Sure, but we call that <strong>composition and delegation</strong>. The Strategy Pattern and Dependency Injection might seem structurally similar but their intents are different.</p>\n<p><strong>The Strategy Pattern</strong> allows runtime modification of behavior under the same interface. I could tell a mallard duck to fly and watch it fly-with-wings. Then swap it out for a jet pilot duck and watch it fly with Delta airlines. Doing that while the program is running is a Strategy Pattern thing.</p>\n<p><strong>Dependency Injection</strong> is a technique to avoid hard coding dependencies so they can change independently without requiring clients to be modified when they change. Clients simply express their needs without knowing how they will be met. Thus how they are met is decided elsewhere (typically in main). You don't need two ducks to make use of this technique. Just something that uses a duck without knowing or caring which duck. Something that doesn't build the duck or go looking for it but is perfectly happy to use whatever duck you hand it.</p>\n<p>If I have a concrete duck class I can have it implement it's fly behavior. I could even have it switch behaviors from fly-with-wings to fly-with-Delta based on a state variable. That variable could be a boolean, an int, or it could be a <code>FlyBehavior</code> that has a <code>fly</code> method that does whatever flying style without me having to test it with an if. Now I can change flying styles without changing duck types. Now Mallards can become pilots. This is <strong>composition and delegation</strong>. The duck is composed of a FlyBehavior and it can delegate flying requests to it. You can replace all your duck behaviors at once this way, or hold something for each behavior, or any combination in between.</p>\n<p>This gives you all the same powers that inheritance has except one. Inheritance lets you express what Duck methods you're overriding in the Duck subtypes. Composition and delegation requires the Duck to explicitly delegate to subtypes from the start.  This is far more flexible but it involves more keyboard typing and Duck has to know it's happening.</p>\n<p>However, many people believe that inheritance has to be explicitly designed for from the beginning. And that if it hasn't been, that you should mark your classes as sealed/final to disallow inheritance. If you take that view then inheritance really has no advantage over composition and delegation. Because then either way you have to either design for extensibility from the start or be willing to tear things down later.</p>\n<p>Tearing things down is actually a popular option. Just be aware that there are cases where it's a problem. If you've independently deployed libraries or modules of code that you don't intend to update with the next release you can end up stuck dealing with versions of classes that know nothing about what you're up to now.</p>\n<p>While being willing to tear things down later can free you from over designing there is something very powerful about being able to design something that uses a duck without having to know what the duck will actually do when used. That not knowing is powerful stuff. It lets you stop thinking about ducks for awhile and think about the rest of your code.</p>\n<p>&quot;Can we&quot; and &quot;should we&quot; are different questions. <a href=\"https://www.thoughtworks.com/insights/blog/composition-vs-inheritance-how-choose\" rel=\"nofollow noreferrer\">Favor Composition over Inheritance</a> doesn't say never use inheritance. There are still cases where inheritance makes the most sense. I'll show you <a href=\"https://softwareengineering.stackexchange.com/a/341007/131624\">my favorite example</a>:</p>\n<pre><code>public class LoginFailure : System.ApplicationException {}\n</code></pre>\n<p>Inheritance lets you create exceptions with more specific, descriptive names in only one line.</p>\n<p>Try doing that with composition and you'll get a mess. Also, there is no risk of the inheritance <a href=\"https://en.wikipedia.org/wiki/Yo-yo_problem\" rel=\"nofollow noreferrer\">yo-yo problem</a> because there is no data or methods here to reuse and encourage inheritance chaining. All this adds is a good name. Never underestimate the value of a good name.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am doing database programming using Java with SQLite.</p>\n\n<p>I have found that only one connection at a time to the database has write capabilities, while many connections at once have read capability.</p>\n\n<p>Why was the architecture of SQLite designed like this? As long as the two things that are being written are not being written to the same place in the database, why can't two writes occur at once?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Because \"multiple concurrent writes\" is much, much harder to accomplish in the core database engine than single-writer, multiple-reader. It's beyond SQLite's design parameters, and including it would likely subvert SQLite's delightfully small size and simplicity.</p>\n\n<p>Supporting high degrees of write concurrency is a hallmark of large database engines such as DB2, Oracle, SQL Server, MySQL, PostgreSQL, NonStop SQL, and Sybase. But it's technically hard to accomplish, requiring extensive concurrency control and optimization strategies such as database, table, and row locking or, in more modern implementations, <a href=\"https://en.wikipedia.org/wiki/Multiversion_concurrency_control\">multi-version concurrency control</a>. The research on this problem/requirement is voluminous and goes back <em>decades</em>. </p>\n\n<p>SQLite has a very different design philosophy from most of those server-centric DBMSs that support multiple writers. It's designed to bring the power of SQL and the relational model to individual applications, and indeed to be embeddable within each application. That goal requires significant tradeoffs. Not adding the significant infrastructure and overhead needed to handle multiple concurrent writers is one of those.</p>\n\n<p>The philosophy can be summed up by a statement on SQLite's <a href=\"https://sqlite.org/whentouse.html\" title=\"Appropriate Uses For SQLite\">appropriate uses</a> page:</p>\n\n<blockquote>\n  <p>SQLite does not compete with client/server databases. SQLite competes with fopen(). </p>\n</blockquote>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I offered to do a little bit training in F# at my company and they seemed to show some interest. They are generally VB6 and C# programmers who don't follow programming with too much passion. That being said I feel like it is easier to write correct code when you think in a functional matter so they should definitely get some benefit out of it.</p>\n\n<p>Can anyone offer up some advice on how I should approach this?</p>\n\n<p><strong>Ideas</strong></p>\n\n<ul>\n<li>Don't focus on the syntax, instead focus on how this language and the idioms it promotes can be used.</li>\n<li>Try and think of examples that are a pain to write in an imperative fashion but translates to elegant code when written in a declarative fashion.</li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p>Functional programming is an odd beast for me.  I learned F# and Haskell, wrote a few simple programs and love using them, but never had the \"flash of revelation\" that some people talk about.  But slowly, I noticed that more and more I was writing code that was meant to be immutable, breaking up tasks into more, smaller functions, and trying to use delegates a lot more.  Its a thing that, if you like it, creeps into your work because the value of those techniques are self-evident.</p>\n\n<p>Now, more practically for training:\nI find that two concepts really click Functional Programming as a style to me.  </p>\n\n<p>First, FP style is based on structure of data, not composition as in OOP.  I looked at something like List in C# as being a clever trick to generate type-safe lists, something that composed the type (string) into the other type (list).  After learning FP, I look at generics more like Monads now.  List is a structured form that code can take, and it decorates the strings.  </p>\n\n<p>Second, and perhaps more useful to C#/ASP programmers, is the idea that FP works on recursion and repetition, while OOP works on mutability and looping. I tend to think of the ASP page lifecycle as a kind of FP now: each request is processed from scratch through the entire life-cycle, so the entire page is, in effect, one big slowly recursing program.  If you can narrow that notion down, you get a better idea of how an imperative program can be structured around loops of functions that take in data, operate over it, and return out new data instead of modifying the old.</p>\n\n<p>The trickiest hurdle, at least for me, to overcome with this approach is that sinking feeling that you're wasting tons of resources when using mutable objects would save a ton of memory.  In GC we trust, and I just had to learn to let go of performance concerns until I'd actually seen the program run and verified if there even were any, and if so to use a profiler to see exactly where the problems were.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>For single-threaded applications I like to use class diagrams to get an overview of the architecture of that application. This type of diagram, however, hasnt been very helpful when trying to understand heavily multi-threaded/concurrent applications, for instance because different instances of a class \"live\" on different threads (meaning accessing an instance is save only from the one thread it lives on). Consequently, associations between classes dont necessarily mean that I can call methods on those objects, but instead I have to make that call on the target object's thread.</p>\n\n<p>Most literature I have dug up on the topic such as <a href=\"http://rads.stackoverflow.com/amzn/click/0201657937\"><em>Designing Concurrent, Distributed, and Real-Time Applications with UML</em> by Hassan Gomaa</a>  had some nice ideas, such as drawing thread boundaries into object diagrams, but overall seemed a bit too academic and wordy to be really useful.</p>\n\n<p>I dont want to use these diagrams as a high-level view of the problem domain, but rather as a detailed description of my classes/objects, their interactions and the limitations due to thread-boundaries I mentioned above.</p>\n\n<p>I would therefore like to know:</p>\n\n<ol>\n<li>What types of diagrams have you found to be most helpful in understanding multi-threaded applications?</li>\n<li>Are there any extensions to classic UML that take into account the peculiarities of multi-threaded applications, e.g. through annotations illustrating that\n<ul>\n<li>some objects might live in a certain thread while others have no thread-affinity;</li>\n<li>some fields of an object may be read from any thread, but written to only from one;</li>\n<li>some methods are synchronous and return a result while others are asynchronous that get requests queued up and return results for instance via a callback on a different thread.</li>\n</ul></li>\n</ol>\n\n\nAssistant:",
        "golden_answer": " <p>The most important insight about how thread executions happen can be depicted by what is known as <em>sequence diagram</em>. Here is an example from <a href=\"https://en.wikipedia.org/wiki/Sequence_diagram\" rel=\"noreferrer\">wikipedia</a>  </p>\n\n<p><img src=\"https://i.stack.imgur.com/R1I59.png\" alt=\"enter image description here\"></p>\n\n<p>This diagram essentially draws the list of events along with a direction over a vertical single line often called <em>lifeline</em>. In this case, each thread is an owner of it's own life line. The diagram allow representation all types of events such as synchronous, asynchronous etc. </p>\n\n<p>The other most important thing in such systems is the state-charts or state-diagrams. Usually, this applies only if the model is represented as a state machine. However, in most multi threaded systems (where threads are non-trivial) it is best that they are designed to function with isolated algorithms for different states.</p>\n\n<p>There are other diagram types like <em>interaction diagram</em> and <em>communication diagram</em> but i think trying to draw <em>sequence diagram</em> and <em>state diagrams</em> will put maximum clarity. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm due to meet with a developer/sales person from a new 3rd party resource we're about to start using.  The main topic I'll be interested in, is their API as I will be the developer making use of it and explaining it to the rest of the team.</p>\n\n<p>What questions would you recommend asking?</p>\n\n<p>Things I'm already thinking about are:</p>\n\n<ul>\n<li>What happens and how will I be notified when they depreciate a method? </li>\n<li>Is there ever any downtime?</li>\n<li>Who will I deal with first when I have API issues?</li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p>Besides the things you suggested by yourself (among which \"who will I deal with first when I have API issues\" is IMHO the most important question) I would ask</p>\n\n<ul>\n<li><p>What kind of documentation do you provide? </p></li>\n<li><p>Do you provide samples how to use the API?</p></li>\n<li><p>How often do you provide new releases? </p></li>\n<li><p>Do you provide a detailed and complete (!) change list for a new release with special hints on breaking changes? </p></li>\n<li><p>Do your developers have a test suite in place (for example, to detect breaking changes)? <em>(if the answer is no or \"just for parts\", you may consider bringing your own test suite in place)</em></p></li>\n<li><p>Which requirements for the OS environment or run time environment does the lib have? What happens if there is a new version of the OS / run time environment, how quick can you test the lib / provide a new version if necessary?</p></li>\n<li><p>What requirements on resources (memory, network, file system space, processor speed etc.) does the lib have?</p></li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In my understanding, the GPL prohibits static linking from non-GPL code to GPL code, but permits dynamic linking from non-GPL code to GPL code. So which is it when the code in question is not linked at all because the code is written in an interpreted language (e.g. Perl)?</p>\n\n<p>It would seem to be too easy to exploit the rule if it was considered dynamic linking, but on the other hand, it would also seem to be impossible to legally reference GPL code from non-GPL code if it was considered static! Compiled languages at least have a distinction between static and dynamic linking, but when all \"linking\" is just running scripts, it's impossible to tell what the intent is without an explicit license!</p>\n\n<p>Or is my understanding of this issue incorrect, rendering the question moot? I've also heard of a \"classpath exception\" which involves dynamic linking; is that not part of the GPL but instead something that can be added on to it, so dynamic linking is only allowed when the license includes this exception?</p>\n\n\nAssistant:",
        "golden_answer": " <p>As for specific question regarding interpreted languages, <a href=\"http://www.gnu.org/licenses/gpl-faq.html#IfInterpreterIsGPL\">GPL FAQ is very clear</a>:</p>\n\n<blockquote>\n  <p>The interpreted program, to the interpreter, is just data; a free\n  software license like the GPL, based on copyright law, cannot limit\n  what data you use the interpreter on. You can run it on any data\n  (interpreted program), any way you like, and there are no requirements\n  about licensing that data to anyone.</p>\n</blockquote>\n\n<p>As for generic question about dynamic vs static linking. First of all, FSF's and Stallman's view is that it doesn't matter if linking is static or dynamic, GPL infects either way. From FSF GPL FAQ:</p>\n\n<blockquote>\n  <p>If the program <strong>dynamically links plug-ins</strong>, and they make function calls to each other and share data structures, we believe they form a single program, which must be treated as an extension of both the main program and the plug-ins. This means that combination of the GPL-covered plug-in with the non-free main program would violate the GPL.</p>\n</blockquote>\n\n<p>and </p>\n\n<blockquote>\n  <p><strong>Linking</strong> [name of your program] <strong>statically or dynamically</strong> with other\n  modules is making a combined work based on [name of your program].\n  Thus, the terms and conditions of the GNU General Public License cover\n  the whole combination</p>\n</blockquote>\n\n<p>However, this is questionable from legal point of view. In the only case that actually went to court regarding dynamic linking &mdash; <a href=\"http://en.wikipedia.org/wiki/Galoob_v._Nintendo\">Galoob  v. Nintendo</a> &mdash;  Court of Appeals ruled that derivative work <em>\"must incorporate a portion of the copyrighted work in some form\"</em>. Which is not the case with dynamic linking. </p>\n\n<p>Anyway regardless if dynamic linking does indeed infect or not, there is work around. It's used for example by Nvidia to provide binary drivers for Linux. You create (L)GPL wrapper, but as author you are allowed to add special exception to link with specific closed-source. Vide <a href=\"http://www.gnu.org/licenses/gpl-faq.html#GPLIncompatibleLibs\">FSF GPL FAQ</a>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I understand that the main code uses the factory to return an abstract pointer of the object desired, but it doesn't change the heritability of classes.</p>\n\n<p>Can you explain in which context does the factory pattern reduce coupling?</p>\n\n\nAssistant:",
        "golden_answer": " <p>By using a factory, the calling code can ignore what the concrete implementation is. That decouples the calling code from the implementations of an interface (or whatever abstraction the factory returns). The calling code also can ignore what the rules are for creating the implementation. That decouples your calling code from that logic (and allows it to be reused).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I would like to implement interprocess communication between an Ubuntu Linux 15.10 mono 4.1.2 C# recorder client and Ubuntu Linux 15.10 mono 4.1.2 C# video server using a C++ mutex  class and C++ event class  which harnesses pthreads, shm_open and mmap.</p>\n\n<p>The recorder client and video server reside on the same Ubuntu Linux machine. In addition, a Windows 7 C# client running on a separate machine communicates with an Ubuntu Linux 15.10 C# client-server program using TCP/IP sockets.</p>\n\n<p>In <em>Advanced Programming in the UNIX Environment Second Edition</em> by W. Richard Stevens and Stephen A. Rago, I read page  489 which states</p>\n\n<blockquote>\n  <p>A memory-mapped region is inherited by a child across a fork (since it's part of the parent's address space) , but for the same reason, is not inherited by the new program across  an  exec</p>\n</blockquote>\n\n<p>I need to know if I have to fork the video server program as an \"C\" child process in order for interprocess communication to take place by casting the mmap return value to a pthread_mutex_t pointer . I want to share pthread mutex and pthread condition variable between the video server process and recorder client process.</p>\n\n<p>Have I confused threads with processes? </p>\n\n<p>Boost wrote an interesting article about this topic which  I have extracted an excerpt from shown below,</p>\n\n<p><a href=\"http://www.boost.org/doc/libs/1_37_0/doc/html/interprocess/sharedmemorybetweenprocesses.html#interprocess.sharedmemorybetweenprocesses.mapped_region_object_limitations\" rel=\"nofollow\">http://www.boost.org/doc/libs/1_37_0/doc/html/interprocess/sharedmemorybetweenprocesses.html#interprocess.sharedmemorybetweenprocesses.mapped_region_object_limitations</a></p>\n\n<p>Limitations When Constructing Objects In Mapped Regions \nOffset pointers instead of raw pointers </p>\n\n<p>When two processes create a mapped region of the same mappable object, two processes can communicate writing and reading that memory. A process could construct a C++ object in that memory so that the second process can use it. However, a mapped region shared by multiple processes, can't hold any C++ object, because not every class is ready to be a process-shared object, specially, if the mapped region is mapped in different address in each process. </p>\n\n<p>When placing objects in a mapped region and mapping that region in different address in every process, raw pointers are a problem since they are only valid for the process that placed them there. To solve this, Boost.Interprocess offers a special smart pointer that can be used instead of a raw pointer. So user classes containing raw pointers (or Boost smart pointers, that internally own a raw pointer) can't be safely placed in a process shared mapped region. These pointers must be replaced with offset pointers, and these pointers must point only to objects placed in the same mapped region if you want to use these shared objects from different processes. </p>\n\n<p>Of course, a pointer placed in a mapped region shared between processes should only point to an object of that mapped region. Otherwise, the pointer would point to an address that it's only valid one process and other processes may crash when accessing to that address. </p>\n\n<p>Basile Starynkevitch wrote on April 21 2016, \"The point is won't use pthread mutex and condition variable like you dream of. Be creative too...\" , in response to my question about how to emulate a Windows event in Linux.<br>\n      So, I found the pdf, Implementing Condition Variables with Semaphores , <a href=\"http://research.microsoft.com/pubs/64242/implementingcvs.pdf\" rel=\"nofollow\">http://research.microsoft.com/pubs/64242/implementingcvs.pdf</a>, written by Microsoft researcher , Andrew D. Birrell . Below . I show an excerpt from this article , </p>\n\n<pre><code>class Lock {\n Semaphore sm;\npublic Lock() { // constructor\n sm = new Semaphore(); sm.count =1; sm.limit = 1;\n }\npublic void Acquire() { sm.P(); }\npublic void Release() { sm.V(); }\n}\nYou can come quite close to implementing a condition variable in a similar way:\nclass CV {\n Semaphore s;\n Lock m;\npublic CV(Lock m) { // Constructor\n this.m = m;\n s = new Semaphore(); s.count = 0; s.limit = 1;\n }\npublic void Wait() { // Pre-condition: this thread holds m\n m.Release();\n s.P();\n m.Acquire();\n }\npublic void Signal() {\n s.V();\n }\n}\n</code></pre>\n\n<p>Could I  harness Andrew D. Birrell's research to emulate a Windows event with a class like this:</p>\n\n<pre><code>class Event {\n    Lock theLock;\n    CV   theCV;\n    bool triggered;\n\n    Event* MakeEvent(string Name);\n    Event* OpenEvent(string Name);\n    void   CloseEvent(string Name, Event* anEvent);\n    void   NukeEvent(string Name, Event* anEvent);\n    void   SetEvent(Event* anEvent);\n    void   ResetEvent(Event* anEvent);\n    int    WaitForSingleObject(Event* anEvent, int millisecond);\n}\n</code></pre>\n\n<p>?</p>\n\n\nAssistant:",
        "golden_answer": " <p><code>pthread_mutex_t</code> is not designed to work cross process like that. It was built with the assumption that all threads using it will have the same address space.</p>\n\n<p>There are however other options to share a mutex between processes. As discussed in the comments there is <code>futex(7)</code> (which will work over shared memory) and <code>sem_overview(7)</code> (an explicit named semaphore shared across processes) both of these will work cross process. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm dealing, again, with a messy C++ application, tons of classes with confusing names, objects have pointers into each other and all over, longwinded Boost and STL data types, etc.  (Pause and consider your favorite terror of messy legacy code.  We probably have it.)  The phrase \"code rot\" oft comes to mind when I work on this project.   </p>\n\n<p>Is there a quantitative way to measure code rot?  I wouldn't expect anything highly meaningful or scientific, since no other measure of code productivity or quality is so fine.   I'm not looking for a mere opposite of measures of code quality, but specifically a measure of how many bad things  happened after a series of maintenance software \"engineers\" have had turns hacking at the code.</p>\n\n<p>A general measure applying to any language, or many languages, would be great.  If there's no such thing, at least for C++, which is a better than average language for creating messes.</p>\n\n<p>Maybe something involving a measure of topology of how objects connect during runtime, a count of chunks of commented out code, how mane files a typical variable's usage is scattered over, I don't know... but surely now, a decade into the 21st Century, someone has attempted to define some sort of rot measure.</p>\n\n<p>It would be especially interesting to automate a series of svn checkouts, measure the \"rottenosity\" of each, and plot the decay over time.</p>\n\n\nAssistant:",
        "golden_answer": " <p><a href=\"http://www.mccabe.com/iq_research_metrics.htm\" rel=\"nofollow\">This list</a> has a whole bunch of metrics that can be used to measure one aspect or another of code rot.</p>\n\n<blockquote>\n  <p><a href=\"http://www.mccabe.com/iq.htm\" rel=\"nofollow\">McCabe IQ uses a vast number of software metrics</a> to get the most precise assessment of your application's quality, security, and testing. We've defined these metrics below for your reference. Further details on many of these metrics can be found in the <a href=\"http://www.mccabe.com/iq_research_nist.htm\" rel=\"nofollow\">NIST document- \"Structured Testing: A Testing Methodology Using the Cyclomatic Complexity Metric\"</a> by Arthur Watson and Tom McCabe...</p>\n</blockquote>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I see and work with a lot of software, written by a fairly large group of people.  LOTS of times, I see integer type declarations as wrong.  Two examples I see most often: creating a regular signed integer when there can be no negative numbers.  The second is that often the size of the integer is declared as a full 32 bit word when much smaller would do the trick.  I wonder if the second has to do with compiler word alignment lining up to the nearest 32 bits but I'm not sure if this is true in most cases.</p>\n\n<p>When you create a number, do you usually create it with the size in mind, or just create whatever is the default \"int\"?</p>\n\n<p>edit - Voted to reopen, as I don't think the answers adequately deal with languages that aren't C/C++, and the \"duplicates\" are all C/C++ base.  They fail to address strongly typed languages such as Ada, where there cannot be bugs due to mismatched types...it will either not compile, or if it can't be caught at compile time, will throw an exception.  I purposely left <em>out</em> naming C/C++ specifically, because other languages treat different integers much differently, even though most of the answers seem to be based around how C/C++ compilers act.</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>Do you see the same thing? </p>\n</blockquote>\n\n<p>Yes, the overwhelming majority of declared whole numbers are <code>int</code>.</p>\n\n<blockquote>\n  <p>Why?</p>\n</blockquote>\n\n<ol>\n<li>Native ints are the size your processor does math with*. Making them smaller doesn't gain you any performance (in the general case). Making them larger means they maybe (depending on your processor) can't be worked on atomically, leading to potential concurrency bugs. </li>\n<li>2 billion and change is big enough to ignore overflow issues for most scenarios. Smaller types mean more work to address them, and <em>lots</em> more work if you guess wrong and you need to refactor to a bigger type.</li>\n<li>It's a pain to deal with conversion when you've got all kinds of numeric types. Libraries use ints. Clients use ints. Servers use ints. Interoperability becomes more challenging, because serialization often assumes ints - if your contracts are mismatched, suddenly there are subtle bugs that crop up when they serialize an <code>int</code> and you deserialize a <code>uint</code>.</li>\n</ol>\n\n<p>In short, there's not a lot to gain, and some non-trivial downsides. And frankly, I'd rather spend my time thinking about the <em>real</em> problems when I'm coding - not what type of number to use.</p>\n\n<p>*- these days, most personal computers are 64 bit capable, but mobile devices are dicier.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I was thinking to make some jQuery functions that will use ajax to control mysql. The whole idea is to make separate files of PHP (e.g query.php, addRow.php, update.php and delete.php) provide data to them via the <code>GET</code> variables like <code>query.php?sql=SELECT * FROM table</code> and then control them with jQuery AJAX functions that I'll make later. Expected code:  </p>\n\n<pre><code>$(element).click(function (e) {\n    mysql.query(\"DELETE row FROM table WHERE name = 'John Doe'\");\n});\n</code></pre>\n\n<p>And then it'll send query through AJAX and the query will be performed.<br>\nSo the problem is <strong>SECURITY</strong> . I mean anyone can just change javascript from browser's inspector or use console to control my databases. What can be done for this problem. Is there anyway to not let anyone change elements in the browser console. If not is there <strong>ANYWAY</strong> to overcome this security problem?</p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>Never</strong> expose direct access to your database from the web layer. You can never lock that down; someone <strong>will</strong> send <code>\"DROP TABLE table\"</code> to your server, however much you lock down the JS source.</p>\n\n<p>All they have to do is see what the browser sends to your server to detect that your server accepts arbitrary SQL commands.</p>\n\n<p>Not that you can lock down the JS code; it is not the browser you need to worry about, anyone can send a HTTP request and start introspecting your client-side code anyway.</p>\n\n<p>Build a <a href=\"https://stackoverflow.com/questions/671118/what-exactly-is-restful-programming\">RESTful API</a> instead, use that from the client. Such an API is limited in the damage it can do if someone starts calling it directly.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I apologize if this question is a duplicate but I am having trouble phrasing my question. I am a beginner and for the last months I have been working on a Java program. Sometimes I work on the go from my laptop and sometimes I work at home from my desktop. This means that if I am done writing some code in the desktop then I have to upload all the files to Google Drive and then download them again when I work on my laptop and vice versa. I am switching computers more often and it's becoming tedious to have to do this uploading and downloading to Google Drive all the time (open browser, delete old files from computer, download new files from Drive, move files from Download folder to the program folder). </p>\n\n<p>Is there something more convenient? Something that I can run from the terminal that will immediately save my files to some server and then allow me to pull them from the server to any computer?</p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>Problem with working on different pc's on the same code/project?</strong></p>\n\n<p>This issue was also my problem before, luckily I found out about <strong><a href=\"http://en.wikipedia.org/wiki/Revision_control\" rel=\"nofollow\">revision control systems</a></strong>..</p>\n\n<p>I used <strong><a href=\"http://git-scm.com/\" rel=\"nofollow\">git</a></strong> as my tool so whenever I modify my code to my pc at home, as I continue to code at my office, I could just update it flawlessly using <code>git pull</code> and when I finish updating my code I will just update the repo by <code>git push origin master</code> and so..</p>\n\n<p>You can also modify your code in your workplace and in home pc with different codes and just merge the codes later..</p>\n\n<p>there are other tools like this: svn, cvs, etc.. but I would suggest GIT...</p>\n\n<p>for more info on git, visit this <a href=\"http://git-scm.com/about\" rel=\"nofollow\">link</a>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I think I understand the theoretical benefits of automated testing, especially unit testing.  However, I'm not sure what the optimal amount of testing is when the project is a non-critical, rapidly developed (and deployed) web app with a reasonably large user base.  My current reasoning goes like this:</p>\n\n<ul>\n<li>Most of the core functionality of our app can be manually tested in a matter of seconds.  (The site is a type of search engine, so basically - run search, get results, it works.)</li>\n<li>Of course, there are many edge cases and options and such that could be tested, as well as unit testing of underlying logic, but if anything significant breaks and isn't caught before it's made live, we literally tend to get email from users within an hour.  (Within minutes if it's a major problem, but very rarely does one of those get out.)</li>\n<li>So the consequence of any significant problem going live is that a few people are inconvenienced for a few minutes.  Maybe some percentage of new visitors we get in that period would be lost, although the numbers should be very low since the time period is so short.</li>\n<li>Lower impact bugs might take longer for someone to email about - days, or even weeks depending on the severity - but they will also have less of an impact on users, so from a business perspective likely don't \"matter\" as much.</li>\n</ul>\n\n<p>Now, I'm not saying that excellent test coverage is useless.  Of course it would be nice to catch every issue before it goes live.  But in the cost/benefit tradeoff between working on tests and responding quickly to user feedback / adding and refining features, the latter seems to win.</p>\n\n<p>The one exception I've found is in code that doesn't directly affect the user.  For example, ad serving code, or data collection.  These don't directly impact the user's value from the site, so people are unlikely to let us know when they break.  They will also be less noticeable in our feature testing.  So I can see a strong case for well-defined unit tests there.  (And from there, there ironically seems to be a spectrum where good test coverage becomes less important as features become more important, to the point where code that is critical to the site's operation doesn't really need to be tested (in a well defined manner) at all.)</p>\n\n<p>So my question is, am I way off base here?  Is widespread test coverage and/or test-driven development optimal even in a non-critical, continuous-release environment?  And if so, where am I failing in my reasoning?</p>\n\n<p>Or, assuming we fix bugs immediately when reported, is it reasonable to focus on rapid, nimble development, knowing that our users will let us know if we break something?  (With the exception that we will have formal tests for functionality that is not directly exposed to the user.)</p>\n\n\nAssistant:",
        "golden_answer": " <p>To be honest, these days I am more and more inclined to simply comment on this as <em>unprofessional</em> behavior. There are very good books like Legacy Code <a href=\"https://softwareengineering.stackexchange.com/questions/116531/what-are-the-disadvantages-of-automated-testing/116535#116535\">1</a>, Refactoring [2], or Clean Code [3], which explain much better why professional software development should always include tests.</p>\n<p><em>Warning:</em> the following are my opinions and sometimes phrased rather strongly, because I do strongly believe them, not because I want to put you or your project into a bad light.</p>\n<h2>Advantages</h2>\n<p>You gave a few reasons, why one might want to add tests, however, you seemed to have missed a few details on those.</p>\n<h3>Code that doesn't directly affect the user</h3>\n<p>This is a double-edged sword at best, or just plain pointless. If it doesn't affect your user, then it's simply by the very definition of the word <em>useless</em>. Every piece of code should affect your user, because it is the reason why your user wants your app at all. Of course, you meant it in the sense of code that relates to the visually observable aspects of your app (aka GUI parts). But that means we're discounting such a small portion of your overall codebase, that it's not really worth discussing. It's like having a warehouse full of plums and wondering whether it's worth it to buy a corer for the plums at all, because it may not even work for that one apple in your hand.</p>\n<h3>Consequence is inconvenience</h3>\n<p>You are quite correct in that existing users are inconvenienced. But I do hope you are the market leader, or even better the monopolist. If there is a second app available to the user which does not inconvenience her - guess what? she'll switch. Often this happens faster than you can say &quot;I'll fix it&quot;. Obviously, newcomers to your app will just throw it into the trash right away.. it's not working at all when they try, so why bother? However, apart from simply losing direct sales on your app, there is another thing at stake: your company's reputation. What do you want people to think and tell others about your company? &quot;These guys know what they're doing. Almost never do I have an issue with their products and if I do, they fix it asap&quot;, or do you prefer &quot;I have no idea what these guys are doing.. every once in a while their products just stop working for a few hours. They should have fixed that long ago, but somehow they just can't get it right&quot;. The more impact your products have, the worse the problem. As a rather extreme case look at something like the Diablo 3 game, which was not functional for the first week after its release due to the massive demand of players. What did function very well though was the users venting their frustration everywhere on the net.. even today, the game has not exceeded 3 stars on amazon - granted, there are other issues with it, but the name Blizzard is marked in players' heads as &quot;do not even expect to play on release dates. they'll screw it up again.&quot;.</p>\n<h3>Complexity of test suite</h3>\n<p>(you mentioned that one in your comment) Oh so true, more complex software means more complex tests.. or maybe not. This is a typical fallacy. Stop believing this. It is on the same line as &quot;Sh<em>t in, sh</em>t out&quot;.. if your software is ever-so-complex, then tests or their complexity are not your problem. It's simply that software's complexity. Increased test complexity is just a symptom of that original problem. Tackle the real problem and make your software less complex, and lo and behold, your tests don't need to be complex either. It is also a very short-sighted argument that you lose time due to having to update tests when you make changes. Look at what really happens: you change the code and a test fails. Duh.. stupid tests.. but really, this just told you that you changed the code in a way that also changes the previously specified behavior of your program. Were you aware of that even? If not, then stop complaining right now, because you have been acting carelessly! If you do want to change the specified behavior, then tests even ensure that you did just that. What if you want to change from previous behavior to a new one, so you change the code, but no test fails? Oh oh.. major problem spotted right there. Complexity is a beast and truly unavoidable overall. But tests are the cage that keep it at bay and help you deal with it in a controlled manner.</p>\n<p>And several more you missed:</p>\n<h3>Legacy code</h3>\n<p>Most developers consider the code you are writing for your app <em>today</em> as legacy code. In <a href=\"https://softwareengineering.stackexchange.com/questions/116531/what-are-the-disadvantages-of-automated-testing/116535#116535\">1</a> legacy code is even defined as <em>code without tests</em>. So what are the problems of legacy code? oh right.. that one guy which knew the code was just hit by the bus (aka left the company for a better opportunity). I bet your successor would contemplate giving his left foot for solid test coverage when he realizes that he now has to maintain someone else's software which goes into production to thousands of users, which even expect bugs to be fixed by the hour.</p>\n<h3>Refactoring</h3>\n<p>You can't do that. Period. The evolvability of your software is crippled to the point of non-existence. Everything you add to the product, every bug you fix, every minute you invest into that code, translates to even more costs further down the road. There is no risk-free clean up and there quickly comes a limit when you will no longer be able to just say &quot;oh let's rewrite that.. if we mess up we'll hear from our users soon&quot;. Since you have no evolvability and refactoring, it just snowballs from there.. code complexity will rise together with bug counts and costs, each trying to out-do the other. Of course, this is no issue for you and your software, because it's small, simple, easy to maintain - step back just one step and look into the mirror. When you tell that to others what they hear is &quot;famous last words&quot;. Stop fooling yourself if you really still believe that. In my experience, the only software that does not grow is the one that has utterly failed all of its assigned tasks - and you have bigger worries than testing in those projects.</p>\n<h3>Development speed</h3>\n<p>Every fix, every new feature, every single line of code you add or change, profit from tests. Combined with active refactoring of your codebase the development speed surpasses a project without tests very very quickly. The keyword here is <em>feedback loop</em>. While the feedback loop you have described via your customers is indeed a very short one, which is good!, it is also a very costly one (see above). Tests simply mean that you get an earlier feedback loop that is shorter and cheaper.</p>\n<ul>\n<li>Multi-Project view: When working on source code in a company, your project seldomly works in isolation. Projects can cross-fertilize each other by re-using or sharing common code. While this does add complexity and gives your architects headaches, it is all based on the very foundation of testing. Do not even dare to think about re-using or sharing code that is untested - you'll sacrifice both projects on the altar of ignorance that way.</li>\n</ul>\n<h3>Regression</h3>\n<p>Even though you can fix bugs within an hour (I do certainly not admire your sleeping pattern if that is for real!), your customers MAY (yes, that is a huge may) accept that for new features and previously unknown bugs. It is simply unacceptable and projects an immensely bad picture of your company, if the same bugs appear again lateron. If you start fixing a bug without writing a test to verify its existence first, then you are making a huge and costly mistake. If you cannot write a test against the bug, then you definitely are in no position whatsoever to even attempt to fix it. And if you wrote that test, you immediately see when it is fixed (because the test should of course assert the correct behavior, hence, turn from red to green due to the fix). Finally, the very same test serves as a regression test from now on to ensure your users will never ever see that identical bug again. (Off-topic: I'm sometimes wondering if it's worthwhile to introduce a saying like &quot;Write once, profit everywhere&quot; to capture this..)</p>\n<h3>Professionalism</h3>\n<p>What do you tell your manager? Do you have any moral conflict in confidently stating that you made this piece of software? or do you feel slightly ashamed, knowing that you just hacked it together and most of your confidence of the software's capabilities relies on sheer hope? Have you really done the company a service, or did you just create further obligations it has to pay for dearly in the future?</p>\n<h2>The other side of the coin</h2>\n<p>While I do argument in favor of automated testing, it was correctly pointed out, that this answer was one-sided, so let's take a look at the cons of automated testing.</p>\n<p>I have written <a href=\"https://softwareengineering.stackexchange.com/questions/116531/what-are-the-disadvantages-of-automated-testing/116535#116535\">another lengthy answer</a> that goes into more detail on the general disadvantages of all automated testing. But in short, these disadvantages turn into advantages when you do not implement automated testing. Here's that same list in its &quot;advantage&quot;-point of view formulation:</p>\n<ul>\n<li>Development time: You get faster time-to-market</li>\n<li>Skill level: Your developers don't need to know anything about automated testing.</li>\n<li>Tooling: You don't need these tools or licenses.</li>\n<li>Failed and non-failed tests: You are not wasting time on tests anyways.</li>\n<li>Deployment costs: Costs are reduced to what you need for operation. Testing infrastructure cost is no longer needed.</li>\n</ul>\n<h2>Summary</h2>\n<p>In the end, its up to a lot of factors on what the best approach is. I would argue that there is no objective answer that holds for all projects and is concrete enough to implement.</p>\n<p>You can of course say that there are costs/profits (positive and/or negative) over time and you can think of two mathematical functions, one for automated tests, one for development without them. At the very least, there will be an intersection somewhere after which if you spend more time on the project, automated tests will have a better overall cost/profit. That point is definitely too late for a switching strategy though.</p>\n<p>Personally, in my experience, people severely over-estimate how long it takes to reach the point when automation pays off - myself included. Even projects that are supposed to only take 2 weeks have that tendency to keep going. Since the automated tests already help during development, the time delay caused by adding automated testing is similarly over-estimated. I am still unsure at what point automated tests start to pay off, but in my past that point was reached already a week or two into the project. In some projects the tests were there and a retrospective revealed the benefit, in other projects problems soon (and later) started to come up that would have been avoidable.</p>\n<p>I'd suggest to dismiss the notion of automated testing yes-or-no, and instead have automated testing and think of it as a tradeoff trying to find out just how much of it you need.</p>\n<p><a href=\"https://softwareengineering.stackexchange.com/questions/116531/what-are-the-disadvantages-of-automated-testing/116535#116535\">1</a> Michael Feathers' Working Effectively with Legacy Code (ISBN 0-13-117705-2)</p>\n<p>[2] 1999. Refactoring: Improving the Design of Existing Code, With Kent Beck, John Brant, William Opdyke, and Don Roberts (June 1999). . Addison-Wesley. ISBN 0-201-48567-2.</p>\n<p>[3] Clean Code: A Handbook of Agile Software Craftsmanship. Prentice Hall PTR. 2008. ISBN 0-13-235088-2</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p><a href=\"http://www.cs.utexas.edu/~wcook/\">William Cook</a> in a <a href=\"https://twitter.com/w7cook/status/215527404184158209\">tweet</a> wrote that: </p>\n\n<p>\"<em>UML is the worst thing to ever happen to MDD. Fortunately many people now realize this ...</em>\"</p>\n\n<p>I would like to know the reasoning behind that claim (apparently, I'm not referring to his personal opinion). </p>\n\n<p>I've noticed that many people out there don't like UML that much. Also it is worth mentioning that he is in academia, where UML is preety much the holy grail of effective design and modelling.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Well, I'm the academic who posted the original tweet. Tweets are not meant to be scholarly articles. They are advertisements, and I think they can also be controversial. Here are my follow-up tweets:</p>\n\n<p>1) UML was created to model OO designs. It effect you are modeling the code of a system, not the system's behavior. UML is at wrong level.</p>\n\n<p>2) the idea that 7 (or 13) diagram formats in UML can cover everything is crazy. What about GUIs, web wireframes, authorization, etc. ???</p>\n\n<p>3) UML has encouraged the idea that models must be graphical. Ridiculous! Text and graphic models are both useful and often interchangeable</p>\n\n<p>4) UML is at once too large and complex and at the same time very limiited. Stereotype and profiles are not effective for usable extensions.</p>\n\n<p>Note that I'm not necessarily saying UML is bad. I'm simply saying that it is not helping the goal of \"model-driven development\", which is what I'm interested in. I don't understand the comment about \"holy grail\".</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Some people have the view of programming that it is just repetitive typing on a keyboard. None of this is true. First of all, there is so much more you have to do than actually typing down the code, such as design architecture and so on. Secondly, it could be a greatly varying, non-repetitive task, with new challenges coming all the time.</p>\n\n<p>How should you explain that programming is <em>not</em> a repetitive task to <strong>non-programmers</strong>?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Give them examples they can relate to.</p>\n\n<p>Tennis is repetitive. You just keep hitting the ball all the time over to the other side of the net.</p>\n\n<p>Soccer is repetitive. You just keep kicking the ball every time until you find a goal post.</p>\n\n<p>Playing the piano is repetitive. You keep on moving your fingers on the board.</p>\n\n<p>Damn, all so boring!!!</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In some colleges students are let to use an IDE and Internet and in mine you have to write down your solution in paper.</p>\n\n<p>As far as I know, it's pretty much impossible to make a correct non-trivial program on the first try. I'd be fine with no using computers if my teachers assessed my <em>approach</em> instead my <em>code</em> -literally-... that's not the case unfortunately.</p>\n\n<p>Which ones are more usual, 'written' or 'coded' exams? And which way is the most adequate?</p>\n\n<p><strong>Edit</strong> - question title changed (it used to be <em>Should students have the right to do exams using a computer?</em>)</p>\n\n\nAssistant:",
        "golden_answer": " <p>I only ever had \"written\" exams in university. And the written code didn't have to be perfect. A forgotten semicolon here or there was usually forgiven. Sometimes they didn't even require it to be a specific language, they'd ask for an algorithm to be implemented in pseudocode, because the language didn't really matter. And the programs were usually relatively short. I don't think any were more than 30 lines, and any more than that and you should have that \"You're doing it wrong!!\" feeling (and the amount of space provided was also sometimes a clue as to how \"big\" your solution should be).</p>\n\n<p>Also, running computers in an exam is tricky. They have to be 100% garaunteed to work the same or some studen will complain they did poorly because they had the \"lemon\" machine. No internet connections (or connections to any resource that could help them cheat). And if a computer <em>does</em> crash in the middle of an exam, or suffers some other random problem, how do you handle it? Do they get a re-write later? Extra time (unless that impacts other schedules)? What if some devious student compromises the whole lab of exam computers?</p>\n\n<p>So to answer the question... No. I don't think students should have a \"right\" to use a computer during an exam because <em>it shouldn't even be necessary</em>. Of course, the instructor should also be willing to forgive some <em>minor</em> syntax errors if the rest of the program is fine.</p>\n\n<hr>\n\n<p>To answer the changed question: No, in general it is not a good idea for exams to be done on the computer. The exam should test their overall comprehension of the course material, and for <em>most</em> courses (but there are probably a few that I don't know about that are actually much easier tested <em>with</em> a computer), I don't believe a computer is necessary or will add anything that can't be done with paper and pencil.</p>\n\n<p>Actual interaction with and usage of computers is usually tested by projects and assignments over the term, and in some courses the sum of those assignments weighs heavier than the exams.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>A friend of mine, a beginner PHP programmer, needs to link the product his company develops with a third-party product (a set of web services). He received the \"relevant\" documentation (a few hundred of pages of unreadable stuff) from this third-party, have read the PHP documentation related to SOAP client, have read about SOAP and WSDL, but <strong>doesn't have a slightest idea where to start</strong>. Instead of a step-by-step tutorial, he has lots of overly verbose documentation.</p>\n\n<p>I suggested him to use prototyping:</p>\n\n<ol>\n<li>Imagine the most basic scenario where the third-party web services can be used,</li>\n<li>Select the relevant documentation,</li>\n<li>Build (from scratch) the simplest PHP script which will play this scenario,</li>\n<li>Once the prototype works, integrate the functionality into the existing product,</li>\n<li>Refactor,</li>\n<li>Expand the existing product with additional features.</li>\n</ol>\n\n<p>While this may help pushing this person to the right direction, I feel that my suggestion is only partially helpful. I imagine myself six years ago knowing nothing about WSDL and SOAP and having to search inside hundreds of pages of documentation: I would be already discouraged at steps 2 and 3.</p>\n\n<p>Experienced developers have a bunch of patterns, practices and processes which help solving basic problems frequently encountered in software development:</p>\n\n<ul>\n<li><p>The technical aspects of a feature are uncertain? Use prototyping.</p></li>\n<li><p>The application \"feels unresponsive\"? Use profiling to find bottlenecks.</p></li>\n<li><p>The requirements are subject to frequent change? Use Agile.</p></li>\n<li><p>Programmers need to be sure their code doesn't contain omissions? Use code reviews.</p></li>\n<li><p>The successive versions of a product are not deployed fast enough? Use DevOps.</p></li>\n</ul>\n\n<p>While those patterns and practices help developers solving purely technical/organizational issues (such as \"I know how to implement Web Sockets in Java, Python and Node.js, but now I need to do it in Haskell.\"), the same patterns and practices are not helpful for less experienced programmers who need to solve more substantial and less technical problems (such as \"I believe Web Sockets are a sort of HTTP but it happens the other way, something like that; now lead developer asked me to implement that in my app, but I'm not sure why do we need it.\")</p>\n\n<p>Inviting the programmer to spend three years in college or twelve months reading programming-related books is not always an option: some people need to work to pay their bills, need to finish the project for the next deadline, and are not paid to read books.</p>\n\n<p>So what are other options?</p>\n\n\nAssistant:",
        "golden_answer": " <p>We already do; that's what <a href=\"http://en.wikipedia.org/wiki/Multi-core_processor\">multi-core processors</a> are for.</p>\n\n<p>Part of highly-optimizing for speed is specialization.  When you build processors that specialize in one thing, you can optimize for that one thing, and ignore optimizing for anything else.</p>\n\n<p>Optimization can have conflicting goals.  That's the reason we have many different kinds of data structures; each is optimized for a specific task.  If you could write a data structure that was fully optimized for <em>any</em> task, then we'd all be using only that data structure, and nothing else.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Often times in programming, we need to represent some value which can easily be represented using a simple primitive type.</p>\n\n<p>For example, in a game we might need to represent the velocity of a moving object. This could easily be represented with a <code>double</code> value. This object might also have a value of mass; this can also be represented with a <code>double</code>.</p>\n\n<p>Some would argue that we should have a <code>Speed</code> type and a <code>Mass</code> type for each of these, instead of the general-purpose <code>double</code> type. The argument for that is that this way we take advantage of 'strong-typing'; the compiler doesn't let us pass a speed for a mass or a mass for a speed and make mistakes like those.</p>\n\n<p>This argument makes sense. However, I can't help but thinking that this would be an overkill.</p>\n\n<p>So what would you use? A simple <code>double</code> (following KISS and keeping everything as simple as possible) or a type made for a specific purpose?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I would say yes if that type has a meaning more than just the simple value. In your example,  Speed and Mass might be represented by a double, but they have different meanings, and they have different calculations that can be done on them. </p>\n\n<p>I can tell you from personal experience that doing this (it's called micro domain btw), has made my code much more readable and saved me lots of times from passing the wrong variable by mistake.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have been adapting poor-man's <a href=\"https://martinfowler.com/bliki/CQRS.html\" rel=\"noreferrer\">CQRS</a><sup>1</sup> for quite some time now because I love its flexibility to have granular data in one data store, providing great possibilities for analysis and thus increasing business value and when needed another for reads containing denormalized data for increased performance.</p>\n\n<p>But unfortunately pretty much from the beginning I have been struggling with the problem where exactly I should place business logic in this type of architecture.</p>\n\n<p>From what I understand, a command is a mean to communicate intent and does not have ties to a domain by itself. They are basically data (dumb - if you wish) transfer objects. This is to make commands easily transferable between different technologies. Same applies to events as responses to successfully completed events.</p>\n\n<p>In a typical DDD application the business logic resides within entities, value objects, aggregate roots, they are rich in both data as well as behavior. But a command is not a domain object thus it should not be limited to domain representations of data, because that puts too much strain on them.</p>\n\n<p>So the real question is: <em>Where exactly is the logic?</em></p>\n\n<p>I have found out I tend to face this struggle most often when trying to construct a quite complicated aggregate which sets some rules about combinations of its values. Also, when modeling domain objects I like to follow the <a href=\"https://en.wikipedia.org/wiki/Fail-fast\" rel=\"noreferrer\">fail-fast</a> paradigm, knowing when an object reaches a method it's in a valid state.</p>\n\n<p>Let's say an aggregate <code>Car</code> uses two components:</p>\n\n<ul>\n<li><code>Transmission</code>,</li>\n<li><code>Engine</code>.</li>\n</ul>\n\n<p>Both <code>Transmission</code> and <code>Engine</code> value objects are represented as super types and have according sub types, <code>Automatic</code> and <code>Manual</code> transmissions, or <code>Petrol</code> and <code>Electric</code> engines respectively.</p>\n\n<p>In this domain, living on its own a successfully created <code>Transmission</code>, be it <code>Automatic</code> or <code>Manual</code>, or either type of an <code>Engine</code> is completely fine. But the <code>Car</code> aggregate introduces a few new rules, applicable only when <code>Transmission</code> and <code>Engine</code> objects are used in the same context. Namely:</p>\n\n<ul>\n<li>When a car uses <code>Electric</code> engine the only allowed transmission type is <code>Automatic</code>.</li>\n<li>When a car uses <code>Petrol</code> engine it may have either type of <code>Transmission</code>.</li>\n</ul>\n\n<p>I could catch this component combination violation at the level of creating a command, but as I have stated before, from what I understand that should not be done because the command would then contain business logic which should be limited to the domain layer.</p>\n\n<p>One of the options is to move this business logic validation to command validator itself, but this does not seem to be right either. It feels like I would be deconstructing the command, checking its properties retrieved using getters and comparing them within the validator and inspecting results. That screams like a violation of the <a href=\"https://en.wikipedia.org/wiki/Law_of_Demeter\" rel=\"noreferrer\">law of Demeter</a> to me.</p>\n\n<p>Discarding the mentioned validation option because it does not seem viable, it seems like one should use the command and construct the aggregate from it. But where should this logic exist? Should it be within the command handler responsible for handling a concrete command? Or should it perhaps be within the command validator (I don't like this approach either)?</p>\n\n<p>I am currently using a command and create an aggregate from it within the responsible command handler. But when I do this, should I have a command validator it would not contain anything at all, because should the <code>CreateCar</code> command exist it would then contain components which I know are valid on separate cases but the aggregate might say different.</p>\n\n<hr>\n\n<p>Let's imagine a different scenario mixing different validation processes - creating a new user using a <code>CreateUser</code> command.</p>\n\n<p>The command contains an <code>Id</code> of a users which will have been created and their <code>Email</code>.</p>\n\n<p>The system states the following rules for user's email address:</p>\n\n<ul>\n<li>must be unique,</li>\n<li>must not be empty,</li>\n<li>must have at most 100 characters (max length of a db column).</li>\n</ul>\n\n<p>In this case, even though having a unique email is a business rule, checking it in an aggregate makes very little sense, because I would need to load the entire set of current emails in the system to a memory and check the email in the command against the aggregate (<strong>Eeeek!</strong> Something, something, performance.). Because of that, I would move this check to the command validator, which would take <code>UserRepository</code> as a dependency and use the repository to check whether a user with the email present in the command already exists.</p>\n\n<p>When it comes to this it suddenly makes sense to put the other two email rules in the command validator as well. But I have a feeling the rules should be really present within a <code>User</code> aggregate and that the command validator should only check about the uniqueness and if validation succeeds I should proceed to create the <code>User</code> aggregate in the <code>CreateUserCommandHandler</code> and pass it to a repository to be saved.</p>\n\n<p>I feel like this because the repository's save method is likely to accept an aggregate which ensures that once the aggregate is passed all invariants are fulfilled. When the logic (e.g. the non-emptiness) is only present within the command validation itself another programmer could completely skip this validation and call the save method in the <code>UserRepository</code> with a <code>User</code> object directly which could lead to a fatal database error, because the email might have been too long.</p>\n\n<p>How do you personally handle these complex validations and transformations? I am mostly happy with my solution, but I feel like I need affirmation that my ideas and approaches are not completely stupid to be pretty happy with the choices. I am entirely open to completely different approaches. If you have something you have personally tried and worked very well for you I would love to see your solution.</p>\n\n<hr>\n\n<p><sup>1</sup> Working as a PHP developer responsible for creating RESTful systems my interpretation of CQRS deviates a little from the standard <em>async-command-processing</em> approach, such as sometimes returning results from commands due to the need of processing commands synchronously.</p>\n\n\nAssistant:",
        "golden_answer": " <p>The following answer is in the context of the CQRS style promoted by the <a href=\"http://cqrs.nu/\" rel=\"noreferrer\">cqrs.nu</a> in which commands arrive directly on the aggregates. In this architectural style the application services are being replaced by an infrastructure component (the <a href=\"https://github.com/xprt64/dudulina/blob/master/src/Dudulina/Command/CommandDispatcher.php\" rel=\"noreferrer\">CommandDispatcher</a>) that identifies the aggregate, loads it, sends it the command and then persists the aggregate (as a series of events if Event sourcing is used).</p>\n\n<blockquote>\n  <p>So the real question is: Where exactly is the logic?</p>\n</blockquote>\n\n<p>There are multiple kinds of (validation) logic. The general idea is to execute the logic as early as possible - fail fast if you want. So, the situations are as follows:</p>\n\n<ul>\n<li>the structure of the command object itself; the command's constructor has some required fields that must be present for the command to be created; this is the first and fastest validation; this is obviously contained in the command.</li>\n<li>low level field validation, like the non-emptiness of some fields (like the username) or the format (a valid email address). This kind of validation should be contained inside the command itself, in the constructor. There is another style of having an <code>isValid</code> method but this seems pointless to me as someone would have to remember to call this method when in fact successful command instantiation should suffice.</li>\n<li>separate <code>command validators</code>, classes that have the responsibility to validated a command. I use this kind of validation when I need to check information from multiple aggregates or external sources. You could use this to check the uniqueness of an username. <code>Command validators</code> could have any dependencies injected, like repositories. Keep in mind that this validation is eventually consistent with the aggregate (i.e. when the user gets created, another user with the same username could be created in the meantime)! Also, do not try to put here logic that should reside inside the aggregate! Command validators are different from the Sagas/Process managers which generate commands based on events.</li>\n<li>the aggregate methods that receive and process the commands. This is the last (kind of) validation that occurs. The aggregate extract the data from the command and using some core business logic it accepts (it performs changes to it's state) or rejects it. This logic is checked in a strong consistent manner. This is the last line of defense. In your example, the rule <code>When a car uses Electric engine the only allowed transmission type is Automatic</code> should be checked here.</li>\n</ul>\n\n<blockquote>\n  <p>I feel like this because the repository's save method is likely to accept an aggregate which ensures that once the aggregate is passed all invariants are fulfilled. When the logic (e.g. the non-emptiness) is only present within the command validation itself another programmer could completely skip this validation and call the save method in the UserRepository with a User object directly which could lead to a fatal database error, because the email might have been too long.</p>\n</blockquote>\n\n<p>Using the above techniques nobody can create <em>invalid</em> commands or bypass the logic inside the aggregates. Command validators are automatically loaded+called by the <code>CommandDispatcher</code> so nobody can send a command directly to the aggregate. One could call a method on the aggregate passing a command but could not persist the changes so it would be pointless/harmless to do so.</p>\n\n<blockquote>\n  <p>Working as a PHP developer responsible for creating RESTful systems my interpretation of CQRS deviates a little from the standard async-command-processing approach, such as sometimes returning results from commands due to the need of processing commands synchronously.</p>\n</blockquote>\n\n<p>I'm also a PHP programmer and I don't return anything from my command handlers (aggregate methods in the form <code>handleSomeCommand</code>). I do, however, quite often, return information to the client/browser in the <code>HTTP response</code>, for example the ID of the newly created aggregate root or something from a read-model but I never return (really <em>never</em>) anything from my aggregate command methods. The simple fact that the command was accepted (and processed - we are talking about synchronous PHP processing, right?!) is sufficient.</p>\n\n<p>We return something to the browser (and still doing CQRS by the book) because <a href=\"https://www.infoq.com/news/2016/04/event-sourcing-anti-pattern\" rel=\"noreferrer\">CQRS is not a high level architecture</a>.</p>\n\n<p>An example of how command validators work:</p>\n\n<p><a href=\"https://i.stack.imgur.com/LArZv.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/LArZv.jpg\" alt=\"Command&#39;s path through command validators on its way to the Aggregate\"></a></p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The GO programming language has objects but no inheritance. It also has generics for the built-in types Array and Map. Is there a programming language with objects but no inheritance and with generics (i.e. parameterized types) for all user created types?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Rust has objects and general-purpose generics but not inheritance.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Ok, I understand the normal conventions of using verbs with functions and nouns with classes. What about interfaces? Is there any methodology when coming up with interface names that may not be that obvious?</p>\n\n<p>Just to make it clear, I'm not talking about whether to put an \"I\" in front of the name or if to use camelCase or PascalCase. I'm wondering about the method of figuring out a clear, semantic name for an interface.</p>\n\n<p><strong>EDIT</strong>\nI'm obsessing on how to name an interface in the clearest way. I guess it just needs to be a noun too because when I think of naming classes I think of the closest \"real\" world object it can relate to. I suppose real world interfaces are things like a keyboard, mouse, remote control, ATM screen. Those are all nouns. Anyhow, any additional insight on a good way to formulate interface names would be appreciated.</p>\n\n\nAssistant:",
        "golden_answer": " <p>I'd say it depends on what the interface defines. In some cases when the interface is rather specific and detailed, I think a noun is best. Examples are <code>IList</code>, <code>ICollection</code>.</p>\n\n<p>Sometimes though an interface is more about adding certain general features to a class. In that case I think an <em>adjective</em> is best. Examples are <code>IDisposable</code>, <code>IEnumerable</code>, ...</p>\n\n<p>Maybe another way to think about this is how many \"abilities\" your interface defines.</p>\n\n<p>For example, the <code>IList&lt;T&gt;</code> interface defines these abilities: Add, Clear, Contains, Insert, Remove, ... These are all properties of a list so <code>IList</code> is a good name.</p>\n\n<p><code>IDisposable</code> on the other hand only defines one ability: Dispose. So it is suited for anything that is disposable. Hence the name <code>IDisposable</code>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Many people are talking about somethings like accelerator, opcode, etc to speed up a website's performance. To be honest I do not know how to make any PHP website perform well and when do I need to use such things and what if I use them will that cost me a lot? I generally like websites to perform well with excellent and quick load time for the user (I know the load time has other factors such as the internet speed but what I care about here is the performance of the PHP code itself how to make it perform better).</p>\n\n<p>So, could you tell me about all the ways to speed up any PHP website and whether they are possible and easy to implement or not?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You need to know what is slowing down the site most before you can effectively 'speed-up' a website.</p>\n\n<p>Do some profiling and determine exactly where your biggest bottle necks are first and pick of the most effective low-lying fruit until you get your desired performance. Remember, you will experience the effects of diminishing returns, so you will have to find the point of maximum value for the particular case in hand.</p>\n\n<p>Typical areas you will have are as indicated by @guiman in <a href=\"https://softwareengineering.stackexchange.com/questions/66261/how-to-speed-up-php-powered-websites/66272#66272\">his answer</a>.</p>\n\n<p>I would also add in:</p>\n\n<ul>\n<li><p>Hardware limitations</p>\n\n<ul>\n<li>Are you being memory bound</li>\n<li>CPU bound?</li>\n<li>Waiting on the disk?</li>\n<li>If any of the above, is the DB being run on a separate machine?</li>\n</ul></li>\n<li><p>Network limitations</p>\n\n<ul>\n<li>What is the utilization on the connect to the web server?</li>\n<li>What is the latency like?</li>\n<li>Potential to utilize a CDN to move traffic elsewhere?</li>\n</ul></li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Say, that you are handling a multi-step process (like a complex registration form, with a number of steps the user has go through in order). You need to be able to save the current state of the process (e.g. so the user can come back to that registration form later and continue form the step where they were left off).</p>\n\n<p>Obviously, youll probably want to give each step an identifier you can refer to: 1, 2, 3, 4, etc. Your logic will check for this <code>step_id</code> (or whatever you call it) to render the appropriate data.</p>\n\n<p>The question: how would you identify the stage after the final step, like the completed registration state (say, that you <strong>have</strong> to give that last step its own id, thats how your logic is structured). Would it be a <code>0</code>, <code>999</code>, a non-integer value, something else entirely?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The task you are trying to perform is called \"license management\" and the tool you are looking for is a \"license manager\" program. </p>\n\n<p>You can find a few different license manager programs out there but, even better, you can also write your own with a relativly small effort.</p>\n\n<p>Most license managers are just <a href=\"https://en.wikipedia.org/wiki/Webservice\" rel=\"nofollow\">webservices</a> (nowadays they are almost always <a href=\"https://en.wikipedia.org/wiki/Restful_web_service\" rel=\"nofollow\">RESTful</a> webservices, like the one you can esily create with <a href=\"http://www.sinatrarb.com/\" rel=\"nofollow\">Sinatra</a>, for example) that performs these basic steps:</p>\n\n<ol>\n<li>Accept a request for an authorization key from a client program (that resides on the same LAN or on the Internet).</li>\n<li>Give the client an authorization key (taken from a pool of keys), if any key is available in the pool.</li>\n<li>Get back the key (this is a metaphor. Actually, the license server just reset the key after a pre-defined period of time).</li>\n</ol>\n\n<p>The client program, on its side, requests the key when it gets started and gives it back (deletes it) when it stops.</p>\n\n<p>Of course:</p>\n\n<ol>\n<li>You have to be able to trust both the license server and the client program. The server runs on a server machine that you control, so it is easy to trust it. The client program must be compiled (closed source) in order to keep any \"hacker\" from creating a new copy of the program that never deletes its keys.</li>\n<li>Client and server must be able to communicate through a LAN or on the Internet.</li>\n</ol>\n\n<p>The server must be under your control or must be linked to the hosting machine in some way (usually using a hardware key).</p>\n\n<p>Hope this helps.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>A large SQL transactional database has more than 100 tables (and it will grow). One of them is called <strong>Order</strong>. Then, there is another table <strong>WorkLoad</strong> which derives from Order and many other joined table which contains a list of all active order. Every time an order record is created, if it meets certain conditions, it should be instantly inserted into WorkLoad table. And finally, there is a third table <strong>WorkLoadAggregation</strong> which displays aggregated data grouped by date and shop and it is completely built from WorkLoad table. WorkLoadAggregation should also display live data meaning that if a record is inserted in WorkLoad table then matching date/shop aggregation should also be updated.</p>\n\n<p>My idea was to handle this by triggers:</p>\n\n<ul>\n<li>When record is <strong>inserted in Order table</strong>, trigger calls stored procedure which inserts record into WorkLoad table</li>\n<li>When <strong>Order record is deleted</strong> trigger deletes the record from WorkLoad table</li>\n<li>When <strong>Order record is updated</strong> in a way that it doesn't meet WorkLoad conditions, trigger deletes the record from WorkLoad table</li>\n<li>When record is <strong>inserted/deleted/updated in WorkLoad</strong> table, trigger calls stored procedure which updates matching date/shop aggregated record in WorkLoadAggregation table</li>\n</ul>\n\n<p>I haven't used triggers that much in such large transaction dbs and for such frequent calls. Is there anything bad in this approach? My biggest concern is usage of \"chained triggers\", meaning that trigger on one table activates trigger on another table. I've been reading few articles which state that developers should be very cautious when using triggers. Are there any better solutions? Should I consider any NoSQL solution?</p>\n\n\nAssistant:",
        "golden_answer": " <p>If I were you I would make <code>SocialInsuranceNumber</code> a Value Object with validation in its constructor. However, since the logic for validation is complex you might prefer to delegate the validation logic into a Domain Factory instead.</p>\n\n<p>The factory will have a validation strategy injected into it depending on the type of the social security number you are validating.</p>\n\n<p>So <code>SocialInsuranceNumber</code>'s constructor will validate for <code>NULL</code>, empty, min length, illegal characters, ...etc, but <code>SocialInsuranceNumberFactory</code> will validate whether the pattern used in valid in case it was Canadian or not using a <code>CanadianSocialInsuranceNumberValidator</code> or <code>DefaultSocialInsuranceNumberValidator</code>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have an intern and he writes code fast.</p>\n\n<p>However, I have difficulty making him understand the importance of writing classes and follow the OOP paradigm.</p>\n\n<p>We recently had a discussion that went like something this:</p>\n\n<p>\"Instead of having this long function that extracts data from two different queries and then combine the data into a new data structure as a standalone function, why not start by putting it in a class?</p>\n\n<p>I understand that it's not much differences for now, but I can foresee that this class will grow to have more functions and the next guy who takes over will naturally refactor the giant function into more functions within the same class.\"</p>\n\n<p>When he objected, I told him, \"Okay, I gave you my criteria (write the function within a class) and my reason (we will likely have it as a class in the future, might as well start now no matter how imperfect the start). If you have a better criteria and a better reason, why don't you suggest it?\"</p>\n\n<p>One day later his reply was, \"python is an object oriented programming language so when codes are organised inside a file, it is somewhat oop alr\"</p>\n\n<p>How do I make him understand the importance or better yet appreciate the importance of software craftsmanship?</p>\n\n<p>In case, I made some bad assumptions myself, I am willing to stand corrected and I understand the dangers of asking this question and having it closed down. So if there was a better place to pose this question, I am willing to try it.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Python is a multi-paradigm language in which procedural code is quite common, and the decision to write a class or a function is taken on a case by case basis.  Python recognizes that a class is not always the best tool for the job.  If you hope to convince someone of the merits of OOP, you need to solidify the merits in your own mind first, and not just use a class because it's the default \"best practice\" or whatever.</p>\n\n<p>People choose classes when they need to carry related state between function invocations.  In other words, when you already have something resembling a <code>self</code> that gets passed between a group of functions, that's a good sign that a class would be a great fit there.  If you have no state being passed, or a different set of state every time, then OOP is a poor fit.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>What is exactly meant when software-engineers talk about \"behaviour\" in contrast to \"state\" (<a href=\"https://softwareengineering.stackexchange.com/questions/150120/definition-of-state\">Definition of \"state\"</a>)?</p>\n\n\nAssistant:",
        "golden_answer": " <p>There are multiple layers to the answer.</p>\n\n<p>On the technical level, <em>state</em> is simply the instance variables of an object, and <em>behavior</em> are the methods. Both of these can be extended to other granularity units, like a group of objects or the whole system. Should be clear from the context.</p>\n\n<p>On the semantic (\"meaning\") level, specifically for object-orientation, both have additional constraints. Not all methods constitute \"real\" behavior. Getter/setters methods are not behavior for example, because they don't really mean anything in the problem domain. <em>Behavior</em> needs to connect directly with the requirements in some form to be a real <em>behavior</em>.</p>\n\n<p>There may be additional layers of meaning. For example in the context of Domain-Driven Design, I would expect methods to have an even more stricter connection with the vocabulary of the requirements (i.e. the Ubiquitous Language).</p>\n\n<p>It's worth pointing out, that many projects settle for just the technical level, and even in the context of Domain-Driven Design many are completely ok with meaningless methods such as setters/getters in objects and still talk about \"behavior\" (or \"responsibility\") in some form. Which may confuse the issue somewhat.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <h2>Background</h2>\n\n<p>A local database contains nearly 1.3 billion unique rows. Each row is indirectly associated with a specific latitude and longitude (location). Each row has a date stamp.</p>\n\n<h2>Use Case</h2>\n\n<p>The problem is as follows:</p>\n\n<ol>\n<li>The user sets a starting/ending date, and a range of values (e.g., 100 to 105).</li>\n<li>The system gathers all the rows that match the given date, grouped by location.</li>\n<li>The system performs determines the locations that, during those dates, have a statistical likelihood of falling into the given range of values.</li>\n<li>The system displays all matching locations to the user.</li>\n</ol>\n\n<p>This is a problem of speed and scale.</p>\n\n<h2>Question</h2>\n\n<p>What is the least expensive solution architecture you can imagine that would allow such a system to retrieve results for users in under five seconds?</p>\n\n<h2>Current System</h2>\n\n<p>The environment is currently:</p>\n\n<ul>\n<li>PostgreSQL 8.4 (upgrade is possible; switching databases is not an option)</li>\n<li>R and PL/R</li>\n<li>XFS</li>\n<li><a href=\"http://www.wdvelociraptor.com/en/\" rel=\"nofollow\">WD VelociRaptor</a></li>\n<li>8 GB RAM (Corsair G.Skill; 1.3 GHz)</li>\n<li>Quad core GenuineIntel 7 (2.8 GHz)</li>\n<li>Ubuntu 10.10</li>\n</ul>\n\n<p>Hardware upgrades are acceptable.</p>\n\n<h2>Update - Database Structure</h2>\n\n<p>The billions of rows are in a table resembling:</p>\n\n<pre><code>id | taken | location_id | category | value1 | value2 | value3\n</code></pre>\n\n<ul>\n<li>id - Primary key</li>\n<li>taken - Date assigned to the row</li>\n<li>location_id - Reference to the latitude/longitude</li>\n<li>category - A description of the data</li>\n<li>value1 .. 3 - The other values the user can query</li>\n</ul>\n\n<p>The <code>taken</code> column is typically consecutive dates per <code>location_id</code>, sometimes each location has data from 1800 to 2010 (about 77,000 dates, many of them duplicated as each location has data in the same date range).</p>\n\n<p>There are seven categories and the tables are already split by category (using child tables). Each category contains ~190 million rows. In the near future, the number of rows per category will exceed a billion.</p>\n\n<p>There are approximately 20,000 locations and 70,000 cities. The locations are correlated to city by latitude and longitude. Assigning each location to a particular city means finding the city's boundaries, which is not a trivial task.</p>\n\n<h2>Ideas</h2>\n\n<p>Some ideas I have include:</p>\n\n<ul>\n<li>Find a cloud service to host the database.</li>\n<li>Create an <a href=\"http://www.youtube.com/watch?v=96dWOEa4Djs\" rel=\"nofollow\">SSD raid stripe</a> (great video).</li>\n<li>Create a table that amalgamates all the locations by city (pre-calculation).</li>\n</ul>\n\n<p>Thank you!</p>\n\n\nAssistant:",
        "golden_answer": " <p>The most important thing is to be absolutely certain where the bottleneck is now for a given number of representative requests as you cannot switch databases.</p>\n\n<p>If you do full table scans, you need appropriate indexes.</p>\n\n<p>If you wait on I/O you need more memory for caching (Jeff Atwood recently mentioned that 24 Gb systems were reachable on desktop systems).</p>\n\n<p>If you wait on CPU you need to see if your calculations can be optimized.</p>\n\n<p>This requires a pointy DBA-hat and a Operating System-hat, but is worth it to ensure you are barking up the right tree.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a specific case for this inquiry, but hopefully it can be generalized to anything else.</p>\n\n<p>I'm working with an aircraft simulator and have been tasked to implement a module whose goal is to improve the performance, if you will, of the existing module. After reading up about how to write proper requirements (and there's company procedure and all that), I'm still a little stumped about how to go about writing a requirement.</p>\n\n<p>The good news is that there's data from the aircraft being simulated, so for testing purposes there's at least some real data to compare to. And I'm aware of the FAA document AC-120-40B, but I don't believe we're trying to approach the FAA requirements since we're not trying to get FAA certification (It'd be nice to get there, but that hasn't been a stated goal)</p>\n\n<p>Still I don't think \"The [software component] shall perform better than [component] from versions prior to [version] when compared to [real data]\" would cut it as a good requirement.</p>\n\n<p>I suppose I'm concerned with what makes something objectively better. The FAA doc does have some scenarios that cover this module, but then there might be someone who goes \"but what about X scenario!?\"</p>\n\n<p>And then I feel like I'm trying to prove or disprove some substance causes cancer in a variety of situations.</p>\n\n<p>For others with this inquiry, the project does not have any existing performance requirements for the module. </p>\n\n\nAssistant:",
        "golden_answer": " <p>To start, I'd say you don't have sufficient information to write the requirements. Your task would be to gather specific details. When you're tasked to improve performance, the first thing you should probably do is measure what the current performance is and record these numbers. </p>\n\n<p>Then, you should decide together with the business what the target is. If you have this, you can write out the requirements. Here are a few examples:</p>\n\n<ul>\n<li>Component X should calculate Y within 2 seconds</li>\n<li>The module should have a throughput of at least 100 requests/second</li>\n</ul>\n\n<p>Doing this makes the subjective \"improve performance\" more objective and measurable. It also prevents later discussions where some say it's gotten worse, some say it stayed the same and others say it has improved. With real data and benchmarks you can prove the impact the changes had.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am a Software Engineer and over the past few years I have become the de-facto software project manager simply because there isn't one. So to keep our sanity in the R&amp;D/Engineering department, customers have become accustomed to coming to me with their requests. I have no experience in this realm so it is my first time acting as a project manager for software projects. I have managed other things but not software.</p>\n\n<p>So, how do you manage software projects and mark priorities? Requests come in at infrequent intervals so we very well could be working on something for someone else and then another person comes in with a \"rush\" job that needs working on. Is it easier to just say First Come, First Serve or is it the person with the most money?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I've found that the more a customer complains about how urgent their request is, unless they are also a developer in their own right, it's usually a good sign that the request isn't urgent at all.  One of my professors in college always used to tell us not to let the urgent interrupt the important.</p>\n\n<p>I usually classify requests in this order (YMMV):</p>\n\n<ol>\n<li>Issues related to a recent upgrade or migration (most important). </li>\n<li>Security fixes. </li>\n<li>Broken functionality of the existing system. </li>\n<li>Broken functionality in RC and beta features. </li>\n<li>Paid feature requests. </li>\n<li>R&amp;D feature requests from a large part of the user base. </li>\n<li>R&amp;D feature requests from only one or two users.</li>\n</ol>\n\n<p>This last one actually takes a lot more time because they tend to be those \"urgent, I need it yesterday\" requests.  In reality, the user has rarely thought completely through what they actually need or how it will support their business model.  Most often, these urgent requests, once delivered, end up being used once or twice and forgotten about.  And once forgotten, they become an endless headache of security holes and unintended consequences.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In many languages such as C, C++, and Java, the <code>main</code> method/function has a return type of <code>void</code> or <code>int</code>, but not <code>double</code> or <code>String</code>.   What might be the reasons behind that?</p>\n\n<p>I know a little bit that we can't do that because <code>main</code> is called by runtime library and it expects some syntax  like <code>int main()</code> or <code>int main(int,char**)</code> so we have to stick to that.</p>\n\n<p>So my question is:  why does <code>main</code> have the type signature that it has, and not a different one?</p>\n\n\nAssistant:",
        "golden_answer": " <p>The return value of <code>main</code> is to be passed to the operating system (<em>any</em> operating system) in a single, consistent way.  The information that the operating system needs to know is \"did the program terminate successfully, or was there an error?\"</p>\n\n<p>If this is a string, the response becomes difficult in different languages.  The internals of a Pascal string (first byte is length) and a FORTRAN string (fixed, padded to some value) and a C string (null terminated) are all different.  This would make returning a consistent value to the operating system challenging.  Assuming that this was solved, what would you do to answer the question the OS had of the program?  String comparisons are fraught with errors (\"success\" vs \"Success\"), and while the error may be more useful to a human, it is more difficult for the operating system or another program (shell) to deal with.  There also were significant differences even in the strings themselves -- <a href=\"http://en.wikipedia.org/wiki/EBCDIC\">EBCDIC</a> (with all of its code pages) vs. ASCII.</p>\n\n<p>Floats and doubles provide no additional value over the integer for communicating back data to the OS (and shell).  For the most part, neither of these parts of the computer deal with floating point numbers.  Doubles are also not enumerable making comparisons difficult.  Not being enumerable, they make reporting what the error was (assuming you have picked a particular value for success).  Again, floating points are not consistent - a float on an 8 bit machine was different than the float on a 16 bit and a 32 bit machine (and those are just the 'normal' ones - even within IBM, floating point wasn't standardized between machines by the same manufacturer until the 1980's).  And then you've got decimal vs. binary computers.  Floating point values aren't consistent and don't provide meaningful data back.</p>\n\n<p>That really leaves us with the byte and integer as options.  The convention that was established was '0' was success, and anything else was an error.  An integer gives more room than a byte for reporting the error.  It can be enumerated (return of 1 means XYZ, return of 2 means ABC, return of 3, means DEF, etc..) or used as flags (<code>0x0001</code> means this failed, <code>0x0002</code> means that failed, <code>0x0003</code> means both this and that failed).  Limiting this to just a byte could easily run out of flags (only 8), so the decision was probably to use an integer.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>In the book <a href=\"http://pragprog.com/book/tpp/the-pragmatic-programmer\" rel=\"nofollow noreferrer\">The Pragmatic Programmer</a>, the writers mention the <em><a href=\"http://pragprog.com/the-pragmatic-programmer/extracts/coincidence\" rel=\"nofollow noreferrer\">programming by coincidence</a></em> concept. It explains what it is, why it is caused, what are the dangers you may encounter and it compares with a landmine field in a war.</p>\n<blockquote>\n<p>Do you ever watch old black-and-white war movies? The weary soldier advances cautiously out of the brush. There's a clearing ahead: are there any land mines, or is it safe to cross? There aren't any indications that it's a minefieldno signs, barbed wire, or craters. The soldier pokes the ground ahead of him with his bayonet and winces, expecting an explosion. There isn't one. So he proceeds painstakingly through the field for a while, prodding and poking as he goes. Eventually, convinced that the field is safe, he straightens up and marches proudly forward, only to be blown to pieces.</p>\n</blockquote>\n<p>The soldier's initial probes for mines revealed nothing, but this was merely lucky. He was led to a false conclusionwith disastrous results.</p>\n<p>As developers, we also work in minefields. There are hundreds of traps just waiting to catch us each day. Remembering the soldier's tale, we should be wary of drawing false conclusions. We should avoid programming by coincidencerelying on luck and accidental successesin favor of programming deliberately...</p>\n<p>But I am not really satisfied on the way they describe the &quot;how to overcome it&quot; issue. Yeah, you have to think ahead before writing the code, but how to practice that? The only thing I can think is by adding features to existing Open source projects, where you must have knowledge on both the &quot;what I am doing now&quot; and the &quot;How the other pieces of code are working&quot;, and it is not that applicable when you are writing your own projects.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You don't have to think ahead, merely be very clear on what was done, and be very clear on what you are doing right now.</p>\n\n<p>Subroutines should say what they do, do what they say, and not have hidden dependencies.  Then someone calling them can more easily reason about what they will do.</p>\n\n<p>Avoid global state.  (Variables, singletons, etc.)  The more state that you have to have in your head to understand what things do, the harder it is to understand what is supposed to happen and find the edge cases.</p>\n\n<p>Write unit tests.  Unit tests are great for capturing the actual behavior of code that you just wrote, rather than the ideal behavior that you are hoping to find.</p>\n\n<p>Shorten your edit/compile/test cycle.  When you add a large chunk of code and test poorly, then the odds are that it will behave differently than you think.  Then you \"fix\" it with some random change, and you got the right answer for the moment, but have no idea how it actually happened.  You're now programming by coincidence.  But when you add 5 lines and then test, the odds that you got the right answer because it works like you think it works are much better.  I can say from experience that 5 chunks of 10 lines each, individually tested, is a very different beast than 50 lines of code tested all at once.</p>\n\n<p>Refactor ruthlessly.  Many times I've spotted a refactor that will make my code somewhat simpler but take a bunch of work that I didn't want to do.  After I began deliberately tackling those refactors as a priority, I have found that it usually pays off for itself inside of a month.  But note the key, the refactors that I focus on are ones that make day to day life simpler, and not ones that meet some arbitrary aesthetic of better or more general.  Those refactors I've learned to be much more cautious with.</p>\n\n<p>None of these things require advance planning.  But they all make it easier to understand your existing code, and therefore make it easy to implement your next little chunk in a deliberate way.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>To design an algorithm that will output the smallest integer number 'x' which contains only digits 1's and 0's such that x mod n = 0 and x > 0..... \nFor example:</p>\n\n<p>2   divides 10</p>\n\n<p>3   divides 111</p>\n\n<p>4   divides 100</p>\n\n<p>5   divides 10</p>\n\n<p>6   divides 1110</p>\n\n<p>7   divides 1001\nand so on. </p>\n\n<p>The 1's and 0's are in base 10 representation.</p>\n\n<p>I know that we can solve this using the pigeon hole principle but in this problem we are interested in the smallest number.</p>\n\n<p>I was thinking of using a DP approach similar to a subset sum problem where the set contains 1, 10, 100, 1000 and so on. I am not completely clear about how to formulate the recurrence relation for this problem. Can someone give some insight?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Just an outline of thought.</p>\n\n<p>To me, it seems bruteforce and streetsmart will beat any theoretical approach. </p>\n\n<p>Example #1</p>\n\n<p>If N contains a factor of 2 up to multiplicities K, then you can deduce that the lowest digits of X will have to contain at least K consecutive zeroes, because only consecutive zeroes in the lowest digits can provide factors of 2. And so on. Doesn't seem to involve any theories.</p>\n\n<p>Example #2</p>\n\n<p>Another streetsmart is the divisibility by 9 of decimal numbers judged by the sum of decimal digits. (More precisely it's the property of the modulo by 9. Divisibility refers to modulo giving zero. Divisibility by 3 is a simple corollary derived from the modulo by 9.) Note that by using \"modulo\", it is apply it to any numbers, say 13, by filtering the candidates of X with the requirement that <code>mod(X_candidate, 9) == mod(13, 9) == 4</code>. The requirement is necessary but not sufficient, but it helps cutting down the number of cases needed by the bruteforce.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p><a href=\"https://www.rfc-editor.org/rfc/rfc6530\" rel=\"nofollow noreferrer\">RFC6530</a> defines the necessary steps for &quot;international e-mail&quot; (i.e., especially for UTF-8 e-mail addresses). Apparently Google adopted the RFC back in 2014 (<a href=\"https://www.theregister.co.uk/2014/08/07/gmail_goes_international_with_rfc_6530_support/\" rel=\"nofollow noreferrer\">source</a>). Still, most validators I find on the web are having trouble with international e-mail addresses to say the least. One very popular contender is HTML5's integrated e-mail validator of <code>type=&quot;email&quot;</code> fields, which does NOT support international e-mail addresses at all.</p>\n<p>So my question is: are international e-mail addresses a thing or is this &quot;dead technology&quot;?</p>\n<p>We're writing test data generators and are thinking about extending our e-mail address generator but are unsure whether to include international e-mail addresses as well. We could make it a configurable option of course, still, if this technology is actually dead, we are not going to include it.</p>\n\n\nAssistant:",
        "golden_answer": " <p>I share MrSMith42's experience that anytihn outside of the most simple email has a hard time getting used in many systems that currently exist, however I disagree with their assesment. </p>\n\n<p>As it stands the RFC is not widely used, but as the internet keeps booming and non English markets keep gaining in force in the world rather than simply call the RFC \"dead technology\" I would refer to it as a \"future technology\". </p>\n\n<p>By refering to it this way I am saying that it should not be outright dismissed but rather than your systems should be set up to deal with such emails, but that for the time being you should not generate emails outside of the typical English character only emails. By doing so, you are helping those that do possess such an email and prepare yourself for a strong future when it becomes more commonplace as well.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am new to jQuery and mobile apps development. I know the features of jQuery Mobile. I want to know where and why to use it. Can I use jQuery Mobile if I am developing a native app?</p>\n\n\nAssistant:",
        "golden_answer": " <p><a href=\"http://jquerymobile.com/\">jQuery Mobile</a> is:</p>\n\n<blockquote>\n  <p>A unified, HTML5-based user interface system for all popular mobile device platforms, built on the rock-solid jQuery and jQuery UI foundation. </p>\n</blockquote>\n\n<p>Its use is to provide a consistent experience across mobile devices UI for <strong>web applications</strong>. Web applications are applications that are accessible via a web browser through the Internet. Some web applications are intended for local use but you would still need a browser to access them. </p>\n\n<p>So if your intentions are to build a native mobile application (your question wasn't very clear), jQuery Mobile is not of much use to you. But if you are developing a web application that targets mobile devices, jQuery Mobile is a valid option. If it's better than other similar options is not a question that's considered on topic here, you should decide for yourself. Personally, I like it and use it but I don't have much experience on the mobile domain, so don't take my word for it.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have seen many implementations of the Builder pattern (mainly in Java). All of them have an entity class (let's say a <code>Person</code> class), and a builder class <code>PersonBuilder</code>. The builder \"stacks\" a variety of fields and returns a <code>new Person</code> with the arguments passed. Why do we explicitly need a builder class, instead of putting all the builder methods in the <code>Person</code> class itself?</p>\n\n<p>For example:</p>\n\n<pre><code>class Person {\n\n  private String name;\n  private Integer age;\n\n  public Person() {\n  }\n\n  Person withName(String name) {\n    this.name = name;\n    return this;\n  }\n\n  Person withAge(int age) {\n    this.age = age;\n    return this;\n  }\n}\n</code></pre>\n\n<p>I can simply say <code>Person john = new Person().withName(\"John\");</code></p>\n\n<p>Why the need for a <code>PersonBuilder</code> class?</p>\n\n<p>The only benefit I see, is we can declare the <code>Person</code> fields as <code>final</code>, thus ensuring immutability.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Why use/provide a builder class:</p>\n\n<ul>\n<li>To make immutable objects &#8212; the benefit you've identified already.&nbsp; Useful if the construction takes multiple steps.&nbsp; FWIW, immutability should be seen a significant tool in our quest to write maintainable and bug free programs.</li>\n<li>If the runtime representation of the final (possibly immutable) object is optimized for reading and/or space usage, but not for update.&nbsp; String and StringBuilder are good examples here.&nbsp; Repeatedly concatenating strings is not very efficient, so the StringBuilder uses a different internal representation that is good for appending &#8212; but not as good on space usage, and not as good for reading and using as the regular String class.</li>\n<li>To clearly separate constructed objects from objects under construction.&nbsp; This approach requires a clear transition from under-construction to constructed.&nbsp; For the consumer, there is no way to confuse an under-construction object with a constructed object: the type system will enforce this.&nbsp; That means sometimes we can use this approach to \"fall into the pit of success\", as it were, and, when making abstraction for others (or ourselves) to use (like an API or a layer), this can be a very good thing.</li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've recently started a C# programming job, but I've got quite a bit of background in Haskell. </p>\n\n<p>But I understand C# is an object-orientated language, I don't want to force a round peg into a square hole.</p>\n\n<p>I read the article <a href=\"https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/exception-throwing\" rel=\"noreferrer\">Exception Throwing</a> from Microsoft which states:</p>\n\n<blockquote>\n  <p><strong>DO NOT</strong> return error codes.</p>\n</blockquote>\n\n<p>But being used to Haskell, I've been using the C# data type <a href=\"https://github.com/mcintyre321/OneOf/\" rel=\"noreferrer\"><code>OneOf</code></a>, returning the result as the \"right\" value or the error (most often an Enumeration) as the \"left\" value.</p>\n\n<p>This is much like the convention of <a href=\"http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Either.html\" rel=\"noreferrer\"><code>Either</code></a> in Haskell.</p>\n\n<p>To me, this seems safer than exceptions. In C#, ignoring exceptions does not produce a compile error, and if they are not caught they just bubble up and crash your program. This is perhaps better than ignoring an error code and producing undefined behaviour, but crashing your client's software is still not a good thing, particularly when it's performing many other important business tasks in the background.</p>\n\n<p>With <a href=\"https://github.com/mcintyre321/OneOf/\" rel=\"noreferrer\"><code>OneOf</code></a>, one has to be quite explicit about unpacking it and handling the return value and the error codes. And if one doesn't know how to handle it at that stage in the call stack, it needs to be put into the return value of the current function, so callers know an error could result.</p>\n\n<p>But this doesn't seem to be the approach Microsoft suggests.</p>\n\n<p>Is using <a href=\"https://github.com/mcintyre321/OneOf/\" rel=\"noreferrer\"><code>OneOf</code></a> instead of exceptions for handling \"ordinary\" exceptions (like File Not Found etc) a reasonable approach or is it terrible practice?</p>\n\n<hr>\n\n<p>It's worth noting that I've heard that <a href=\"https://softwareengineering.stackexchange.com/questions/189222/are-exceptions-as-control-flow-considered-a-serious-antipattern-if-so-why\">exceptions as control flow are considered a serious antipattern</a>, so if the \"exception\" is something you would normally handle without ending the program, isn't that \"control flow\" in a way? I understand there's a bit of a grey area here.</p>\n\n<p>Note I'm not using <a href=\"https://github.com/mcintyre321/OneOf/\" rel=\"noreferrer\"><code>OneOf</code></a> for things like \"Out Of Memory\", conditions I don't expect to recover from will still throw exceptions. But I feel like quite reasonable issues, like user input that doesn't parse are essentially \"control flow\" and probably shouldn't throw exceptions.</p>\n\n<hr>\n\n<p><strong>Subsequent thoughts:</strong></p>\n\n<p>From this discussion what I'm taking away currently is as follows:</p>\n\n<ol>\n<li>If you expect the immediate caller to <code>catch</code> and handle the exception most of the time and continue its work, perhaps through another path, it probably should be part of the return type. <code>Optional</code> or <code>OneOf</code> can be useful here.</li>\n<li>If you expect the immediate caller to not catch the exception most of the time, throw an exception, to save the silliness of manually passing it up the stack.</li>\n<li>If you're not sure what the immediate caller is going to do, maybe provide both, like <code>Parse</code> and <code>TryParse</code>. </li>\n</ol>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>but crashing your client's software is still not a good thing</p>\n</blockquote>\n\n<p>It most certainly is a good thing.</p>\n\n<p>You want anything that leaves the system in an undefined state to stop the system because an undefined system can do nasty things like corrupt data, format the hard drive, and send the president threatening emails. If you cannot recover and put the system back into a defined state then crashing is the responsible thing to do. It's exactly why we build systems that crash rather than quietly tear themselves apart. Now sure, we all want a stable system that never crashes but we only really want that when the system stays in a defined predictable safe state.</p>\n\n<blockquote>\n  <p>I've heard that exceptions as control flow are considered a serious antipattern</p>\n</blockquote>\n\n<p>That's absolutely true but it's often misunderstood. When they invented the exception system they were afraid they were breaking structured programming. Structured programming is why we have <code>for</code>, <code>while</code>, <code>until</code>, <code>break</code>, and <code>continue</code> when all we need, to do all of that, is <code>goto</code>.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Edsger_W._Dijkstra\" rel=\"noreferrer\">Dijkstra</a> taught us that using goto informally (that is, jumping around wherever you like) makes reading code a nightmare. When they gave us the exception system they were afraid they were reinventing goto. So they told us not to \"use it for flow control\" hoping we'd understand. Unfortunately, many of us didn't.</p>\n\n<p>Strangely, we don't often abuse exceptions to create spaghetti code as we used to with goto. The advice itself seems to have caused more trouble. </p>\n\n<p>Fundamentally exceptions are about rejecting an assumption. When you ask that a file be saved you assume that the file can and will be saved. The exception you get when it can't might be about the name being illegal, the HD being full, or because a rat has gnawed through your data cable. You can handle all those errors differently, you can handle them all the same way, or you can let them halt the system. There is a happy path in your code where your assumptions must hold true. One way or another exceptions take you off that happy path. Strictly speaking, yeah that's a kind of \"flow control\" but that's not what they were warning you about. They were talking about <a href=\"https://xkcd.com/1188/\" rel=\"noreferrer\">nonsense like this</a>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/2ip3n.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/2ip3n.png\" alt=\"enter image description here\"></a></p>\n\n<p>\"Exceptions should be exceptional\". This little tautology was born because the exception system designers need time to build stack traces. Compared to jumping around, this is slow. It eats CPU time. But if you're about to log and halt the system or at least halt the current time intensive processing before starting the next one then you have some time to kill. If people start using exceptions \"for flow control\" those assumptions about time all go out the window. So \"Exceptions should be exceptional\" was really given to us as a performance consideration. </p>\n\n<p>Far more important than that is not confusing us. How long did it take you to spot the infinite loop in the code above?</p>\n\n<blockquote>\n  <p><strong>DO NOT</strong> return error codes.</p>\n</blockquote>\n\n<p>...is fine advice when you're in a code base that doesn't typically use error codes. Why? Because no one's going to remember to save the return value and check your error codes. It's still a fine convention when you're in C.</p>\n\n<blockquote>\n  <p><code>OneOf</code></p>\n</blockquote>\n\n<p>You're using yet another convention. That's fine so long as you're setting the convention and not simply fighting another one. It's confusing to have two error conventions in the same code base. If somehow you've gotten rid of all code that uses the other convention then go ahead. </p>\n\n<p>I like the convention myself. One of the best explanations of it I found <a href=\"https://vimeo.com/97344498\" rel=\"noreferrer\">here</a><sup><a href=\"https://www.slideshare.net/ScottWlaschin/railway-oriented-programming\" rel=\"noreferrer\">*</a></sup>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/FDqde.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/FDqde.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>But much as I like it I'm still not going to mix it with the other conventions. Pick one and stick with it.<sup>1</sup></p>\n\n<p><sub>1 : By which I mean don't make me think about more than one convention at the same time.</sub></p>\n\n<hr>\n\n<blockquote>\n  <p>Subsequent thoughts:</p>\n  \n  <p>From this discussion what I'm taking away currently is as follows:</p>\n  \n  <ol>\n  <li>If you expect the immediate caller to catch and handle the exception most of the time and continue its work, perhaps through another path, it probably should be part of the return type. Optional or OneOf can be useful here.</li>\n  <li>If you expect the immediate caller to not catch the exception most of the time, throw an exception, to save the silliness of manually passing it up the stack.</li>\n  <li>If you're not sure what the immediate caller is going to do, maybe provide both, like Parse and TryParse.</li>\n  </ol>\n</blockquote>\n\n<p>It's really not this simple. One of the fundamental things you need to understand is what a zero is.</p>\n\n<p>How many days are left in May? 0 (because it's not May. It's June already).</p>\n\n<p>Exceptions are a way to reject an assumption but they are not the only way. If you use exceptions to reject the assumption you leave the happy path. But if you chose values to send down the happy path that signal that things are not as simple as was assumed then you can stay on that path so long as it can deal with those values. Sometimes 0 is already used to mean something so you have to find another value to map your assumption rejecting idea on to. You may recognize this idea from its use in good old <a href=\"https://math.stackexchange.com/a/1696269/151778\">algebra</a>. Monads can help with that but it doesn't always have to be a monad.</p>\n\n<p>For example<sup><a href=\"https://i.stack.imgur.com/TPoz7.png\" rel=\"noreferrer\">2</a></sup>:</p>\n\n<pre><code>IList&lt;int&gt; ParseAllTheInts(String s) { ... }\n</code></pre>\n\n<p>Can you think of any good reason this must be designed so that it deliberately throws anything ever? Guess what you get when no int can be parsed? I don't even need to tell you. </p>\n\n<p>That's a sign of a good name. Sorry but <a href=\"https://blogs.msdn.microsoft.com/ericlippert/2008/09/10/vexing-exceptions/\" rel=\"noreferrer\">TryParse</a> is not my idea of a good name.</p>\n\n<p>We often avoid throwing an exception on getting nothing when the answer could be more than one thing at the same time but for some reason if the answer is either one thing or nothing we get obsessed with insisting that it give us one thing or throw:</p>\n\n<pre><code>IList&lt;Point&gt; Intersection(Line a, Line b) { ... }\n</code></pre>\n\n<p>Do parallel lines really need to cause an exception here? Is it really that bad if this list will never contain more than one point?</p>\n\n<p>Maybe semantically you just can't take that. If so, it's a pity. But Maybe Monads, that don't have an arbitrary size like <code>List</code> does, will make you feel better about it.</p>\n\n<pre><code>Maybe&lt;Point&gt; Intersection(Line a, Line b) { ... }\n</code></pre>\n\n<p>The Monads are little special purpose collections that are meant to be used in specific ways that avoid needing to test them. We're supposed to find ways of dealing with them regardless of what they contain. That way the happy path stays simple. If you crack open and test every Monad you touch you're using them wrong.</p>\n\n<p>I know, it's weird. But it's a new tool (well, to us). So give it some time. Hammers make more sense when you stop using them on screws.</p>\n\n<hr>\n\n<p>If you'll indulge me, I'd like to address this comment:</p>\n\n<blockquote>\n  <p>How come none of the answers clarifies that the Either monad is not an error code, and nor is OneOf? They are fundamentally different, and the question consequently seems to be based on a misunderstanding. (Though in a modified form its still a valid question.)  <a href=\"https://softwareengineering.stackexchange.com/users/2366/konrad-rudolph\">Konrad Rudolph</a> <a href=\"https://softwareengineering.stackexchange.com/questions/372034/exceptions-error-codes-and-discriminated-unions/372036#comment816760_372034\">Jun 4 `18 at 14:08</a></p>\n</blockquote>\n\n<p>This is absolutely true. Monads are much closer to collections than exceptions, flags, or error codes. They do make fine containers for such things when used wisely.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm currently developing a web application for government land planning. The application runs mostly in the browser, using ajax to load and save data.</p>\n\n<p>I will do the initial development, and then graduate (it's a student job). After this, the rest of the team will add the occasional feature as needed. They know how to code, but they're mostly land-planning experts.</p>\n\n<p>Considering the pace at which Javascript technologies change, how can I write code that will still work 20 years from now? Specifically, which libraries, technologies, and design ideas should I use (or avoid) to future-proof my code?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Planning software for such a lifespan is difficult, because we don't know what the future holds. A bit of context: Java was published 1995, 21 years ago. XmlHttpRequest first became available as a proprietary extension for Internet Explorer 5, published 1999, 17 years ago. It took about 5 years until it became available across all major browsers. The 20 years you are trying to look ahead are just about the time rich web applications have even existed.</p>\n\n<p>Some things have certainly stayed the same since then. There has been a strong standardization effort, and most browsers conform well to the various standards involved. A web site that worked across browsers 15 years ago will still work the same, provided that it worked because it targeted the <em>common subset</em> of all browsers, not because it used workarounds for each browser.</p>\n\n<p>Other things came and went  most prominently Flash. Flash had a variety of problems that led to its demise. Most importantly, it was controlled by a single company. Instead of competition inside the Flash platform, there was competition between Flash and HTML5  and HTML5 won.</p>\n\n<p>From this history, we can gather a couple of clues:</p>\n\n<ul>\n<li><p>Keep it simple: Do what works right now, without having to use any workarounds. This behaviour will likely stay available long into the future for backwards-compatibility reasons.</p></li>\n<li><p>Avoid reliance on proprietary technologies, and prefer open standards.</p></li>\n</ul>\n\n<p>The JavaScript world today is relatively volatile with a high flux of libraries and frameworks. However, nearly none of them will matter in 20 years  the only framework I'm certain that will still be used by then is <em>Vanilla JS</em>.</p>\n\n<p>If you want to use a library or tool because it really makes development a lot easier, first make sure that it's built on today's well-supported standards. You must then download the library or tool and include it with your source code. Your code repository should include everything needed to get the system runnable. Anything external is a dependency that could break in the future. An interesting way to test this is to copy your code to a thumb drive, go to a new computer with a different operating system, disconnect it from the internet, and see whether you can get your frontend to work. As long as your project consists of plain HTML+CSS+JavaScript plus perhaps some libraries, you're likely going to pass.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Assume you have a project that (in your opinion) is mostly decently well written, modularized, etc. and you want to keep much of it's functionality. However, an essential portion of this project is not well designed, and it can't easily be fixed with minor changes. The only way to fix it is to rip out a lot of the code; it's not so bad that you need (or should) start from scratch, but it's very pervasive.</p>\n\n<p>Assume that the code is something like 20,000 lines of non-whitespace, non-single curly brace, non-comment Java, C++, C#, PHP or Ruby code. You estimate about 2000-3000 lines need to be thrown out or changed. In the case of something like Java or C#, one of your packages/namespaces will probably be entirely rewritten from scratch, and many of the references to those classes will change.</p>\n\n<p>Here's the challenging part: the code that needed to change was the GLUE within the system. Here's a very simple picture that summarizes the problem:</p>\n\n<p><img src=\"https://i.stack.imgur.com/bdhY9.png\" alt=\"enter image description here\"></p>\n\n<p>This is the situation I was in that led to this question: <a href=\"https://softwareengineering.stackexchange.com/questions/230624/what-to-do-when-youve-already-waited-too-long-between-commits?noredirect=1#comment459484_230624\">What should I do when I&#39;ve already waited too long between commits?</a> </p>\n\n<p>As you can see, it's not only the parts of the code that were doing the internal processing, but also the parts that were communicating with the other parts of the system. Both the APIs and the internal data structures were insufficient. Attempting to keep both sets of APIs working for incremental changes would have been woefully redundant.</p>\n\n<p>I, of course, branched before I did anything, but every change I made produced a product that simply did not work. In many cases I created compile errors. This led to me continually putting off commits, because I thought \"yes, I wired these pieces back together, but I still need to implement this other new interface, write this essential functionality, etc.\" This resulted in the cardinal sin of not checking anything in, a mistake I'd prefer not to repeat should I be in this situation again. This was mitigated by the fact that all my APIs were internal, except that I had to conform to the APIs of the outside world and third party modules, but my wrappers to those sections were changing.</p>\n\n<p>One obvious alternate solution would be to just accept the fact that each change will result in a broken overall product, but since you're checking into a branch, it's okay. Especially since I am the only developer working on this code and using these APIs. So maybe that's the right thing to do. Or maybe the right thing to do is try to first refactor the API to the new one, without actually changing the functionality (if possible), even if some arguments are dummy or will eventually be removed, and then incremental changes are a lot more self contained. Or maybe there's a better way entirely?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Put simply: <a href=\"http://www.investopedia.com/terms/b/boil-the-ocean.asp\" rel=\"nofollow\">Don't boil the ocean</a>.</p>\n\n<p>In other words, break off little, manageable chunks instead of trying to do the entire thing at once. In one branch. Without regular checkins.</p>\n\n<p>I've always liked <a href=\"http://www.joelonsoftware.com/articles/fog0000000348.html\" rel=\"nofollow\">this article at Joel on Software</a>. It gives very good concrete examples about the kind of small changes that can be made against a code base to make it cleaner little by little.</p>\n\n<p>Decide on a conceptually similar chunk of changes, and make a branch for that. An example might be moving all of your SQL code into classes. In that branch, your workflow would look like this:</p>\n\n<ul>\n<li>Remove one SQL statement</li>\n<li>Run your tests</li>\n<li>Check in your code</li>\n<li>Repeat</li>\n</ul>\n\n<p>Once you've finished that chunk of changes, merge it into your master branch, and start a new chunk.</p>\n\n<p>This is assuming you have tests. If not, you should create them before you start (including unit, regression, and integration tests). Again, not all at once. If you have a function you want to refactor that you don't have tests for, write the tests, refactor your code and run the tests until they pass. This is exactly what these tests are built for. Make sure you're making use of them.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Context: I recently found out about <a href=\"https://semver.org/\" rel=\"noreferrer\">Semantic Versioning</a>, and am trying to determine how to best use it practically for my own projects.</p>\n\n<p>Given that semver takes major changes, minor changes, and patches into account for versioning, when should a commit not be tagged with an updated version? It seems to me that every change would fit into one of these categories, and so every change should be versioned, but when I look at various popular projects on GitHub this doesn't seem to be the way things are done (just looking at the fact that large projects have tens of thousands of commits, with only hundreds of tags).</p>\n\n\nAssistant:",
        "golden_answer": " <p>SemVer concerns versioning <em>releases</em>, not <em>commits</em>. If your version control model happens to require that every commit to master be a release, then yes, every commit will need to be tagged according to the degree of the change.</p>\n\n<p>Generally, though, projects develop a mostly stable product on master and tag the releases they deem worthy of support. When they do so, they will tag according to their versioning scheme, which doesn't necessarily have to be SemVer in particular. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am currently in the process of trying to master C#, so I am reading <strong>Adaptive Code via C#</strong> by <em>Gary McLean Hall</em>.</p>\n<p>He writes about patterns and anti-patterns. In the implementations versus interfaces part he writes the following:</p>\n<blockquote>\n<p>Developers who are new to the concept of programming to interfaces often have difficulty letting go of what is behind the interface.</p>\n<p>At compile time, any client of an interface should have no idea which implementation of the interface it is using. Such knowledge can lead to incorrect assumptions that couple the client to a specific implementation of the interface.</p>\n<p>Imagine the common example in which a class needs to save a record in persistent storage. To do so, it rightly delegates to an interface, which hides the details of the persistent storage mechanism used. However, it would not be right to make any assumptions about which implementation of the interface is being used at run time. For example, <strong>casting the interface reference to any implementation is <em>always</em> a bad idea.</strong></p>\n</blockquote>\n<p>It might be the language barrier, or my lack of experience, but I don't quite understand what that means. Here is what I understand:</p>\n<p>I have a free time fun project to practice C#. There I have a class:</p>\n<pre><code>public class SomeClass...\n</code></pre>\n<p>This class is used in a lot of places. While learning C#, I read that it is better to abstract with an interface, so I made the following</p>\n<pre><code>public interface ISomeClass &lt;- Here I made a &quot;contract&quot; of all the public methods and properties SomeClass needs to have.\n\npublic class SomeClass : ISomeClass &lt;- Same as before. All implementation here.\n</code></pre>\n<p>So I went into all some class references and replaced them with ISomeClass.</p>\n<p>Except in the construction, where I wrote:</p>\n<pre><code>ISomeClass myClass = new SomeClass();\n</code></pre>\n<p>Am I understanding correctly that this is wrong? If yes, why so, and what should I do instead?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Abstracting your class into an interface is something you should consider if and only if you intend on writing other implementations of said interface or the strong possibility of doing so in the future exists.  </p>\n\n<p>So perhaps <code>SomeClass</code> and <code>ISomeClass</code> is a bad example, because it would be like having a <code>OracleObjectSerializer</code> class and a <code>IOracleObjectSerializer</code> interface.</p>\n\n<p>A more accurate example would be something like <code>OracleObjectSerializer</code> and a <code>IObjectSerializer</code>.  The only place in your program where you care what implementation to use is when the instance is created.  Sometimes this is further decoupled by using a factory pattern.  </p>\n\n<p>Everywhere else in your program should use <code>IObjectSerializer</code> not caring how it works.  Lets suppose for a second now that you also have a <code>SQLServerObjectSerializer</code> implementation in addition to <code>OracleObjectSerializer</code>.  Now suppose you need to set some special property to set and that method is only present in OracleObjectSerializer and not SQLServerObjectSerializer.  </p>\n\n<p>There are two ways to go about it: the incorrect way and the <a href=\"https://en.wikipedia.org/wiki/Liskov_substitution_principle\" rel=\"noreferrer\">Liskov substitution principle</a> approach.   </p>\n\n<h2>The incorrect way</h2>\n\n<p>The incorrect way, and the very instance referred to in your book, would be to take an instance of <code>IObjectSerializer</code> and cast it to <code>OracleObjectSerializer</code> and then call the method <code>setProperty</code> available only on <code>OracleObjectSerializer</code>.  This is bad because <em>even though</em> you may know an instance to be an <code>OracleObjectSerializer</code>, you're introducing yet another point in your program where you care to know what implementation it is.  When that implementation changes, and presumably it will sooner or later if you have multiple implementations, best case scenario, you will need to find all these places and make the correct adjustments.  Worst case scenario, you cast a <code>IObjectSerializer</code> instance to a <code>OracleObjectSerializer</code> and you receive a runtime failure in production.</p>\n\n<h2>Liskov Substitution Principle approach</h2>\n\n<p>Liskov said that you should never need methods like <code>setProperty</code> in the implementation class as in the case of my <code>OracleObjectSerializer</code> if done properly.  If you abstract a class <code>OracleObjectSerializer</code> to <code>IObjectSerializer</code>, you should encompass all the methods necessary to use that class, and if you can't, then something is wrong with your abstraction (trying to make a <code>Dog</code> class work as a <code>IPerson</code> implementation for instance).  </p>\n\n<p>The correct approach would be to provide a <code>setProperty</code> method to <code>IObjectSerializer</code>.  Similar methods in <code>SQLServerObjectSerializer</code> would ideally work through this <code>setProperty</code> method.  Better still, you standardize property names through an <code>Enum</code> where each implementation translates that enum to the equivalent for its own database terminology.</p>\n\n<p>Put simply, using an <code>ISomeClass</code> is only half of it. You should never need to cast it outside the method that is responsible for its creation.  To do so is almost certainly a serious design mistake.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm using event sourcing in an application and constantly find a problem for which I do not find a good solution.</p>\n<p>In this scenario we have an application for a hair stylist. We have a <code>CustomerAggregate</code> which performs all actions for a customer. But some times we need to find a range of specific customers, and for that we use projections. Let's say that we need to find all customers with <strong>red hair</strong>. For that scenario we have a projection (which is a flat database table), which may look something like this:</p>\n<pre><code>CustomerId   | HairColor    | Name\n1              Red            Alice\n2              Blue           Bob\n3              Red            Cecilia\n</code></pre>\n<p>The aggregate has a method called <code>ChangeHairColor(newColor)</code>, which will apply an event called <code>HairColorChanged</code>. When the event <code>HairColorChanged</code> occurs the projection is updated. This works fine. We can query the projection and find all customers with a red hair color if we for example need to make a newsletter targeting that audience.</p>\n<p>My problem occurs when my domain logic is depending on a projection. Writing to the projection is async and occurs outside of my domain logic. Let's consider this scenario:</p>\n<pre><code>1. Get all customers with red hair.\n2. Dye hair to blue for all those customers.\n3. Get all customers with blue hair.\n4. Send newsletter to all customers with blue hair telling them what a nice color they have!\n</code></pre>\n<p>When we have iterated through step 2 the update of the projection is async and may not be completed before step 3 occurs. Therefore we may not get the correct customers in step 3. We have a race condition.</p>\n<p>How do I properly address this issue? As I understand it a projection should be separated from the domain logic. But in this case the domain logic is dependant on the projection. Should I therefore include updating the projection in my <code>CustomerAggregate</code>?</p>\n\n\nAssistant:",
        "golden_answer": " <p>An observation: &quot;simplified&quot; problems are rarely a good idea in DDD, because the details of the problems tend to matter, and contrived examples rarely have the details fleshed out.</p>\n<blockquote>\n<p>How do I properly address this issue?</p>\n</blockquote>\n<p>For the problem as described, you would probably do something like this: at step #1, you would capture a snapshot of some pool of your customers that are going to be participants in this process, and then from that point forward you would handle each of those customers in parallel, performing the update, sending off the email, and so on.  The &quot;projection&quot; that describes their hair color would be updated asynchronously, until eventually it was again consistent with the information in your book of record.</p>\n<p>If the process itself were important, then you would have a stream of events for tracking it, and projections off of that stream so that you could see whether the process was complete, what works is outstanding, and so on.</p>\n<p>But this report, like all of the others, is going to be a snapshot of information that is not necessarily synchronized with what information is &quot;live&quot;.  For instance, you might be looking at a report that shows you our best guess at the progress as of close of business the previous day.</p>\n<p>In any distributed system, reports are going to be stale - the human reader is probably sitting a nanosecond from the display, the report needs time to copy across the network, and so on.  Part of what we need to work out, in our designs, is how much &quot;stale&quot; the business can tolerate, and whether or not we can mitigate the mistakes that are made when we process stale data.</p>\n<p>This isn't specific to event sourcing, of course.  We have exactly the same sorts of problems when our book of record is a relational database.  The big difference between the two cases is that relational databases have general purpose locking strategies available that allows us to coordinate writes in a way that may not be available in our event store (aka locking <em>multiple</em> streams to make a coordinated change).</p>\n<hr />\n<p>A useful reference is Pat Helland's paper <a href=\"https://blog.acolyer.org/2016/09/13/data-on-the-outside-versus-data-on-the-inside/\" rel=\"nofollow noreferrer\">Data on the Outside vs Data on the Inside</a>.  Another to review would be Udi Dahan's <a href=\"https://udidahan.com/2010/08/31/race-conditions-dont-exist/\" rel=\"nofollow noreferrer\">Race Conditions Don't Exist</a>.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I seem to recall that there is a specific term for an accessor method that returns a Boolean value but it escapes me. For example: typical methods such as:</p>\n\n<pre><code>class Example {\n    bool isDirty();\n    bool hasChildren();\n    bool isValid(SomeType obj);\n};\n</code></pre>\n\n<p>I will also settle for such a term as applied to a non-member functions.</p>\n\n\nAssistant:",
        "golden_answer": " <p>A function from some type <code>T</code> to <code>Boolean</code> is usually called a <em>predicate</em>, and if you want to make clear that it is a method of an object, i.e. that it takes the implicit <code>this</code> argument in addition to its other arguments, then you could call it a <em>predicate method</em>. If it takes no other arguments except the implicit <code>this</code> argument, then you can call it a <em>predicate property</em>.</p>\n\n<p>See for example <code>Predicate&lt;T&gt;</code> in .NET and e.g. <code>javax.sql.rowset.Predicate</code> or <code>com.google.common.base.Predicate</code> in Java.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I just read an Joel's <a href=\"http://www.joelonsoftware.com/articles/APIWar.html\" rel=\"nofollow\">article about Microsoft's breaking change</a> (non-backwards compatibility) with dot net's introduction. It is interesting and explicitly reflected the condition during that time. But now almost 10 years has passed.</p>\n\n<h2>The breaking change</h2>\n\n<p>It is mainly on how bad is Microsoft introducing non-backwards compatibility development tools, such as dot net, instead of improving the already-widely used asp classic or VB6. As much have known, dot net is not natively embedded in windows XP (yes in vista or 7), so in order to use the .net apps, you need to install the .net framework of over 300mb (it's big that day).</p>\n\n<p>However, as we see that nowadays many business use .net as their main development tools, with asp.net or mvc as their web-based applications. C# nowadays be one of tops programming languages (the most questions in stackoverflow). The more interesing part is, win32api still alive even there is newer technology out there (and still widely used).</p>\n\n<p>Imagine if microsoft does not introduce the breaking change, there will many corporates still uses asp classic or vb-based applications (there still is, but not that much). There are many corporates use additional services such as azure or sharepoint (beside how expensive is it).</p>\n\n<p>Please note that I also know there are many flagships applications (maybe adobe's and blizzard's) still use C-based or older language and not porting to newer high-level language.</p>\n\n<h2>The question</h2>\n\n<p>How can Microsoft persuade the users to migrate their old applications into dot net? As we have known it is very hard and give no immediate value when rewrite the applications (netscape story), and it is very risky. I am more interested in Microsoft's way and not opinion such as \"because dot net is OOP, or dot net is dll-embedable, etc\".</p>\n\n<p>This question may be constructive, as the technology is vastly changes over times lately. As we can see, Microsoft changes Asp.Net webform to MVC, winform is legacy now, it is starting to change to use windows store rather than basic-installment, touchscreen and later on we will have see-through applications such as google class. And that will be breaking changes.</p>\n\n<p>We will need to account portability as an issue nowadays. We will need other than just mere technology choice, but also migration plans. Even maybe as critical as we might need multiplatform language compiler, as approached by <a href=\"http://www.joelonsoftware.com/items/2006/09/01b.html\" rel=\"nofollow\">Joel's Wasabi</a>. (hey, I read his articles too much!)</p>\n\n\nAssistant:",
        "golden_answer": " <p>Aside from the technological breakthroughs, Microsoft Marketed the Dot Net framework by making it so easy for the developers to use that it became their first choice when being asked to develop new applications. Just look at Microsoft loves to spoil developers with Visual Studio. Microsoft sold the idea to developers first then they sold it to the business. Once the businesses saw that it made developers more productive, they started to make more use of it. Though it wasn't a field of roses as there are people who shun Microsoft after experiencing breaking changes every now and then.</p>\n\n<p>Ok, so back to the way of the \"Breaking Changes\"</p>\n\n<p>Why did Microsoft invest in the .NET Framework, because after seeing the success of java with the JVM, they perceived that was where the market was going, and they want a piece of that market. And thus, .NET was born. Microsoft is making these breaking changes to somehow force the market to move forward and to keep its market from stagnating. Their competitors are steadily improving as well, and to keep themselves relevant, they have to make decisions. These breaking changes are a result of those decisions. If MS ignored the java threat back then and didn't make .NET, M$ might've spiraled into oblivion long ago. And these changes continue to happen, just look at the metro interface. If M$ didn't do that, their tablet market share would never be able to recover from the onslaught of ipads and android tablets.</p>\n\n<p>Lastly, migration plans and a language to run across all platforms. Microsoft's solution to that is the .NET Framework. Though it is limited to Windows devices only. But as you can see, they borrowed the idea from java, compile once then run everywhere. Their big difference is how they handle backwards compatibility. .NET allows you to keep multiple version of it to keep older applications from being broken. And Microsoft will keep on supporting older .NET framework versions to a certain extent in newer platforms to keep this backward compatibility.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Considering that Spring framework can manage pretty everything related to object creation (life cycle, object scope ..), is it longer necessary to use singleton pattern in an application using the framework, or are there still situations when we need to use Singleton pattern instead of singleton instance created by Spring? </p>\n\n<p>One of the problem of using the singleton pattern is global state. Is the problem avoided using the Spring-defined singleton scope?</p>\n\n\nAssistant:",
        "golden_answer": " <p>If you are not familiar with JavaScript patterns, I can tell you a lot of large applications and libraries are using <a href=\"https://addyosmani.com/resources/essentialjsdesignpatterns/book/#revealingmodulepatternjavascript\" rel=\"noreferrer\">Revealing Module Pattern</a>, but there are many other patterns you can use depending to your needs.</p>\n\n<p>The Revealing Module Pattern though should give you a nice way to split large files and logically organise them; However when you are working with any design patterns in JavaScript, be aware that <em>this</em> can become very confusing. Try to use <em>this</em>, <em>new</em>, <em>prototype</em>, <code>.call()</code> and <code>.apply()</code> wisely.</p>\n\n<p>While working on large projects, these can be useful also:</p>\n\n<ul>\n<li>If possible, switch to TypeScript or ES6.</li>\n<li>Write <em>Modular</em> code. There are various ways and third-party libraries, but any of them is better than nothing.</li>\n<li>Use a <em>Task Runner/Build System</em> to automate tasks.</li>\n<li>Read about <em>Design Patterns</em>. <a href=\"https://addyosmani.com/resources/essentialjsdesignpatterns/book/\" rel=\"noreferrer\">This</a> could be a good start. As I said above, the <a href=\"https://addyosmani.com/resources/essentialjsdesignpatterns/book/#revealingmodulepatternjavascript\" rel=\"noreferrer\">Revealing Module Pattern</a> is very useful, specially if you think you need time to master all the popular patterns.</li>\n<li>Write <em>Unit Tests</em>. Working with a dynamic language can be more challenging. Testing the crucial parts of your application can save a lot of time.</li>\n<li>Use an <em>IDE</em> or <em>Text Editor</em> that can actually help you with both writing code and catching bugs. WebStorm is a good choice. Sublime Text too.</li>\n<li>If your IDE doesn't offer a debugger, try to master your favorite web browser's debugger.</li>\n<li>Use libraries. Depending on the nature of project, try to employ the best third-party code you can find. If you are writing a web application, have a look at <em>Angular</em>, <em>React</em> and the good-old <em>backbone.js</em>. If you are writing a Node.js application, then take your time to search in <em>NPM</em> repository. You will be surprised how many packeges are already doing what you were just about to do.</li>\n<li>Even if you are the only person who's working on the project, still use a version control system like <em>Git</em> and follow a <em>Coding Standard</em> that is not too strict and opinionated but still provides a good guide line that your team-mates would be also happy to follow.</li>\n<li>Even if you opt for TypeScript or ES6, still understanding JavaScript's class-less OOP, the <em>Prototypal OOP</em> can be useful, specially while debuging. </li>\n</ul>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I was reading a text. It said,</p>\n\n<pre><code>\"Information presentation must be compatible with the response time needs of \nsystems. The response time should be short enough that the information  does not \nlose its freshness and value but it should be long enough to reduce volume (and \ncosts) and reveal important trends that signal the need for action\"\n</code></pre>\n\n<p>What does volume mean in it? Please help out. Thanks</p>\n\n\nAssistant:",
        "golden_answer": " <p>Oded is right, but in the case of databases, this can mean not just the amount of data that you return, but also the number of queries or requests it takes to get there.</p>\n\n<p>This text appears to be talking about performance of a chatty information dashboard. The tradeoff is always \"OK, do I grab a bunch of data up front and save making lots of requests, or do I get the data up as quickly as possible by using small requests that return limited portions of the dashboard\".</p>\n\n<p>Your needs will vary, depending on the application.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm looking for good practices or any advice regarding <strong>file access transaction mechanisms</strong>. We will have multiple instances of an application spread over a redundant network (cloud) watching a directory on a 100% available NAS. I'm also looking for any alternative architecture that may be more appropriate.</p>\n\n<ul>\n<li>We will have thousands of mobile devices accessing the system every minute. The devices produce a binary file (picture for example) that is sent to a RESTful service without transformation. The device must do the job quickly to preserve battery.</li>\n<li>Since RESTful service must take the input as fast as possible, the binary file is currently written directly as a file in a 100% availability NAS.</li>\n<li>If an error occurs (file not being written correctly), the client is notified and can try again.</li>\n</ul>\n\n<p>We must build a worker service that will <em>watch</em> the file folder for new files to process them. The worker will convert them to another format then move them to another folder on the NAS. We will use as many instances as possible to handle load.</p>\n\n<p>My main concern is about file access. The RESTful service is writing to a temporary file with an extension that the worker service is ignoring (.tmp), then after the last byte is written, the file is renamed. The process is quick, but we can't afford the case where 2 or more worker services access the same file at the same time.</p>\n\n<p>We need some transaction mechanism or any other entreprise architecture pattern.</p>\n\n<p><strong>Is there any kind of file system transaction mechanism that scales?</strong></p>\n\n\nAssistant:",
        "golden_answer": " <p>A database for example would handle this situation in a transactional and  almost any db excepting MSAccess and SQLite will handle this quicker, more reliably and more efficiently than file access.</p>\n\n<p>Another possibility is to use one of the many available Queue Managers (RabbitMQ,WebsphereMQ etc.) which would also ease any scheduling and load balancing problems you have.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have started learning about C# and I come to what is called 'Automatic memory management' or 'Garbage collectors' and I'm wondering if Java contains something like this as well? and if it does, does it do that as effective as C# when it comes to windows desktop application and web applications?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Java is a garbage collected language though the collection model is different than C#'s. Effectiveness would vary considerably depending on the structure of the program but Java does run just fine on Windows and the Web.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm working with ASP.NET Web User Control (WUC) and I got to this question:</p>\n\n<p>I'm creating a WUC to show an object's data. This object is already loaded when I call that WUC. I'm wondering what would be better: give the WUC the full object or only the necessary attributes?</p>\n\n\nAssistant:",
        "golden_answer": " <p>If the UC is responsible for displaying the entire object, and only <em>that</em> object (not other objects) then it should be passed an instance of it, or a base class/interface of it.</p>\n\n<p>If the UC is meant to be more general, though, or only displays a couple properties, you might just expose members for those specific properties.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am developing a system that is designed for multiple forms of interfacing. There is a website, but that is connected through an SDK, as well as an HTTP query interface to access data. But to improve speed and quality, I was thinking of creating a system inside IIS that get any message sent to the server, any response, but still let IIS manage SSL and normal socket connections. </p>\n\n<p>Is there a way to host my project in IIS without ASP or any other kind of script with extra behavioral events?</p>\n\n\nAssistant:",
        "golden_answer": " <p>By leveraging the <a href=\"http://msdn.microsoft.com/en-us/netframework/aa663324\">Windows Communications Foundation</a> framework, you can create services over a number of different network protocols.  This includes HTTP, HTTPS, MSMQ, and even TCP/IP sockets.  In addition to these, it also support Named Pipes for connections between two processes on the same machine.</p>\n\n<p>IIS can host applications developed for WCF, even if they aren't HTTP or HTTPS based.</p>\n\n<p>For more in-depth information about the different protocols that WCF supports, and information about the relative strengths and weaknesses of each, <a href=\"http://msdn.microsoft.com/en-us/library/ms733769.aspx\">MSDN</a> has good information about this.</p>\n\n<p>While many people have argued that WCF is complicated to configure, it does an excellent job of allowing you to focus on writing code at a fairly high level of abstraction without worrying about the actual transport layer implementation details.  I know of a number of projects that have made excellent use of the MSMQ transport in particular in order to enable durable transports that survive intermittent connectivity.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Reusability is a feature of good <a href=\"http://en.wikipedia.org/wiki/Software_design\">software design</a>.</p>\n\n<p>Is reusability an acceptable <a href=\"http://en.wikipedia.org/wiki/Gloss\">gloss</a> (\"brief notation of the meaning\") for good software design? Why?</p>\n\n\nAssistant:",
        "golden_answer": " <h2>No.</h2>\n<p><strong>Reuse</strong> is an <em>indicator</em> of good design.  It indicates that the <a href=\"http://en.wikipedia.org/wiki/Coupling_(computer_programming)\" rel=\"noreferrer\">coupling</a> of the system is loose enough and the <a href=\"http://en.wikipedia.org/wiki/Cohesion_(computer_science)\" rel=\"noreferrer\">cohesion</a> of a particular unit is high enough to facilitate reuse without running into dependency issues or having to rewrite most of the code.</p>\n<p><strong>Reusability</strong> is largely an illusion.  It is verifiably impossible to measure the &quot;reusability&quot; of a unit without knowing in advance where or how it is going to be used.  Many developers will <em>try</em> to design &quot;reusable&quot; components and often find out later that the specific aspects they tried to make &quot;flexible&quot; are exactly the ones which <em>didn't</em> need to be.</p>\n<p>I would use a different &quot;gloss&quot;: <strong>Testability.</strong></p>\n<p>Now I am not an advocate of TDD, nor do I feel the need to unit test anything and everything.  But writing tests for a component will give you a very good idea of its coupling/cohesion characteristics, and very quickly.  If it depends on abstractions, then that is loose coupling; you will find it easy to mock out the dependencies and that suggests a good design.  If it has a clear purpose (see also <a href=\"http://en.wikipedia.org/wiki/Single_responsibility_principle\" rel=\"noreferrer\">Single Responsibility Principle</a>) then its behaviour will be relatively intuitive, you will find it easy to figure out <em>what</em> to test, which again, suggests a good design.</p>\n<p>That does not, of course, <em>guarantee</em> a good design; the actual implementation or even the whole architecture may be entirely inappropriate for its stated purpose.  But at least it tells you that you are not working with spaghetti code or God Objects.</p>\n<p>Please, do not try to make wild guesses as to the &quot;reusability&quot; of a component, especially not to use as evidence of &quot;good design&quot;.  That is something you can only establish in hindsight, once it actually gets reused, and by then the design may have changed significantly.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <h1>Introduction</h1>\n\n<p>I am implementing a abstract Java class of a processing framework*. By implementing the function <code>execute</code>, I am able to add business logical functionality. I would like to add logging at the start and end of every implementation of every of my execute functions. Also in between some logging, if specific things are done. However, I would like to make this in a uniform manner. My thought was to inherit the framework class to an own new class which implements the logging and provides some new <code>executeWithLogging</code> functions, which are wrapping the logging around the specific parts. I am not sure if that is the best idea and whether I am able to use a design pattern that would make the whole endeavor elegant. How would I go on about the whole thing?</p>\n\n<h1>Challenges (please consider these!)</h1>\n\n<ol>\n<li>One challenge in my case is that the original class has only one <code>execute</code> function, however, I'd need logging around multiple parts.</li>\n<li>The second thing is: Using a decorator pattern (was my first idea as well) does not quite work, if I am using also a <code>execute</code>, because the <code>super.execute()</code>-function would have to be called in the first line of my new <code>execute()</code>, isn't it?</li>\n<li>There would be at least 4 classes involved: <code>BaseFunction</code> from the framework, <code>LoggingFunction extends BaseFunction</code> from me, <code>MyBusinessFunction extends LoggingFunction</code> from me, <code>MyBusinessClass</code> which instanciates <code>MyBusinessFunction</code>.</li>\n<li>Not only do I need logging at the beginning and end of <code>execute</code>, but also in the middle.</li>\n<li>The \"logging\" is not just simple Java logging, but actually logging to a database. This does not change anything about the principles, but demonstrates that the logging might be more than just one line of code.</li>\n</ol>\n\n<hr>\n\n<p>Maybe an example how I'd do the whole thing would be nice, to get me going.</p>\n\n<p>|* A Storm Trident Function, similar to a Storm bolt, but this is not particularly important. </p>\n\n\nAssistant:",
        "golden_answer": " <p>There are generally several possible ways to perform logging around a certain execution. First of all, it is good that you want to separate this, as logging is a typical example for <a href=\"https://en.wikipedia.org/wiki/Separation_of_concerns\" rel=\"noreferrer\">Separation of Concerns</a>. It truly doesn't make much sense to add logging directly into your business logic.</p>\n\n<p>As for possible design patterns, here is a (non-conclusive) list from the top of my head:</p>\n\n<ul>\n<li><p><a href=\"https://en.wikipedia.org/wiki/Decorator_pattern\" rel=\"noreferrer\">Decorator pattern</a>: A well-known design pattern, whereby you basically wrap the non-logging class into another class of the same interface and the wrapper does the logging before and/or after calling the wrapped class.</p></li>\n<li><p><a href=\"https://en.wikipedia.org/wiki/Function_composition\" rel=\"noreferrer\">Function composition</a>: In a functional programming language, you can simply compose your function with a logging function. This is similar to the decorator pattern in OO languages, but not a preferred way really, since the composed logging function would be based on a side-effecting implementation.</p></li>\n<li><p><a href=\"https://en.wikipedia.org/wiki/Monad_(functional_programming)\" rel=\"noreferrer\">Monads</a>: Monads are also from the functional programming world and allow you to decouple your execution and logging. This basically means you aggregate necessary logging messages and executions methods, but do not yet execute either. You can then process the monad in order to perform log-writing and/or actual execution of the business logic.</p></li>\n<li><p><a href=\"https://en.wikipedia.org/wiki/Aspect-oriented_programming\" rel=\"noreferrer\">Aspect-oriented programming</a>: More sophisticated approach, which achieves complete separation, as the class that does the non-logging behavior never directly interacts with the logging.</p></li>\n<li><p>Relaying: Other standard design patterns may be suitable as well, for example, a Facade could serve as the logged entrypoint, before forwarding the call to another class which performs the business logic part. This can be applied to different abstraction levels as well. For example, you could log requests made to an externally reachable service URL, before relaying to an internal URL for actual non-logged processing of requests.</p></li>\n</ul>\n\n<p>As for your added requirement that you need to perform logging \"in the middle\" - that's probably pointing to a strange design. Why is it, that your execute is doing so much, that something like a \"middle\" of its execution is even remotely of interest? If there is indeed such a lot of stuff going on, then why not bunch it up into stages/phases/what-have-you? You could in theory achieve logging in the middle with AOP I guess, but I'd still argue that a design change seems to be much more appropriate.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The title really says it all, I want to have all the readable memory of another process in a buffer. I understand that I will have to use <code>ReadProcessMemory()</code>, but If I'm correct I can't just use one call to <code>ReadProcessMemory()</code> starting from address 0 for example, because there would be addresses that are non readable in the range.</p>\n<p>I have one idea, which I believe should work, I would like to know if this is an actual solution and if there are any better solutions.</p>\n<p>My idea would be to start from address 0 and use <code>VirtualQueryEx</code> to check if the current range is readable, if yes I read it, and in both cases I jump forward the size of the range, and repeat until <code>VirtualQueryEx</code> returns that my address is too high.</p>\n<p>Would this actually get all the memory? Is there a better/different method?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes, as you have surmised, you can start from address 0, use <code>VirtualQueryEx</code> to get information about that whole region of memory, including the start and end address of the region. Then you can go straight to the end of that region, which is the beginning of the next region, and use <code>VirtualQueryEx</code> to get information about <em>that</em> region. Repeat until you get to the end of the address space.</p>\n<p>As you go along, you can use <code>ReadProcessMemory</code> to read the data. Note that there are many types of memory regions; only &quot;committed&quot; regions are actually associated with memory. Reading from uncommitted memory regions will fail.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>By first, i mean i have read articles which puts project planning as the first phase of the sdlc.</p>\n\n<p>In my opinion it should come after the requirement analysis and specification, because <strong>if you dont know the reqirements of a project, how can you plan about it?</strong></p>\n\n<p>it does not make any sense to me.</p>\n\n<p>you're planning for a project whose requirements you don't know, it simply stupid!</p>\n\n\nAssistant:",
        "golden_answer": " <p>Both.</p>\n\n<p>The idea of \"planning\" as a step you do once in your project and never afterwards is pretty unrealistic. Planning is something you will do before requirements analysis (for exactly this step), you will do it afterwards, you will do it again whenever you reach a certain milestone in your projects and maybe between milestones.</p>\n\n<p>Don't take models of the SDLC too literal, they are <strong>models</strong>, which are approximations of reality at best, not reality.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Let's say you have created a programming language, maybe because there was a problem which was unfeasible to try to solve using existing languages, what would you do to market it (and so on) in order to make it gain attention in the software engineering (or academic etc. depending on the purpose of the language) industry?</p>\n\n\nAssistant:",
        "golden_answer": " <p><strong>Use it.</strong></p>\n\n<p>Use it as your primary development tool. When you run into its failings, address them, because you can afford to change basically whatever you want about it before it becomes popular. The language will improve and solidify over time. As you produce more and more great applications <em>written</em> in your language, people will take notice of it and begin to take it seriously as a tool, and they <em>might</em> start using it. That's step one.</p>\n\n<p>Step two is to keep using it, and make it as easy as possible for the people who might <em>want</em> to use it. That means top-notch documentation and examples, actively promoting the language to everyone you can, and getting your <em>users</em> to actively promote it by making it good enough to use as a primary tool.</p>\n\n<p>But it all starts with using it yourself for real tasks. If you never get to that point, neither will anyone else.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>This is more of an OOD problem and I have no specific code to post here. Can the same class violate the SRP in one context and be SRP compliant in other without changing a single line of code?</p>\n\n<p>In other words, can there be a situation that within the frameworks of the former requirements the class is SRP compliant and then, when requirements change, it is no longer compliant.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Good question.</p>\n\n<p>First, the easy one: Different contexts, as in the single responsibility of a class, or of a method, or of a component, or microservice, or what-have-you. In those terms, the SRP is clearly context dependent, though you are talking about different units in each context.</p>\n\n<p>Your question of fixing the unit whilst changing the context is more interesting of course.</p>\n\n<p>However, I fail to see a way in which the SRP is violated by that. The responsibility itself will certainly change though. For example, a class could be a DTO-POJO for one framework and then you switch frameworks and it has to be a JPA entity or something. It still has a single responsibility though and you would have changed the code.</p>\n\n<p>Having a SRP compliance difference without changing the code, however, would require your responsibilty to be directly dependent on the requirement. However, this still should not lead to a compliance problem on change. When you think about it, the old requirement is tightly coupled to the responsibility of your unit, then changing the requirement means that your code has to be changed as well or it will no longer satisfy the new requirement. Given that your code is plain and simply wrong at that time, discussing the merit of its SRP compliance becomes sort of void.</p>\n\n<p>In short: making changes to frameworks/requirements is highly likely to void the necessity of your responsiblity, but the unchanged unit still only has its single responsibility. However, that responsibility may no longer be deemed correct or necessary.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am a QA/Test manager in my organization and until today I verified the quality of the software (tests written and executed and bugs fixed). Who will verify this in Scrum? How do I know that the team wrote and executed all the right tests? On the other hand I'm afraid that if I continue to do the verification the team will not feel empowered enough. But I need some verification process that \"Done\" is indeed \"Done\". What do you suggest?</p>\n\n\nAssistant:",
        "golden_answer": " <p>One major idea in Scrum is that the team should agree on a \"definition of done\". Ideally, this is something like a set of objective criteria that anyone can verify by going through a checklist. </p>\n\n<p>But to reduce the chance of something slipping through, it makes perfect sense to have a rule that verifying \"done\" most be performed by someone other than the person who implemented an item - or a designated QA guy like you (but that risks making you a bottleneck).</p>\n\n<p>If in doubt, discuss is with the team and the Scrum Master and decide together.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a very simple question that baffles me for a long time. I am dealing with networks and databases so a lot of data I am dealing with are 32-bit and 64-bit counters (unsigned), 32-bit and 64-bit identification ids (also do not have meaningful mapping for sign). I am practically never deal with any real word matter that could be expressed as a negative number. </p>\n\n<p>Me and my co-workers routinely use unsigned types like <code>uint32_t</code> and <code>uint64_t</code> for these matters and because it happens so often we also use them for array indexes and other common integer uses.</p>\n\n<p>At the same time various coding guides I am reading (e.g. Google) discourage use of unsigned integer types, and as far as I know neither Java nor Scala have unsigned integer types.</p>\n\n<p>So, I could not figure out what is the right thing to do: using signed values in our environment would be very inconvenient, at the same time coding guides to insist on doing exactly this.</p>\n\n\nAssistant:",
        "golden_answer": " <p>First of all, the Google C++ coding guideline is not a very good one to follow: it shuns things like exceptions, boost, etc which are staples of modern C++. Secondly, just because a certain guideline works for company X doesn't mean it will be the right fit for you. I would continue using unsigned types, as you have a good need for them.</p>\n\n<p>A decent rule of thumb for C++ is: prefer <code>int</code> unless you have a good reason to use something else.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a structure for storing item properties on SQL Server:</p>\n\n<pre><code>ItemId PropertyId Value\n1      1          a\n1      2          b\n2      1          a\n2      2          5\n</code></pre>\n\n<p>Currently there are over 130000 items and 10000 properties and the numbers are growing. Current row count is a little over 15M. If I created a pivot table for this data, it would have a little over 1.3 billion cells, 15 million of which are not null.</p>\n\n<p>Users can form custom expressions on this data like:</p>\n\n<pre><code>X: P1 = 'a' (rule X selects items which have property 1 with value 'a')\nY: P2 &lt;&gt; 'b'\nZ: P3 like '%c%'\nT: P4 &gt; 5 (rule T selects items which have property 4 with a value greater than 5)\n</code></pre>\n\n<p>and they form filters by using expressions like:</p>\n\n<pre><code>(X AND T) (items that match both X and Y)\n(X AND Y) OR (Z AND T)\n(X OR Y) AND (Z OR NOT T)\n(X OR Y AND T) OR Z\n</code></pre>\n\n<p>I need to query the result of a few filters (generally 4 or 5) as a response of a single web request. How can I do this fast? Is there a storage method or a super efficient algorithm to get this filter results?</p>\n\n<p>It'd be great if this is possible on SQL Server but I am also open to solutions like storing this portion of data on a no sql database.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You will need carefully constructed indexes on your table, based on an iterative session with the SQL server to ensure that the engine selects your indexes and avoid full table scans.</p>\n\n<p>I suppose that a, b, c and d are user provided values.  If so, I would expect X, Y and T to be easy to create indexes for, but that the \"like\" clause of Z will be a killer since generic text search is very space requiring and you still risk needing full table searches.  I do not know if SQL Server supports full text search directly without doing full table searches.</p>\n\n<p>So - you need to learn how the SQL Server planner works deciding how to evaluate your SQL and put in indexes to avoid full table scans.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Is there any good reason (except \"GCC is better\") to use the MinGW win32api/headers/libs with LLVM/Clang. Suppose that in two to three years, Clang has matured enough (in C++0x and performance) that it's a competitor/replacement and has its advantages over MSVC like GCC does on some accounts. Why on earth would one want to avoid using the MS library and header implementations of the win32 API, which is freely available in the form of the Windows SDK?</p>\n\n\nAssistant:",
        "golden_answer": " <p>One reason for the MingW header files to exist is certainly copyright: while they are \"free as in beer\", you are not allowed to redistribute them. Neither could the LLVM authors redistribute them, instead, every LLVM/Clang user would have to download them on their own. So it would be reasonable for Clang to provide a set of header files, and it would then be reasonable to use the MingW code as a starting point.</p>\n\n<p>In addition, another reason for the MingW header files to exist (IIRC) is that the SDK headers use C extensions that were not supported by gcc. They may be supported now, so that reason may have gone.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am making a simple web app mostly in JavaScript. I was wondering as to how do I deploy settings/preferences? Do I just store user preferences somewhere and make use of if...else... statements all over the code?</p>\n\n<p>I think that there must be a better alternative. I am know JS, jQuery &amp; PHP and willing to learn anything new if at all required.</p>\n\n<p>I have already made the app, only the settings are remaining. I know what options to give users and how to program them in js.</p>\n\n<p>What's the most optimal way? How is it done in professional web apps and software made by companies (I am independent Student Developer - this is my first \"BIG\" project)?</p>\n\n<p><strong>EDIT:</strong></p>\n\n<p>For all the modifications that the settings are supposed to make (in this particular app), the whole js code base would litterally be filled with many branches of if...else...statements and I think that would make the code a lot harder to read and maintain.</p>\n\n<p>In my app, the whole database table to be fetched from the database and the number and types of HTML DOM manipulation to be done, new elements to be added to HTML dom and whether some  are visible or not would change. How do I deal with all that?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I think it depends on the nature of the settings.</p>\n\n<p>Some settings are basically numbers, like number of results to display or a zoom factor or such like. These settings can be read from your settings structure (or API) as needed and plugged in as parameters to functions in your code. I think these are straightforward.</p>\n\n<p>Other settings control functionality, like whether entire blocks of information are displayed. These naturally lead to branches in the logic of the app (if/else statements). If you want to eliminate these, use the <a href=\"http://en.wikipedia.org/wiki/Strategy_pattern\" rel=\"nofollow\">strategy</a> or <a href=\"http://en.wikipedia.org/wiki/Delegation_pattern\" rel=\"nofollow\">delegate</a> design patterns. You basically have a function preconfigured to follow one path or the other, and you pass that function as a parameter. The main code then becomes simple, and complexity is pushed to the set-up code that composes and selects the desired implementation functions.</p>\n\n<p>If the logic that you think you need to generate your page is complex, and the content of the page is complex, some logic in the final implementation might be unavoidable. What you can do to keep it manageable is to rethink the logic and see if you can simplify it. I find this is often quite possible. Factoring out implementation from the logic that engages it can also make your code more manageable. In the main body you will have some logic that reads settings values and that invokes subroutines as needed. Well-selected parameters to those subroutines, including function parameters, might result in fewer of them overall. JavaScript lends itself to this model. Take advantage of it.</p>\n\n<p>For example:</p>\n\n<pre><code>function addTable(tablename)\n{\n    while (readFromDatabase(tablename))\n    {\n        writeTableLine(...);\n    }\n}\n\nfunction addGraph(tablename)\n{\n    while (readFromDatabase(tablename))\n    {\n        buildGraph(...);\n    }\n}\n\n// in the main code:\nvar table1 = settings.getTable1name();\nvar table2 = settings.getTable2name();\nvar outputFunction = settings.shouldShowGraph() ? addGraph : addTable;\n\noutputFunction(table1);\n// more stuff\noutputFunction(table2);\n</code></pre>\n\n<p>The code above can output data from any number of tables in either table or graph form with no if statements.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Including customizable, JavaScript-based scrollbars (and scrolling functionality in general, i.e. bind the control to the mouse scroll wheel) in your webapp can be a great temptation.</p>\n\n<p>However all solutions I could find were developed by individuals (which can equal lack of formal or future support). In addition I fail to remember any mainstream site using them.</p>\n\n<p>In my particular case, no-JavaScript or IE6/odd-browser environments are not intended to be supported.</p>\n\n<p>Should custom scrollbars be avoided nowadays? If not, what's the best option one can choose?</p>\n\n\nAssistant:",
        "golden_answer": " <p>One very important argument that is always convincing to me when it comes to usability is consistency. You may want to make all the handles in your site look the same, noble goal, but think about how someone uses your app or site. They're not just using yours, they're using loads. In fact, I have got 8 tabs of 6 different websites open right now. I can switch to any tab and still have the same scrollbar, looking the same, no matter where. I always know where I can scroll my content. </p>\n\n<p>So if at all possible, and if it doesn't angry any graphic designer, stick with what people know :) Unless you have a brilliant new idea, which is going to be a new revolution in scrolling!</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>DDD/\"hexagonal architecture\" insist on separating the domain, aka model, from infrastructure requirements. This looks clean and logical until you realize that storing your domain object in memory might hurt performance if the domain object happens to be too large, and even more so fetching such domain object from persistent storage/network.</p>\n\n<p>The proposed \"cure\" which I have seen, is centered around defining the aggregates to be \"small\" and around \"eventual consistency\". Both seem to delegate the business rules to stateless (\"domain\") services and not the aggregates (domain entities) behaviour. So this appears to favour the creation of \"anemic domain objects\"; however \"rich domain objects\" seems to me the main purpose of DDD (together with the creation of the ubiquitous domain language).</p>\n\n<p>What you, as a DDD practitioner, think of this concern? (I am not currently a DDD practitioner, but given the hype around \"microservices\", I might perhaps become one).</p>\n\n\nAssistant:",
        "golden_answer": " <blockquote>\n  <p>The proposed \"cure\" which I have seen, is centered around defining the aggregates to be \"small\" and around \"eventual consistency\". Both seem to delegate the business rules to stateless (\"domain\") services and not the aggregates (domain entities) behaviour.</p>\n</blockquote>\n\n<p>Something got lost in the messaging here.</p>\n\n<p>Many applications today separate storage from compute.  The compute elements may be completely stateless (with regards to the model), or they may have in memory caches that they use to improve latency.</p>\n\n<p>The domain model is a way of isolating, in compute, the business logic from everything else.</p>\n\n<p>The basic outline is </p>\n\n<ol>\n<li>read state from the durable store</li>\n<li>create a domain model representation of that state</li>\n<li>apply changes to the domain model</li>\n<li>create a representation of the new state from the model</li>\n<li>write state to the durable store</li>\n</ol>\n\n<p>This flow of control would normally live, not in a domain service (which has a different meaning in domain driven design), but in an application service.</p>\n\n<p>What I find interesting is, if you look at the process as a whole:</p>\n\n<ol>\n<li>read state from the durable store</li>\n<li>???</li>\n<li>write state to the durable store</li>\n</ol>\n\n<p>The basic shape is that of an <a href=\"https://www.martinfowler.com/bliki/AnemicDomainModel.html\" rel=\"nofollow noreferrer\">anemic domain model</a> -- we pull data out of the database, fuss with it in some stateless \"service\", then put the data back in.  <a href=\"http://blog.ploeh.dk/2011/05/31/AttheBoundaries,ApplicationsareNotObject-Oriented/\" rel=\"nofollow noreferrer\">At the boundaries</a>, applications are not object oriented.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The question emerged for me in embedded programming but I think it can be applied to quite a number of general networking situations e.g. when a communication partner fails. </p>\n\n<p>Assume we have an application logic (a program) running on a computer and a gadget connected to that computer via e.g. a serial interface like RS232. The gadget has a red/green/blue LED and a button which disables the LED. The LEDs color can be driven by software commands over the serial interface and the state (red/green/blue/off) is read back and causes a reaction in the application logic. Asynchronous behaviour of the application logic with regard to the LED color down to a certain delay (depending on the execution cycle of the application) is tolerated.</p>\n\n<p>What we essentially have is a resource (the LED) which can not be reserved and handled atomically by software because the (organic) user can at any time press the button to interfere/break the software attempt to switch the LED color. </p>\n\n<p>Stripping this example from its physical outfit I dare to say that we have two communicating state machines A (application logic) and G (gadget) where G executes state changes unbeknownst to A (and also the other way round, but this is not significant in our example) and only A can be modified at a reasonable price. A needs to see the reaction and state of G in one piece of information which may be (slightly) outdated but not inconsistent with respect to the short time window when this information was generated on the side of G.</p>\n\n<p>What I am looking for is a concise method to handle such a situation in embedded software (i.e. no layer/framework like CORBA etc. available). A programming technique which is able to map the complete behaviour of both participants on classical interfaces of a classical programming language (C in this case). To complicate matters (or rather, to generalize), a simple high frequency communication cycle of A to G and back (IOW: A is rapidly polling G) is out of focus because of technical restrictions (delay of serial com, A not always active, etc.). \nWhat I currently see as a general solution is:</p>\n\n<ul>\n<li>the application logic A as one thread of execution </li>\n<li>an adapter object (proxy) PG (presenting G inside the computer), together with the serial driver as another thread</li>\n<li>a communication object between the two (A and PG) which is transactionally safe to exchange </li>\n</ul>\n\n<p>The two execution contexts (threads) on the computer may be multi-core or just interrupt driven or tasks in an RTOS.\nThe com object contains the following data:</p>\n\n<ul>\n<li>suspected state (written by A): effectively a member of the power set of states in G (in our case: red, green, blue, off, red_or_green, red_or_blue, red_or_off...etc.)</li>\n<li>command data (written by A): test_if_off, switch_to_red, switch_to_green, switch_to_blue</li>\n<li>operation status (written by PG): operation_pending, success, wrong_state, link_broken</li>\n<li>new state (written by PG): red, green, blue, off</li>\n</ul>\n\n<p>The idea of the com object is that A writes whichever (set of) state it thinks G is in, together with a command. (Example: suspected state=\"red_or_green\", command: \"switch_to_blue\") Notice that the commands issued by A will not work if the user has switched off the LED and A needs to know this. PG will pick up such a com object and try to send the command to G, receive its answer (or a timeout) and set the operation status and new state accordingly. A will take back the oject once it is no longer at operation_pending and can react to the outcome. The com object could be separated of course (into two objects, one for each direction) but I think it is convenient in nearly all instances to have the command close to the result. </p>\n\n<p>I would like to have major flaws pointed out or hear an entirely different view on such a situation.</p>\n\n\nAssistant:",
        "golden_answer": " <p>The hidden transitions and the latency make this a pretty interesting problem, especially since you can't modify the gadget. You may be looking for a synchronizing sequence or a homing sequence. (\"Synchronization\" means you can issue some sequence of commands, and be sure of the state of the target state machine when you're done. \"Homing\" means that you can issue some sequence of commands, then verify the state by examining the output of the state machine).</p>\n\n<p>Sven Sandberg has a pretty good paper showing that (for any well-defined Mealy machine) you can always construct these two types of sequences. It's all theory, no code, so you'll have to do some implementation. Here's the <a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.108.2650\" rel=\"nofollow\">citeseer reference</a> to the paper itself, and a <a href=\"http://web.cecs.pdx.edu/~mperkows/CLASS_573/Kumar_2007/presentation.pdf\" rel=\"nofollow\">PDF slideshow</a> of the ideas.</p>\n\n<p>In the case you describe, latency is still an issue. I'm curious to know if you have some idea of the margin of error on these \"hidden\" state changes. How long between them? Are they more common, or more frequent, in some cases than others? Answers to these questions can help you define these control sequences.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm pushing out a new feature soon that has a lot of different UX components. The key metric that I want to track is user engagement (I have the equation for what this means for me and how to measure it). What I want to measure is the best combination of the UX components that maximizes the engagement. The problem is that there are a lot of variations in terms of what UX components I can display at any time, and how I can display them.</p>\n\n<p>To provide some examples, consider a widget with tiles where each tile represents a book (Note: this is just a simple example, my actual product has more variations). Clicking on one of the book tiles opens up more details about the book but thats irrelevant. What I want to maximize is the chance that the user clicks on one of the tiles. Each tile can have a thumbnail, the name of the author, rating from Goodreads and the year in which it was written etc. Each one of the components (Author Name, Rating and Year) can be hidden or displayed.</p>\n\n<p>The first answer that comes to my mind is AB testing. For example, Week 1, deploy AB test two versions of the widget. One that only has thumbnails alone and the other that thumbnails and Goodreads rating. Week 2 will depend on the results of week 1, if week 1 gives us the result that rating gets more engagement, then the new test will be thumbnails + ratings vs. thumbnails + ratings + author name. If week 1 gave us that ratings gets less engagement, then we can repeat the same test, but this time replacing ratings with author name. And we will can follow the similar approach for week 3 and so on.</p>\n\n<p>My concern is that this process seems a little inefficient. For weeks, I will be just experimenting with different variations of the widget and drawing conclusions. Data of each phase will be limited to the length of the experiment. Who know how long it would take for me to find an ideal combinations.</p>\n\n<p>Given my lack of experience when it comes to solving problems like this, I'm a little hesitant to move forward. My questions are</p>\n\n<ul>\n<li>Is AB testing even the right solution to this kind of a problem?</li>\n<li>If yes, then is my approach (week 1 do x, week 2 do y etc) correct when it comes to the implementation? </li>\n<li>What improvements can I make to this process? Would be great if you can point me to some helpful resources regarding this topic.</li>\n</ul>\n\n\nAssistant:",
        "golden_answer": " <p><strong>Is AB testing even the right solution to this kind of a problem?</strong></p>\n\n<p>Like amon said in his <a href=\"https://softwareengineering.stackexchange.com/a/369147/262998\">post</a>: A/B tests can be a powerful tool to test a hypothesis but there are also other ways. </p>\n\n<p>When you're talking about fine-grained optimisation, you might want to take a data-driven approach like A/B testing, but just asking end-users is often easily overlooked. In software engineering it is generally very valuable to hear end-users' feedback. Like this, there are more, simpler ways to test the effectiveness of features.</p>\n\n<p><strong>If yes, then is my approach (week 1 do x, week 2 do y etc) correct when it comes to the implementation?</strong></p>\n\n<p>This works, but you have to take into account the noise that is created by other factors that play in week 1 and week 2. Also note that this approach will also take <code>n</code> weeks, where <code>n = amount of features</code>.</p>\n\n<p><strong>What improvements can I make to this process? Would be great if you can point me to some helpful resources regarding this topic.</strong></p>\n\n<p>Ideally you would want to test multiple versions of a feature in parallel, each version tested against a percentage of the user-base. However this requires your production infrastructure to allow for this kind of releasing.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>An executive at my workplace asked me and my group of developers the question:</p>\n\n<blockquote>\n  <p>How many lines of code can a C#\n  developer produce per month?</p>\n</blockquote>\n\n<p>An old system was to be ported to C# and he would like this measure as part of the project planning.</p>\n\n<p>From some (apparently creditable) source he had the answer of \"10 SLOC/<strong>month</strong>\" but he was not happy with that.</p>\n\n<p>The group agreed that this was nearly impossible to specify because it would depend on a long list of circumstances. But we could tell that the man would not leave (or be very disappointed in us) if we did not come up with an answer suiting him better. So he left with the many times better answer of \"10 SLOC/<strong>day</strong>\"</p>\n\n<p><em>Can this question be answered?</em> (offhand or even with some analysis)</p>\n\n\nAssistant:",
        "golden_answer": " <p>Ask your executive how many pages of contract his lawyer can write per month. Then (hopefully) he will realize that there's a huge difference between writing a single-page contract and writing a 300-page contract without loopholes and contradictions. Or between writing a new contract and changing an existing one. Or between writing a new contract and translating it to a different language. Or to a different law system. Maybe he'll even agree that \"pages of contract per unit of time\" is not a very good measure for lawyer productivity.</p>\n\n<p>But to give you <em>some</em> answer to your real question: In my experience, for a new project a few hundred SLOC per day and developer aren't uncommon. But as soon as the first bugs appear, this number will drop sharply.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have come to python from C++ (I also know a little Java).  I am writing code to exercise a server so I basically use http methods to send a load of requests to the server.  As part of my code I created a class and called it testdata.  This contains basically test input data (to send in requests) and output data to check against.</p>\n\n<p>With my C++ hat on I created a load of getter and setter methods which were one lines.  I even had an <code>__init__</code> method to set eg <code>self.&lt;some_attribute_name&gt; = \"\"</code> or some safe default.</p>\n\n<p>I realise now that you can freely add attributes to a python object and there is no need to pre-initialise simple variables in init.</p>\n\n<p>So I have some questions.</p>\n\n<ol>\n<li><p>For my testdata class, should I even be using a class?</p></li>\n<li><p>I just add data items like this:</p>\n\n<pre><code>import testing\n\ntd = testing.testdata()\ntd.sessionid = \"123\"\n</code></pre></li>\n<li><p>But what about access eg to <code>td.sessionid</code> before I have previously assigned a value.  I know I can use <code>hasattr</code> but that is an extra burden.  Do I have to make sure I always assign first?  What if I do <code>td.sessionid</code> before it is even assigned anything?  I will get an AttributeError at runtime.  How to handle this?</p></li>\n<li><p>Due to problem 3. above.  Should I always use <code>__init__</code> to initialise member data to safe default values? eg \"\" for strings.  </p></li>\n</ol>\n\n<p>What are recommended approaches in Python?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Generally, you use class attributes to provide defaults:</p>\n\n<pre><code>class TestData(object):\n    sessionid = None\n</code></pre>\n\n<p>You only need to define a <code>__init__</code> if you need to provide a new instance with attributes that <em>have</em> to be uniquely set for that new instance.</p>\n\n<p>However, don't define a class just to hold state. Use classes when you are going to provide both state <em>and</em> behaviour. Python's standard types and library is otherwise more than rich enough to cover the just-data needs.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm defining coding conventions for Progress OpenEdge in our company.\nIn this language one can use symbols or keywords for operators, both work the same. For code quality purpose (code review, code readability, ...) it's a good idea to select one preference.</p>\n\n<p>I consulted code conventions from other companies. They all had the rule: use symbols.\nI simply copied this rule BUT some developers start holy wars to use keywords instead.</p>\n\n<p>Is there any best practice in this respect? What to choose, symbols or keywords?</p>\n\n<p><a href=\"https://i.stack.imgur.com/tzLJP.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/tzLJP.png\" alt=\"enter image description here\"></a></p>\n\n\nAssistant:",
        "golden_answer": " <p>\"I simply copied this rule\" I think this sums it up. </p>\n\n<p>If you cant justify a coding convention with a pretty strong argument, just don't have one. They slow developers down and cause arguments.</p>\n\n<p>'readability' just isn't good enough. As you have discovered its a subjective thing and people have strong views one way or the other.</p>\n\n<p>Reasons I would agree are sensible</p>\n\n<ul>\n<li><p>Automated tests. So we can run regression checks faster and cheaper than manually.</p></li>\n<li><p>Work on a feature branch. So if another feature finished before yours we can release it.</p></li>\n<li><p>Version Apis. So we can upgrade with zero downtime</p></li>\n</ul>\n\n<p>that kind of thing</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>My problem is as follows.  I have an array of <code>n</code> strings with <code>m &lt; n</code> of them distinct.  I want to create a one-to-one function which assigns each of the <code>m</code> distinct strings to the numbers <code>0 ... m-1</code>.  For example, if my strings are:</p>\n\n<p><code>Bob, Amy, Bob, Charlie, Amy</code></p>\n\n<p>then the function:</p>\n\n<p><code>Bob -&gt; 0, Amy -&gt; 1, Charlie -&gt; 2</code></p>\n\n<p>would meet my needs.  I have thought of three possible approaches:</p>\n\n<ol>\n<li><p>Sort the list of strings, remove duplicates, and construct the function using a search algorithm.</p></li>\n<li><p>Create a hash table and check each string to see if it is already in the table before inserting it.</p></li>\n<li><p>Sort the list of strings, remove duplicates, and put the resulting list into a hash table.</p></li>\n</ol>\n\n<p>My code will be written in Java, and I will likely use standard Java algorithms: merge sort for sorting, binary search for searching, and whatever the standard Java hash table algorithm is.</p>\n\n<p><strong>Question:</strong> Assume that after creating the function I will have to evaluate it on each of the n original strings.  Which of the three approaches is fastest?  Is there a better way?</p>\n\n<p>Part of the problem is that I don't really know what's going on \"under the hood\" in standard hashing algorithms.  Any help would be appreciated.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Firstly, I'll note that there are two different things to be concerned with. How long will it take to assign all the numbers, and how long will it take to lookup the number later.</p>\n\n<h2>Sort the list of strings, remove duplicates, and construct the function using a search algorithm</h2>\n\n<p>Sorting will take O(n log n) time, you can remove the duplicate in O(n) time. To lookup the number you can use binary search which will take O(log m) time for each search.</p>\n\n<h2>Create a hash table and check each string to see if it is already in the table before inserting it.</h2>\n\n<p>Hash table operations are typically considered to be O(1). This is a bit of lie because it depends on the number of collisions you get. But its close to O(1) and definitely better then O(log m). Checking and inserting all values will then be O(n). Fetching the counts later will be O(1) for each fetch.</p>\n\n<h2>Sort the list of strings, remove duplicates, and put the resulting list into a hash table.</h2>\n\n<p>Sorting and deduplicating will take O(n log n) time. Inserting all of that into a hash will take O(m) time. Then fetching the individual elements will take O(1) time. This is basically the same as the previous option except that you spend O(n log n) extra time sorting.</p>\n\n<p>The second option will be fastest, at least for large enough cases. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Every time I am working on a project, specially a project from scratch, I always feel like I am doing a messy job. I feel bugged all the time by the need or organizing code that is clean or proper way.</p>\n\n<p>For example;</p>\n\n<ul>\n<li>Avoid hard-coding file paths in gulpfile.</li>\n<li>Require all node modules in similar fashion.</li>\n<li>What should be the ideal directory structure for this project.</li>\n<li>UI. The *** UI.</li>\n</ul>\n\n<p><strong>The Question</strong></p>\n\n<p>What are the strategies I can follow to not drown into that world? Thinking over and over on the organization aspect of the project gets me really low on productivity.</p>\n\n<p>In general, how to approach a project from scratch so I can get the most done without the code organization overhead?</p>\n\n<hr>\n\n<p><em>Notes after the possible duplicate flag</em></p>\n\n<p>I can understand why this is flagged as possible duplicate as the question is more of an overview rather than a specific question.</p>\n\n<p>The question I have is more about what kind of mentality a programmer should have when starting a project from scratch so they end up delivering more rather than getting trapped by code organization issues. </p>\n\n\nAssistant:",
        "golden_answer": " <p>This post reads like you really are feeling the frustration - I can empathise. There are a few things that could help you through this;</p>\n\n<ul>\n<li>A good book on code construction etc. <a href=\"http://rads.stackoverflow.com/amzn/click/0735619670\" rel=\"nofollow\">Code complete 2</a> is often cited in this regard</li>\n<li>More or better familiarity with you tools\n\n<ul>\n<li>Using their features well</li>\n<li>Making peace with their short comings, no tool is perfect</li>\n</ul></li>\n<li>Time, it takes practise to get really good at what you do. <a href=\"http://norvig.com/21-days.html\" rel=\"nofollow\">Some say 10 years/10'000 hours</a></li>\n<li>Study and follow common techniques with the tools and languages you use, study your favourite open source projects - they may not be perfect, but there are lessons there</li>\n</ul>\n\n<p>Do not forget that shipping code is a feature, get it out the door; <a href=\"http://c2.com/cgi/wiki?TheBestIsTheEnemyOfTheGood\" rel=\"nofollow\">best is the enemy of good</a>, get it good enough, make peace with that and ship it.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have developed a unique website but do not have a lot of fund to protect it with trademark or patents. I'm looking for suggestions so that when my supervisor gets my codes, some laws restrict anyone from copying it and claim their work. I'm in the middle of thinking, making the application a commercial one or never allowing it to be copied at all. What kind of steps am I required to take in order to make full measurements so my applications are fully-protected?</p>\n\n<p>I've come across a few, one under my consideration is MIT license. Some say we can have a mixture of both commercial and MIT. I would also like to be able to distribute some functions so it can be modified by others but I'd still retain the ownership. </p>\n\n<p>Last but not least, it's confusing when I think of protecting the whole website, and protecting codes by codes in division. How should we go about this?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Check with a lawyer.  Odds are surprisingly high that the university <b>already</b> legally owns the source code.  However in the USA universities are generally fairly willing to license your code back to you.  So if you want to, say, build a startup using the website you have built, you probably will be able to.  But you need to cooperate with the university, not make them into adversaries.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have used some kind of \"listeners\" where I have an interface implemented by classes that need to be notified of some event (e.g.: CurrencyListener, with a method <strong>currencyUpdated(Currency currency)</strong>)\nThen, the object that needs to send a notification, has a list of listeners (List) and just iterates over this list invoking the <strong>currencyUpdated(Currency currency)</strong> method.</p>\n\n<p>The structure of this listener, is very similar to the Observer pattern, there is no Observer and Observable class, just the listener interface(CurrencyListener). </p>\n\n<p>What are the advantages/disadvantages of using one approach over the other?</p>\n\n\nAssistant:",
        "golden_answer": " <p>This <em>is</em> the Observer pattern - it's the exact same thing. </p>\n\n<blockquote>\n  <p>I have used some kind of \"listeners\" where I have an interface implemented by classes that need to be notified of some event (e.g.: CurrencyListener, with a method currencyUpdated(Currency currency)) </p>\n</blockquote>\n\n<p>In the Observer pattern, you have an abstraction (an interface or a base class) <em>Observer</em> which defines the things the observer can observe (or listen for). Your CurrencyListener is the <em>Observer</em>. </p>\n\n<p>The other part of the pattern is the <em>Observable</em>, which is the object that sends notifications, which may or may not be itself an abstraction, or part of some hierarchy. I.e., the pattern <em>does not require</em> the ConcreteObservable subclases to be present. In the Go4 Patterns book, one of the roles for a ConcreteObservable is described as </p>\n\n<blockquote>\n  <p>\"stores state of interest to ConcreteObserver objects.\"</p>\n</blockquote>\n\n<p>If a ConcreteObserver can has no need for any special state, or can work with just the interface provided by the Observable base class, then <em>there's no need</em> for a ConcreteObservable.</p>\n\n<blockquote>\n  <p>Then, the object that needs to send a notification, has a list of listeners (List) and just iterates over this list invoking the currencyUpdated(Currency currency) method</p>\n</blockquote>\n\n<p>The <em>Observer</em> provides methods for the <em>Observables/Listeners</em> to register with it, and it internally maintains a collection of these listeners. That's exactly what your object does.</p>\n\n<p>Again, it's just the classic Observer pattern. The Observers and the Observables are independent of each other because they both depend on the abstraction provided by the Observer interface, and because they rely on the client code that uses them to hook up the Observers/Listeners with the Observable.</p>\n\n<p>P.S. There's a number of variations on the pattern, and a number of features in different languages that are just the Observer pattern in disguise. For example, in C#, events are clearly a variation of the pattern. Another example of a variation would be what's usually called a Messenger (or an Event Aggregator, as Martin Fowler calls it), an can be found in some libraries and frameworks - it's a class that acts as as an intermediary between the observers and the observables. The structure is slightly different, but it is based around the Observer pattern; in fact, the Go4 book describes something similar near the end of the Implementation section in the description of the pattern (they call it ChangeManager).  </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>After many years of coding, trying various programming styles, weeding out unreadable or impractical stuff, I still can't figure out one thing: what is the best way to single-line-comment multiple lines of indented code.</p>\n\n<p>1.</p>\n\n<pre><code>    setup_checkpoint();\n//    if (object-&gt;looks_suspicious())\n//        guard-&gt;full_body_scan(object);\n</code></pre>\n\n<p>2.</p>\n\n<pre><code>    setup_checkpoint();\n    // if (object-&gt;looks_suspicious())\n    //     guard-&gt;full_body_scan(object);\n</code></pre>\n\n<p>3.</p>\n\n<pre><code>    setup_checkpoint();\n    // if (object-&gt;looks_suspicious())\n        // guard-&gt;full_body_scan(object);\n</code></pre>\n\n<p>Please, don't suggest multiline commenting, because sometimes you want to leave that possibility for bigger blocks, which may include smaller pieces of comments.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Since you do this for testing purposes, you normally want to have that stand out as much as possible, so you don't overlook removing the comments or the code later.  Comment markers on the left margin are more visible.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I am using EF Code First and I had a model like below.</p>\n\n<pre><code>public class Account\n{\n    [Required]\n    public string AccountNo { get; set; }\n    [Required]\n    public decimal Balance { get; set; }\n}\n</code></pre>\n\n<p>I used a Service class to withdraw and deposit amount to Account. Then I came across <a href=\"https://stackoverflow.com/questions/3484193/repository-pattern-and-or-vs-business-logic-layer\">this</a> and realised that Account is Anemic. So I happily added Withdraw and Deposit methods to Account.</p>\n\n<pre><code>public class Account\n{\n    [Required]\n    public string AccountNo { get; set; }\n    [Required]\n    public decimal Balance { get; set; }\n    public void Withdraw(decimal amount)\n    {\n        // TODO: Check if enough balance is available\n        Balance -= amount; \n    }\n    public void Deposit(decimal amount)\n    {\n        Balance += amount; \n    }\n</code></pre>\n\n<p>}</p>\n\n<p>I was very happy with this until I realised that this does not implement encapsulation correctly. You should not be able to modify the Balance directly - you should use Withdraw and Deposit methods. But in my solution you can modify the Balance directly.</p>\n\n<p>But I cannot make Balance a readonly property as I am using EF code first approach and readonly properties won't result in the column being created in the database table. </p>\n\n<p>I thought of leaving Account as anemic and create a higher level Account class which implements encapsulation and Withdraw/Deposit methods. But in that case the higher level class would not have validation data annotations and I won't get the free functionality provided by the framework.</p>\n\n<p>What is the solution?</p>\n\n\nAssistant:",
        "golden_answer": " <p>There is a fundamental difference between your Data Access Object (DAO) and your Business Object (BO). Your DAO is a one-to-one mapping of what your data store looks like. In this case, for your <code>AccountDAO</code> object, the <code>AccountNo</code> and <code>Balance</code> properties will have getters and setters. Your <code>Account</code> object - the business layer objects - will <strong>not</strong> look the same as your DAO.</p>\n\n<pre><code>// This is a DAO\npublic class AccountDAO {\n   public string AccountNo { get; set; }\n   public decimal Balance { get; set; }\n}\n\n// This is a business object\npublic class Account {\n   private readonly string accountNo;\n   private readonly decimal openingBalance;\n   private readonly List&lt;decimal&gt; adjustments; // This should probably be a list of transactions.\n\n   public class Account(string accountNo, decimal openingBalance) {\n      this.accountNo = accountNo;\n      this.openingBalance = openingBalance;\n      this.adjustments = new List&lt;decimal&gt;();\n   }\n\n   public string AccountNo {\n      get { return accountNo; }\n   }\n\n   public decimal Balance {\n      get { return openingBalance + SumOfAdjustments(); }\n   }\n\n   public void Deposit(decimal amount) {\n      adjustments.Add(amount);\n   }\n\n   public void Withdraw(decimal amount) {\n      decimal testBalance = Balance - amount;\n      if (testBalance &lt; 0.0m)\n         throw new AccountBalanceException(\"Account Balance for \" + accountNo + \" is less than $0.00.\");\n\n      adjustments.Add(-1.0m * amount);\n   }\n\n   private decimal SumOfAdjustments() {\n      decimal sum = 0.0m;\n      foreach (var adjustment in adjustments) {\n         sum += adjustment;\n      }\n      return sum;\n   }\n}\n\n// Let's come up with a good way of performing actions on an account.    \npublic class CashDepositActivity {\n   private readonly Account account;\n   private readonly decimal amount;\n\n   public CashDepositAction(Account account, decimal amount) {\n      this.account = account;\n      this.amount = amount;\n   }\n\n   public void ExecuteAction() {\n      // You should probably have some logging here.\n      account.Deposit(amount);\n   }\n}\n\npublic class BalanceTransferActivity {\n   private readonly Account sourceAccount;\n   private readonly Account targetAccount;\n   private readonly decimal amount;\n\n   public BalanceTransferActivity(Account sourceAccount, Account targetAccount, decimal amount) {\n      this.sourceAccount = sourceAccount;\n      this.targetAccount = targetAccount;\n      this.amount = amount;\n   }\n\n   public void ExecuteAction() {\n      sourceAccount.Withdraw(amount);\n      targetAccount.Deposit(amount);\n   }  \n}\n</code></pre>\n\n<p>This is just an example, of course, and it is by no means an end-all solution. I know tools like EF have myriad examples where the data object, business object, and view/edit object are all the same object, passed from the database to view. In my experience, that works great on small projects where there is not a lot of business logic. However, it breaks down as your business rules and access restrictions grow in complexity.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>JavaMail sends e-mails using an e-mail server, typically through the SMTP interface of an e-mail provider.  Is it necessary to use an e-mail server to send e-mails?</p>\n\n<p>I have a web site that will send e-mails and if possible I'd like to send the e-mails directly from the web site code without using an e-mail server.  The JavaMail FAQ says that an e-mail server is required.</p>\n\n<p>Is there a way to send e-mails without using an e-mail server, either with JavaMail or another API?</p>\n\n\nAssistant:",
        "golden_answer": " <p>You can deliver an email directly to one of the SMTP servers mentioned in the MX record of the address's domain. Usually that is a bad idea,though:</p>\n\n<p>Delivering the mail to a local server is fast - you can almost immediately continue and do something else and let the server handle the delivery.</p>\n\n<p>The actual delivery can take some time, for instance the remote mail server might be slow. Or it might reject the mail first - it is a known strategy against spam to tell a sender to try sending a mail a second time, which some spam bots won't do.</p>\n\n<p>Also the mail server can easily try again a day later or so when the remote server is down, this reduces risk of lost mail.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>this is a highly theoretical question about my parallelization approach.</p>\n<p>First of all, I want to inform everybody that I do not claim that I am the 'inventor' of that approach but I couldn't find any information about something like that.</p>\n<p>I will explain my idea through example.</p>\n<p><a href=\"https://i.stack.imgur.com/XXFUw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/XXFUw.png\" alt=\"enter image description here\" /></a></p>\n<p><strong>I assume that every task that is a dependency of <em>dress-up pizza</em> task is CPU bounded, so I make sense to execute it on another thread</strong></p>\n<p><strong>Usually approach</strong></p>\n<ol>\n<li>Compute dependencies of <em>dress-up pizza</em> on other threads</li>\n<li>Join every thread</li>\n<li>Execute <em>Dress up pizza task</em></li>\n</ol>\n<p>I got the idea that if we don't care about which thread is executing the <em>dress-up pizza</em> task we can avoid joining threads simply by executing that task on a thread that finishes last.</p>\n<p>We could store the result of every task on struct with an additional field for the atomic counter.</p>\n<p><strong>Pseudo-code example</strong></p>\n<pre><code>struct pizza_dependencies {\n    cheese,\n    olives,\n    dough,\n    counter\n}\n\nfn grate_the_cheese(dependencies){\n    dependencies.cheese = cheese\n\n    if dependencies.counter == 2 {\n        dress_up_pizza(dependencies)\n    } else {\n        couter += 1\n    }\n    \n}\n\n</code></pre>\n<p>The rest of the tasks would be implemented the same way. Counter by default is 0.</p>\n<ul>\n<li>What would be the advantages/disadvantages of such an approach?</li>\n<li>Is there any better/faster way of doing this?</li>\n<li>Is some research/project using a similar approach?</li>\n</ul>\n<p>I really want to know what do you think about my idea, have a great day :)</p>\n\n\nAssistant:",
        "golden_answer": " <p>Yes, that's not entirely unreasonable. In practice, you would likely replace the (atomic) counter by a semaphore but all of that is more or less equivalent. A synchronization method that ensures no tasks remain in a critical section is also called a <a href=\"https://en.wikipedia.org/wiki/Barrier_(computer_science)\" rel=\"nofollow noreferrer\"><em>barrier</em></a> and actually works quite similar to your counter, except that it doesn't concern itself with what comes next.</p>\n<p>The issue with your approach is that the tasks need to know what the next task is. Hardcoding the tasks like you did here prevents composability of tasks (you can't recombine them, add or remove tasks). And when done manually this is error prone.</p>\n<p>There is also the question what happens if any of the tasks fails without incrementing the shared state counter. As designed, your system would hang forever. If you have a supervisor process, it could e.g. check results for error codes or set a timeout. This is more robust in practice.</p>\n<p>To some degree these aspects can be fixed, e.g. running each task under its own error handler, or using explicit continuations to ensure composability.</p>\n<p>But why use a complicated solution when a simple solution is just fine? Tasks are usually reasonably cheap so the difference between three tasks in your solution and three tasks with an additional supervisor or main thread shouldn't be that dramatic.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I've noticed that a lot of companies use \"reverse domain name\" namespaces and I'm curious where that practice originated and why it continues. Does it merely continue because of rote practice, or is there an outstanding architecture concept I might be missing here?</p>\n\n<p>Also note questions such as: <a href=\"https://stackoverflow.com/questions/189209/do-you-really-use-your-reverse-domain-for-package-naming-in-java\">https://stackoverflow.com/questions/189209/do-you-really-use-your-reverse-domain-for-package-naming-in-java</a> that sort of answer my question but not 100%</p>\n\n<p><sub><sub>(If it makes you feel any better, I'm really curious if I should be using it for my javascript namespacing efforts, but I'm more curious about then when and why, and that should help guide me on the javascript answer, nota bene: \"window\")</sub></sub></p>\n\n<p>Example of this practice extending to folders and files: <img src=\"https://i.imgur.com/jtdXo.jpg\" alt=\"http://imgur.com/jtdXo\"></p>\n\n\nAssistant:",
        "golden_answer": " <p><a href=\"http://en.wikipedia.org/wiki/Reverse_domain_name_notation\">Reverse Domain Notation</a> has its origins in Java, but is widely used in many platforms, such as Android Packages, Mac OS X Packages, JavaScript, ActionScript, and more.</p>\n\n<p>The practice is extremely useful because it provides a decentralized system for namespacing software. There is no need to apply to a centralized agency for a namespace; simply use the domain name you own (reversed) and manage that within your own organization. <strong>By naming packages like this, one can be almost certain that code won't conflict with other packages.</strong></p>\n\n<p><a href=\"http://docs.oracle.com/javase/tutorial/java/package/namingpkgs.html\">From Oracle's Java Tutorials</a>:</p>\n\n<blockquote>\n  <p>Companies use their reversed Internet domain name to begin their package names\n  for example, com.example.mypackage for a package named mypackage created by a \n  programmer at example.com.</p>\n  \n  <p>Name collisions that occur within a single company need to be handled by\n  convention within that company, perhaps by including the region or the\n  project name after the company name (for example,\n  com.example.region.mypackage).</p>\n</blockquote>\n\n<p>It's more than a rote practice, it's good practice because it's a <strong>complete and fully specific</strong> namespace. If there were two companies named <strong>Acme</strong> and both chose the namespace <code>acme.</code>, their code would conflict. But only one of those companies can own the domain <strong>acme.com</strong>, so they get to use the <code>com.acme.</code> namespace.</p>\n\n<p>Reversing the domain name allows for a top-down architecture. <code>com</code> would contain code for companies (or anyone who owns own a .com domain name), and underneath that would company (domain) names. Then, deeper within that would be the structure of the organization and/or the actual namespace. (For example, if it was code from a network called <strong>internal.acme.com</strong>, that gives this department their own sub-namespace of <code>com.acme</code>.) This top-down structure is used in a number of applications, including in systems administration. (It's similar to reverse IP address lookups.)</p>\n\n<p>Personally, I use it for all new JavaScript code I write for my company. It ensures that the code will never conflict with any other code, even if I later write the same code for another company. It can make accessing the code cumbersome (typing <code>com.digitalfruition.</code> can get a bit much) but that can easily be worked around with a closure and a local variable (<code>var DF = com.digitalfruition</code>).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm trying to determine how we can measure how much time the developers are loosing to poorly managed environment and inefficient ways-of-working. </p>\n\n<p><strong>The goals are:</strong></p>\n\n<ol>\n<li>Show managment how big the problem really is, in terms they can relate to. I.e $$$</li>\n<li>Get a good baseline so that we can measure the progress. </li>\n</ol>\n\n<p><strong>Short background:</strong></p>\n\n<p>We manage the programming environment for 500 developers. This includes IDE (mainly Eclipse and Visual Studio), version control systems (ClearCase), what programs they have available. \nBasically, everything related to the computer that involves programming.</p>\n\n<p>Examples: </p>\n\n<p>Not being able to work with tools they are used to due to strict security requirements.\nUsing version control system in a bad way causing problems when working in parallell. \nSetting up project environment is done manually and different each time.\nUsing homecooked frameworks, rather than what are industry standard.\nBuilding takes longer than needed due to homemade practices. \nDeploying takes longer than needed due to homemade practices. </p>\n\n<p>This does <strong>not</strong> include the actual coding pratices, project management or meetings. Sure, we can influence those things too, but for this questions those things are out of scope. </p>\n\n<p><strong>The question:</strong></p>\n\n<p>So, how can we determine how much time are lost due to the project environment?</p>\n\n<p>The only thing I can think of to get some good data are polls and questionnaires. </p>\n\n<p>Have anyone done something like this? What were the experiences and results?</p>\n\n<p>Are there other literature or reasearch where I can get ideas from or compare results with? </p>\n\n<p><em>Other questions exists regarding programmers inefficiency (like <a href=\"https://softwareengineering.stackexchange.com/questions/43464/source-of-programmer-inefficiency\">this</a>), but those relate to coding practices and bugs.</em></p>\n\n\nAssistant:",
        "golden_answer": " <p>What it appears that you're doing is attempting to measure productivity. Measuring productivity is notoriously difficult. Here's how I go about it...</p>\n\n<p>I've found that you don't want to tackle the situation by measuring <em>losses</em>, you want to measure the <em>gains</em> of potential solutions. From a purely philosophical point of view, the former implies that you're doing something wrong, which may not be true. </p>\n\n<p>Things change, and periodically, someone (like yourself, it seems) needs to take a look at the landscape and see if those changes can provide a better environment. With that said, I look at:</p>\n\n<p><strong>Things That Don't Exist</strong></p>\n\n<ul>\n<li>Tools (e.g. computers, version control)</li>\n<li>Practices (e.g. TDD)</li>\n<li>Processes (e.g. code reviews, agile)</li>\n</ul>\n\n<p>This is a common problem and I've successfully argued in favour of adopting certain things based on:</p>\n\n<p><em>Product Documentation and Sales Information</em> </p>\n\n<p>This is always the first place to start. If the product costs money, the sales documentation is almost always targeted or worded for management types. It's easy to find, easy to access, and a human that works for the vendor is almost always available to provide other resources like the following...</p>\n\n<p><em>Case Studies</em></p>\n\n<p>A good example I have is the book \"Best Kept Secrets of Peer Code Review\" was written by Jason Cohen (founder of Smart Bear IIRC) contains case studies in order to make the case for code reviews. Sure, the book was basically written by the vendor, but the case studies were legitimate.</p>\n\n<p><em>Proofs of Concept</em></p>\n\n<p>If it's a potential implementation (thinking CI, build system, TCM, or any other process or automation facilitating tool) then the best way to go about it is to get a trial and set it up. After performing some initial investigation (ie, using it on fake projects) it might be a good idea to try it out in a small project, or possibly in tandem with the existing solution.</p>\n\n<p>For processes, it's similar. This is basically the way that a lot of developers introduce unit testing. They maintain their own tests for a while, and when the critical \"BAM! Regression Caught!\" scenario hits, they perform the reveal and show how it saved the project. A little dramatic, yes, but it makes sense. People need to see the benefit with their own eyes.</p>\n\n<p><strong>Things That Exist but are Broken/Inefficient</strong></p>\n\n<p>This will almost always be a comparative analysis. If you approach it that way, then you should be able to get numbers to work with. </p>\n\n<p>Sales info from the vendor doesn't always work well here, unless it's a product that directly and obviously competes with the currently implemented solution - in that case, you can usually get the vendor to help you out here. (I'm thinking SourceGear Vault vs. SourceSafe as an example)</p>\n\n<p>I've found that case studies rarely exist that compare tools/practices but do exist for processes (think Agile vs. Waterfall studies).</p>\n\n<p>In my experience, proofs of concept are often the most successful ways of converting management/developers from one tool or practice to another. They have to see it working, and more importantly, see it working <em>better</em> than what already exists. Then you hit them with the numbers. \"This system, which is only a POC, is <em>still</em> x times faster than our previous one. That translates to y reduced man-hours of work and z reduced overhead\" Remember that POCs can <em>sometimes</em> be done on small projects to test out a process, usually after sufficient evidence of potential gains has been given.</p>\n\n<p><strong>Things That We Have No Idea About</strong></p>\n\n<p>Here's where your polls and questionnaires come into play... but these will lead you to the categories outlined above. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a typical MVC based website, and I'd like to give some registered users the abillity to extract data from the database (in a variety of formats). The workflow is very simple:</p>\n<ul>\n<li>User logs in,</li>\n<li>User clicks export,</li>\n<li>A file is generated,</li>\n<li>User downloads the file.</li>\n</ul>\n<p>I'm trying to figure out a way to secure the last step and limit access to the file. In order for the user to be able to download the file, it should be in a publicly accessible folder. That, however, means that the file is accesible to everyone else that has access to its full url.</p>\n<p>I thought of a few possible solutions:</p>\n<ol>\n<li><p>Email the export file</p>\n<p>Instead of having the user download the file, I could simply email it to their email (the one they used to register on the site). This seems like a decent option when the export files are small, but I don't think it'll be optimal for larger files.</p>\n</li>\n<li><p>.htaccess magic</p>\n<p>I could automagically generate an .htaccess in the export dir that would only let the user who requested the export access it. Also a decent option, but it's webserver specific and IP based. I don't know if Apache will always be the webserver of choice for the project, and I'm not sure an IP based solution is actually secure.</p>\n</li>\n<li><p>Store the export file in a private folder and have the user fetch it through ftp</p>\n<p>Secure, but not particularly user friendly.</p>\n</li>\n</ol>\n<p>All my options seem to have problems, and I'm at that point where I'm completely stuck and can't shake the feeling I'm missing something obvious. Am I? Is there a better workflow?</p>\n<p>I'm more interested in a high level overview than technical details, the project is still in its early days and technical requirements haven't yet stabilized (e.g. we may not use Apache after all). The project is build in PHP, but I don't think that matters (does it?).</p>\n<p>Thanks.</p>\n\n\nAssistant:",
        "golden_answer": " <p>You could serve the file via your PHP script, which checks if the user is authentificated.</p>\n\n<p>E.g. pseudocode</p>\n\n<pre><code>if session.user is loggedIn\n    filename = url.filename\n    if filename belongs to session.user\n        fetchfile(filename)\n    else\n        \"you are not authorized to download this file\"\nelse\n    \"please log in\"\n</code></pre>\n\n<p>so only the user requested the export is able to download it. If another user gets the url he cannot download anything.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Say I have an aggregate root called Customer.  In this example, the customer has a collection of invoices. </p>\n\n<p>Is it ever \"acceptable\" for the Application Service layer to create an instance of the Invoice class? The invoice class is not the aggregate root.</p>\n\n<p>I realise it is not \"acceptable\" for a none aggregate root from another aggregate to access the Customer class, however I wandered if this also applies to the Application Service.</p>\n\n<p>I am talking from the perspective of a DDD purist.  I realise that DDD is not always the best choice to solve a problem - I am just trying to improve my thinking in this specific area.</p>\n\n<p><strong>Update</strong></p>\n\n<p>Please see the code below:</p>\n\n<pre><code>public class InvoiceService\n{\n\n Invoice Invoice;\n\n public InvoiceService(Invoice invoice)\n {\n   Invoice=invoice;\n }\n\n public void DoSomething()\n {\n   Invoice.DoSomething();\n }\n\n}\n</code></pre>\n\n<p>I am asking if it is \"acceptable\" to access the Invoice domain object from an application service even though it is not an aggregate root i.e. must all Invoice actions go through Customer.Invoices instead of Invoices.</p>\n\n\nAssistant:",
        "golden_answer": " <p>TLDR; <strong>\"non-aggregate root\" is not the same as \"component of another aggregate\"</strong></p>\n\n<p>Your invoice class might not be an aggregate root, but not because it is component of the Customer aggregate (or at least it should not be a component). It is (or should be) a simple domain object, and when it is (currently) not an aggregate (root), then because it does not consist of more than one class and does not consist of other components. </p>\n\n<p>Just because there is 1:n association between customers and invoices does not make invoices automatically components of a customer. You obviously have requirements to deal with invoices as objects on its own, without loading them through a customer repository first, that proofs this point.</p>\n\n<p>So by seeing an invoice as a simple domain object, accessing such an object from some service layer is pretty fine, even from a DDD purists point of view.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Definitions used by this question:</p>\n\n<ul>\n<li>'functional' <code>Try</code> is what <a href=\"https://github.com/lambdista/try\" rel=\"noreferrer\">https://github.com/lambdista/try</a> is. <code>Success</code> and <code>Failure</code> are subclasses of <code>Try</code>. Exceptions aren't thrown by the called function.</li>\n<li>'rx' <code>Try</code> is what <a href=\"https://github.com/aol/cyclops/wiki/Try-:-functional-exception-handling-for-Java-8\" rel=\"noreferrer\">https://github.com/aol/cyclops/wiki/Try-:-functional-exception-handling-for-Java-8</a> is. Exceptions are thrown by the called function.</li>\n</ul>\n\n<p>Under what scenarios would one style be more beneficial than the other?</p>\n\n<p>Of course, if the called function throws an exception, it's easier to use the 'rx' style. OTOH, it's still possible to wrap that function with another function that follows the 'functional' style.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Both of those are \"functional-style\" error handling.  The only difference is the latter lets you specify that it will handle certain exceptions functional-style while leaving the rest to be handled imperative-style, while the former handles <em>all</em> exceptions functional-style, forcing the programmer to rethrow any unhandled exceptions manually.</p>\n\n<p>The main drawback of imperative-style exception handling is that exceptions only propagate one way:  straight up the call stack.  You have either the option to handle it there in the call stack or let it propagate.  It also forces certain variable scoping choices on you.  That is very limiting semantics.</p>\n\n<p>In contrast, <code>Trys</code> are very flexible.  They are regular objects that can be stored, shared, aggregated, chained, and handled wherever you like, not just wherever the call stack happened to be when the error occurred.  It can take a while to see the usefulness of this.</p>\n\n<p>One recent example from work was we had a list of servers, and wanted to find the first one with a working connection.  The API we were working with threw an exception upon an attempt to connect to a down server.  The developer who wrote the first draft of this code had a lot of problems with boundary conditions and variable scope due to using try-catch blocks, and asked for help.  <code>Trys</code> made the task very simple by lazily mapping the list of servers to a list of <code>Trys</code>, then finding the first <code>Success</code>.</p>\n\n<p>I encourage you to give these libraries a <em>try</em> (pun intended) and see how they can simplify complex error handling.  Since learning about <code>Trys</code>, I haven't seen a case yet that they haven't simplified.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm part of a small team that currently uses an Access database for scheduling a larger team's availability. This has presented some issues with corruption of the Access database. Additionally, I want to implement additional functionality over time.</p>\n\n<p>I've set out to create an application for the 4-5 of us to use that will solve the concurrent database issue, as well as give the team more functionality.</p>\n\n<p>Since this is a shared network drive, I won't have access to SQL Server (from my guess). I thought maybe a web service would be the way to go, but I don't really want to front the bill for this. Additionally, when I eventually leave the team I don't want to maintain this.</p>\n\n<p>Some ideas I've come up with is an application written in C# that acts as the front-end with SQLite embedded as the back-end. However, I've spent days trying to get the Entity Framework to work with SQLite and am at the point of giving up.</p>\n\n<p>I'm trying to decide what else I can do to solve this issue. Is there another technology I can use?</p>\n\n\nAssistant:",
        "golden_answer": " <p><a href=\"https://support.office.com/en-us/article/split-an-access-database-ef500182-5ebd-46af-8db9-fd450ba49372\" rel=\"nofollow noreferrer\">Splitting the Access database</a> is an officially-supported thing for precisely this scenario. It turns into Front-End and Back-End files. The front-end is kinda like the application part, and the back-end is the database. You distribute a copy of the front-end to each machine and keep the back-end on the shared drive.</p>\n\n<p>Whether to bite the bullet and make an full app really depends on your situation. If they do not ordinarily have access to a developer, and you think you might move on at some point, then probably continuing with Access is the better choice.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>According to the commonly used TDD strategy, to implement something, you write a test that fail the code first, write the simplest code, refactor, and then repeat. I am trying to imagine this scenario with implementing a flexible length list (e.g. <a href=\"http://msdn.microsoft.com/en-us/library/6sh2ey19.aspx\" rel=\"nofollow\"><code>List&lt;T&gt;</code></a> in .net.</p>\n\n<p>Let's say I first test by inserting one item. Probably the simplest way to achieve this is by backing the list with an array with length 1 (which will pass the test). Nothing to refactor here, so I'll go ahead and write another test that insert 2 items. I'll simply change the array length to 2, and the test pass again. Then I write test with 3 items, expand the array, and repeat again. I will end up forever doing this until I'm tired.</p>\n\n<p>Is this an exception to the fail-test-first strategy? Or am I missing something in the above strategy?</p>\n\n<p>PS: <a href=\"http://weblogs.asp.net/gunnarpeipman/archive/2010/09/09/experiment-list-lt-t-gt-internals-and-performance-when-adding-new-elements.aspx\" rel=\"nofollow\">The actual implementation</a> backs the list with an array which grows twice as large every time the number of elements exceed the array length.</p>\n\n\nAssistant:",
        "golden_answer": " <p>\"Write the most simple thing that could possibly work\" is <em>one</em> principle, but it is not the only one, and it isn't always the most important one. \"Don't repeat yourself\" is arguably more important, and repeating yourself the way you describe is definitely not justified by \"most simple\". As soon as you notice repeating yourself, you should switch to a solution that can handle more than one list length. </p>\n\n<p>Note that this solution may very well still be a fixed-length array if you know that you will not need more than a given number of elements as per the requirements. Alternatively, it might be a dynamic structure that grows with the demands made on it. But in no case is it useful to climb the latter of integers one by one - not least because you can't possibly reach the top.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Our project head is a genius software architect, a gentle and considerate person in general, a geek by nature and delicate by voice. But, at times, we (my teammates and I) differ in opinions -- especially of software architecture issues, system design issues, UI issues, etc., with our leader.</p>\n\n<p>When and how (if ever) should we express the difference in opinions?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Suppose you think your boss is wrong. You have three options</p>\n\n<ul>\n<li>do what he says and end up frustrated thinking that you do something stupid - not very good long term</li>\n<li>tell him he's an idiot - he'll either ignore it or you get communication problems - gets you nothing or hurts you.</li>\n<li>tell him that you have <strong><em>specific concerns</em></strong> about the ideas he proposes and <strong><em>explain those concerns</em></strong> - any good boss will explain his position and then you can get to a decision that is good for the business. It's quite likely you'll see that his idea is better than yours and you've been ignoring something very important.</li>\n</ul>\n\n<p>Always think of the outcome. In most cases you don't want to be right for the sake of being right, you just have to do good job. The third option helps achieve that.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I just read a chapter in a programming book about Dynamic types. Although they are quite neat I cant think of a single real world example where I would use them. Does anyone here actually use them and for what?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I've used <code>dynamic</code> to evaluate logical expressions represented in an object graph, where using the <code>dynamic</code> keyword allowed me to largely ignore the types of the operands.</p>\n\n<p>For example, if my expression graph was an arithmetic expression with a multiplication operator (e.g. <code>12 * 1.3</code>), I would use <code>dynamic</code> to store the operands <code>12</code> and <code>1.3</code>, and <code>dynamic</code> again to catch the result from the multiplication.</p>\n\n<p>Without <code>dynamic</code> I would be forced to deal with concrete numeric types (<code>int</code>/<code>long</code>/<code>decimal</code>/<code>float</code>, etc...) and the resulting code bloat. My <code>dynamic</code> solution requires very little code and is much easier to grasp and maintain.</p>\n\n<p>My initial idea was to turn my logical expressions into snippets of Python or Ruby, then run these snippets through IronPython or IronRuby to evaluate the result. It struck me all I required from Python or Ruby was their dynamic typing, so I was very happy to see that <code>dynamic</code> affords Python-like typing for C#. </p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>Over the years I've constantly heard horror stories, had people say \"Real Programmers Dont Use VSS\", and so on. BUT, then in the workplace I've worked at two companies, one, a very well known public facing high traffic website, and another high end Financial Services \"Web-Based\" hosted solution catering to some very large, very well known companies, which is where I currently Reside and everything's working just fine (KNOCK KNOCK!!).</p>\n\n<p>I'm constantly interfacing with EXTREMELY Old technology with some of these financial institutions.. OLD LIKE YOU WOULDN'T BELIEVE.. which leads me to the conclusion that if it works \"LEAVE IT\", and that maybe there's some value in old technology? at least enough value to overrule a rewrite!? right??</p>\n\n<p>Is there something fundamentally flawed with the underlying technology that VSS uses? I have a feeling that if i said \"someone said VSS Sucks\" they would beg to differ, most likely give me this look like i dont know -ish, and I'd never gain back their respect and my credibility (well, that'll be hard to blow.. lol), BUT, give me an argument that I can take to someone whose been coding for 30 years, that builds Platforms that leverage current technology (.NET 3.5 / SQL 2008 R2 ), write's their own ORM with scaffolding and is able to provide a quality platform that supports thousands of concurrent users on a multi-tenant hosted solution, and does not agree with any benefits from having Source Control Integrated, and yet uses the Infamous Visual Source Safe.</p>\n\n<p>I have extensive experience with TFS up to 2010, and honestly I think it's great when a team (beyond developers) can embrace it. I've worked side by side with someone whose a die hard SVN'r and from a purist standpoint, I see the beauty in it (I need a bit more, out of my SS, but it surely suffices). So, why are such smarties not running away from Visual Source Safe? surely if it was so bad, it would've have been realized by now, and I would not be sitting here with this simple old, Check In, Check Out, Version Resistant, Label Intensive system. But here I am... </p>\n\n<p>I would love to drop an argument that would be the end all argument, but if it's a matter of opinion and personal experience, there seems to be too much leeway for keeping VSS.</p>\n\n<p>UPDATE: I guess the best case is to have the VSS supporters check other people's experiences and draw from that until we (please no) experience the breaking factor ourselves. Until then, i wont be engaging in a discussion to migrate off of VSS..</p>\n\n<p>UPDATE 11-2012: So i was able to convince everyone at my work place that since MS is sun downing Visual Source Safe it might be time to migrate over to TFS. I was able to convince them and have recently upgraded our team to Visual Studio 2012 and TFS 2012. The migration was fairly painless, had to run analyze.exe which found a bunch of errors (not sure they'll ever affect the project) and then manually run the VSSConverter.exe. Again, painless, except it took 16 hours to migrate 5 years worth of everything.. and now we're on TFS.. much more integrated.. much more cooler.. so all in all, VSS served it's purpose for years without hick-up. There were no horror stories and Visual Source Save as source control worked just fine. so to all the nay sayers (me included). there's nothing wrong with using VSS. i wouldnt start a new project with it, and i would definitely consider migrating to TFS. (it's really not super difficult and a new \"wizard\" type converter is due out any day now so migrating should be painless). But from my experience, it worked just fine and got the job done. </p>\n\n\nAssistant:",
        "golden_answer": " <p>The fundamental problem with technologies like Access and SourceSafe is that they are <em>shared-file solutions.</em>  This makes them vulnerable to catastrophic crashes (yes, it's happened to me before).  </p>\n\n<p>That said, if you're working in a <em>very small</em> developer environment, SourceSafe works perfectly fine.  Checkouts are exclusive by default (unless you enable <a href=\"http://msdn.microsoft.com/en-us/library/f16a0cw0%28v=vs.80%29.aspx\">\"multiple checkout\" mode</a>, which I've never used), which means only one person can work on a file at any given moment, but if you're all in one room, that's not an issue.</p>\n\n<p>Everyone should be required to check in when they leave for the day.  The person who doesn't check in and then takes a day off gets to buy everyone donuts when he gets back.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm curious on the best way to handle lookup-type codes that can be shared across bounded contexts.  For instance, state codes, or business-specific type codes that might be used in more than one bounded context.  Does it make sense to have a single database for these, with an api in front to fetch the code lists, or duplicate them per each bounded context that needs them?  Furthermore, this has me wondering what to do with referential integrity if the first option is desired.  Many of the codes aren't using a natural key but instead a surrogate (auto-generated by the database) id.  </p>\n\n\nAssistant:",
        "golden_answer": " <p>DDD is great but it doesn't go as high as it could. Above DDD we can imagine business roles that have business responsibilities.</p>\n<p>One such business responsibility is managing records as the authority of reference  e.g. if we accept an order, we can give it an ID. There is a certain department responsible for accepting or rejecting orders, keeping the list of orders as the authority of record for them, and no one else should be allowed to accept an order, issue an order id, or claim they are the authority for the list of accepted orders.</p>\n<p>Thus, when we think about multiple bounded contexts we should try to realize that the intention is to bring (maintainable) automation to the jobs of various business roles and their business responsibilities  not merely to separate concerns in order to address monolithic automation designs.</p>\n<hr />\n<blockquote>\n<p>...business-specific type codes that might be used in more than one bounded context.</p>\n<p>Many of the codes aren't using a natural key but instead a surrogate (auto-generated by the database) id</p>\n</blockquote>\n<p>Maintaining your business codes is probably a business function that some department will (ought to) have responsibility for. You should to ask questions about what will happen if each bounded context maintains their own version of these codes? One bounded context may add a code that other's haven't yet added. Is that an issue? Is there a department that is responsible for this (could be IT, I suppose), and how would they feel about maintaining codes centrally vs. across business contexts?</p>\n<blockquote>\n<p>Does it make sense to have a single database for these, with an api in front to fetch the code lists, or duplicate them per each bounded context that needs them?</p>\n</blockquote>\n<p>You're asking whether to provide a normalized implementation of the codes, or  duplicate them in multiple bounded contexts.</p>\n<p>Ideally, we would manage these codes in one place. At minimum, I would say you might cache them across bounded contexts rather than merely duplicating them, and they should be managed (new ones added, old ones obsoleted) centrally.</p>\n<blockquote>\n<p>Furthermore, this has me wondering what to do with referential integrity if the first option is desired.</p>\n</blockquote>\n<p>Perhaps you should not delete business codes that are potentially used by other bounded contexts. You can instead obsolete them, and even provide a forwarding or replacement code  this as part of the API around the management of the business codes. So, the API would speak to what codes, the business intention, the definition of the code, the policies &amp; rules associated with the codes, the status of each code (current or not), and when not current: the replacement(s) and/or clarifications (preferred subcodes).</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I work for a consulting company and we're doing a software contract for a big company.  Part of what we are doing for them is helping them figure out what they want, which means the requirements are pretty much in continuous update mode.  We're busy speccing out version 3 while working on version 2 while fixing bugs in version 1.  Right now we're using Jira in &quot;scrum&quot; mode only not really.  We create Jira issues for bugs &amp; improvements, move the high-priority issues into the current &quot;sprint&quot;, and then as fires arise we move them into the current &quot;sprint&quot; as well (this has happened on every &quot;sprint&quot; in the last 18 months).  We release once a week unless they hit a bug that causes enough problems that they need it fixed (and thus released) faster.  So yeah, we're not really doing scrum, but it makes management happy to think this is an agile/scrum project.  Management may not understand software, but they know agile is magic and makes everything better.</p>\n<p>Our process goes like this: they create the issue in state &quot;To Do&quot; and assign it to me.  I move it to &quot;In Progress&quot;, make the fix or add the improvement, and move it to &quot;Internal Test&quot;.  When it's time to release, we test the issues in &quot;Internal Test&quot; again and if all is well we release the software and move the completed issues to &quot;External Test&quot; and assign it to an engineer at the client company.  They test it, verify the fix, and then move it to &quot;Done&quot; (or assign it back to me if it's not right).</p>\n<p>It works pretty well as an issue tracking system, with two challenges:</p>\n<ol>\n<li>They have no incentive to test our Jira issues.  Stuff sits in &quot;External Test&quot; for many months.</li>\n<li>They want metrics to show how close we are to being complete.  How do you do this while you're in the middle of creating the requirements, and thus &quot;complete&quot; is a moving target?  Dunno.</li>\n</ol>\n<p>A friend of mine said our process sounded more like Kanban, and today we tried creating a Kanban board in Jira, and now that I'm an expert on Kanban (I watched more than one YouTube video) I can see why my friend suggested it.  It definitely matches our workflow better.</p>\n<p>However, the two problems we encountered with scrum (stuff never gets tested, no metrics to show when project will be complete) seem to exist just as much with Kanban.</p>\n<p>Are there any methodologies that work well when you have two disparate companies trying to work on the same project?</p>\n\n\nAssistant:",
        "golden_answer": " <p>Scrum and Kanban aside, the fundamental problem you are facing isn't unique to your situation. It's quite common when there's a hand-off between the development organization and another organization. In your case, it's an external customer who is receiving the software, testing it, and providing feedback. I've seen similar things happen with an independent verification and validation or system integration team as well.</p>\n<p>The general solution is to move their process outside of your process. That is, your development team should produce a high-quality product that is highly likely to meet their needs and not have blocking defects.</p>\n<p>Whenever the client carries out their work, any feedback would go onto your backlog for future consideration. In a Scrum approach, it would be ordered with everything else in the Product Backlog, refined, and eventually brought into a Sprint. In a Kanban approach, you wouldn't have Sprints, but you'd still order the work and refine it as it gets closer to the top.</p>\n<p>The target goal would be to be able to address the feedback at your leisure. You shouldn't have any feedback from client reviews that are &quot;drop everything and do this now&quot;, which would allow you to take the time to order it and refine it. If you do have critical issues coming out of the client tests whenever that happens, it may be worthwhile understanding why it was a critical issue and what changes need to be made to prevent similar things from happening in the future.</p>\n<p>The end result is that Done and all of the associated metrics happen after your development organization designs, implements, integrates, tests, and verifies that a solution is likely to be correct. Your agile approaches should help you to continually refine your understanding of the customer needs and what is necessary to have work be Done.</p>\n<p>The incentive for the other organization to conduct their testing and carry out their feedback is that is how they know when you are done and can stop paying you to develop the system, or perhaps switch from a development-mode contract to a lighter support-mode contract. Until they accept the solution and their feedback is that no additional work is necessary (or doing more work would cost more than the value the work would deliver), then you'd continue to burn through your backlog and eventually get through the musts into the shoulds and coulds.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I wanted to know how do people generically think of, in a data base table:</p>\n\n<ul>\n<li><p>Columns <del>that people are expected to use mostly for grouping</del> expectable of <em>groupability</em>.</p></li>\n<li><p>Columns <del>that people are expected to use mostly for actual business data</del> that not.</p></li>\n</ul>\n\n<p><del>For instance, let us consider a quick example of a school. I would say the <em>nth</em> grade might be a column used mostly for grouping, while the mark, qualification, assessment whatever, I would say that is a column used mostly for actual business data. Which would be a generic name for those kind of data base columns?</del></p>\n\n<p><strong>Annex</strong></p>\n\n<p>For instance, let us consider a quick example of a school. I would say the <em>nth</em> grade might be a column used mostly for grouping, together with the mark, qualification, assessment whatever, but I would not say their passwords' MD5 hashes (I guess if the context was a consumer application where those students would log in) will be ever used for grouping. Which would be a generic name for those kind of data base columns? Is there a concept for column cardinality or grouping-ness?</p>\n\n\nAssistant:",
        "golden_answer": " <p>They are all <em>\"actual business data\"</em>, save surrogate PK (and FKs that point to them) that can be used for grouping and searching but are meaningless business-wise. All other columns can also be used for grouping and searching and they still are <em>\"actual business data\"</em>.</p>\n\n<p>Not everything has an specific name or can be pigeon-holed into any arbitrary taxonomy.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>me and a friend are working on a project, and we are both doing seperate things (he does UI, I do some data structure), and his code relies on my code. Right now we have a master, a develop and 2 feature branches (one for UI and one for data structure). How can he test his UI with my commits, without making one huge mess out of the commit history and without committing to develop (since both features are not done yet)?</p>\n<p>Sorry if it's a beginner question, quite new to git!</p>\n\n\nAssistant:",
        "golden_answer": " <p>There is no good way to test code when such a dependency exists. This leaves two solutions:</p>\n<ul>\n<li>resolve the dependency. Merge the data structure stuff first before working on the UI.</li>\n<li>break the dependency. Introduce some interface that decouples UI and data so that they can be worked on truly independently. For testing, you could introduce mock implementations for those interfaces.</li>\n</ul>\n<p>There's another alternative that works quite well when you're only two persons: just work on everything together in a pair-programming session. That might sound slow and <em>inefficient</em>, but can be very <em>effective</em> since everyone understands all the code, and problems are spotted earlier. In my experience, doing pair programming from the start ends up being much faster than trying to resolve a giant merge of different feature branches.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have an array of unsorted positive real numbers. I need to create a frequency distribution by their ranges.</p>\n\n<p>The simplest approach goes like this</p>\n\n<pre><code>for num in numbers\n if (num &gt; 0 and num &lt; 10) a++\n elseif (num &gt;= 10 and num &lt; 20) b++\n ...\n else z++\n\nreturn [a, b, c, ..., z]\n</code></pre>\n\n<p>Is there any faster or more efficient way to do this? Or this is the best in this case?</p>\n\n\nAssistant:",
        "golden_answer": " <p>There are a lot of approaches, but I'm going to start by saying that most of them fall into the realm of micro-optimizations.</p>\n\n<p>The basic problem is O(N x M), where N is the number of input values and M is the number of ranges. </p>\n\n<p>In the worst case, you could have M equal to or larger than N, but that's unlikely. In all of the bucketing code that I've written, M tends to be quite small: around a half-dozen to a dozen values. </p>\n\n<p>In that case, the overhead of repeated <code>if</code> tests is small, and the problem is essentially O(N) (where the constant is the number of tests). You should be able to process several million input values per second (you'll have to run your own tests to see what \"several\" means).</p>\n\n<p>If M is large, then there are several optimizations that you can make:</p>\n\n<ul>\n<li>As <em>Killian Foth</em> said, if the ranges are equal-sized, simply divide by the spacing. This reduces the problem to O(N) (although with a different constant that may or may not be less than the repeated tests, depending on the low-level cost of branching versus division).</li>\n<li>If the range of your input values is constrained, use a counter for each input value and then sum those counters afterward. For example, if you know that each of your input values will be in the range 0-999, just allocate a thousand-element array. How big an input value you can handle depends on how much RAM you have. This is also O(N), with perhaps the lowest constant.</li>\n<li>If you have a lot of arbitrarily sized ranges, then you could turn them into a binary tree. This will give you O(N log M).</li>\n<li>If your input values span a very wide range, then perhaps you can change the problem to use bucketing by logarithm (eg: 0 -> 0-9, 1 -> 10-99, 2 -> 100-999, and so on). This will also be O(N), but the constant will be huge as logarithms are an expensive operation.</li>\n</ul>\n\n<p>In my opinion, the best approach is to use the simple iterative-test implementation unless you have a very good reason not to. One thing that I <em>would</em> do, however, is to implement using a table of ranges rather than explicit tests. I believe that the latter is more prone to bugs, especially if you need to change the ranges.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I would like to know how I can use a <code>switch</code> statement with <code>enum</code> values for the following scenarios:</p>\n\n<p>I am making a small program for a flight reservation system. The program is meant to enter certain details about the passenger. The program also restricts the user to choose destinations other than the following 3 destinations. Once destination is chosen, the flight number  is supposed to be automatically assigned. \nThe user will choose one of three destinations and program will assign an appropriate Flight No for the passenger.</p>\n\n<p>The Flight No will be assigned as below:</p>\n\n<pre><code>     Destination                    Flight No.\n      London                            201\n      Frankfurt                         233\n      Berlin                            241\n</code></pre>\n\n<p>So let's say I make an <code>enum</code> of destinations, then how can I use switch statement here? This isn't a homework. I am doing it just for the sake of exploring.</p>\n\n\nAssistant:",
        "golden_answer": " <p>Your scenario doesn't sound like an appropriate use for an enumeration. Also, unless the values never change, this should be data driven.</p>\n\n<p>If the values never change, then a key-value pair is more appropriate where the destination is the key and the flight number is the value. This would eliminate any need for a switch statement, as the key can be used to directly and efficiently locate the value.</p>\n\n<p>if you really want to use an enum, then the switch statement in C# would be something like:</p>\n\n<pre><code>int flightNumber;\nDestination selection = // some value collected from user input;\n\nswitch( selection )\n{\n    case Destination.London:\n        flightNumber = 201;\n    break;\n\n    // etc.\n}\n</code></pre>\n"
    },
    {
        "prompt": "\n\nHuman: <p><a href=\"https://i.stack.imgur.com/buTEX.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/buTEX.png\" alt=\"architecture\"></a></p>\n\n<p>We have three layers in our application. Service layer to provide an external API. BO layer for our business logic, and a DAO layer for our database connection. </p>\n\n<p>Let's say every time we update a File, we also want to change something in the Folder, for example 'last modified date'.\nThis needs to be done in a transaction. Either it succeeds and both File and Folder are edited. Or there's a failure and the transaction gets rolled back so both objects are in the previous state.</p>\n\n<p>The \"Edit a folder when a file get edited\"-action is purely business logic. So this would mean it belongs in the BO-layer.\nHowever, we use Objectify for our Database, so to start a transaction we need to call ofy().transact(...).\nIf we call this function in the BO layer, this breaks our design as there will be Database specific calls (Objectify) in our Business layer.</p>\n\n<p>What would be a clean solution for this problem?</p>\n\n\nAssistant:",
        "golden_answer": " <p>How you cut your transactions is indeed business logic. So let your DAO layer provide a db framework independent API for the <code>transact</code> method you mentioned (and probably for things like <code>commit</code> and <code>rollback</code>). Then you can use it from your BO layer without making it dependent from your database or your db framework.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>When teaching recently about the Big vs. Little Endian battle, a student asked whether it had been settled, and I realized I didn't know. Looking at the <a href=\"http://en.wikipedia.org/wiki/Endianness\">Wikipedia article</a>, it seems that the most popular current OS/architecture pairs use Little Endian but that Internet Protocol specifies Big Endian for transferring numeric values in packet headers. Would that be a good summary of the current status? Do current network cards or CPUs provide hardware support for switching byte order?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I'd argue that it's not so much won as ceased to matter. ARM which makes up basically all of the mobile market is bi-endian (oh, the heresy!). In the sense that x86 basically \"won\" the desktop market I suppose you could say that little endian won but I think given the overall code depth (shallow) and abstraction (lots) of many of today's applications, it's much less of an issue than it used to be. I don't recall endianness really coming up in my Computer Architecture class.</p>\n\n<p>I suspect that many developers aren't even aware of endianness or why it's important. Because for the vast (and I mean <strong>vast</strong>) majority it's utterly irrelevant to their daily working environment. This was different 30 years ago when everyone was coding much closer to the metal as opposed to manipulating text files on a screen in fancy and dramatic ways.</p>\n\n<p>My general suspicion is that Object Oriented Programming was the beginning of the end of caring about endianness since the layers of access and abstraction in a good OO system hide implementation details from the user. Since implementation includes endianness, people got used to it not being an explicit factor.</p>\n\n<p>Addendum: zxcdw mentioned portability being concern. However, what has arisen with a vengeance in the last 20 years? Programming Languages built on virtual machines. Sure the virtual machine endianness might matter but it can be made very consistent for that one language to the point where it's basically a non-issue. Only the VM implementors would even have to worry about endianness from a portability standpoint.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I had a friend in college who programmed something that worked the first time, that was pretty amazing.  But as for me, I just fire up the debugger as soon as I finally get whatever I'm working on to compile - saves me time (kidding of course, I sometimes hold out a little bit of hope or use a lot of premeditated debug strings).</p>\n\n<p>What's the best way to approach the Dijkstrain ideal for our programs? </p>\n\n<p>-or-</p>\n\n<p>Is this just some sort of pie-in-the-sky old fools quest for greatness applicable only to finite tasks that no one should hope for in our professional lives because programming is just too complex? </p>\n\n\nAssistant:",
        "golden_answer": " <p>Make small components with their own standalone test harnesses that demonstrate that each piece works. Getting a program to work the first time is just a question of throwing together components (I mean \"pieces,\" I'm not talking about some particular component technology) that already work.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm working on a Meteor app which lets users create events and assign them crew members. I've played around with MongoDB before and made some experiences along the way, where for instance my first attempt went overboard with embedded objects and quickly became sluggish and hard to maintain. Several people therefore suggested to try a more traditional design approach and that's what I've done this time.</p>\n\n<p>I've split my collections up with manual refs in mind,</p>\n\n<p><strong>Events</strong></p>\n\n<pre><code>_id : ObjectID,\npropA: \"Some prop\",\npropB: \"Some other prop\",\nemployees: [\n    {employee_id: ObjectID, crew_id: ObjectID},\n    {employee_id: ObjectID, crew_id: ObjectID},\n]\n</code></pre>\n\n<p><strong>Employees</strong></p>\n\n<pre><code>_id : ObjectID,\npropA: \"Some prop\",\ncrew_id: ObjectID\n</code></pre>\n\n<p><strong>Crews</strong></p>\n\n<pre><code>_id : ObjectID,\npropA: \"Some prop\"\n</code></pre>\n\n<p>The reasoning is that the events collection will become quite substantial during the applications life cycle and thus I consider duplication to be a bad thing.\nAnother noteworthy feature is that an employee must belong to a certain crew, but on an actual event can work in any crew. </p>\n\n<p>Intially I was quite happy with this design, but I have however found some problems which has lead me here. </p>\n\n<p>1) When listing an event I have to manually join refs in order to show the actual properties of the employees and crews (such as name), it's a bit tedious but what worries me most is performance: Rather then running one query I have to run three (first get the event, then loop trough the employee array and then join employee with the Employee collection and finally join the crew with the Crew collection).</p>\n\n<p>2) My biggest problem so far though is what I believe is known as deep querying. Before adding an employee to an event I have to know if he/she is already assigned, thus requiring to query the Events collection for an Event with a given ID and also find check if the given Employee ID exists in the employee array. So far I've been unable to do this in a single query.</p>\n\n<p>So my question boils down to this. Is my design fine as it is or should I change it given my use cases? Or alternatively, if I keep my current design how should I tackle problem 1 and 2 (that is, manual joins and refs are fine. But is performance a real possible showstopper down the line?).</p>\n\n\nAssistant:",
        "golden_answer": " <p>Why are you using a non-relational database in this case?</p>\n\n<p>You said:</p>\n\n<blockquote>\n  <p>When listing an event I have to <strong>manually join</strong> refs in order to show the actual properties of the employees and crews (such as name), it's a <strong>bit tedious</strong> but what <strong>worries me most is performance</strong>:</p>\n</blockquote>\n\n<p>and </p>\n\n<blockquote>\n  <p>My biggest problem so far though is what I believe is known as <strong>deep querying</strong></p>\n</blockquote>\n\n<p>[<em>emphasis added</em>]</p>\n\n<p>You already have some strong indicators that a non-relational database is not the right fit for your needs.  Use a relational database instead.  Changing the schema in this case, won't compensate for issues within the toolset.</p>\n\n<p>Try your design out with a relational database and see if the issues go away.  That will provide the proof you need that you haven't picked the right tool to use in this case.</p>\n\n<hr>\n\n<p>In a comment, you added that your stuck with this particular environment and are seeking alternative schema designs.</p>\n\n<p>From what I have seen, the best way to compensate in this case is to denormalize all of your tables.  Instead of 3 tables, you'll have 1 table where you lay out the crew and the employees per event.  </p>\n\n<p>That does raise some challenges with making sure you don't double assign employees, but having a status flag for the event should help control for that.  Essentially you'll query to see if employee ABC is already assigned to an event (or crew) that is still active.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>The CPython implementation seems to have the same modules written both in C (e.g., <a href=\"https://github.com/python/cpython/blob/main/Modules/_datetimemodule.c\" rel=\"noreferrer\"><code>datetime</code> in <code>.c</code></a>) and also in .py for the same module (e.g., <a href=\"https://github.com/python/cpython/blob/main/Lib/datetime.py\" rel=\"noreferrer\"><code>datetime</code> in <code>.py</code></a>).</p>\n<p>My question is which version is used when I use datetime in my .py file when using the CPython interpreter? And why are there two module versions in the first place?</p>\n\n\nAssistant:",
        "golden_answer": " <p>It's certainly plausible that moving definitions to a new translation unit has meant the optimiser couldn't do as well.</p>\n<p>You can <code>#include</code> whatever files you like, so you can re-create the old structure as seen by the compiler while keeping the new files.</p>\n<p><strong>beatles.h</strong></p>\n<pre><code>class beatles { ... }\n</code></pre>\n<p><strong>beatles.cpp</strong></p>\n<pre><code>#include &quot;john.cpp&quot; // transitively #includes &quot;john.h&quot;\n#include &quot;paul.cpp&quot;\n#include &quot;george.cpp&quot;\n#include &quot;ringo.cpp&quot;\n\n...\n\n// Implementation of beatles\n</code></pre>\n<p><strong>test_john.cpp</strong></p>\n<pre><code>#include &quot;john.h&quot;\n</code></pre>\n<p>You will have to be careful that you don't try to link <code>beatles.o</code> and <code>john.o</code> in the same executable.</p>\n<p>This structure will surprise some people, so you  probably want a big warning at the top of <code>beatles.cpp</code> along the lines of</p>\n<blockquote>\n<p>IMPORTANT! We found an unacceptably long (yyy seconds wall clock time) performance degradation splitting these translation units (under compiler(s) foo x.y.z bar h.j.k)</p>\n<p>Do not rearrange unless you can show they all now have better optimisers</p>\n</blockquote>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I have a class which has an inner (nested) class. I have shown this relationship between the two classes in my class diagram. However, I am also using the inner class within the outer class... do I show another relationship for this or is the containment relationship enough?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I would say no. You don't have to specify another relationship.</p>\n\n<p>Inner classes AFAIK are implied to be used by their container. That's why they're an inner class. No one else needs to know about this class and no one has a use for it. This inner class is separate from it's containing object because it's different from the containing object, yet the container has an explicit need for this class and only this object has this need. Therefore, specifying a relationship between the containing class and inner class is enough to inherently imply these two classes are communicating with each other.</p>\n\n<p>If the container class and inner class WEREN'T communicating with each other or worse yet, another object was calling directly to the inner class would show a clear design flaw of ever having this class as an inner class because its design purpose of being an inner class was not being correctly fulfilled.</p>\n\n<p>If you wanted to go deeper in your design at some point you'd specify how the containing class is using the inner class and not just specify the container is using this inner class.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>C is a static-typed language that is not type-safe, because pointers(<code>void *y</code>) let you do pretty much anything you like, even things that will crash your program.</p>\n\n<p>GO is also a static typed language</p>\n\n<p>Despite, GO has pointers(<code>var y *int</code>), it is still considered type-safe language.</p>\n\n<hr>\n\n<p>Question:</p>\n\n<p>Considering GO pointers,</p>\n\n<p>Why GO language is called type-safe language?</p>\n\n\nAssistant:",
        "golden_answer": " <p>There are a few differences between Go and C that makes the former at least more type safe:</p>\n<ol>\n<li><p>Unless you muck about with the <a href=\"https://golang.org/pkg/unsafe/\" rel=\"nofollow noreferrer\">unsafe</a> package, you're not going to crash a Go program (in the sense that it won't do something that causes the OS to kill it). You may cause it to panic, but this is not the same thing as a crash (and it is recoverable).</p>\n</li>\n<li><p>Go does not have pointer arithmetic (<a href=\"https://tour.golang.org/moretypes/1\" rel=\"nofollow noreferrer\">source</a>) -- although it does have null reference of sort called <a href=\"https://stackoverflow.com/questions/35983118/what-does-nil-mean-in-golang\"><code>nil</code></a>.</p>\n</li>\n<li><p>Go's <code>void*</code> equivalent, <code>interface{}</code>,  is cast in a more safe manner using <a href=\"https://tour.golang.org/methods/15\" rel=\"nofollow noreferrer\">type assertions</a>, which will not just crash and permit safer type testing, or type switches.</p>\n</li>\n</ol>\n<p>Basically Go and languages with similar mixes of declared types and runtime types (C# and Java) are type safe because they supplement an unsound type system with a runtime type system that turns type errors that would have caused crashes into runtime exceptions.</p>\n<p>C has an unsound type system and no runtime system that would prevent unsafe behavior.</p>\n<p>Some languages, like <a href=\"https://en.wikipedia.org/wiki/ATS_(programming_language)\" rel=\"nofollow noreferrer\">ATS</a>, also like runtime protections but are type-safe because their type systems make illegal operations unsayable.</p>\n<p>Basically: <em>type safe</em> means the language won't let you do anything illegal.</p>\n<p>Sometimes the runtime stops you (like in dynamic languages like Python).</p>\n<p>Sometimes the type system stops you.</p>\n<p>For Go it is a combination of both.</p>\n"
    },
    {
        "prompt": "\n\nHuman: <p>I'm currently trying to make a case for adopting dependency management for builds (ala Maven, Ivy, NuGet) and creating an internal repository for shared modules, of which we have over a dozen enterprise wide.  What are the primary selling points of this build technique?  The ones I have so far:</p>\n\n<ul>\n<li>Eases the process of distributing and importing shared modules, especially version upgrades.</li>\n<li>Requires the dependencies of shared modules to be precisely documented.</li>\n<li>Removes shared modules from source control, speeding and simplifying checkouts/check ins <sub>(when you have applications with 20+ libraries this is a real factor)</sub>.</li>\n<li>Allows more control or awareness of what third party libs are used in your organization.</li>\n</ul>\n\n<p>Are there any selling points that I'm missing?  Are there any studies or articles giving improvement metrics?</p>\n\n\nAssistant:",
        "golden_answer": " <p>I'm not 100% sure on the positives. Here's a few negatives </p>\n\n<ol>\n<li><p>You often end up adding dependencies to 3rd party servers/endpoints that might\nnot be stable.</p>\n\n<p>I've had it happen with bower that the repo of some dependencies\nwas deleted or moved. So a new dev comes along, clones my repo, types \n<code>bower install</code> and gets errors for un-accessible repos. If instead I\nhad checked in the 3rd party code into my repo that problem disappears.</p>\n\n<p>This is solved like the OP suggests if you're pulling deps from copies\nkept on a server you run.</p></li>\n<li><p>Harder for noobs.</p>\n\n<p>I work with art students with very little command line experience. \nThey make art with Processing, arduino, Unity3D, and get by with very \nlittle tech knowledge. They wanted to use some HTML5/JavaScript I wrote. \nSteps because of bower</p>\n\n<ol>\n<li>Download Zip of repo from github  (notice that's on the right of every\nrepo on github. Because they don't know git)</li>\n<li>Download and install node (so we can run npm to install bower)</li>\n<li>Install git or msysgit (because bower requires it and it's not installed\non many students' machines)</li>\n<li>Install bower (<code>npm install -g bower</code>)</li>\n<li><code>bower install</code> (finally to get our dependencies)</li>\n</ol>\n\n<p>Steps 2-5 can all be deleted if we just check in the files to our github repo.\nThose steps likely sound super easy to you and me. To the students they were\nvery confusing and they wanted to know what all the steps where and what\nthey were for which <em>might</em> be good learning possibly but was entirely\northogonal to the class topic and so likely quickly forgotten. </p></li>\n<li><p>It adds another step when pulling.</p>\n\n<p>It's happened many times I do a <code>git pull origin master</code> and then test my\ncode and it takes 5 to 10 minutes to remember I needed to type <code>bower install</code>\nto get the latest deps. I'm sure that's easily solved with some pull script\nhook.</p></li>\n<li><p>It makes git branching harder</p>\n\n<p>If 2 branches have different deps you're kind of screwed. I suppose you can\ntype <code>bower install</code> after every <code>git checkout</code>. So much for speed.</p></li>\n</ol>\n\n<p>As for your positives I think there are counter examples to each of those</p>\n\n<blockquote>\n  <p>Eases the process of distributing and importing shared modules, especially version upgrades.</p>\n</blockquote>\n\n<p>vs what? It's certainly not easier to distribute. Pulling one repo instead of 20 is not easier and is more likely to fail. See #1 above</p>\n\n<blockquote>\n  <p>Removes shared modules from source control, speeding and simplifying checkouts/check ins (when you have applications with 20+ libraries this is a real factor).</p>\n</blockquote>\n\n<p>Conversely it means your dependent on others for fixes. Meaning if your deps are pulling from a 3rd party source and you need a bug fixed you have to wait for them to apply your patch. Worse, you probably can't just take the version you want plus your patch, you'd have to take the latest which might not be backward compatible with your project. </p>\n\n<p>You can solve that by cloning their repos separately and then you point your project deps to your copies. Then you apply any fixes to your copies. Of course you could also do that if you just copy the source into your repo</p>\n\n<blockquote>\n  <p>Allows more control or awareness of what third party libs are used in your organization.</p>\n</blockquote>\n\n<p>That seems arguable. Just require devs to put 3rd party libraries in their own folder under <code>&lt;ProjectRoot&gt;/3rdparty/&lt;nameOfDep&gt;</code>.  It's just as easy to see what 3rd party libs are used.</p>\n\n<p>I'm not saying there are no positives. The last team I was on had > 100 3rdparty deps. I'm just pointing out it's not all roses. I'm evaluating if I should get rid of bower for my needs for example.</p>\n"
    }
]